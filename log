diff -r -N code-worker/analysis.py code-worker/code-worker/analysis.py
0a1,13
> #!/usr/bin/env python
> # -*- coding: utf-8 -*-
> 
> import json
> 
> fName = "ccresult.json"
> textToWrite = "{'answer':42}"
> FILE = open(fName, "w")
> FILE.writelines(textToWrite)
> FILE.close()
> 
> print 'This is an output log from test.py'
> 
diff -r -N code-worker/ccresult.json code-worker/code-worker/ccresult.json
0a1
> {'answer':42}
diff -r -N code-worker/code-worker/analysis.py code-worker/code-worker/code-worker/analysis.py
1,13d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< 
< import json
< 
< fName = "ccresult.json"
< textToWrite = "{'answer':42}"
< FILE = open(fName, "w")
< FILE.writelines(textToWrite)
< FILE.close()
< 
< print 'This is an output log from test.py'
< 
diff -r -N code-worker/code-worker/ccresult.json code-worker/code-worker/code-worker/ccresult.json
1d0
< {'answer':42}
diff -r -N code-worker/code-worker/downloadRepoExec.py code-worker/code-worker/code-worker/downloadRepoExec.py
1,48d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< # Author: Karthik Muthuswamy
< # Downloads files from a repo. Param: argv[1]
< # Locates the file in the downloaded repo to execute: Param argv[2]
< 
< import sys,os
< from commands import getoutput as cmd
< 
< fileFound = False
< 
< # Reads the arguments from the command prompt
< # If there are 3 arguments then it contains the 
< # 	repository name and the file to be executed
< # Else it sets to default values
< args = sys.argv
< if len(args)==3:
< 	repoFolder = args[1]
< 	fExecute = args[2]
< else:
< 	repoFolder = 'downloadTestRepo'
< 	fExecute = 'hello.py'
< 
< # If the directory exists, update the folder with
< # the latest code from git
< if os.path.exists(repoFolder):
< 	os.chdir(repoFolder)
< 	print('Updating git repository to latest version: %s' % (repoFolder))
< 	os.system('git pull')
< else:
< 	print('Cloning git repository: %s' % (repoFolder))
< 	os.system('git clone git@github.com:karthikmswamy/' + repoFolder + '.git ' + repoFolder)
< 	os.chdir(repoFolder);
< 
< dirList = os.listdir('.')
< 
< for fName in dirList:
< 	if fName.lower().strip() == fExecute:
< 		fileFound = True
< 
< if fileFound == True:
< 	print('File ' + fExecute + ' found in ' + repoFolder + '. Executing with output...')
< 	try:
< 		os.system('python ' + fExecute)
< 	except OSError:
< 		pass
< else:
< 	print('No file named ' + fExecute + ' found in ' + repoFolder)
diff -r -N code-worker/code-worker/downloadRepoFromURL.py code-worker/code-worker/code-worker/downloadRepoFromURL.py
1,43d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< # Author: Karthik Muthuswamy
< # Downloads files from a repo retrieved from the URL
< # Locates the file in the downloaded repo by parsing the JSON
< 
< import urllib2, json, sys, os
< from commands import getoutput as cmd
< 
< 
< # Reads the data from the URL passed
< f = urllib2.urlopen('http://dl.dropbox.com/u/4972572/get_next_job')
< 
< # Decode the JSON string from URL
< jsonStr = json.load(f)
< f.close()
< 
< # Obtain the repository and command strings
< repos = jsonStr['repo'].strip()
< fExecute = jsonStr['command'].strip()
< 
< # Obtain the folder from the git URL
< sp = repos.partition('/')
< repoFolder = sp[2].replace('.git','')
< 
< # If the directory exists, update the folder with
< # the latest code from git
< # Else clone the repository
< if os.path.exists(repoFolder):
< 	os.chdir(repoFolder)
< 	print('Updating git repository to latest version: %s' % (repoFolder))
< 	os.system('git pull')
< else:
< 	print('Cloning git repository: %s' % (repoFolder))
< 	os.system('git clone ' + repos + ' ' + repoFolder)
< 	os.chdir(repoFolder);
< 
< # Execute the command retrieved from the JSON string
< print('Executing \"' + fExecute + '\" with output...')
< try:
< 	os.system('python ' + fExecute.replace('python ','').strip())
< except OSError:
< 	pass
diff -r -N code-worker/code-worker/.git/config code-worker/code-worker/code-worker/.git/config
1,11d0
< [core]
< 	repositoryformatversion = 0
< 	filemode = true
< 	bare = false
< 	logallrefupdates = true
< [remote "origin"]
< 	fetch = +refs/heads/*:refs/remotes/origin/*
< 	url = git@github.com:karthikmswamy/code-worker.git
< [branch "master"]
< 	remote = origin
< 	merge = refs/heads/master
diff -r -N code-worker/code-worker/.git/description code-worker/code-worker/code-worker/.git/description
1d0
< Unnamed repository; edit this file 'description' to name the repository.
diff -r -N code-worker/code-worker/.git/HEAD code-worker/code-worker/code-worker/.git/HEAD
1d0
< ref: refs/heads/master
diff -r -N code-worker/code-worker/.git/hooks/applypatch-msg.sample code-worker/code-worker/code-worker/.git/hooks/applypatch-msg.sample
1,15d0
< #!/bin/sh
< #
< # An example hook script to check the commit log message taken by
< # applypatch from an e-mail message.
< #
< # The hook should exit with non-zero status after issuing an
< # appropriate message if it wants to stop the commit.  The hook is
< # allowed to edit the commit message file.
< #
< # To enable this hook, rename this file to "applypatch-msg".
< 
< . git-sh-setup
< test -x "$GIT_DIR/hooks/commit-msg" &&
< 	exec "$GIT_DIR/hooks/commit-msg" ${1+"$@"}
< :
diff -r -N code-worker/code-worker/.git/hooks/commit-msg.sample code-worker/code-worker/code-worker/.git/hooks/commit-msg.sample
1,24d0
< #!/bin/sh
< #
< # An example hook script to check the commit log message.
< # Called by "git commit" with one argument, the name of the file
< # that has the commit message.  The hook should exit with non-zero
< # status after issuing an appropriate message if it wants to stop the
< # commit.  The hook is allowed to edit the commit message file.
< #
< # To enable this hook, rename this file to "commit-msg".
< 
< # Uncomment the below to add a Signed-off-by line to the message.
< # Doing this in a hook is a bad idea in general, but the prepare-commit-msg
< # hook is more suited to it.
< #
< # SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
< # grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"
< 
< # This example catches duplicate Signed-off-by lines.
< 
< test "" = "$(grep '^Signed-off-by: ' "$1" |
< 	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
< 	echo >&2 Duplicate Signed-off-by lines.
< 	exit 1
< }
diff -r -N code-worker/code-worker/.git/hooks/post-commit.sample code-worker/code-worker/code-worker/.git/hooks/post-commit.sample
1,8d0
< #!/bin/sh
< #
< # An example hook script that is called after a successful
< # commit is made.
< #
< # To enable this hook, rename this file to "post-commit".
< 
< : Nothing
diff -r -N code-worker/code-worker/.git/hooks/post-receive.sample code-worker/code-worker/code-worker/.git/hooks/post-receive.sample
1,15d0
< #!/bin/sh
< #
< # An example hook script for the "post-receive" event.
< #
< # The "post-receive" script is run after receive-pack has accepted a pack
< # and the repository has been updated.  It is passed arguments in through
< # stdin in the form
< #  <oldrev> <newrev> <refname>
< # For example:
< #  aa453216d1b3e49e7f6f98441fa56946ddcd6a20 68f7abf4e6f922807889f52bc043ecd31b79f814 refs/heads/master
< #
< # see contrib/hooks/ for a sample, or uncomment the next line and
< # rename the file to "post-receive".
< 
< #. /usr/share/doc/git-core/contrib/hooks/post-receive-email
diff -r -N code-worker/code-worker/.git/hooks/post-update.sample code-worker/code-worker/code-worker/.git/hooks/post-update.sample
1,8d0
< #!/bin/sh
< #
< # An example hook script to prepare a packed repository for use over
< # dumb transports.
< #
< # To enable this hook, rename this file to "post-update".
< 
< exec git update-server-info
diff -r -N code-worker/code-worker/.git/hooks/pre-applypatch.sample code-worker/code-worker/code-worker/.git/hooks/pre-applypatch.sample
1,14d0
< #!/bin/sh
< #
< # An example hook script to verify what is about to be committed
< # by applypatch from an e-mail message.
< #
< # The hook should exit with non-zero status after issuing an
< # appropriate message if it wants to stop the commit.
< #
< # To enable this hook, rename this file to "pre-applypatch".
< 
< . git-sh-setup
< test -x "$GIT_DIR/hooks/pre-commit" &&
< 	exec "$GIT_DIR/hooks/pre-commit" ${1+"$@"}
< :
diff -r -N code-worker/code-worker/.git/hooks/pre-commit.sample code-worker/code-worker/code-worker/.git/hooks/pre-commit.sample
1,46d0
< #!/bin/sh
< #
< # An example hook script to verify what is about to be committed.
< # Called by "git commit" with no arguments.  The hook should
< # exit with non-zero status after issuing an appropriate message if
< # it wants to stop the commit.
< #
< # To enable this hook, rename this file to "pre-commit".
< 
< if git rev-parse --verify HEAD >/dev/null 2>&1
< then
< 	against=HEAD
< else
< 	# Initial commit: diff against an empty tree object
< 	against=4b825dc642cb6eb9a060e54bf8d69288fbee4904
< fi
< 
< # If you want to allow non-ascii filenames set this variable to true.
< allownonascii=$(git config hooks.allownonascii)
< 
< # Cross platform projects tend to avoid non-ascii filenames; prevent
< # them from being added to the repository. We exploit the fact that the
< # printable range starts at the space character and ends with tilde.
< if [ "$allownonascii" != "true" ] &&
< 	# Note that the use of brackets around a tr range is ok here, (it's
< 	# even required, for portability to Solaris 10's /usr/bin/tr), since
< 	# the square bracket bytes happen to fall in the designated range.
< 	test "$(git diff --cached --name-only --diff-filter=A -z $against |
< 	  LC_ALL=C tr -d '[ -~]\0')"
< then
< 	echo "Error: Attempt to add a non-ascii file name."
< 	echo
< 	echo "This can cause problems if you want to work"
< 	echo "with people on other platforms."
< 	echo
< 	echo "To be portable it is advisable to rename the file ..."
< 	echo
< 	echo "If you know what you are doing you can disable this"
< 	echo "check using:"
< 	echo
< 	echo "  git config hooks.allownonascii true"
< 	echo
< 	exit 1
< fi
< 
< exec git diff-index --check --cached $against --
diff -r -N code-worker/code-worker/.git/hooks/prepare-commit-msg.sample code-worker/code-worker/code-worker/.git/hooks/prepare-commit-msg.sample
1,36d0
< #!/bin/sh
< #
< # An example hook script to prepare the commit log message.
< # Called by "git commit" with the name of the file that has the
< # commit message, followed by the description of the commit
< # message's source.  The hook's purpose is to edit the commit
< # message file.  If the hook fails with a non-zero status,
< # the commit is aborted.
< #
< # To enable this hook, rename this file to "prepare-commit-msg".
< 
< # This hook includes three examples.  The first comments out the
< # "Conflicts:" part of a merge commit.
< #
< # The second includes the output of "git diff --name-status -r"
< # into the message, just before the "git status" output.  It is
< # commented because it doesn't cope with --amend or with squashed
< # commits.
< #
< # The third example adds a Signed-off-by line to the message, that can
< # still be edited.  This is rarely a good idea.
< 
< case "$2,$3" in
<   merge,)
<     /usr/bin/perl -i.bak -ne 's/^/# /, s/^# #/#/ if /^Conflicts/ .. /#/; print' "$1" ;;
< 
< # ,|template,)
< #   /usr/bin/perl -i.bak -pe '
< #      print "\n" . `git diff --cached --name-status -r`
< #	 if /^#/ && $first++ == 0' "$1" ;;
< 
<   *) ;;
< esac
< 
< # SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
< # grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"
diff -r -N code-worker/code-worker/.git/hooks/pre-rebase.sample code-worker/code-worker/code-worker/.git/hooks/pre-rebase.sample
1,172d0
< #!/bin/sh
< #
< # Copyright (c) 2006, 2008 Junio C Hamano
< #
< # The "pre-rebase" hook is run just before "git rebase" starts doing
< # its job, and can prevent the command from running by exiting with
< # non-zero status.
< #
< # The hook is called with the following parameters:
< #
< # $1 -- the upstream the series was forked from.
< # $2 -- the branch being rebased (or empty when rebasing the current branch).
< #
< # This sample shows how to prevent topic branches that are already
< # merged to 'next' branch from getting rebased, because allowing it
< # would result in rebasing already published history.
< 
< publish=next
< basebranch="$1"
< if test "$#" = 2
< then
< 	topic="refs/heads/$2"
< else
< 	topic=`git symbolic-ref HEAD` ||
< 	exit 0 ;# we do not interrupt rebasing detached HEAD
< fi
< 
< case "$topic" in
< refs/heads/??/*)
< 	;;
< *)
< 	exit 0 ;# we do not interrupt others.
< 	;;
< esac
< 
< # Now we are dealing with a topic branch being rebased
< # on top of master.  Is it OK to rebase it?
< 
< # Does the topic really exist?
< git show-ref -q "$topic" || {
< 	echo >&2 "No such branch $topic"
< 	exit 1
< }
< 
< # Is topic fully merged to master?
< not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
< if test -z "$not_in_master"
< then
< 	echo >&2 "$topic is fully merged to master; better remove it."
< 	exit 1 ;# we could allow it, but there is no point.
< fi
< 
< # Is topic ever merged to next?  If so you should not be rebasing it.
< only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
< only_next_2=`git rev-list ^master           ${publish} | sort`
< if test "$only_next_1" = "$only_next_2"
< then
< 	not_in_topic=`git rev-list "^$topic" master`
< 	if test -z "$not_in_topic"
< 	then
< 		echo >&2 "$topic is already up-to-date with master"
< 		exit 1 ;# we could allow it, but there is no point.
< 	else
< 		exit 0
< 	fi
< else
< 	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
< 	/usr/bin/perl -e '
< 		my $topic = $ARGV[0];
< 		my $msg = "* $topic has commits already merged to public branch:\n";
< 		my (%not_in_next) = map {
< 			/^([0-9a-f]+) /;
< 			($1 => 1);
< 		} split(/\n/, $ARGV[1]);
< 		for my $elem (map {
< 				/^([0-9a-f]+) (.*)$/;
< 				[$1 => $2];
< 			} split(/\n/, $ARGV[2])) {
< 			if (!exists $not_in_next{$elem->[0]}) {
< 				if ($msg) {
< 					print STDERR $msg;
< 					undef $msg;
< 				}
< 				print STDERR " $elem->[1]\n";
< 			}
< 		}
< 	' "$topic" "$not_in_next" "$not_in_master"
< 	exit 1
< fi
< 
< exit 0
< 
< <<\DOC_END
< ################################################################
< 
< This sample hook safeguards topic branches that have been
< published from being rewound.
< 
< The workflow assumed here is:
< 
<  * Once a topic branch forks from "master", "master" is never
<    merged into it again (either directly or indirectly).
< 
<  * Once a topic branch is fully cooked and merged into "master",
<    it is deleted.  If you need to build on top of it to correct
<    earlier mistakes, a new topic branch is created by forking at
<    the tip of the "master".  This is not strictly necessary, but
<    it makes it easier to keep your history simple.
< 
<  * Whenever you need to test or publish your changes to topic
<    branches, merge them into "next" branch.
< 
< The script, being an example, hardcodes the publish branch name
< to be "next", but it is trivial to make it configurable via
< $GIT_DIR/config mechanism.
< 
< With this workflow, you would want to know:
< 
< (1) ... if a topic branch has ever been merged to "next".  Young
<     topic branches can have stupid mistakes you would rather
<     clean up before publishing, and things that have not been
<     merged into other branches can be easily rebased without
<     affecting other people.  But once it is published, you would
<     not want to rewind it.
< 
< (2) ... if a topic branch has been fully merged to "master".
<     Then you can delete it.  More importantly, you should not
<     build on top of it -- other people may already want to
<     change things related to the topic as patches against your
<     "master", so if you need further changes, it is better to
<     fork the topic (perhaps with the same name) afresh from the
<     tip of "master".
< 
< Let's look at this example:
< 
< 		   o---o---o---o---o---o---o---o---o---o "next"
< 		  /       /           /           /
< 		 /   a---a---b A     /           /
< 		/   /               /           /
< 	       /   /   c---c---c---c B         /
< 	      /   /   /             \         /
< 	     /   /   /   b---b C     \       /
< 	    /   /   /   /             \     /
<     ---o---o---o---o---o---o---o---o---o---o---o "master"
< 
< 
< A, B and C are topic branches.
< 
<  * A has one fix since it was merged up to "next".
< 
<  * B has finished.  It has been fully merged up to "master" and "next",
<    and is ready to be deleted.
< 
<  * C has not merged to "next" at all.
< 
< We would want to allow C to be rebased, refuse A, and encourage
< B to be deleted.
< 
< To compute (1):
< 
< 	git rev-list ^master ^topic next
< 	git rev-list ^master        next
< 
< 	if these match, topic has not merged in next at all.
< 
< To compute (2):
< 
< 	git rev-list master..topic
< 
< 	if this is empty, it is fully merged to "master".
< 
< DOC_END
diff -r -N code-worker/code-worker/.git/hooks/update.sample code-worker/code-worker/code-worker/.git/hooks/update.sample
1,128d0
< #!/bin/sh
< #
< # An example hook script to blocks unannotated tags from entering.
< # Called by "git receive-pack" with arguments: refname sha1-old sha1-new
< #
< # To enable this hook, rename this file to "update".
< #
< # Config
< # ------
< # hooks.allowunannotated
< #   This boolean sets whether unannotated tags will be allowed into the
< #   repository.  By default they won't be.
< # hooks.allowdeletetag
< #   This boolean sets whether deleting tags will be allowed in the
< #   repository.  By default they won't be.
< # hooks.allowmodifytag
< #   This boolean sets whether a tag may be modified after creation. By default
< #   it won't be.
< # hooks.allowdeletebranch
< #   This boolean sets whether deleting branches will be allowed in the
< #   repository.  By default they won't be.
< # hooks.denycreatebranch
< #   This boolean sets whether remotely creating branches will be denied
< #   in the repository.  By default this is allowed.
< #
< 
< # --- Command line
< refname="$1"
< oldrev="$2"
< newrev="$3"
< 
< # --- Safety check
< if [ -z "$GIT_DIR" ]; then
< 	echo "Don't run this script from the command line." >&2
< 	echo " (if you want, you could supply GIT_DIR then run" >&2
< 	echo "  $0 <ref> <oldrev> <newrev>)" >&2
< 	exit 1
< fi
< 
< if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
< 	echo "Usage: $0 <ref> <oldrev> <newrev>" >&2
< 	exit 1
< fi
< 
< # --- Config
< allowunannotated=$(git config --bool hooks.allowunannotated)
< allowdeletebranch=$(git config --bool hooks.allowdeletebranch)
< denycreatebranch=$(git config --bool hooks.denycreatebranch)
< allowdeletetag=$(git config --bool hooks.allowdeletetag)
< allowmodifytag=$(git config --bool hooks.allowmodifytag)
< 
< # check for no description
< projectdesc=$(sed -e '1q' "$GIT_DIR/description")
< case "$projectdesc" in
< "Unnamed repository"* | "")
< 	echo "*** Project description file hasn't been set" >&2
< 	exit 1
< 	;;
< esac
< 
< # --- Check types
< # if $newrev is 0000...0000, it's a commit to delete a ref.
< zero="0000000000000000000000000000000000000000"
< if [ "$newrev" = "$zero" ]; then
< 	newrev_type=delete
< else
< 	newrev_type=$(git cat-file -t $newrev)
< fi
< 
< case "$refname","$newrev_type" in
< 	refs/tags/*,commit)
< 		# un-annotated tag
< 		short_refname=${refname##refs/tags/}
< 		if [ "$allowunannotated" != "true" ]; then
< 			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
< 			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
< 			exit 1
< 		fi
< 		;;
< 	refs/tags/*,delete)
< 		# delete tag
< 		if [ "$allowdeletetag" != "true" ]; then
< 			echo "*** Deleting a tag is not allowed in this repository" >&2
< 			exit 1
< 		fi
< 		;;
< 	refs/tags/*,tag)
< 		# annotated tag
< 		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
< 		then
< 			echo "*** Tag '$refname' already exists." >&2
< 			echo "*** Modifying a tag is not allowed in this repository." >&2
< 			exit 1
< 		fi
< 		;;
< 	refs/heads/*,commit)
< 		# branch
< 		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
< 			echo "*** Creating a branch is not allowed in this repository" >&2
< 			exit 1
< 		fi
< 		;;
< 	refs/heads/*,delete)
< 		# delete branch
< 		if [ "$allowdeletebranch" != "true" ]; then
< 			echo "*** Deleting a branch is not allowed in this repository" >&2
< 			exit 1
< 		fi
< 		;;
< 	refs/remotes/*,commit)
< 		# tracking branch
< 		;;
< 	refs/remotes/*,delete)
< 		# delete tracking branch
< 		if [ "$allowdeletebranch" != "true" ]; then
< 			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
< 			exit 1
< 		fi
< 		;;
< 	*)
< 		# Anything else (is there anything else?)
< 		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
< 		exit 1
< 		;;
< esac
< 
< # --- Finished
< exit 0
Binary files code-worker/code-worker/.git/index and code-worker/code-worker/code-worker/.git/index differ
diff -r -N code-worker/code-worker/.git/info/exclude code-worker/code-worker/code-worker/.git/info/exclude
1,6d0
< # git ls-files --others --exclude-from=.git/info/exclude
< # Lines that start with '#' are comments.
< # For a project mostly in C, the following would be a good set of
< # exclude patterns (uncomment them if you want to use them):
< # *.[oa]
< # *~
diff -r -N code-worker/code-worker/.git/logs/HEAD code-worker/code-worker/code-worker/.git/logs/HEAD
1d0
< 0000000000000000000000000000000000000000 de0893c87b9770812d5eb18062ac2c3a156bdba0 Karthik Muthuswamy <muthuswamy.karthik@gmail.com> 1310094131 +0800	clone: from git@github.com:karthikmswamy/code-worker.git
diff -r -N code-worker/code-worker/.git/logs/refs/heads/master code-worker/code-worker/code-worker/.git/logs/refs/heads/master
1d0
< 0000000000000000000000000000000000000000 de0893c87b9770812d5eb18062ac2c3a156bdba0 Karthik Muthuswamy <muthuswamy.karthik@gmail.com> 1310094131 +0800	clone: from git@github.com:karthikmswamy/code-worker.git
Binary files code-worker/code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.idx and code-worker/code-worker/code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.idx differ
Binary files code-worker/code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.pack and code-worker/code-worker/code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.pack differ
diff -r -N code-worker/code-worker/.git/packed-refs code-worker/code-worker/code-worker/.git/packed-refs
1,2d0
< # pack-refs with: peeled 
< de0893c87b9770812d5eb18062ac2c3a156bdba0 refs/remotes/origin/master
diff -r -N code-worker/code-worker/.git/refs/heads/master code-worker/code-worker/code-worker/.git/refs/heads/master
1d0
< de0893c87b9770812d5eb18062ac2c3a156bdba0
diff -r -N code-worker/code-worker/.git/refs/remotes/origin/HEAD code-worker/code-worker/code-worker/.git/refs/remotes/origin/HEAD
1d0
< ref: refs/remotes/origin/master
diff -r -N code-worker/code-worker/log.txt code-worker/code-worker/code-worker/log.txt
1d0
< This is an output log from test.py
diff -r -N code-worker/code-worker/readme.rtf code-worker/code-worker/code-worker/readme.rtf
1,8d0
< {\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf350
< {\fonttbl\f0\fswiss\fcharset0 Helvetica;}
< {\colortbl;\red255\green255\blue255;}
< \paperw11900\paperh16840\margl1440\margr1440\vieww9000\viewh8400\viewkind0
< \pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
< 
< \f0\fs24 \cf0 Readme file for code-worker project.\
< }
\ No newline at end of file
diff -r -N code-worker/code-worker/worker.py code-worker/code-worker/code-worker/worker.py
1,119d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< # Author: Karthik Muthuswamy
< # Reads jobs and models from the given URL
< # Clones a repo retrieved from data retrieved from the URL
< # Executes a file and logs the result from the downloaded repo
< 
< import urllib2, json, os
< from commands import getoutput as cmd
< 
< baseURL = 'http://code-comparison.appspot.com/rest/'
< 
< # The main worker thread that fetches a job
< def mainWorker():
< 	URL = baseURL + 'metadata'
< 	f = urllib2.urlopen(URL)
< 
< 	jsonStr = json.load(f)
< 	for i in range(0, len(jsonStr['type'])):
< 		fetchJobFromURL(jsonStr['type'][i])
< 	f.close()
< 
< # Fetches a job from a given URL
< # Params: job - the type of the job as string, to be retrieved
< def fetchJobFromURL(job):
< 	print 'Processing job: ' + job
< 	# Concatenate with the base URL
< 	URL = baseURL + job + '?feq_jobType=TEST&fne_status=PROCESSED'
< 	# For testing: remove itr otherwise
< 	# Will be replaced with while True or any other break condition
< 	itr = 10
< 	for i in range(0,10):
< 		f = urllib2.urlopen(URL)
< 		req = f.read()
< 
< 		jobStr = json.loads(req)
< 		numJobs = len(jobStr)
< 		print 'There are ' + str(numJobs) + ' TEST jobs pending'
< 		# There are no jobs pending, hence sleep and check again
< 		if numJobs == 0:
< 			# Checks to see if there are jobs available every 2^iteration
< 			# Once time reaches 64, it checks constantly every minute
< 			sleepTime = math.pow(i,2)
< 			if sleepTime < 64:
< 				time.sleep(sleepTime)
< 				continue
< 			else:
< 				time.sleep(60)
< 				continue
< 
< 		for i in range(0, numJobs):
< 			fetchURL = baseURL + job + '/' + jobStr[i]['key']
< 			fetchModelFromURL(fetchURL)
< 
< # Fetches a job from a given URL using the key
< # Params: URL - the URL as string, of the job to be retrieved
< def fetchModelFromURL(URL):
< 	data = json.dumps({'status':'PROCESSED'})
< 	print 'Processing model from : ' + URL
< 	u = urllib2.urlopen(URL)
< 	req = u.read()
< 
< 	modelStr = json.loads(req)
< 	# Obtain the repository and command strings
< 
< 	tarRepos = modelStr['target'].strip()
< 	masRepos = modelStr['master'].strip()
< 	fExecute = modelStr['command'].replace('python ','').strip()
< 
< 	# Obtain the folder from the git URL
< 	sp = tarRepos.partition('/')
< 	tarRepoFolder = sp[2].replace('.git','')
< 	sp = masRepos.partition('/')
< 	masRepoFolder = sp[2].replace('.git','')
< 
< 	gitCloneUpdateRepo(masRepos, masRepoFolder, fExecute)
< 	gitCloneUpdateRepo(tarRepos, tarRepoFolder, fExecute)
< 
< 
< def gitCloneUpdateRepo(repoFolder, folderName, fExecute):
< 	# If the directory exists, update the folder with
< 	# the latest code from git
< 	# Else clone the repository
< 	if os.path.exists(folderName):
< 		os.chdir(folderName)
< 		print('Updating git repository to latest version: %s' % (folderName))
< 		os.system('git pull')
< 	else:
< 		print('Cloning git repository: %s' % (folderName))
< 		os.system('git clone ' + repoFolder + ' ' + folderName)
< 		os.chdir(folderName);
< 		# Execute the command retrieved from the JSON string
< 	print('Executing \"' + fExecute + '\" with output...')
< 
< 	try:
< 		if os.path.isfile(fExecute):
< 			os.system('python ' + fExecute + ' > log.txt')
< 			if os.path.isfile('ccresult.json'):
< 				f = open('ccresult.json','r')
< 				fContents = f.read()
< 				if checkForJSONValidity(fContents):
< 					print 'JSON Validity Approved'
< 				else:
< 					print 'JSON Validity Not Approved'
< 	except OSError:
< 		pass
< 
< 	os.chdir('..')
< 
< # Tests the JSON validity 
< # Params: jsonContent - the data as string, which is tested for validity
< def checkForJSONValidity(jsonContent):
< 	try:
< 		json.loads(jsonContent)
< 		return True
< 	except ValueError:
< 		return False
< 
< mainWorker()
diff -r -N code-worker/downloadRepoFromURL.py code-worker/code-worker/downloadRepoFromURL.py
11,21c11,12
< # Reads the arguments from the command prompt
< # If there are 3 arguments then it contains the 
< # 	repository name and the file to be executed
< args = sys.argv
< if len(args)==3:
< 	repoFolder = args[1]
< 	fExecute = args[2]
< 	repos = 'git@github.com:karthikmswamy/' + repoFolder + '.git'
< 	print repos
< else:
< 	f = urllib2.urlopen('http://dl.dropbox.com/u/4972572/get_next_job')
---
> # Reads the data from the URL passed
> f = urllib2.urlopen('http://dl.dropbox.com/u/4972572/get_next_job')
23,25c14,16
< 	# Decode the JSON string from URL
< 	jsonStr = json.load(f)
< 	f.close()
---
> # Decode the JSON string from URL
> jsonStr = json.load(f)
> f.close()
27,29c18,20
< 	# Obtain the repository and command strings
< 	repos = jsonStr['repo'].strip()
< 	fExecute = jsonStr['command'].strip()
---
> # Obtain the repository and command strings
> repos = jsonStr['repo'].strip()
> fExecute = jsonStr['command'].strip()
31,33c22,24
< 	# Obtain the folder from the git URL
< 	sp = repos.partition('/')
< 	repoFolder = sp[2].replace('.git','')
---
> # Obtain the folder from the git URL
> sp = repos.partition('/')
> repoFolder = sp[2].replace('.git','')
Binary files code-worker/.DS_Store and code-worker/code-worker/.DS_Store differ
diff -r -N code-worker/.git/config code-worker/code-worker/.git/config
8c8
< 	url = git@github.com:SMU-SIS/code-worker.git
---
> 	url = git@github.com:karthikmswamy/code-worker.git
Binary files code-worker/.git/index and code-worker/code-worker/.git/index differ
diff -r -N code-worker/.git/logs/HEAD code-worker/code-worker/.git/logs/HEAD
1c1
< 0000000000000000000000000000000000000000 dfdb0f77dbfdb2eba8cdf02717cfb36b5e25a736 Karthik Muthuswamy <muthuswamy.karthik@gmail.com> 1310046497 +0800	clone: from git@github.com:SMU-SIS/code-worker.git
---
> 0000000000000000000000000000000000000000 de0893c87b9770812d5eb18062ac2c3a156bdba0 Karthik Muthuswamy <muthuswamy.karthik@gmail.com> 1310094131 +0800	clone: from git@github.com:karthikmswamy/code-worker.git
diff -r -N code-worker/.git/logs/refs/heads/master code-worker/code-worker/.git/logs/refs/heads/master
1c1
< 0000000000000000000000000000000000000000 dfdb0f77dbfdb2eba8cdf02717cfb36b5e25a736 Karthik Muthuswamy <muthuswamy.karthik@gmail.com> 1310046497 +0800	clone: from git@github.com:SMU-SIS/code-worker.git
---
> 0000000000000000000000000000000000000000 de0893c87b9770812d5eb18062ac2c3a156bdba0 Karthik Muthuswamy <muthuswamy.karthik@gmail.com> 1310094131 +0800	clone: from git@github.com:karthikmswamy/code-worker.git
Binary files code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.idx and code-worker/code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.idx differ
Binary files code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.pack and code-worker/code-worker/.git/objects/pack/pack-5b8edc72cf7f99f95d21201e11d6c0a3aaa95e47.pack differ
Binary files code-worker/.git/objects/pack/pack-d82f6915c4ef1e2474023f12c3c4147b16bda897.idx and code-worker/code-worker/.git/objects/pack/pack-d82f6915c4ef1e2474023f12c3c4147b16bda897.idx differ
Binary files code-worker/.git/objects/pack/pack-d82f6915c4ef1e2474023f12c3c4147b16bda897.pack and code-worker/code-worker/.git/objects/pack/pack-d82f6915c4ef1e2474023f12c3c4147b16bda897.pack differ
diff -r -N code-worker/.git/packed-refs code-worker/code-worker/.git/packed-refs
2c2
< dfdb0f77dbfdb2eba8cdf02717cfb36b5e25a736 refs/remotes/origin/master
---
> de0893c87b9770812d5eb18062ac2c3a156bdba0 refs/remotes/origin/master
diff -r -N code-worker/.git/refs/heads/master code-worker/code-worker/.git/refs/heads/master
1c1
< dfdb0f77dbfdb2eba8cdf02717cfb36b5e25a736
---
> de0893c87b9770812d5eb18062ac2c3a156bdba0
diff -r -N code-worker/.gitignore code-worker/code-worker/.gitignore
1d0
< *.pyc
\ No newline at end of file
diff -r -N code-worker/log.txt code-worker/code-worker/log.txt
0a1
> This is an output log from test.py
diff -r -N code-worker/tasks/clonedigger/abstract_syntax_tree.py code-worker/code-worker/tasks/clonedigger/abstract_syntax_tree.py
1,307d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import types
< 
< import arguments
< 
< free_variable_cost = 0.5
< 
< class ParseError:    
<     def __init__(self, descr):
<         self._descr = descr
<     def __str__(self):
<         return self._descr
< 
< class SourceFile:        
<     size_threshold = 5
<     distance_threshold = 5
<     def __init__(self, file_name):      
<         f = open(file_name, 'r')
<         def filter_func(s):
<             for i in range(len(s)-1, -2, -1):
<                 if i<0 or not s[i].isspace():
<                     break
<             if i>=0:
<                 return s[:i+1]
<             else:
<                 return s
<         self._source_lines = [filter_func(s) for s in f.readlines()]
<         f.close()
<         self._file_name = file_name
<     def getSourceLine(self, n):
< #       if n >= len(self._source_lines):
< #           return ''
< #TODO
< #error here
<         return self._source_lines[n] 
<     def _setTree(self, tree):
<         self._tree = tree
<     def getTree(self):
<         return self._tree
<     def getFileName(self):
<         return self._file_name
< 
< class AbstractSyntaxTree:
<     def __init__(self, name=None, line_numbers=[], source_file=None):
<         self._childs = []
<         self._line_numbers= line_numbers
<         self._covered_line_numbers = None
<         self._parent = None
<         self._hash = None
<         self._source_file = source_file
<         self._is_statement = False
<         if name != None:
<             self.setName(name)
<     def getSourceFile(self):
<         return self._source_file
<     def setMark(self, mark):
<         self._mark = mark 
<     def getMark(self):
<         return self._mark
<     def markAsStatement(self, val=True):
<         self._is_statement = val
<     def isStatement(self):
<         return self._is_statement
<     def setName(self, name):
<         self._name = name
<     def getLineNumbers(self):
<         return self._line_numbers   
<     def getCoveredLineNumbers(self):
<         return self._covered_line_numbers
<     def getParent(self):
<         return self._parent
<     def setParent(self, parent):
<         self._parent = parent
<     def getAncestors(self):
<         r = []
<         t = self.getParent()    
<         while t:
<             if t.isStatement():
<                 r.append(t)
<             t = t.getParent()
<         return r
<     def getSourceLines(self):
<         source_line_numbers = set([])
<         r = []  
<         source_line_numbers = self.getCoveredLineNumbers()
<         source_line_numbers_list = list(range(min(source_line_numbers), max(source_line_numbers)+1))
<         source_line_numbers_list.sort()
<         for source_line_number in source_line_numbers_list:
<             r.append(self.getSourceFile().getSourceLine(source_line_number) ) 
<         return r
<     def getName(self):
<         return self._name
<     def getChilds(self):
<         return self._childs
<     def getChildCount(self):
<         return len(self._childs)
<     def propagateCoveredLineNumbers(self):
<         self._covered_line_numbers = set(self._line_numbers)
<         for child in self.getChilds():
<             self._covered_line_numbers.update(child.propagateCoveredLineNumbers())
<         return self._covered_line_numbers
<     def propagateHeight(self):
<         if self.getChildCount()==0:
<             self._height = 0
<         else:
<             self._height = max([c.propagateHeight() for c in self.getChilds()])+1
<         return self._height
<     def getHeight(self):
<         return self._height
<     def addChild(self, child, save_parent = False):
<         if not save_parent:
<             child.setParent(self)
<         self._childs.append(child)
<     def setChildCount(self, count):
<         assert(not self._childs)
<         self._childs = count * [None]
<     def setNextUndefinedChild(self, c):
<         for i in range(len(self.getChilds())):
<             if self.getChilds()[i] == None:
<                 self._childs[i] = c
<         assert()
<     def __str__(self):
<         return ' ( ' + self.getName() + ' '.join([str(child) for child in self.getChilds()]) + ' ) '
<     def getFullHash(self):
<         return self.getDCupHash(-1) 
<     def getDCupHash(self, level):
<         if len(self._childs) == 0:
<             ret = 0 # in case of names and constants
<         else:
<             ret = (level+1) * hash(self._name) * len(self._childs)
<         # if level == -1, it will not stop until it reaches the leaves 
<         if level != 0:
<             for i in range(len(self._childs)):
<                 child = self._childs[i]
<                 ret += (i+1)*child.getDCupHash(level-1)
<         return hash(ret)
<     def __hash__(self):
<         #TODO check correctness
<         if not self._hash:
<             self._hash =  hash(self.getDCupHash(3) + hash(self.getName()))
<         return self._hash
< #       return  hash(self.getDCupHash(3) + hash(self.getName()))
<  
<     def __eq__(self, tree2):
<         tree1 = self
<         if type(tree2) == types.NoneType:
<             return False
<         if tree1.getName() != tree2.getName():
<             return False
<         if tree1.getChildCount() != tree2.getChildCount():
<             return False
<         for i in range(tree1.getChildCount()):
<             if tree1.getChilds()[i] != tree2.getChilds()[i]:
<                 return False
<         return True
<     def getAllStatementSequences(self):
<         r = []
<         current = StatementSequence()
<         for child in self.getChilds():
<             if child.isStatement():
<                 current.addStatement(child)
<             else:
<                 if (not current.isEmpty()) and len(current.getCoveredLineNumbers())>=arguments.size_threshold:
<                     r.append(current)
<                     current = StatementSequence() 
<             r.extend(child.getAllStatementSequences())
<         if (not current.isEmpty()) and len(current.getCoveredLineNumbers())>=arguments.size_threshold:
<             r.append(current)
<         return r
<     def storeSize(self):
<         observed = set()
<         self._none_count = 0
<         def rec_calc_size(t):
<             r = 0
<             if not t in observed:
<                 if t.getChildCount():
<                     for c in t.getChilds():
<                         r += rec_calc_size(c)
<                 else:
<                     observed.add(t)
<                     if t.getName()=='None':
<                         self._none_count += 1
<                     if t.__class__.__name__ == 'FreeVariable':
<                         r+= free_variable_cost
<                     else:
<                         r+= 1
<             return r
<         if not hasattr(self, '_size'):
<             self._size = rec_calc_size(self)
<     def getSize(self, ignore_none = True):
<         ret = self._size
<         if ignore_none:
<             ret -= self._none_count
<         return ret    
<     def getTokenCount(self):
<         def rec_calc_size(t):
< 	    if t.getChildCount():
< 		if t.getName() in ['Add', 'Assign', 'Sub', 'Div', 'Mul', 'Mod', 'Function', 'If', 'Class', 'Raise']:
< 	            r = 1
< 		else:
< 	            r = 0
< 		for c in t.getChilds():
< 	            r += rec_calc_size(c)
< 	    else:
< 	        if t.getName()[0] != "'" and t.getName() != 'Pass':
< 		   return 0
< 		else:
< 		   return 1
<             return r
<         return rec_calc_size(self)
< 
< class StatementSequence:
<     def __init__(self, sequence = []):
<         self._sequence = []
<         self._source_file = None
<         for s in sequence:
<             self.addStatement(s)
<     def getCoveredLineNumbers(self):
<         r = set()
<         for s in self:
<             r.update(s.getCoveredLineNumbers())
<         return r
<     def getAncestors(self):
<         return self[0].getAncestors()
<     def isEmpty(self):
<         return (self._sequence == [])
<     def addStatement(self, statement):
<         self._sequence.append(statement)
<         if self._source_file == None:
<             self._source_file = statement.getSourceFile()
<         else:
<             assert(self._source_file == statement.getSourceFile())
<     def __getitem__(self, *args):
<         return self._sequence.__getitem__(*args)
<     def __len__(self):
<         return self._sequence.__len__()
<     def __str__(self):
<         return ','.join([str(s) for s in self])
<     def getWeight(self):
<         return sum([s.getCluster().getUnifierSize() for s in self._sequence])
<     def getSourceFile(self):
<         return self._source_file
<     def getSourceLines(self):
<         source_line_numbers = set([])
<         r = []
<         for statement in self:
<             r.extend(statement.getSourceLines())
<         return r
<     def getLineNumbers(self):
<         r = []
<         for statement in self:
<             r.extend(statement.getLineNumbers())
<         return r
<     def getLineNumberHashables(self):   
<         source_file_name = self.getSourceFile().getFileName()
<         line_numbers = self.getCoveredLineNumbers()
<         return set([(source_file_name, line_number) for line_number in line_numbers])
<     def constructTree(self):
<         tree = AbstractSyntaxTree('__SEQUENCE__')
<         for statement in self:
<             tree.addChild(statement, True)
<         return tree    
<     def getLength(self):
<         return len(self)
<     def getCoveredLineNumbersCount(self):
<         covered = set()
<         for t in self:
<             covered.update(t.getCoveredLineNumbers())
<         return len(covered)
< 
< class PairSequences:
<     def __init__(self, sequences):
<         self._sequences = sequences
<     def __getitem__(self, *args):
<         return self._sequences.__getitem__(*args)
<     def __str__(self):
<         return ';\t'.join([str(s) for s in self])
<     def getWeight(self):
<         assert(self[0].getWeight() == self[1].getWeight())
<         return self[0].getWeight()
<     def calcDistance(self):
<         import anti_unification
<         trees = [s.constructTree() for s in self]
<         unifier = anti_unification.Unifier(trees[0], trees[1])
<         return unifier.getSize()
<     def subSequence(self, first, length):
<         return PairSequences([StatementSequence(self[0][first:first+length]), StatementSequence(self[1][first:first+length])])
<     def getLength(self):
<         return self[0].getLength()
<     def getMaxCoveredLineNumbersCount(self):
<         return min([s.getCoveredLineNumbersCount() for s in self])
diff -r -N code-worker/tasks/clonedigger/anti_unification.py code-worker/code-worker/tasks/clonedigger/anti_unification.py
1,150d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import copy
< import sys
< 
< from abstract_syntax_tree import *
< import suffix_tree
< import arguments
< 
< # NOTE that everywhere is written Unifier instead of AntiUnifier, for simplicity
< 
< # Constants here
< verbose = True 
< 
< class FreeVariable(AbstractSyntaxTree):
<     free_variables_count = 1
<     def __init__(self):
<         global free_variables_count
<         FreeVariable.free_variables_count += 1
<         name =  'VAR(%d)'%(FreeVariable.free_variables_count, )
< #       self._childs = []
<         AbstractSyntaxTree.__init__(self, name)
< 
< class Substitution:
<     def __init__(self, initial_value = None):
<         if initial_value == None:
<             initial_value = {}
<         self._map = initial_value
<     def substitute(self, tree, without_copying=False):  
<         if tree in self._map.keys():
<             return self._map[tree]
<         else:
<             if isinstance(tree, FreeVariable):
<                 return tree 
<             if without_copying:
<                 return tree
<             else:
<                 r = AbstractSyntaxTree(tree.getName())
<                 for child in tree.getChilds():
<                     r.addChild(self.substitute(child, without_copying))
<                 return r
< 
<     def getMap(self):
<         return self._map
<     def getSize(self):
<         ret = 0
<         for (u, tree) in self.getMap().items():
<             ret += tree.getSize(False) - free_variable_cost
<         return ret
< 
< class Unifier:
<     def __init__(self, t1, t2, ignore_parametrization=False):
<         def combineSubs(node, s, t):
<             # s and t are 2-tuples
<             assert(s[0].getMap().keys() == s[1].getMap().keys())
<             assert(t[0].getMap().keys() == t[1].getMap().keys())
<             newt = (copy.copy(t[0]), copy.copy(t[1]))
<             relabel = {}
<             for si in s[0].getMap().keys():
<                 if not ignore_parametrization:
<                     foundone = False
<                     for ti in t[0].getMap().keys():
<                         if (s[0].getMap()[si] == t[0].getMap()[ti]) and (s[1].getMap()[si] == t[1].getMap()[ti]): 
<                             relabel[si] = ti
<                             foundone = True
<                             break
<                 if ignore_parametrization or not foundone:
<                     newt[0].getMap()[si] = s[0].getMap()[si]
<                     newt[1].getMap()[si] = s[1].getMap()[si]
<             return (Substitution(relabel).substitute(node), newt)
<         def unify(node1, node2):
<             if node1 == node2:
<                 return (node1, (Substitution(), Substitution()))
<             elif (node1.getName() != node2.getName()) or (node1.getChildCount() != node2.getChildCount()):
<                 var = FreeVariable()
<                 return (var, (Substitution({var:node1}), Substitution({var:node2})))
<             else:
<                 s = (Substitution(), Substitution())
<                 name = node1.getName()
<                 retNode = AbstractSyntaxTree(name) 
<                 count = node1.getChildCount()
<                 for i in range(count):              
<                     (ai, si) = unify(node1.getChilds()[i], node2.getChilds()[i])
<                     (ai, s) = combineSubs(ai, si, s)
<                     retNode.addChild(ai)
<                 return (retNode, s)
<         (self._unifier, self._substitutions) = unify(t1, t2)
<         self._unifier.storeSize()
<         for i in (0,1):
<             for key in self._substitutions[i].getMap():
<                 self._substitutions[i].getMap()[key].storeSize()
<     def getSubstitutions(self):
<         return self._substitutions
<     def getUnifier(self):
<         return self._unifier
<     def getSize(self):
<         return sum([s.getSize() for s in self.getSubstitutions()])
< 
< class Cluster:
<     count = 0
<     def __init__(self, tree=None):
<         if tree:
<             self._n = 1
<             self._unifier_tree = tree
<             self._trees = [tree]
<             self._max_covered_lines = len(tree.getCoveredLineNumbers())
<         else:
<             self._n = 0
<             self._trees = []
<             self._max_covered_lines = 0
<         Cluster.count += 1
<         self._cluster_number = Cluster.count    
<     def getUnifierTree(self):
<         return self._unifier_tree
<     def getCount(self):
<         return self._n
<     def getAddCost(self, tree):
<         unifier = Unifier(self.getUnifierTree(), tree)
<         return (self.getCount()* unifier.getSubstitutions()[0].getSize() + unifier.getSubstitutions()[1].getSize())
<     def unify(self, tree):
<         self._n += 1
<         self._unifier_tree = Unifier(self.getUnifierTree(), tree).getUnifier()
<         self._trees.append(tree)
<     def eraseAllTrees(self):
<         self._n = 0
<         self._trees = []
<     def addWithoutUnification(self, tree):
<         self._n += 1
<         self._trees.append(tree)
<         if len(tree.getCoveredLineNumbers())>self._max_covered_lines:
<             self._max_covered_lines = len(tree.getCoveredLineNumbers())
<     def getMaxCoveredLines(self):
<         return self._max_covered_lines
<     def getUnifierSize(self):
<         return self.getUnifierTree().getSize()
Binary files code-worker/tasks/clonedigger/antlr_runtime/antlr-3.1.1.jar and code-worker/code-worker/tasks/clonedigger/antlr_runtime/antlr-3.1.1.jar differ
Binary files code-worker/tasks/clonedigger/antlr_runtime/antlr-runtime-3.1.jar and code-worker/code-worker/tasks/clonedigger/antlr_runtime/antlr-runtime-3.1.jar differ
Binary files code-worker/tasks/clonedigger/antlr_runtime/runtime-2008-01-10.16.jar and code-worker/code-worker/tasks/clonedigger/antlr_runtime/runtime-2008-01-10.16.jar differ
diff -r -N code-worker/tasks/clonedigger/antlr_runtime/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/all-wcprops
1,23d0
< K 25
< svn:wc:ra_dav:version-url
< V 65
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/antlr_runtime
< END
< runtime-2008-01-10.16.jar
< K 25
< svn:wc:ra_dav:version-url
< V 90
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/antlr_runtime/runtime-2008-01-10.16.jar
< END
< antlr-3.1.1.jar
< K 25
< svn:wc:ra_dav:version-url
< V 81
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/antlr_runtime/antlr-3.1.1.jar
< END
< antlr-runtime-3.1.jar
< K 25
< svn:wc:ra_dav:version-url
< V 87
< /svnroot/clonedigger/!svn/ver/182/trunk/clonedigger/antlr_runtime/antlr-runtime-3.1.jar
< END
diff -r -N code-worker/tasks/clonedigger/antlr_runtime/.svn/entries code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/entries
1,130d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/antlr_runtime
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< runtime-2008-01-10.16.jar
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< 065fefe9bd468664f012e192ec561cd7
< 2008-04-24T20:49:04.917217Z
< 18
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 116239
< 
< antlr-3.1.1.jar
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< 3e0ba59a6ab2c7f50f86b86a9a410da8
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 1513525
< 
< antlr-runtime-3.1.jar
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< ff4b9865f2f87f4e1fe4a14d82ececec
< 2008-08-29T11:39:47.746139Z
< 182
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 124456
< 
diff -r -N code-worker/tasks/clonedigger/antlr_runtime/.svn/prop-base/antlr-3.1.1.jar.svn-base code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/prop-base/antlr-3.1.1.jar.svn-base
1,5d0
< K 13
< svn:mime-type
< V 24
< application/octet-stream
< END
diff -r -N code-worker/tasks/clonedigger/antlr_runtime/.svn/prop-base/antlr-runtime-3.1.jar.svn-base code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/prop-base/antlr-runtime-3.1.jar.svn-base
1,5d0
< K 13
< svn:mime-type
< V 24
< application/octet-stream
< END
diff -r -N code-worker/tasks/clonedigger/antlr_runtime/.svn/prop-base/runtime-2008-01-10.16.jar.svn-base code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/prop-base/runtime-2008-01-10.16.jar.svn-base
1,5d0
< K 13
< svn:mime-type
< V 24
< application/octet-stream
< END
Binary files code-worker/tasks/clonedigger/antlr_runtime/.svn/text-base/antlr-3.1.1.jar.svn-base and code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/text-base/antlr-3.1.1.jar.svn-base differ
Binary files code-worker/tasks/clonedigger/antlr_runtime/.svn/text-base/antlr-runtime-3.1.jar.svn-base and code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/text-base/antlr-runtime-3.1.jar.svn-base differ
Binary files code-worker/tasks/clonedigger/antlr_runtime/.svn/text-base/runtime-2008-01-10.16.jar.svn-base and code-worker/code-worker/tasks/clonedigger/antlr_runtime/.svn/text-base/runtime-2008-01-10.16.jar.svn-base differ
diff -r -N code-worker/tasks/clonedigger/arguments.py code-worker/code-worker/tasks/clonedigger/arguments.py
1,8d0
< clustering_threshold = 10
< hashing_depth = 1
< clusterize_using_dcup = False
< report_unifiers = False
< print_time = True
< force = False  
< use_diff = False 
< clusterize_using_hash = False
diff -r -N code-worker/tasks/clonedigger/ast_suppliers.py code-worker/code-worker/tasks/clonedigger/ast_suppliers.py
1,33d0
< #    Copyright 2008 Peter Bulychev
< #        http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< # Abstract Syntax Tree suppliers
< abstract_syntax_tree_suppliers = {}
< 
< import python_compiler
< abstract_syntax_tree_suppliers['python'] = python_compiler.PythonCompilerSourceFile
< 
< import java_antlr
< abstract_syntax_tree_suppliers['java'] = java_antlr.JavaANTLRSourceFile
< 
< import lua_antlr
< abstract_syntax_tree_suppliers['lua'] = lua_antlr.LuaANTLRSourceFile
< 
< import js_antlr
< abstract_syntax_tree_suppliers['javascript'] = js_antlr.JsANTLRSourceFile
< abstract_syntax_tree_suppliers['js'] = js_antlr.JsANTLRSourceFile
diff -r -N code-worker/tasks/clonedigger/clone_detection_algorithm.py code-worker/code-worker/tasks/clonedigger/clone_detection_algorithm.py
1,361d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import sys
< 
< from anti_unification import *
< from abstract_syntax_tree import *
< 
< def findDuplicateCode(source_files, report):
<     statement_sequences = []
<     statement_count = 0
<     sequences_lengths = []
<     for source_file in source_files:
<         sequences = source_file.getTree().getAllStatementSequences()
<         statement_sequences.extend(sequences)
<         sequences_lengths.extend([len(s) for s in sequences])
<         statement_count += sum([len(s) for s in sequences])
< 
<     if not sequences_lengths:
<         print 'Input is empty or the size of the input is below the size threshold'
<         sys.exit(0)
< 
<     if verbose:
<         n_sequences = len(sequences_lengths)    
<         avg_seq_length = sum(sequences_lengths)/float(n_sequences)
<         max_seq_length = max(sequences_lengths)
< 
<         print '%d sequences' %(n_sequences,)
<         print 'average sequence length: %f' % (avg_seq_length,)
<         print 'maximum sequence length: %d' % (max_seq_length,)
<         sequences_without_restriction = statement_sequences
<         sequences = []
<         if not arguments.force:
<             for sequence in sequences_without_restriction:
<                 if len(sequence) > 1000:
<                     first_statement = sequence[0]
<                     print
<                     print '-----------------------------------------'
<                     print 'Warning: sequences of statements, consists of %d elements is too long.' %(len(sequence),)
<                     print 'It starts at %s:%d.'%(first_statement.getSourceFile().getFileName(), min(first_statement.getCoveredLineNumbers()))
<                     print 'It will be ignored. Use --force to override this restriction.'
<                     print 'Please refer to http://clonedigger.sourceforge.net/documentation.html'
<                     print '-----------------------------------------'
<                 else:
<                     sequences.append(sequence)
<   
<     def calc_statement_sizes():
<         for sequence in statement_sequences:
<             for statement in sequence:
<                 statement.storeSize()
< 
<     def build_hash_to_statement(dcup_hash = True):
<         hash_to_statement = {}
<         for statement_sequence in statement_sequences:
<             for statement in statement_sequence:
<                 if dcup_hash:
<                     # 3 - CONSTANT HERE!
<                     h = statement.getDCupHash(arguments.hashing_depth)
<                 else:
<                     h = statement.getFullHash()
<                 if not hash_to_statement.has_key(h):
<                     hash_to_statement[h] = [statement]
<                 else:
<                     hash_to_statement[h].append(statement)                  
<         return hash_to_statement
<     def build_unifiers(hash_to_statement):
<         processed_statements_count = 0
<         clusters = []
<         ret = {}
<         for h in hash_to_statement.keys():
<             local_clusters = []
<             statements = hash_to_statement[h]
<             for statement in statements:
<                 processed_statements_count += 1
<                 if verbose and ((processed_statements_count % 1000) == 0):
<                     print '%d,' %(processed_statements_count,),
<                     sys.stdout.flush()
<                 bestcluster = None
<                 mincost = sys.maxint
<                 for cluster in local_clusters:
<                     cost = cluster.getAddCost(statement)
<                     if cost < mincost:
<                         mincost = cost
<                         bestcluster = cluster
<                 assert(local_clusters==[] or bestcluster)
<                 if mincost < 0:
<                     pdb.set_trace()
<                 assert(mincost >= 0)
<                 if bestcluster == None or mincost > arguments.clustering_threshold:
<                     newcluster = Cluster(statement)
<                     local_clusters.append(newcluster)
<                 else:
<                     bestcluster.unify(statement)                
<             ret[h] = local_clusters 
<             clusters.extend(local_clusters)
<         return ret
< 
<     def clusterize(hash_to_statement, clusters_map):
<         processed_statements_count = 0
<         # clusters_map contain hash values for statements, not unifiers
<         # therefore it will work correct even if unifiers are smaller than hashing depth value
<         for h in hash_to_statement.keys():
<             clusters = clusters_map[h]
<             for statement in hash_to_statement[h]:
<                 processed_statements_count += 1
<                 if verbose and ((processed_statements_count % 1000) == 0):
<                     print '%d,' %(processed_statements_count,),
<                     sys.stdout.flush()
<                 mincost = sys.maxint
<                 for cluster in clusters:
<                     new_u = Unifier(cluster.getUnifierTree(), statement)
< #                   assert(new_u.getSubstitutions()[0].getSize() == 0)
<                     cost = new_u.getSize()
<                     if cost < mincost:
<                         mincost = cost
<                         statement.setMark(cluster)
<                         cluster.addWithoutUnification(statement)
<     def filterOutLongEquallyLabeledSequences(statement_sequences):
<         #TODO - refactor, combine with the previous warning
<         sequences_without_restriction = statement_sequences
<         statement_sequences = []
<         for sequence in sequences_without_restriction:
<             new_sequence = copy.copy(sequence._sequence) 
<             current_mark = None
<             length = 0
<             first_statement_index = None
<             flag = False 
<             for i in range(len(sequence)):
<                 statement = sequence[i]
<                 if statement.getMark() != current_mark:
<                     if flag == True:
<                         flag = False 
<                     current_mark=statement.getMark()
<                     length=0
<                     first_statement_index = i
<                 else:
<                     length += 1
<                     if length>10:
<                         new_sequence[i] = None
<                         if not flag:
<                             for i in range(first_statement_index, i):
<                                 new_sequence[i] = None
<                             first_statement = sequence[first_statement_index]                        
<                             print
<                             print '-----------------------------------------'
<                             print 'Warning: sequence of statements starting at %s:%d'%(first_statement.getSourceFile().getFileName(), min(first_statement.getCoveredLineNumbers()))
<                             print 'consists of many similar statements.'
<                             print 'It will be ignored. Use --force to override this restriction.'
<                             print 'Please refer to http://clonedigger.sourceforge.net/documentation.html'
<                             print '-----------------------------------------'
<                             flag = True 
<             new_sequence = new_sequence + [None]
<             cur_sequence = StatementSequence() 
<             for statement in new_sequence:
<                 if statement == None:
<                     if cur_sequence:
<                         statement_sequences.append(cur_sequence)
<                         cur_sequence = StatementSequence() 
<                 else:
<                     cur_sequence.addStatement(statement)
<         return statement_sequences
< 
<     def mark_using_hash(hash_to_statement):     
<         for h in hash_to_statement:
<             cluster = Cluster()
<             for statement in hash_to_statement[h]:
<                 cluster.addWithoutUnification(statement)
<                 statement.setMark(cluster)              
<     def findHugeSequences():
<         def f_size(x):    
<             return x.getMaxCoveredLines()
<         def f_elem(x):
<             return StatementSequence(x).getCoveredLineNumbersCount()
<         def fcode(x):
<             return x.getMark()
<         f = f_size
<         suffix_tree_instance = suffix_tree.SuffixTree(fcode)
<         for sequence in statement_sequences:
<             suffix_tree_instance.add(sequence)
<         return [PairSequences([StatementSequence(s1), StatementSequence(s2)]) for (s1,s2) in suffix_tree_instance.getBestMaxSubstrings(arguments.size_threshold, f, f_elem)]
<     def refineDuplicates(pairs_sequences):
<         r = []
<         flag = False
<         while pairs_sequences:      
<             pair_sequences = pairs_sequences.pop()
<             def all_pairsubsequences_size_n_threshold(n):
<                 lr = []
<                 for first in range(0, pair_sequences.getLength()-n+1):
<                     new_pair_sequences = pair_sequences.subSequence(first, n)
<                     size = new_pair_sequences.getMaxCoveredLineNumbersCount()
<                     if size >= arguments.size_threshold:
<                         lr.append((new_pair_sequences, first))
<                 return lr
<             n = pair_sequences.getLength() + 1
<             while 1:
<                 n-=1
<                 if n == 0:
<                     break
<                 new_pairs_sequences = all_pairsubsequences_size_n_threshold(n)
<                 for (candidate_sequence, first) in new_pairs_sequences:             
<                     distance = candidate_sequence.calcDistance()
<                     if (distance < arguments.distance_threshold):
<                         r.append(candidate_sequence)
<                         if first > 0:
<                             pairs_sequences.append(pair_sequences.subSequence(0, first-1))
<                         if first+n < pair_sequences.getLength():
<                             pairs_sequences.append(pair_sequences.subSequence(first+n, pair_sequences.getLength() - first - n))
<                         n+=1
<                         flag = True
<                         break
<                 if flag:
<                     flag = False
<                     break
<         return r
<     def remove_dominated_clones(clones):
<         ret_clones = []
< #       def f_cmp(a, b):
< #           return a.getLevel().__cmp__(b.getLevel())
< #       clones.sort(f_cmp)
<         statement_to_clone = {}
<         for clone in clones:
<             for sequence in clone:
<                 for statement in sequence:
<                     if not statement_to_clone.has_key(statement):
<                         statement_to_clone[statement] = []
<                     statement_to_clone[statement].append(clone)
<         for clone in clones:
<             ancestors_2 = clone[1].getAncestors()
<             flag = True
<             for s1 in clone[0].getAncestors():
<                 if statement_to_clone.has_key(s1):
<                     for clone2 in statement_to_clone[s1]:
<                         if s1 in clone2[0]:
<                             seq = clone2[1]
<                         else:
<                             assert(s1 in clone2[1])
<                             seq = clone2[0]
<                         for s2 in seq:
<                             if s2 in ancestors_2:
<                                 flag = False
<                                 break
<                         if not flag:
<                             break
<                 if not flag:
<                     break
<             if flag:
<                 ret_clones.append(clone)
<         return ret_clones
< 
<     if verbose:
<         print 'Number of statements: ', statement_count
<         print 'Calculating size for each statement...',
<         sys.stdout.flush()
<     calc_statement_sizes() 
<     if verbose:
<         print 'done'
< 
<     if verbose:
<         print 'Building statement hash...',
<         sys.stdout.flush()
<     report.startTimer('Building statement hash')
<     if arguments.clusterize_using_hash:
<         hash_to_statement = build_hash_to_statement(dcup_hash = False)
<     else:
<         hash_to_statement = build_hash_to_statement(dcup_hash = True)
<     report.stopTimer()
<     if verbose:
<         print 'done'
<         print 'Number of different hash values: ', len(hash_to_statement)
<     
<     if arguments.clusterize_using_dcup or arguments.clusterize_using_hash:
<         print 'Marking each statement with its hash value'
<         mark_using_hash(hash_to_statement)
<     else:
<         if verbose:
<             print 'Building patterns...',
<             sys.stdout.flush()
<         report.startTimer('Building patterns')
<         clusters_map = build_unifiers(hash_to_statement)    
<         report.stopTimer()
<         if verbose:
<             print Cluster.count, 'patterns were discovered'
<             print 'Choosing pattern for each statement...',
<             sys.stdout.flush()
<         report.startTimer('Marking similar statements')
<         clusterize(hash_to_statement, clusters_map)
<         report.stopTimer()
<         if verbose:
<             print 'done'
< 
<     if arguments.report_unifiers:
<         if verbose:
<             print 'Building reverse hash for reporting ...',
<             sys.stdout.flush()
<         reverse_hash = {}
<         for sequence in statement_sequences:
<             for statement in sequence:
<                 mark = statement.getMark()
<                 if not reverse_hash.has_key(mark):
<                     reverse_hash[mark] = []
<                 reverse_hash[mark].append(statement)
<         report.setMarkToStatementHash(reverse_hash)
<         if verbose:
<             print 'done'
< 
<     if verbose:
<         print 'Finding similar sequences of statements...',
<         sys.stdout.flush()
<     
<     if not arguments.force:
<         statement_sequences = filterOutLongEquallyLabeledSequences(statement_sequences)
< 
<     report.startTimer('Finding similar sequences of statements')
<     duplicate_candidates = findHugeSequences()
<     report.stopTimer()
<     if verbose:
<         print len(duplicate_candidates), ' sequences were found'
<         print 'Refining candidates...',
<         sys.stdout.flush()    
<     if arguments.distance_threshold!=-1:
<         report.startTimer('Refining candidates')
<         clones = refineDuplicates(duplicate_candidates)
<         report.stopTimer()
<     else:
<         clones = duplicate_candidates
<     if verbose:
<         print len(clones), 'clones were found'
<     if arguments.distance_threshold!=-1:
<         if verbose:
<             print 'Removing dominated clones...',
<             sys.stdout.flush()
<         old_clone_count = len(clones)
<         clones = remove_dominated_clones(clones)
<         if verbose:
<             print len(clones) - old_clone_count, 'clones were removed' 
< 
<     covered_source_lines = set()
<     for clone in clones:
<         for sequence in clone:
<             covered_source_lines = covered_source_lines.union(sequence.getLineNumberHashables())
<     source_lines = set()
<     for sequence in statement_sequences:
<         source_lines = source_lines.union(sequence.getLineNumberHashables())
<     report.all_source_lines_count = len(source_lines)
<     report.covered_source_lines_count = len(covered_source_lines)
< 
<     return clones
diff -r -N code-worker/tasks/clonedigger/clonedigger.py code-worker/code-worker/tasks/clonedigger/clonedigger.py
1,202d0
< #!/usr/bin/python
< 
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< import sys
< 
< if __name__ == '__main__':
<     sys.modules['clonedigger.logilab'] = __import__('logilab')
< 
< import re
< import os
< import traceback
< from optparse import OptionParser
< from fnmatch import fnmatch
< 
< import ast_suppliers
< import clone_detection_algorithm
< import arguments 
< import html_report
< 
< def main():
<     cmdline = OptionParser(usage="""To run Clone Digger type:
< python clonedigger.py [OPTION]... [SOURCE FILE OR DIRECTORY]...
< 
< The typical usage is:
< python clonedigger.py source_file_1 source_file_2 ...
<   or
< python clonedigger.py path_to_source_tree
< Don't forget to remove automatically generated sources, tests and third party libraries from the source tree.
< 
< Notice:
< The semantics of threshold options is discussed in the paper "Duplicate code detection using anti-unification", which can be downloaded from the site http://clonedigger.sourceforge.net . All arguments are optional. Supported options are: 
< """)
<     cmdline.add_option('-l', '--language', dest='language',
<                        type='choice', choices=['python', 'java', 'lua', 'javascript', 'js'],
<                        help='the programming language')
<     cmdline.add_option('--no-recursion', dest='no_recursion',
<                        action='store_true', 
<                        help='do not traverse directions recursively')    
<     cmdline.add_option('-o', '--output', dest='output',
<                        help='the name of the output file ("output.html" by default)')
<     cmdline.add_option('--clustering-threshold', 
<                        type='int', dest='clustering_threshold',
<                        help='read the paper for semantics')
<     cmdline.add_option('--distance-threshold', 
<                        type='int', dest='distance_threshold',
<                        help='the maximum amount of differences between pair of sequences in clone pair (5 by default). Larger value leads to larger amount of false positives')
<     cmdline.add_option('--hashing-depth', 
<                        type='int', dest='hashing_depth',
<                        help='default value if 1, read the paper for semantics. Computation can be speeded up by increasing this value (but some clones can be missed)')
<     cmdline.add_option('--size-threshold', 
<                        type='int', dest='size_threshold',
<                        help='the minimum clone size. The clone size for its turn is equal to the count of lines of code in its the largest fragment')
<     cmdline.add_option('--clusterize-using-dcup', 
<                        action='store_true', dest='clusterize_using_dcup',
<                        help='mark each statement with its D-cup value instead of the most similar pattern. This option together with --hashing-depth=0 make it possible to catch all considered clones (but it is slow and applicable only to small programs)')
<     cmdline.add_option('--dont-print-time', 
<                        action='store_false', dest='print_time',
<                        help='do not print time')
<     cmdline.add_option('-f', '--force', 
<                        action='store_true', dest='force',
<                        help='')
<     cmdline.add_option('--force-diff', 
<                        action='store_true', dest='use_diff',
<                        help='force highlighting of differences based on the diff algorithm')
<     cmdline.add_option('--fast', 
<                        action='store_true', dest='clusterize_using_hash',
<                        help='find only clones, which differ in variable and function names and constants')
<     cmdline.add_option('--ignore-dir', 
<                        action='append', dest='ignore_dirs',
<                        help='exclude directories from parsing')
<     cmdline.add_option('--eclipse-output', 
<                        dest='eclipse_output',
<                        help='for internal usage only')
<     cmdline.add_option('--cpd-output', 
<                        action='store_true', dest='cpd_output',
<                        help='output as PMD''s CPD''s XML format. If output file not defined, output.xml is generated')
<     cmdline.add_option('--report-unifiers', 
<                        action='store_true', dest='report_unifiers',
<                        help='')
<     cmdline.add_option('--func-prefixes',
<                       action='store',
<                        dest='f_prefixes',
<                       help='skip functions/methods with these prefixes (provide a CSV string as argument)')
<     cmdline.add_option('--file-list', dest='file_list',
<                       help='a file that contains a list of file names that must be processed by Clone Digger')
< 
<     cmdline.set_defaults(language='python', 
<                          ingore_dirs=[],
<                          f_prefixes = None,
<                          **arguments.__dict__)
< 
<     (options, source_file_names) = cmdline.parse_args()
<     if options.f_prefixes != None:
<        func_prefixes = tuple([x.strip() for x in options.f_prefixes.split(',')])
<     else:
<        func_prefixes = ()
<     source_files = [] 
< 
<     supplier = ast_suppliers.abstract_syntax_tree_suppliers[options.language]
<     if options.language != 'python':
<         options.use_diff = True
< 
<     if options.cpd_output:
<         if options.output is None:
< 	    options.output = 'output.xml'
< 	report = html_report.CPDXMLReport()
<     else:
<     	report = html_report.HTMLReport()    
< 
<     if options.output is None:
<     	options.output = 'output.html'
< 
<     output_file_name = options.output
< 
<     for option in cmdline.option_list:
<         if option.dest == 'file_list' and options.file_list != None:           
<             source_file_names.extend(open(options.file_list).read().split())
<             continue
<         elif option.dest is None:
<             continue
<         setattr(arguments, option.dest, getattr(options, option.dest))
< 
<     if options.distance_threshold is None:
<         arguments.distance_threshold = supplier.distance_threshold
<     if options.size_threshold is None:
<         arguments.size_threshold = supplier.size_threshold
<     
<     report.startTimer('Construction of AST')
< 
<     def parse_file(file_name, func_prefixes):
<         try:
<             print 'Parsing ', file_name, '...',
<             sys.stdout.flush()
<             if options.language=='python':
<                 source_file = supplier(file_name, func_prefixes)
<             else:
<                 # TODO implement func_prefixes for java also
<                 source_file = supplier(file_name)
<             source_file.getTree().propagateCoveredLineNumbers()
<             source_file.getTree().propagateHeight()
<             source_files.append(source_file)
<             report.addFileName(file_name)                
<             print 'done'
<         except:
<             s = 'Error: can\'t parse "%s" \n: '%(file_name,) + traceback.format_exc()
<             report.addErrorInformation(s)
<             print s
< 
<     def walk(dirname):
<         for dirpath, dirs, files in os.walk(file_name):
<             dirs[:] = (not options.ignore_dirs and dirs)  or [d for d in dirs if d not in options.ignore_dirs]
<             # Skip all non-parseable files
<             files[:] = [f for f in files 
<                         if os.path.splitext(f)[1][1:] == supplier.extension]
<             yield (dirpath, dirs, files)
< 
<     for file_name in source_file_names:
<         if os.path.isdir(file_name):
<             if arguments.no_recursion:
<                 dirpath = file_name
<                 files = [os.path.join(file_name, f) for f in os.listdir(file_name) 
<                         if os.path.splitext(f)[1][1:] == supplier.extension]
<                 for f in files:
<                     parse_file(f, func_prefixes)
<             else:
<                 for dirpath, dirnames, filenames in walk(file_name):
<                     for f in filenames:
<                         parse_file(os.path.join(dirpath, f), func_prefixes)
<         else:
<             parse_file(file_name, func_prefixes)
<         
<     report.stopTimer()
<     duplicates = clone_detection_algorithm.findDuplicateCode(source_files, report)
<     for duplicate in duplicates:
<         report.addClone(duplicate)
<     report.sortByCloneSize()
<     try:
<         report.writeReport(output_file_name)
<     except:
<         print "catched error, removing output file"
<         if os.path.exists(output_file_name):
<             os.remove(output_file_name)
<         raise 
< 
< if __name__ == '__main__':
<     main()
< 
Binary files code-worker/tasks/clonedigger/.DS_Store and code-worker/code-worker/tasks/clonedigger/.DS_Store differ
diff -r -N code-worker/tasks/clonedigger/html_report.py code-worker/code-worker/tasks/clonedigger/html_report.py
1,351d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import sys
< import time
< import difflib
< import re
< import copy
< import traceback
< import os.path
< from cgi import escape
< 
< import arguments
< import anti_unification
< import python_compiler
< from abstract_syntax_tree import AbstractSyntaxTree
< 
< class Report:
<     def __init__(self):
<         self._error_info = []
<         self._clones = []
<         self._timers = []
<         self._file_names = []
<     def addFileName(self, file_name):
<         self._file_names.append(file_name)
<     def addErrorInformation(self, error_info):
<         self._error_info.append(error_info)
<     def addClone(self, clone):
<         self._clones.append(clone)
<     def sortByCloneSize(self):
<         def f(a,b):
<             return cmp(b.getMaxCoveredLineNumbersCount(), a.getMaxCoveredLineNumbersCount())
<         self._clones.sort(f)
<     def startTimer(self, descr):
<         self._timers.append([descr, time.time(), time.ctime()])
<         sys.stdout.flush()
<     def stopTimer(self, descr=''):      
<         self._timers[-1][1] = time.time() - self._timers[-1][1]
<     def getTimerValues(self):
<         return self._timers
<     def getTotalTime(self):
<         return sum([i[1] for i in self.getTimerValues()])
< 
< class CPDXMLReport(Report):
<     def __init__(self):
<         Report.__init__(self)
<         self._mark_to_statement_hash = None
<     def setMarkToStatementHash(self, mark_to_statement_hash):   
<         self._mark_to_statement_hash = mark_to_statement_hash
<     def writeReport(self, file_name):
< 	f = open(file_name, 'w')
< 	f.write('<?xml version="1.0" encoding="UTF-8"?>\n')
< 	f.write('<pmd-cpd>\n')
< 	for clone in self._clones:	    
< 	    token_numbers = [sum([s.getTokenCount() for s in clone[i]]) for i in (0,1)]
< 	    f.write('<duplication lines="' + str(max([len(set(clone[i].getCoveredLineNumbers())) for i in [0,1]] )) + '" tokens="' + str(max(token_numbers)) +'">\n')
< 	    for i in [0,1]:
< 		f.write('<file line="' + str(1 + min(clone[i].getCoveredLineNumbers())) +  '" path="' + os.path.abspath(clone[i].getSourceFile().getFileName()) + '"/>\n')
< 	    f.write('<codefragment>\n')
< 	    f.write('<![CDATA[\n')
< 	    for line in clone[0].getSourceLines():
< 		f.write(line.replace(']]>','-CLONEDIGGER REMOVED CDATAEND-'))
<                 f.write('\n')
< 	    f.write(']]>\n')
< 	    f.write('</codefragment>\n')
< 	    f.write('</duplication>\n')
< 	f.write('</pmd-cpd>\n')
< 	f.close()
< 
< 
< class HTMLReport(Report):
<     def __init__(self):
<         Report.__init__(self)
<         self._mark_to_statement_hash = None
<     def setMarkToStatementHash(self, mark_to_statement_hash):   
<         self._mark_to_statement_hash = mark_to_statement_hash
<     def writeReport(self, file_name):
< # TODO REWRITE! This function code was created in a hurry
<         eclipse_start = '\n<!--ECLIPSE START-->'
<         eclipse_end   = '\n<!--ECLIPSE END-->'
<         def format_line_code(s):
<             s = s.replace('\t', ' ')
<             s = s.replace(' ', '&nbsp; ')
<             return '<span style="font-family: monospace;">%s</span>'%(s,)
<         errors_info = "\n".join(['<P> <FONT COLOR=RED> %s </FONT> </P>' % (error_info.replace('\n', '<BR>'),) for error_info in self._error_info])
< 
<         very_strange_const = 'VERY_STRANGE_CONST'
< 
<         clone_descriptions = []
<         for clone_i in range(len(self._clones)):
<             try:
<                 clone = self._clones[clone_i]
<                 s = '<P>'
<                 s += '<B>Clone # %d</B><BR>'%(clone_i +1,)
< #           s = '<P> Clone detected in source files "%s" and "%s" <BR>\n' % (sequences[0].getSourceFile().getFileName(), sequences[1].getSourceFile().getFileName())
<                 s+= 'Distance between two fragments = %d <BR>' %(clone.calcDistance())
<                 s+= 'Clone size = ' + str(max([len(set(clone[i].getCoveredLineNumbers())) for i in [0,1]] ))
<                 s+= '<TABLE NOWRAP WIDTH=100% BORDER=1>'
<                 s+= eclipse_start
<                 s+= '<TR>'
<                 for j in [0,1]:
<                     s+= '<TD> <a href="clone://%s?%d&%d"> Go to this fragment in Eclipse </a> </TD>'%(clone[j].getSourceFile().getFileName(), min(clone[j][0].getCoveredLineNumbers()), max(clone[j][-1].getCoveredLineNumbers()))
<                     if j==0:
<                         s += '<TD></TD>'
<                 s+= '</TR>'
<                 s+= eclipse_end
<                 for j in [0,1]:
<                     s+= '<TD>'
<                     s+= 'Source file "%s"<BR>' %(clone[j].getSourceFile().getFileName(),)
<                     if clone[j][0].getCoveredLineNumbers() == []:
<                         # TODO remove after...
<                         pdb.set_trace()
<                     s+= 'The first line is %d' %(min(clone[j][0].getCoveredLineNumbers())+1,)
<                     s+= '</TD>'
<                     if j == 0:
<                         s+= '<TD></TD>'
<                 s+= '</TR>'
<                 for i in range(clone[0].getLength()):
<                     s += '<TR>\n'
<                     t = []
<                     statements = [clone[j][i] for j in [0,1]]
< 
<                     def diff_highlight(seqs):
<                         s = difflib.SequenceMatcher(lambda x:x == '<BR>\n')
<                         s.set_seqs(seqs[0], seqs[1])
<                         blocks = s.get_matching_blocks()
<                         if not ((blocks[0][0]==0) and (blocks[0][1]==0)):
<                             blocks = [(0,0,0)] + blocks
<                         r = ['', '']
<                         for i in range(len(blocks)):
<                             block = blocks[i]
<                             for j in [0,1]:
<                                 r[j] += escape(seqs[j][block[j]:block[j]+block[2]])
<                             if (i < (len(blocks)-1)):                           
<                                 nextblock = blocks[i+1]
<                                 for j in [0,1]:
<                                     r[j] += '<span'+very_strange_const+'style="color:rgb(255,0,0);">%s</span>'%\
<                                                 (escape(seqs[j][block[j]+block[2]:nextblock[j]]),)
<                         return r
<                     # preparation of indentation
<                     indentations = (set(), set())
<                     for j in (0,1):
<                         for source_line in statements[j].getSourceLines():
<                             indentations[j].add(re.findall('^\s*', source_line)[0].replace('\t', 4*' '))
<                     indentations = (list(indentations[0]), list(indentations[1]))
<                     indentations[0].sort()
<                     indentations[1].sort()
<                     source_lines = ([], [])
<                     def use_diff():
<                         for j in (0,1):
<                             for source_line in statements[j].getSourceLines():
<                                 indent1 = re.findall('^\s*', source_line)[0]
<                                 indent2 = indent1.replace('\t', 4*' ')
<                                 source_line = re.sub('^' + indent1,  indentations[j].index(indent2)*' ', source_line)
<                                 source_lines[j].append(source_line)
<                         d = diff_highlight([('\n'.join(source_lines[j])) for j in [0,1]])
<                         d = [format_line_code(d[i].replace('\n', '<BR>\n')) for i in [0,1]]                
<                         d = [d[i].replace(very_strange_const, ' ') for i in (0,1)]
<                         u = anti_unification.Unifier(statements[0], statements[1])
<                         return d,u
<                     if arguments.use_diff:
<                         (d,u) = use_diff()
<                     else:
<                         try:
<                             def rec_correct_as_string(t1, t2, s1, s2):
<                                 def highlight(s):
<                                     return '<span style="color: rgb(255, 0, 0);">' + s + '</span>'
<                                 class NewAsString:
<                                     def __init__(self, s):
<                                         self.s = highlight(s)
<                                     def __call__(self):
<                                         return self.s
<                                 def set_as_string_node_parent(t):
<                                     if not isinstance(t, AbstractSyntaxTree):
<                                         t = t.getParent()
<                                     n = NewAsString(t.ast_node.as_string())
<                                     t.ast_node.as_string = n
< 
<                                 if (t1 in s1) or (t2 in s2):
<                                     for t in (t1, t2):
<                                         set_as_string_node_parent(t)
<                                     return
<                                 assert(len(t1.getChilds()) == len(t2.getChilds()))
<                                 for i in range(len(t1.getChilds())):
<                                     c1 = t1.getChilds()[i]
<                                     c2 = t2.getChilds()[i]
<                                     rec_correct_as_string(c1, c2, s1, s2)
< 
<                             (s1, s2) = (statements[0], statements[1])
<                             u = anti_unification.Unifier(s1, s2)
<                             rec_correct_as_string(s1, s2, u.getSubstitutions()[0].getMap().values(), u.getSubstitutions()[1].getMap().values() )
<                             d = [None, None]
<                             for j in (0,1):
<                                 d[j] = statements[j].ast_node.as_string()
< 
<                                 lines = d[j].split('\n')
<                                 for ii in range(len(lines)):
<                                     temp_line = ''
<                                     jj = 0
<                                     try:
<                                         while lines[ii][jj] == ' ':
<                                             temp_line += '&nbsp;'
<                                             jj += 1
<                                     except IndexError:
<                                         # suppress errors if line has no leading spaces
<                                         pass
<                                     temp_line += lines[ii][jj:]
<                                     lines[ii] = temp_line
<                                 d[j] = '\n'.join(lines)
< 
<                                 d[j] = d[j].replace('\n', '<BR>\n')
< 
< 
<                         except:
<                             print 'The following error occured during highlighting of differences on the AST level:'
<                             traceback.print_exc()                       
<                             print 'using diff highlight'
<                             (d,u) = use_diff()
<                     for j in [0,1]:                 
<                         t.append('<TD>\n' + d[j] + '</TD>\n')
<                     if u.getSize() > 0:
<                         color = 'RED'
<                     else:
<                         color = 'AQUA'
<                     s+= t[0] + '<TD style="width: 10px;" BGCOLOR=%s> </TD>'%(color,) + t[1]
<                     s += '</TR>\n'
<                 s+= '</TABLE> </P> <HR>'
<                 clone_descriptions.append(s)
<             except:
<                 print "Clone info can't be written to the report. "
<                 traceback.print_exc()                   
<         
<         descr = """<P>Source files: %d</P>
<         <a href = "javascript:unhide('files');">Click here to show/hide file names</a><div id="files" class="hidden"><P><B>Source files:</B><BR>%s</P></div>
<         <P>Clones detected: %d</P>
<         <P>%d of %d lines are duplicates (%.2f%%) </P>
< <P>
< <B>Parameters<BR> </B>
< clustering_threshold = %d<BR>
< distance_threshold = %d<BR>
< size_threshold = %d<BR>
< hashing_depth = %d<BR>
< clusterize_using_hash = %s<BR>
< clusterize_using_dcup = %s<BR>
< </P> 
<         """ % (len(self._file_names), ', <BR>'.join(self._file_names), len(self._clones), self.covered_source_lines_count, self.all_source_lines_count, (not self.all_source_lines_count and 100) or 100*self.covered_source_lines_count/float(self.all_source_lines_count), arguments.clustering_threshold, arguments.distance_threshold, arguments.size_threshold, arguments.hashing_depth, str(arguments.clusterize_using_hash), str(arguments.clusterize_using_dcup))
<         if arguments.print_time:
<             timings = ''
<             timings += '<B>Time elapsed</B><BR>'
<             timings += '<BR>\n'.join(['%s : %.2f seconds'%(i[0], i[1]) for i in self._timers])
<             timings += '<BR>\n Total time: %.2f' % (self.getTotalTime())
<             timings += '<BR>\n Started at: ' + self._timers[0][2]
<             timings += '<BR>\n Finished at: ' + self._timers[-1][2]
<         else:
<             timings = ''
<         
<         marks_report = ''
<         if self._mark_to_statement_hash:
<             marks_report += '<P>Top 20 statement marks:'
<             marks = self._mark_to_statement_hash.keys()
<             marks.sort(lambda y,x:cmp(len(self._mark_to_statement_hash[x]), len(self._mark_to_statement_hash[y])))
<             counter = 0
<             for mark in marks[:20]:
<                 counter += 1
<                 marks_report += '<BR>' + str(len(self._mark_to_statement_hash[mark])) + ':' +  str(mark.getUnifierTree()) + "<a href=\"javascript:unhide('stmt%d');\">show/hide representatives</a> "%(counter,)
<                 marks_report += '<div id="stmt%d" class="hidden"> <BR>'%(counter,)
<                 for statement in self._mark_to_statement_hash[mark]:
<                     marks_report += str(statement) + '<BR>'
<                 marks_report += '</div>'
<                 marks_report += '</P>'
< 
<         warnings = ''
<         if arguments.use_diff:
<             warnings += '<P>(*) Warning: the highlighting of differences is based on diff and doesn\'t reflect the tree-based clone detection algorithm.</P>'
<         save_to = eclipse_start + '<b><a href="file://%s">Save this report</a></b>'%(file_name,) +eclipse_end   
<         HTML_code = """
< <HTML>
<     <HEAD>
<         <TITLE> CloneDigger Report </TITLE>
<         <script type="text/javascript">
<         function unhide(divID) {
<             var item = document.getElementById(divID);
<             if (item) {
<                 item.className=(item.className=='hidden')?'unhidden':'hidden';
<             }
<         }
< </script>
< 
< <style type="text/css">
< .hidden { display: none; }
< .unhidden { display: block; }
< .preformatted {
<         border: 1px dashed #3c78b5;
<     font-size: 11px;
<         font-family: Courier;
<     margin: 10px;
<         line-height: 13px;
< }
< .preformattedHeader {
<     background-color: #f0f0f0;
<         border-bottom: 1px dashed #3c78b5;
<     padding: 3px;
<         text-align: center;
< }
< .preformattedContent {
<     background-color: #f0f0f0;
<     padding: 3px;
< }
< <!--
< <div class="preformatted"><div class="preformattedContent">
< <pre>Clone Digger
< </pre>
< </div></div>
< -->
< 
< </style>
< 
<     </HEAD>
<     <BODY>
<     %s
<     %s
<     %s
<     %s
<     %s
<     %s
<     %s
<     <HR>
<     Clone Digger is aimed to find software clones in Python and Java programs. It is provided under the GPL license and can be downloaded from the site <a href="http://clonedigger.sourceforge.net">http://clonedigger.sourceforge.net</a>
<     </BODY>
< </HTML>""" % (errors_info, save_to, descr, timings, '<BR>\n'.join(clone_descriptions), marks_report, warnings)
<         f = open(file_name, 'w')
<         f.write(re.sub(eclipse_start+'.*?'+eclipse_end, '' ,HTML_code))
<         f.close()
<         if arguments.eclipse_output:
<             f = open(arguments.eclipse_output, 'w')
<             f.write(HTML_code)
<             f.close()
diff -r -N code-worker/tasks/clonedigger/java_antlr/build_jar.sh code-worker/code-worker/tasks/clonedigger/java_antlr/build_jar.sh
1,4d0
< java org.antlr.Tool JavaAST.g
< javac *.java
< jar -cf TreeProducer.jar *.class
< rm *.class
diff -r -N code-worker/tasks/clonedigger/java_antlr/JavaAST.g code-worker/code-worker/tasks/clonedigger/java_antlr/JavaAST.g
1,1326d0
< /** A Java 1.5 grammar for ANTLR v3 derived from the spec
<  *
<  *  This is a very close representation of the spec; the changes
<  *  are comestic (remove left recursion) and also fixes (the spec
<  *  isn't exactly perfect).  I have run this on the 1.4.2 source
<  *  and some nasty looking enums from 1.5, but have not really
<  *  tested for 1.5 compatibility.
<  *
<  *  I built this with: java -Xmx100M org.antlr.Tool java.g 
<  *  and got two errors that are ok (for now):
<  *  java.g:691:9: Decision can match input such as
<  *    "'0'..'9'{'E', 'e'}{'+', '-'}'0'..'9'{'D', 'F', 'd', 'f'}"
<  *    using multiple alternatives: 3, 4
<  *  As a result, alternative(s) 4 were disabled for that input
<  *  java.g:734:35: Decision can match input such as "{'$', 'A'..'Z',
<  *    '_', 'a'..'z', '\u00C0'..'\u00D6', '\u00D8'..'\u00F6',
<  *    '\u00F8'..'\u1FFF', '\u3040'..'\u318F', '\u3300'..'\u337F',
<  *    '\u3400'..'\u3D2D', '\u4E00'..'\u9FFF', '\uF900'..'\uFAFF'}"
<  *    using multiple alternatives: 1, 2
<  *  As a result, alternative(s) 2 were disabled for that input
<  *
<  *  You can turn enum on/off as a keyword :)
<  *
<  *  Version 1.0 -- initial release July 5, 2006 (requires 3.0b2 or higher)
<  *
<  *  Primary author: Terence Parr, July 2006
<  *
<  *  Version 1.0.1 -- corrections by Koen Vanderkimpen & Marko van Dooren,
<  *      October 25, 2006;
<  *      fixed normalInterfaceDeclaration: now uses typeParameters instead
<  *          of typeParameter (according to JLS, 3rd edition)
<  *      fixed castExpression: no longer allows expression next to type
<  *          (according to semantics in JLS, in contrast with syntax in JLS)
<  *
<  *  Version 1.0.2 -- Terence Parr, Nov 27, 2006
<  *      java spec I built this from had some bizarre for-loop control.
<  *          Looked weird and so I looked elsewhere...Yep, it's messed up.
<  *          simplified.
<  *
<  *  Version 1.0.3 -- Chris Hogue, Feb 26, 2007
<  *      Factored out an annotationName rule and used it in the annotation rule.
<  *          Not sure why, but typeName wasn't recognizing references to inner
<  *          annotations (e.g. @InterfaceName.InnerAnnotation())
<  *      Factored out the elementValue section of an annotation reference.  Created 
<  *          elementValuePair and elementValuePairs rules, then used them in the 
<  *          annotation rule.  Allows it to recognize annotation references with 
<  *          multiple, comma separated attributes.
<  *      Updated elementValueArrayInitializer so that it allows multiple elements.
<  *          (It was only allowing 0 or 1 element).
<  *      Updated localVariableDeclaration to allow annotations.  Interestingly the JLS
<  *          doesn't appear to indicate this is legal, but it does work as of at least
<  *          JDK 1.5.0_06.
<  *      Moved the Identifier portion of annotationTypeElementRest to annotationMethodRest.
<  *          Because annotationConstantRest already references variableDeclarator which 
<  *          has the Identifier portion in it, the parser would fail on constants in 
<  *          annotation definitions because it expected two identifiers.  
<  *      Added optional trailing ';' to the alternatives in annotationTypeElementRest.
<  *          Wouldn't handle an inner interface that has a trailing ';'.
<  *      Swapped the expression and type rule reference order in castExpression to 
<  *          make it check for genericized casts first.  It was failing to recognize a
<  *          statement like  "Class<Byte> TYPE = (Class<Byte>)...;" because it was seeing
<  *          'Class<Byte' in the cast expression as a less than expression, then failing 
<  *          on the '>'.
<  *      Changed createdName to use typeArguments instead of nonWildcardTypeArguments.
<  *          Again, JLS doesn't seem to allow this, but java.lang.Class has an example of
<  *          of this construct.
<  *      Changed the 'this' alternative in primary to allow 'identifierSuffix' rather than
<  *          just 'arguments'.  The case it couldn't handle was a call to an explicit
<  *          generic method invocation (e.g. this.<E>doSomething()).  Using identifierSuffix
<  *          may be overly aggressive--perhaps should create a more constrained thisSuffix rule?
<  *      
<  *  Version 1.0.4 -- Hiroaki Nakamura, May 3, 2007
<  *
<  *  Fixed formalParameterDecls, localVariableDeclaration, forInit,
<  *  and forVarControl to use variableModifier* not 'final'? (annotation)?
<  *
<  *  Version 1.0.5 -- Terence, June 21, 2007
<  *  --a[i].foo didn't work. Fixed unaryExpression
<  *
<  *  Version 1.0.6 -- John Ridgway, March 17, 2008
<  *      Made "assert" a switchable keyword like "enum".
<  *      Fixed compilationUnit to disallow "annotation importDeclaration ...".
<  *      Changed "Identifier ('.' Identifier)*" to "qualifiedName" in more 
<  *          places.
<  *      Changed modifier* and/or variableModifier* to classOrInterfaceModifiers,
<  *          modifiers or variableModifiers, as appropriate.
<  *      Renamed "bound" to "typeBound" to better match language in the JLS.
<  *      Added "memberDeclaration" which rewrites to methodDeclaration or 
<  *      fieldDeclaration and pulled type into memberDeclaration.  So we parse 
<  *          type and then move on to decide whether we're dealing with a field
<  *          or a method.
<  *      Modified "constructorDeclaration" to use "constructorBody" instead of
<  *          "methodBody".  constructorBody starts with explicitConstructorInvocation,
<  *          then goes on to blockStatement*.  Pulling explicitConstructorInvocation
<  *          out of expressions allowed me to simplify "primary".
<  *      Changed variableDeclarator to simplify it.
<  *      Changed type to use classOrInterfaceType, thus simplifying it; of course
<  *          I then had to add classOrInterfaceType, but it is used in several 
<  *          places.
<  *      Fixed annotations, old version allowed "@X(y,z)", which is illegal.
<  *      Added optional comma to end of "elementValueArrayInitializer"; as per JLS.
<  *      Changed annotationTypeElementRest to use normalClassDeclaration and 
<  *          normalInterfaceDeclaration rather than classDeclaration and 
<  *          interfaceDeclaration, thus getting rid of a couple of grammar ambiguities.
<  *      Split localVariableDeclaration into localVariableDeclarationStatement
<  *          (includes the terminating semi-colon) and localVariableDeclaration.  
<  *          This allowed me to use localVariableDeclaration in "forInit" clauses,
<  *           simplifying them.
<  *      Changed switchBlockStatementGroup to use multiple labels.  This adds an
<  *          ambiguity, but if one uses appropriately greedy parsing it yields the
<  *           parse that is closest to the meaning of the switch statement.
<  *      Renamed "forVarControl" to "enhancedForControl" -- JLS language.
<  *      Added semantic predicates to test for shift operations rather than other
<  *          things.  Thus, for instance, the string "< <" will never be treated
<  *          as a left-shift operator.
<  *      In "creator" we rule out "nonWildcardTypeArguments" on arrayCreation, 
<  *          which are illegal.
<  *      Moved "nonWildcardTypeArguments into innerCreator.
<  *      Removed 'super' superSuffix from explicitGenericInvocation, since that
<  *          is only used in explicitConstructorInvocation at the beginning of a
<  *           constructorBody.  (This is part of the simplification of expressions
<  *           mentioned earlier.)
<  *      Simplified primary (got rid of those things that are only used in
<  *          explicitConstructorInvocation).
<  *      Lexer -- removed "Exponent?" from FloatingPointLiteral choice 4, since it
<  *          led to an ambiguity.
<  *
<  *      This grammar successfully parses every .java file in the JDK 1.5 source 
<  *          tree (excluding those whose file names include '-', which are not
<  *          valid Java compilation units).
<  *
<  *  Version 1.0.6.CD -- Peter Bulychev, April 25, 2008
<  *	Small modifications for supporting Clone Digger
<  *
<  *  Known remaining problems:
<  *      "Letter" and "JavaIDDigit" are wrong.  The actual specification of
<  *      "Letter" should be "a character for which the method
<  *      Character.isJavaIdentifierStart(int) returns true."  A "Java 
<  *      letter-or-digit is a character for which the method 
<  *      Character.isJavaIdentifierPart(int) returns true."
<  */
< grammar JavaAST;
< options {
<     k=2; 
<     backtrack=true; 
<     memoize=true;
<     output=AST;
<     ASTLabelType=MyAstNode;
< }
< 
< tokens {
<     COMPILATION_UNIT;
<     PACKAGE_DECLARATION;
<     SINGLE_TYPE_IMPORT_DECLARATION;
<     TYPE_IMPORT_ON_DEMAND_DECLARATION;
<     SINGLE_STATIC_IMPORT_DECLARATION;
<     STATIC_IMPORT_ON_DEMAND_DECLARATION;
<     MODIFIERS;
<     CLASS_DECLARATION;
<     TYPE_PARAMETERS;
<     TYPE_PARAMETER;
<     TYPE_BOUND;
<     ENUM_DECLARATION;
<     ENUM_BODY;
<     ENUM_CONSTANTS;
<     ENUM_CONSTANT;
<     ENUM_BODY_DECLARATIONS;
<     INTERFACE_DECLARATION;
<     CLASS_BODY;
<     INTERFACE_BODY;
<     STATIC_INITIALIZER;
<     INSTANCE_INITIALIZER;
<     VOID;
<     FIELD_DECLARATION;
<     METHOD_DECLARATION;
<     ABSTRACT_METHOD_DECLARATION;
<     CONSTRUCTOR_DECLARATION;
<     VARIABLE_DECLARATOR;
<     CONSTANT_DECLARATION;
<     ARRAY_OF;
<     ARRAY_INITIALIZER;
<     CONSTRUCTOR_BODY;
<     INSTANTIATION;
<     SELECT;
<     TYPE_ARGUMENTS;
<     WILDCARD;
<     FORMAL_PARAMETERS;
<     FORMAL_PARAMETER;
<     LAST_FORMAL_PARAMETER;
<     ALTERNATE_CONSTRUCTOR_INVOCATION;
<     UNQUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION;
<     QUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION;
<     NORMAL_ANNOTATION;
<     SINGLE_ELEMENT_ANNOTATION;
<     MARKER_ANNOTATION;
<     ELEMENT_VALUE_PAIR;
<     ELEMENT_VALUE_ARRAY_INITIALIZER;
<     ANNOTATION_INTERFACE;
<     ANNOTATION_TYPE_BODY;
<     ANNOTATION_METHOD;
<     BLOCK;
<     LOCAL_VARIABLE_DECLARATION;
<     ASSERT_STATEMENT;
<     EMPTY_STATEMENT;
<     EXPRESSION_STATEMENT;
<     SWITCH_BLOCK_STATEMENT_GROUP;
<     BASIC_FOR_CONTROL;
<     FOR_INIT_DECLARATION;
<     FOR_INIT_EXPRESSION_LIST;
<     ENHANCED_FOR_CONTROL;
<     FOR_UPDATE;
<     EXPRESSION_LIST;
<     LEFT_SHIFT_ASSIGN;
<     UNSIGNED_RIGHT_SHIFT_ASSIGN;
<     SIGNED_RIGHT_SHIFT_ASSIGN;
<     LESS_THAN_OR_EQUAL_TO;
<     GREATER_THAN_OR_EQUAL_TO;
<     LEFT_SHIFT;
<     UNSIGNED_RIGHT_SHIFT;
<     SIGNED_RIGHT_SHIFT;
<     PREFIX_EXPRESSION;
<     POST_INCREMENT_EXPRESSION;
<     POST_DECREMENT_EXPRESSION;
<     CAST;
<     THIS;
<     UNQUALIFIED_SUPER;
<     CLASS_DESIGNATOR;
<     ARRAY_ACCESS;
<     CALL;
<     QUALIFIED_THIS;
<     QUALIFIED_SUPER;
<     UNQUALIFIED_CLASS_INSTANCE_CREATION;
<     QUALIFIED_CLASS_INSTANCE_CREATION;
<     NEW_INITIALIZED_ARRAY;
<     NEW_ARRAY;
<     EXPLICIT_GENERIC_INVOCATIONS;
<     NON_WILD_TYPE_ARGUMENTS;
<     INNER_THIS;
<     ARGUMENTS;
< }
< 
< @lexer::members {
<   protected boolean enumIsKeyword = true;
<   protected boolean assertIsKeyword = true;
< }
< 
< // starting point for parsing a java file
< /* The annotations are separated out to make parsing faster, but must be associated with
<    a packageDeclaration or a typeDeclaration (and not an empty one). */
< compilationUnit
<     :   ('@')=> annotations
<         (   packageDeclaration[$annotations.tree] importDeclaration* typeDeclaration*
<             -> ^(COMPILATION_UNIT packageDeclaration importDeclaration* typeDeclaration*)
<         |   classOrInterfaceDeclaration[$annotations.tree] typeDeclaration*
<             -> ^(COMPILATION_UNIT classOrInterfaceDeclaration typeDeclaration*)
<        )
<     |   (packageDeclaration[null])? importDeclaration* typeDeclaration*
<         -> ^(COMPILATION_UNIT packageDeclaration? importDeclaration* typeDeclaration*)
<     ;
< 
< packageDeclaration[Tree annotations]
<     :   'package' qualifiedName ';'
<         -> ^(PACKAGE_DECLARATION {annotations} qualifiedName)
<     ;
<     
< importDeclaration
<     :   'import' (staticModifier='static')? qualifiedName ('.' wildcard='*')? ';'
<         -> {staticModifier == null && wildcard == null}?
<             ^(SINGLE_TYPE_IMPORT_DECLARATION qualifiedName)
<         -> {staticModifier == null && wildcard != null}?
<             ^(TYPE_IMPORT_ON_DEMAND_DECLARATION qualifiedName)
<         -> {staticModifier != null && wildcard == null}?
<             ^(SINGLE_STATIC_IMPORT_DECLARATION qualifiedName)
<         -> /*{staticModifier != null && wildcard != null}? */
<             ^(STATIC_IMPORT_ON_DEMAND_DECLARATION qualifiedName)
<     ;
<     
< typeDeclaration
<     :   classOrInterfaceDeclaration[null]
<     |   ';'
<         ->
<     ;
<     
< classOrInterfaceDeclaration[Tree annotations]
<     :   classOrInterfaceModifiers[annotations]! (classDeclaration[$classOrInterfaceModifiers.tree] | interfaceDeclaration[$classOrInterfaceModifiers.tree])
<     ;
<     
< classOrInterfaceModifiers[Tree annotations]
<     :   classOrInterfaceModifier*
<         -> ^(MODIFIERS {annotations} classOrInterfaceModifier*)
<     ;
< 
< classOrInterfaceModifier
<     :   annotation   // class or interface
<     |   'public'     // class or interface
<     |   'protected'  // class or interface
<     |   'private'    // class or interface
<     |   'abstract'   // class or interface
<     |   'static'     // class or interface
<     |   'final'      // class only -- does not apply to interfaces
<     |   'strictfp'   // class or interface
<     ;
< 
< modifiers
<     :   modifier*
<         -> ^(MODIFIERS modifier*)
<     ;
< 
< classDeclaration[Tree modifiers]
<     :   normalClassDeclaration[modifiers]
<     |   enumDeclaration[modifiers]
<     ;
<     
< normalClassDeclaration[Tree modifiers]
< @after {retval.tree.is_statement = true;}
<     :   'class' identifier (typeParameters)?
<         (extendsPhrase)?
<         (implementsPhrase)?
<         classBody
<         -> ^(CLASS_DECLARATION {modifiers} identifier typeParameters? extendsPhrase? implementsPhrase? classBody)
<     ;
< 
< extendsPhrase
<     :   'extends' type
<         -> ^('extends' type)
<     ;
< 
< implementsPhrase
<     :   'implements' typeList
<         -> ^('implements' typeList)
<     ;
< 
< typeParameters
<     :   '<' typeParameter (',' typeParameter)* '>'
<         -> ^(TYPE_PARAMETERS typeParameter+)
<     ;
< 
< typeParameter
<     :   identifier ('extends' typeBound)?
<         -> ^(TYPE_PARAMETER identifier typeBound?)
<     ;
<         
< typeBound
<     :   type ('&' type)*
<         -> ^(TYPE_BOUND type+)
<     ;
< 
< enumDeclaration[Tree modifiers]
<     :   ENUM identifier (implementsPhrase)? enumBody
<         -> ^(ENUM_DECLARATION {modifiers} identifier implementsPhrase? enumBody)
<     ;
< 
< enumBody
<     :   '{' enumConstants? ','? enumBodyDeclarations? '}'
<         -> ^(ENUM_BODY enumConstants? enumBodyDeclarations?)
<     ;
< 
< enumConstants
<     :   enumConstant (',' enumConstant)*
<         -> ^(ENUM_CONSTANTS enumConstant+)
<     ;
<     
< enumConstant
<     :   annotations? identifier (arguments)? (classBody)?
<         -> ^(ENUM_CONSTANT annotations? identifier arguments? classBody?)
<     ;
<     
< enumBodyDeclarations
<     :   ';' (classBodyDeclaration)*
<         -> ^(ENUM_BODY_DECLARATIONS classBodyDeclaration*)
<     ;
<     
< interfaceDeclaration[Tree modifiers]
<     :   normalInterfaceDeclaration[modifiers]
<     |   annotationTypeDeclaration[modifiers]
<     ;
<     
< normalInterfaceDeclaration[Tree modifiers]
<     :   'interface' identifier typeParameters? (extendsInterfaces)? interfaceBody
<         -> ^(INTERFACE_DECLARATION {modifiers} identifier typeParameters? extendsInterfaces? interfaceBody)
<     ;
< 
< extendsInterfaces
<     :   'extends' typeList
<         -> ^('extends' typeList)
<     ;
<     
< typeList
<     :   type (','! type)*
<     ;
<     
< classBody
<     :   '{' classBodyDeclaration* '}'
<         -> ^(CLASS_BODY classBodyDeclaration*)
<     ;
<     
< interfaceBody
<     :   '{' interfaceBodyDeclaration* '}'
<         -> ^(INTERFACE_BODY interfaceBodyDeclaration*)
<     ;
< 
< classBodyDeclaration
<     :   ';'
<         ->
<     |   'static' block
<         -> ^(STATIC_INITIALIZER block)
<     |   block
<         -> ^(INSTANCE_INITIALIZER block)
<     |   modifiers! memberDecl[$modifiers.tree]
<     ;
<     
< memberDecl[Tree modifiers]
<     :   genericMethodOrConstructorDecl[modifiers]
<     |   memberDeclaration[modifiers]
<     |   'void' identifier voidMethodDeclaratorRest[modifiers, $identifier.tree]
<         -> voidMethodDeclaratorRest
<     |   identifier constructorDeclaratorRest[modifiers, null, $identifier.tree]
<         -> constructorDeclaratorRest
<     |   interfaceDeclaration[modifiers]
<     |   classDeclaration[modifiers]
<     ;
<     
< memberDeclaration[Tree modifiers]
<     :   type! (methodDeclaration[modifiers, $type.tree]
<               | fieldDeclaration[modifiers, $type.tree])
<     ;
< 
< genericMethodOrConstructorDecl[Tree modifiers]
<     :   typeParameters! genericMethodOrConstructorRest[modifiers, $typeParameters.tree]
<     ;
<     
< genericMethodOrConstructorRest[Tree modifiers, Tree typeParameters]
<     :   rt=resultType! identifier! 
<         methodDeclaratorRest[modifiers, typeParameters, $rt.tree, $identifier.tree]
<     |   identifier! constructorDeclaratorRest[modifiers, typeParameters, $identifier.tree]
<     ;
< 
< resultType 
<     :   type
<     |   'void' -> VOID
<     ;
< 
< methodDeclaration[Tree modifiers, Tree returnType]
<     :   identifier! methodDeclaratorRest[modifiers, returnType, null, $identifier.tree]
<     ;
< 
< fieldDeclaration[Tree modifiers, Tree fieldType]
<     :   variableDeclarators ';'
<         -> ^(FIELD_DECLARATION {modifiers} {fieldType} variableDeclarators)
<     ;
<         
< interfaceBodyDeclaration
<     :   modifiers! interfaceMemberDecl[$modifiers.tree]
<     |   ';'!
<     ;
< 
< interfaceMemberDecl[Tree modifiers]
<     :   interfaceMethodOrFieldDecl[modifiers]
<     |   interfaceGenericMethodDecl[modifiers]
<     |   'void'! identifier! voidInterfaceMethodDeclaratorRest[modifiers, $identifier.tree]
<     |   interfaceDeclaration[ modifiers]
<     |   classDeclaration[modifiers]
<     ;
<     
< interfaceMethodOrFieldDecl[Tree modifiers]
<     :   t=type! identifier! interfaceMethodOrFieldRest[modifiers, t.tree, $identifier.tree]
<     ;
<     
< interfaceMethodOrFieldRest[Tree modifiers, Tree type, Tree identifier]
<     :   constantDeclaratorsRest[modifiers, type, identifier] ';'!
<     |   interfaceMethodDeclaratorRest[modifiers, null, type, identifier]
<     ;
< 
< /* This converts obsolete post-formal '[]' array specifiers to array specifiers on the
<    return type in the AST. */    
< methodDeclaratorRest[Tree modifiers, Tree type, Tree typeParameters, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters 
<         ( '[' ']'
<           { type = (Tree)adaptor.becomeRoot(adaptor.create(ARRAY_OF, "ARRAY_OF"), type); }
<         )*
<         (throwsPhrase)?
<         (  methodBody
<             -> ^(METHOD_DECLARATION {modifiers} {$type} {typeParameters} {identifier}
<                  formalParameters (throwsPhrase)? methodBody)
<         |   ';'
<             -> ^(METHOD_DECLARATION {modifiers} {$type} {typeParameters} {identifier}
<                  formalParameters (throwsPhrase)?)
<         )
<     ;
< 
< throwsPhrase
<     :   'throws' qualifiedNameList -> ^('throws' qualifiedNameList)
<     ;
<     
< voidMethodDeclaratorRest[Tree modifiers, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters (throwsPhrase)?
<         (  methodBody
<             -> ^(METHOD_DECLARATION {modifiers} VOID {identifier} formalParameters 
<                 (throwsPhrase)? methodBody)
<         |   ';'
<             -> ^(METHOD_DECLARATION {modifiers} VOID {identifier} formalParameters 
<                 (throwsPhrase)?)
<        )
<     ;
<     
< interfaceMethodDeclaratorRest[Tree modifiers, Tree typeParameters, Tree type, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters 
<         ('[' ']'
<             { type = (Tree)adaptor.becomeRoot(adaptor.create(ARRAY_OF, "ARRAY_OF"), type); })*
<         (throwsPhrase)? ';'
<         -> ^(ABSTRACT_METHOD_DECLARATION {modifiers} {typeParameters} {type} {identifier} formalParameters (throwsPhrase)?)
<     ;
<     
< interfaceGenericMethodDecl[Tree modifiers]
<     :   typeParameters! rt=resultType! identifier!
<         interfaceMethodDeclaratorRest[modifiers, $typeParameters.tree, rt.tree, $identifier.tree]
<     ;
<     
< voidInterfaceMethodDeclaratorRest[Tree modifiers, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters (throwsPhrase)? ';'
<         -> ^(ABSTRACT_METHOD_DECLARATION {modifiers} VOID {identifier} formalParameters (throwsPhrase)?)
<     ;
<     
< constructorDeclaratorRest[Tree modifiers, Tree typeParameters, Tree identifier]
<     :   formalParameters (throwsPhrase)? constructorBody
<         -> ^(CONSTRUCTOR_DECLARATION {modifiers} {typeParameters} {identifier}
<              formalParameters (throwsPhrase)? constructorBody)
<     ;
< 
< constantDeclarator[Tree modifiers, Tree type]
<     :   identifier! constantDeclaratorRest[modifiers, type, $identifier.tree]
<     ;
<     
< variableDeclarators
<     :   variableDeclarator (',' variableDeclarator)*
<         -> variableDeclarator+
<     ;
< 
< variableDeclarator
<     :   variableDeclaratorId ('=' variableInitializer)?
<         -> ^(VARIABLE_DECLARATOR variableDeclaratorId variableInitializer?)
<     ;
<     
< constantDeclaratorsRest[Tree modifiers, Tree type, Tree identifier]
<     :   constantDeclaratorRest[modifiers, type, identifier] (','! constantDeclarator[modifiers, type])*
<     ;
< 
< constantDeclaratorRest[Tree modifiers, Tree type, Tree identifier]
<     :   ('[' ']'
<             { type = (Tree)adaptor.becomeRoot(adaptor.create(ARRAY_OF, "ARRAY_OF"), type); })*
<         '=' variableInitializer
<         -> ^(CONSTANT_DECLARATION {modifiers} {type} {identifier} variableInitializer)
<         ;
<     
< variableDeclaratorId
<     :   (identifier -> identifier) 
<         ('[' ']' -> ^(ARRAY_OF $variableDeclaratorId) )*
<     ;
< 
< variableInitializer
<     :   arrayInitializer
<     |   expression
<     ;
<         
< arrayInitializer
<     :   '{' (variableInitializer (',' variableInitializer)* (',')? )? '}'
<         -> ^(ARRAY_INITIALIZER variableInitializer*)
<     ;
< 
< modifier
<     :   annotation
<     |   'public'
<     |   'protected'
<     |   'private'
<     |   'static'
<     |   'abstract'
<     |   'final'
<     |   'native'
<     |   'synchronized'
<     |   'transient'
<     |   'volatile'
<     |   'strictfp'
<     ;
< 
< packageOrTypeName
<     :   qualifiedName
<     ;
< 
< enumConstantName
<     :   identifier
<     ;
< 
< typeName
<     :   qualifiedName
<     ;
< 
< // 4.1 -- The Kinds of Types and Values
< type
< 	:	( classOrInterfaceType -> classOrInterfaceType )
<         ( '[' ']' -> ^(ARRAY_OF $type) )*
< 	|	( primitiveType -> primitiveType )
<         ( '[' ']' -> ^(ARRAY_OF $type) )*
< 	;
< 
< classOrInterfaceType
< 	:	( identifier -> identifier )
<         ( typeArguments -> ^(INSTANTIATION $classOrInterfaceType typeArguments) )?
<         ( ( '.' identifier -> ^(SELECT $classOrInterfaceType identifier) )
<           (typeArguments -> ^(INSTANTIATION $classOrInterfaceType typeArguments) )? 
<         )*
< 	;
< 
< primitiveType
<     :   'boolean'
<     |   'char'
<     |   'byte'
<     |   'short'
<     |   'int'
<     |   'long'
<     |   'float'
<     |   'double'
<     ;
< 
< variableModifier
<     :   'final'
<     |   annotation
<     ;
< 
< typeArguments
<     :   '<' typeArgument (',' typeArgument)* '>'
<         -> ^(TYPE_ARGUMENTS typeArgument+)
<     ;
<     
< typeArgument
<     :   type
<         -> type
<     |   '?' ((kind='extends' | kind='super') type)?
<         -> ^(WILDCARD $kind? type?)
<     ;
<     
< qualifiedNameList
<     :   qualifiedName (','! qualifiedName)*
<     ;
< 
< formalParameters
<     :   '(' formalParameterDecls? ')'
<         -> ^(FORMAL_PARAMETERS formalParameterDecls?)
<     ;
<     
< formalParameterDecls
<     :   variableModifiers! pType=type! formalParameterDeclsRest[$variableModifiers.tree, pType.tree]
<     ;
<     
< formalParameterDeclsRest[Tree modifiers, Tree type]
<     :   variableDeclaratorId 
<         (',' formalParameterDecls
<             -> ^(FORMAL_PARAMETER {modifiers} {type} variableDeclaratorId) formalParameterDecls
<         |
<             -> ^(FORMAL_PARAMETER {modifiers} {type} variableDeclaratorId)
<         )
<     |   '...' variableDeclaratorId
<         -> ^(LAST_FORMAL_PARAMETER {modifiers} {type} variableDeclaratorId)
<     ;
<     
< methodBody
<     :   block
<     ;
< 
< constructorBody
<     :   '{' explicitConstructorInvocation? blockStatement* '}'
<         -> ^(CONSTRUCTOR_BODY explicitConstructorInvocation? blockStatement*)
<     ;
< 
< explicitConstructorInvocation
<     :   (nonWildcardTypeArguments)?
<         ( ( 'this' arguments ';' 
<             -> ^(ALTERNATE_CONSTRUCTOR_INVOCATION nonWildcardTypeArguments? arguments) )
<         | ( 'super' arguments ';'
<             -> ^(UNQUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION nonWildcardTypeArguments? arguments) )
<         )
<     |   primary '.' nonWildcardTypeArguments? 'super' arguments ';'
<         -> ^(QUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION primary nonWildcardTypeArguments? arguments)
<     ;
< 
< 
< qualifiedName
<     :   (identifier->identifier)
<         ('.' identifier -> ^(SELECT $qualifiedName identifier))*
<     ;
<     
< literal 
<     :   integerLiteral
<     |   FloatingPointLiteral
<     |   CharacterLiteral
<     |   StringLiteral
<     |   booleanLiteral
<     |   'null'
<     ;
< 
< integerLiteral
<     :   HexLiteral
<     |   OctalLiteral
<     |   DecimalLiteral
<     ;
< 
< booleanLiteral
<     :   'true'
<     |   'false'
<     ;
< 
< // ANNOTATIONS
< 
< annotations
<     :   annotation+
<     ;
< 
< annotation
<     :   '@' annotationName 
<         ( '(' ( elementValuePairs
<                 -> ^(NORMAL_ANNOTATION annotationName elementValuePairs)
<               | elementValue 
<                 -> ^(SINGLE_ELEMENT_ANNOTATION annotationName elementValue)
<               )? 
<           ')'
<         | // Nothing
<           -> ^(MARKER_ANNOTATION annotationName)
<         )
<     ;
<     
< annotationName
<     :   (identifier -> identifier)
<         ('.' id=identifier -> ^(SELECT $annotationName $id))*
<     ;
< 
< elementValuePairs
<     :   elementValuePair (',' elementValuePair)*
<         -> elementValuePair+
<     ;
< 
< elementValuePair
<     :   identifier '=' elementValue
<         -> ^(ELEMENT_VALUE_PAIR identifier elementValue)
<     ;
<     
< elementValue
<     :   conditionalExpression
<     |   annotation
<     |   elementValueArrayInitializer
<     ;
<     
< elementValueArrayInitializer
<     :   '{' (elementValue (',' elementValue)*)? (',')? '}'
<         -> ^(ELEMENT_VALUE_ARRAY_INITIALIZER elementValue+)
<     ;
<     
< annotationTypeDeclaration[Tree modifiers]
<     :   '@' 'interface' identifier annotationTypeBody
<         -> ^(ANNOTATION_INTERFACE {modifiers} identifier annotationTypeBody)
<     ;
<     
< annotationTypeBody
<     :   '{' (annotationTypeElementDeclaration)* '}'
<         -> ^(ANNOTATION_TYPE_BODY annotationTypeElementDeclaration*)
<     ;
<     
< annotationTypeElementDeclaration
<     :   modifiers! annotationTypeElementRest[$modifiers.tree]
<     ;
<     
< annotationTypeElementRest[Tree modifiers]
<     :   type annotationMethodOrConstantRest[modifiers, $type.tree] ';'
<         -> annotationMethodOrConstantRest
<     |   normalClassDeclaration[modifiers] ';'!?
<     |   normalInterfaceDeclaration[modifiers] ';'!?
<     |   enumDeclaration[modifiers] ';'!?
<     |   annotationTypeDeclaration[modifiers] ';'!?
<     ;
<     
< annotationMethodOrConstantRest[Tree modifiers, Tree type]
<     :   annotationMethodRest[modifiers, type]
<     |   annotationConstantRest[modifiers, type]
<     ;
<     
< annotationMethodRest[Tree modifiers, Tree type]
<     :   identifier '(' ')' (defaultValue)?
<         -> ^(ANNOTATION_METHOD {modifiers} {type} identifier defaultValue?)
<     ;
<     
< annotationConstantRest[Tree modifiers, Tree type]
<     :   variableDeclarators
<         -> ^(FIELD_DECLARATION {$modifiers} {$type} variableDeclarators)
<     ;
<     
< defaultValue
<     :   'default' elementValue
<         -> ^('default' elementValue)
<     ;
< 
< // STATEMENTS / BLOCKS
< 
< block
< @after {retval.tree.is_statement = true;}
<     :   '{' blockStatement* '}'
<         -> ^(BLOCK blockStatement*)
<     ;
<     
< blockStatement
<     :   localVariableDeclarationStatement
<     |   classOrInterfaceDeclaration[null]
<     |   statement
<     ;
<     
< localVariableDeclarationStatement
<     :    localVariableDeclaration ';'!
<     ;
< 
< localVariableDeclaration
< @after {retval.tree.is_statement = true;}
<     :   variableModifiers type variableDeclarators
<         -> ^(LOCAL_VARIABLE_DECLARATION variableModifiers type variableDeclarators)
<     ;
<     
< variableModifiers
<     :   variableModifier*
<         -> ^(MODIFIERS variableModifier*)
<     ;
< 
< statement
< @after {retval.tree.is_statement = true;}
<     : block
<     |   ASSERT e1=expression (':' e2=expression)? ';'
<         -> ^(ASSERT_STATEMENT $e1 $e2?)
<     |   'if' parExpression statement (options {k=1;}:'else' statement)?
<         -> ^('if' parExpression statement+)
<     |   'for' '(' forControl ')' statement
<         -> ^('for' forControl statement)
<     |   'while'^ parExpression statement
<         -> ^('while' parExpression statement)
<     |   'do' statement 'while' parExpression ';'
<         -> ^('do' statement parExpression)
<     |   'try' tryBlock=block
<         ( catches 'finally' finallyBlock=block
<             -> ^('try' $tryBlock catches ^('finally' $finallyBlock))
<         | catches
<             -> ^('try' $tryBlock catches)
<         |   'finally' finallyBlock=block
<             -> ^('try' $tryBlock ^('finally' $finallyBlock))
<         )
<     |   'switch' parExpression '{' switchBlockStatementGroups '}'
<         -> ^('switch' parExpression switchBlockStatementGroups)
<     |   'synchronized' parExpression block
<         -> ^('synchronized' parExpression block)
<     |   'return' expression? ';'
<         -> ^('return' expression?)
<     |   'throw' expression ';'
<         -> ^('throw' expression)
<     |   'break' identifier? ';'
<         -> ^('break' identifier?)
<     |   'continue' identifier? ';'
<         -> ^('continue' identifier?)
<     |   ';' 
<         -> EMPTY_STATEMENT
<     |   statementExpression ';'
<         -> ^(EXPRESSION_STATEMENT statementExpression)
<     |   identifier ':' statement
<         -> ^(':' identifier statement)
<     ;
<     
< catches
<     :   catchClause (catchClause)*
<     ;
<     
< catchClause
<     :   'catch' '(' formalParameter ')' block
<         -> ^('catch' formalParameter block)
<     ;
< 
< formalParameter
<     :   variableModifiers type variableDeclaratorId
<         -> ^(FORMAL_PARAMETER variableModifiers type variableDeclaratorId)
<     ;
<         
< switchBlockStatementGroups
<     :   (switchBlockStatementGroup)*
<     ;
<     
< /* The change here (switchLabel -> switchLabel+) technically makes this grammar
<    ambiguous; but with appropriately greedy parsing it yields the most
<    appropriate AST, one in which each group, except possibly the last one, has
<    labels and statements. */
< switchBlockStatementGroup
<     :   switchLabel+ blockStatement*
<         -> ^(SWITCH_BLOCK_STATEMENT_GROUP switchLabel+ blockStatement*)
<     ;
<     
< switchLabel
<     :   'case'^ constantExpression ':'!
<     |   'case'^ enumConstantName ':'!
<     |   'default'^ ':'!
<     ;
<     
< forControl
< options {k=3;} // be efficient for common case: for (ID ID : ID) ...
<     :   enhancedForControl
<     |   forInit? ';' expression? ';' forUpdate?
<         -> ^(BASIC_FOR_CONTROL forInit? ';' expression? ';' forUpdate?)
<     ;
< 
< forInit
<     :   localVariableDeclaration
<         -> ^(FOR_INIT_DECLARATION localVariableDeclaration)
<     |   expressionList
<         -> ^(FOR_INIT_EXPRESSION_LIST expressionList)
<     ;
<     
< enhancedForControl
<     :   variableModifiers type identifier ':' expression
<         -> ^(ENHANCED_FOR_CONTROL variableModifiers type identifier expression)
<     ;
< 
< forUpdate
<     :   expressionList
<         -> ^(FOR_UPDATE expressionList)
<     ;
< 
< // EXPRESSIONS
< 
< parExpression
<     :   '('! expression ')'!
<     ;
<     
< expressionList
<     :   expression (',' expression)*
<         -> ^(EXPRESSION_LIST expression+)
<     ;
< 
< statementExpression
<     :   expression
<     ;
<     
< constantExpression
<     :   expression
<     ;
<     
< expression
<     :   conditionalExpression (assignmentOperator^ expression)?
<     ;
<     
< assignmentOperator
<     :   '='
<     |   '+='
<     |   '-='
<     |   '*='
<     |   '/='
<     |   '&='
<     |   '|='
<     |   '^='
<     |   '%='
<     |   ('<' '<' '=')=> t1='<' t2='<' t3='=' 
<         { $t1.getLine() == $t2.getLine() &&
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() && 
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() }?
<         -> LEFT_SHIFT_ASSIGN
<     |   ('>' '>' '>' '=')=> t1='>' t2='>' t3='>' t4='='
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() &&
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() &&
<           $t3.getLine() == $t4.getLine() && 
<           $t3.getCharPositionInLine() + 1 == $t4.getCharPositionInLine() }?
<         -> UNSIGNED_RIGHT_SHIFT_ASSIGN
<     |   ('>' '>' '=')=> t1='>' t2='>' t3='='
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() && 
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() }?
<         -> SIGNED_RIGHT_SHIFT_ASSIGN
<     ;
< 
< conditionalExpression
<     :   conditionalOrExpression ( '?'^ expression ':'! expression )?
<     ;
< 
< conditionalOrExpression
<     :   conditionalAndExpression ( '||'^ conditionalAndExpression )*
<     ;
< 
< conditionalAndExpression
<     :   inclusiveOrExpression ('&&'^ inclusiveOrExpression)*
<     ;
< 
< inclusiveOrExpression
<     :   exclusiveOrExpression ('|'^ exclusiveOrExpression)*
<     ;
< 
< exclusiveOrExpression
<     :   andExpression ('^'^ andExpression)*
<     ;
< 
< andExpression
<     :   equalityExpression ('&'^ equalityExpression)*
<     ;
< 
< equalityExpression
<     :   instanceOfExpression (('==' | '!=')^ instanceOfExpression)*
<     ;
< 
< instanceOfExpression
<     :   relationalExpression ('instanceof'^ type)?
<     ;
< 
< relationalExpression
<     :   shiftExpression (relationalOp^ shiftExpression)*
<     ;
<     
< relationalOp
<     :   ('<' '=')=> t1='<' t2='=' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> LESS_THAN_OR_EQUAL_TO
<     |   ('>' '=')=> t1='>' t2='=' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> GREATER_THAN_OR_EQUAL_TO
<     |   '<' 
<     |   '>' 
<     ;
< 
< shiftExpression
<     :   additiveExpression (shiftOp^ additiveExpression)*
<     ;
< 
< shiftOp
<     :   ('<' '<')=> t1='<' t2='<' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> LEFT_SHIFT
<     |   ('>' '>' '>')=> t1='>' t2='>' t3='>' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() &&
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() }?
<         -> UNSIGNED_RIGHT_SHIFT
<     |   ('>' '>')=> t1='>' t2='>'
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> SIGNED_RIGHT_SHIFT 
<     ;
< 
< 
< additiveExpression
<     :   multiplicativeExpression (('+' | '-')^ multiplicativeExpression)*
<     ;
< 
< multiplicativeExpression
<     :   unaryExpression (('*' | '/' | '%')^ unaryExpression)*
<     ;
<     
< unaryExpression
<     :   '+' unaryExpression
<         -> ^(PREFIX_EXPRESSION '+' unaryExpression)
<     |   '-' unaryExpression
<         -> ^(PREFIX_EXPRESSION '-' unaryExpression)
<     |   '++' unaryExpression
<         -> ^(PREFIX_EXPRESSION '++' unaryExpression)
<     |   '--' unaryExpression
<         -> ^(PREFIX_EXPRESSION '--' unaryExpression)
<     |   unaryExpressionNotPlusMinus
<     ;
< 
< unaryExpressionNotPlusMinus
<     :   '~' unaryExpression     -> ^(PREFIX_EXPRESSION '~' unaryExpression)
<     |   '!' unaryExpression     -> ^(PREFIX_EXPRESSION '!' unaryExpression)
<     |   castExpression
<     |   ( primary -> primary )
<         ( (selector[null])=> selector[$unaryExpressionNotPlusMinus.tree]
<             -> selector )*
<         (  ( '++' -> ^(POST_INCREMENT_EXPRESSION $unaryExpressionNotPlusMinus )
<            | '--' -> ^(POST_DECREMENT_EXPRESSION $unaryExpressionNotPlusMinus )
<            ) )?
<     ;
< 
< castExpression
<     :  '(' primitiveType ')' unaryExpression
<         -> ^(CAST primitiveType unaryExpression)
<     |  '(' (type | expression) ')' unaryExpressionNotPlusMinus
<         -> ^(CAST type? expression? unaryExpressionNotPlusMinus)
<     ;
< 
< primary
<     :   parExpression
<     |   ( 'this' -> THIS)
<         ( '.' identifier -> ^(SELECT $primary identifier) )*
<         ( (identifierSuffix[null])=> identifierSuffix[$primary.tree] -> identifierSuffix )?
<     |   ( 'super' -> UNQUALIFIED_SUPER ) 
<         superSuffix[$primary.tree] -> superSuffix
<     |   literal
<     |   'new' creator
<         -> creator
<     |   ( identifier -> identifier )
<         ( '.' identifier -> ^(SELECT $primary identifier) )*
<         ( (identifierSuffix[null])=> identifierSuffix[$primary.tree] -> identifierSuffix )?
<     |   ( primitiveType -> primitiveType )
<         ( '[' ']' -> ^(ARRAY_OF $primary) )*
<         '.' 'class' -> ^(CLASS_DESIGNATOR $primary)
<     |   'void' '.' 'class'
<         -> ^(CLASS_DESIGNATOR VOID)
<     ;
< 
< identifierSuffix[Tree expr]
<     :   ( '[' ']' -> ^(ARRAY_OF {expr}))
<         ( '[' ']' -> ^(ARRAY_OF $identifierSuffix) )*
<         ( '.' 'class' -> ^(CLASS_DESIGNATOR $identifierSuffix) )
<     |   (-> {expr})
<         ('[' expression ']' -> ^(ARRAY_ACCESS $identifierSuffix expression))+
<     |   arguments
<         -> ^(CALL {expr} arguments)
<     |   '.' 'class'
<         -> ^(CLASS_DESIGNATOR {expr})
<     |   '.' explicitGenericInvocation[expr]
<         -> explicitGenericInvocation
<     |   '.' 'this'
<         -> ^(QUALIFIED_THIS {expr})
<     |   '.' 'super' arguments
<         -> ^(CALL ^(QUALIFIED_SUPER {expr}) arguments)
<     |   '.' 'new' innerCreator[expr]
<         -> innerCreator
<     ;
< 
< creator
<     :   nonWildcardTypeArguments createdName classCreatorRest
<         -> ^(UNQUALIFIED_CLASS_INSTANCE_CREATION nonWildcardTypeArguments createdName classCreatorRest)
<     |   createdName
<         (   (arrayCreatorRest[$createdName.tree]
<             -> arrayCreatorRest)
<         |   classCreatorRest
<             -> ^(UNQUALIFIED_CLASS_INSTANCE_CREATION createdName classCreatorRest)
<         )
<     ;
< 
< createdName
<     :   classOrInterfaceType
<     |   primitiveType
<     ;
<     
< innerCreator[Tree expr]
<     :   (nonWildcardTypeArguments)? identifier classCreatorRest
<         -> ^(QUALIFIED_CLASS_INSTANCE_CREATION {expr} nonWildcardTypeArguments? identifier classCreatorRest)
<     ;
< 
< arrayCreatorRest[Tree name]
<     :   
<         dims arrayInitializer
<         -> ^(NEW_INITIALIZED_ARRAY {$name} dims arrayInitializer)
<     |   '[' dimExprs+=expression ']' ('[' dimExprs+=expression ']')* dims?
<         -> ^(NEW_ARRAY {$name} $dimExprs dims?)
<     ;
< 
< dims
<     :   (result+='[' ']')+
<         -> $result
<     ;
< 
< classCreatorRest
<     :   arguments classBody?
<     ;
<     
< explicitGenericInvocation[Tree expr]
<     :   nonWildcardTypeArguments identifier arguments
<         -> ^(EXPLICIT_GENERIC_INVOCATIONS {expr} nonWildcardTypeArguments identifier arguments)
<     ;
<     
< nonWildcardTypeArguments
<     :   '<' typeList '>'
<         -> ^(NON_WILD_TYPE_ARGUMENTS typeList)
<     ;
<     
< selector[Tree expr]
<     :   ('.' identifier -> ^(SELECT {expr} identifier))
<         (arguments -> ^(CALL $selector arguments))?
<     |   '.' 'this'
<         -> ^(INNER_THIS {expr})
<     |   ( '.' 'super' -> ^(QUALIFIED_SUPER {expr}) )
<         superSuffix[$selector.tree]
<         -> superSuffix
<     |   '.' 'new' innerCreator[expr]
<         -> innerCreator
<     |   '[' expression ']'
<         -> ^(ARRAY_ACCESS {expr} expression)
<     ;
<     
< superSuffix[Tree expr]
<     :   arguments
<         -> ^(CALL {expr} arguments)
<     |   ('.' identifier -> ^(SELECT {$expr} identifier))
<         ( arguments -> ^(CALL $superSuffix arguments))?
<     ;
< 
< arguments
<     :   '(' expressionList? ')'
<         -> ^(ARGUMENTS expressionList?)
<     ;
< 
< identifier
<     :   Identifier
<     ;
< 
< // LEXER
< 
< HexLiteral : '0' ('x'|'X') HexDigit+ IntegerTypeSuffix? ;
< 
< DecimalLiteral : ('0' | '1'..'9' '0'..'9'*) IntegerTypeSuffix? ;
< 
< OctalLiteral : '0' ('0'..'7')+ IntegerTypeSuffix? ;
< 
< fragment
< HexDigit : ('0'..'9'|'a'..'f'|'A'..'F') ;
< 
< fragment
< IntegerTypeSuffix : ('l'|'L') ;
< 
< FloatingPointLiteral
<     :   ('0'..'9')+ '.' ('0'..'9')* Exponent? FloatTypeSuffix?
<     |   '.' ('0'..'9')+ Exponent? FloatTypeSuffix?
<     |   ('0'..'9')+ Exponent FloatTypeSuffix?
<     |   ('0'..'9')+ FloatTypeSuffix
<     ;
< 
< fragment
< Exponent : ('e'|'E') ('+'|'-')? ('0'..'9')+ ;
< 
< fragment
< FloatTypeSuffix : ('f'|'F'|'d'|'D') ;
< 
< CharacterLiteral
<     :   '\'' ( EscapeSequence | ~('\''|'\\') ) '\''
<     ;
< 
< StringLiteral
<     :  '"' ( EscapeSequence | ~('\\'|'"') )* '"'
<     ;
< 
< fragment
< EscapeSequence
<     :   '\\' ('b'|'t'|'n'|'f'|'r'|'\"'|'\''|'\\')
<     |   UnicodeEscape
<     |   OctalEscape
<     ;
< 
< fragment
< OctalEscape
<     :   '\\' ('0'..'3') ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7')
<     ;
< 
< fragment
< UnicodeEscape
<     :   '\\' 'u' HexDigit HexDigit HexDigit HexDigit
<     ;
< 
< ENUM:   'enum' {if (!enumIsKeyword) $type=Identifier;}
<     ;
<     
< ASSERT
<     :   'assert' {if (!assertIsKeyword) $type=Identifier;}
<     ;
<     
< Identifier 
<     :   Letter (Letter|JavaIDDigit)*
<     ;
< 
< /**I found this char range in JavaCC's grammar, but Letter and Digit overlap.
<    Still works, but...
<  */
< fragment
< Letter
<     :  '\u0024' |
<        '\u0041'..'\u005a' |
<        '\u005f' |
<        '\u0061'..'\u007a' |
<        '\u00c0'..'\u00d6' |
<        '\u00d8'..'\u00f6' |
<        '\u00f8'..'\u00ff' |
<        '\u0100'..'\u1fff' |
<        '\u3040'..'\u318f' |
<        '\u3300'..'\u337f' |
<        '\u3400'..'\u3d2d' |
<        '\u4e00'..'\u9fff' |
<        '\uf900'..'\ufaff'
<     ;
< 
< fragment
< JavaIDDigit
<     :  '\u0030'..'\u0039' |
<        '\u0660'..'\u0669' |
<        '\u06f0'..'\u06f9' |
<        '\u0966'..'\u096f' |
<        '\u09e6'..'\u09ef' |
<        '\u0a66'..'\u0a6f' |
<        '\u0ae6'..'\u0aef' |
<        '\u0b66'..'\u0b6f' |
<        '\u0be7'..'\u0bef' |
<        '\u0c66'..'\u0c6f' |
<        '\u0ce6'..'\u0cef' |
<        '\u0d66'..'\u0d6f' |
<        '\u0e50'..'\u0e59' |
<        '\u0ed0'..'\u0ed9' |
<        '\u1040'..'\u1049'
<    ;
< 
< WS  :  (' '|'\r'|'\t'|'\u000C'|'\n') {$channel=HIDDEN;}
<     ;
< 
< COMMENT
<     :   '/*' (options {greedy=false;} : .)* '*/' {$channel=HIDDEN;}
<     ;
< 
< LINE_COMMENT
<     : '//' ~('\n'|'\r')* '\r'? '\n' {$channel=HIDDEN;}
<     ;
diff -r -N code-worker/tasks/clonedigger/java_antlr/JavaAST.tokens code-worker/code-worker/tasks/clonedigger/java_antlr/JavaAST.tokens
1,287d0
< T__197=197
< FORMAL_PARAMETERS=39
< T__139=139
< PACKAGE_DECLARATION=5
< T__174=174
< HexDigit=101
< TYPE_ARGUMENTS=37
< T__196=196
< T__144=144
< T__122=122
< T__115=115
< ANNOTATION_INTERFACE=50
< T__137=137
< SIGNED_RIGHT_SHIFT=72
< UNSIGNED_RIGHT_SHIFT_ASSIGN=66
< T__140=140
< ENHANCED_FOR_CONTROL=62
< Letter=108
< COMPILATION_UNIT=4
< INTERFACE_DECLARATION=20
< LEFT_SHIFT=70
< CLASS_DESIGNATOR=79
< TYPE_BOUND=14
< CLASS_BODY=21
< T__138=138
< SELECT=36
< CONSTRUCTOR_DECLARATION=29
< T__173=173
< T__119=119
< CLASS_DECLARATION=11
< ASSERT=99
< MARKER_ANNOTATION=47
< EXPRESSION_STATEMENT=57
< T__198=198
< T__142=142
< T__176=176
< FloatTypeSuffix=104
< T__118=118
< T__135=135
< T__113=113
< ENUM_BODY=16
< FORMAL_PARAMETER=40
< IntegerTypeSuffix=102
< ARGUMENTS=91
< T__156=156
< NEW_ARRAY=87
< WS=110
< T__159=159
< T__177=177
< UNQUALIFIED_SUPER=78
< T__158=158
< NON_WILD_TYPE_ARGUMENTS=89
< LOCAL_VARIABLE_DECLARATION=54
< UnicodeEscape=106
< T__157=157
< ENUM_DECLARATION=15
< T__201=201
< T__114=114
< SINGLE_ELEMENT_ANNOTATION=46
< MODIFIERS=10
< T__143=143
< UNQUALIFIED_CLASS_INSTANCE_CREATION=84
< T__193=193
< T__141=141
< EMPTY_STATEMENT=56
< ENUM_BODY_DECLARATIONS=19
< OctalLiteral=97
< T__167=167
< T__194=194
< CAST=76
< EXPRESSION_LIST=64
< T__191=191
< TYPE_IMPORT_ON_DEMAND_DECLARATION=7
< SWITCH_BLOCK_STATEMENT_GROUP=58
< BLOCK=53
< UNSIGNED_RIGHT_SHIFT=71
< T__192=192
< EscapeSequence=105
< INTERFACE_BODY=22
< NEW_INITIALIZED_ARRAY=86
< SINGLE_STATIC_IMPORT_DECLARATION=8
< TYPE_PARAMETERS=12
< ELEMENT_VALUE_PAIR=48
< FloatingPointLiteral=93
< T__175=175
< ARRAY_OF=32
< T__117=117
< CONSTRUCTOR_BODY=34
< COMMENT=111
< T__199=199
< T__172=172
< STATIC_IMPORT_ON_DEMAND_DECLARATION=9
< THIS=77
< JavaIDDigit=109
< T__170=170
< T__136=136
< NORMAL_ANNOTATION=45
< T__116=116
< T__171=171
< CALL=81
< T__189=189
< OctalEscape=107
< T__134=134
< T__195=195
< PREFIX_EXPRESSION=73
< FOR_INIT_DECLARATION=60
< T__162=162
< FOR_INIT_EXPRESSION_LIST=61
< FIELD_DECLARATION=26
< INSTANTIATION=35
< T__160=160
< T__123=123
< T__145=145
< POST_INCREMENT_EXPRESSION=74
< T__187=187
< GREATER_THAN_OR_EQUAL_TO=69
< CONSTANT_DECLARATION=31
< T__186=186
< ELEMENT_VALUE_ARRAY_INITIALIZER=49
< T__181=181
< SINGLE_TYPE_IMPORT_DECLARATION=6
< T__128=128
< STATIC_INITIALIZER=23
< BASIC_FOR_CONTROL=59
< ENUM_CONSTANTS=17
< LAST_FORMAL_PARAMETER=41
< T__161=161
< T__168=168
< T__150=150
< Identifier=100
< QUALIFIED_THIS=82
< ENUM_CONSTANT=18
< ANNOTATION_METHOD=52
< T__182=182
< T__165=165
< T__130=130
< T__151=151
< LINE_COMMENT=112
< QUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION=44
< METHOD_DECLARATION=27
< HexLiteral=96
< T__125=125
< T__149=149
< T__166=166
< DecimalLiteral=98
< T__132=132
< ARRAY_INITIALIZER=33
< INNER_THIS=90
< LESS_THAN_OR_EQUAL_TO=68
< POST_DECREMENT_EXPRESSION=75
< T__190=190
< T__124=124
< T__131=131
< T__169=169
< QUALIFIED_SUPER=83
< ALTERNATE_CONSTRUCTOR_INVOCATION=42
< T__126=126
< T__148=148
< INSTANCE_INITIALIZER=24
< UNQUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION=43
< T__188=188
< T__200=200
< TYPE_PARAMETER=13
< T__127=127
< VOID=25
< T__183=183
< T__133=133
< ARRAY_ACCESS=80
< T__164=164
< T__120=120
< ENUM=92
< T__163=163
< Exponent=103
< T__153=153
< SIGNED_RIGHT_SHIFT_ASSIGN=67
< T__185=185
< CharacterLiteral=94
< T__178=178
< WILDCARD=38
< LEFT_SHIFT_ASSIGN=65
< StringLiteral=95
< T__129=129
< T__180=180
< EXPLICIT_GENERIC_INVOCATIONS=88
< T__152=152
< VARIABLE_DECLARATOR=30
< ANNOTATION_TYPE_BODY=51
< T__121=121
< QUALIFIED_CLASS_INSTANCE_CREATION=85
< FOR_UPDATE=63
< ASSERT_STATEMENT=55
< T__147=147
< T__179=179
< T__154=154
< ABSTRACT_METHOD_DECLARATION=28
< T__184=184
< T__155=155
< T__146=146
< '<'=128
< '-='=179
< 'interface'=134
< '>'=130
< 'case'=177
< 'try'=169
< 'boolean'=144
< 'else'=165
< '/='=181
< 'package'=113
< '-'=194
< '?'=152
< '!='=191
< '%='=185
< 'do'=168
< '||'=186
< 'double'=151
< '='=139
< '*='=180
< 'volatile'=143
< 'instanceof'=192
< 'super'=153
< 'strictfp'=124
< '|='=183
< 'native'=140
< '++'=197
< '{'=132
< 'void'=135
< 'catch'=176
< 'throws'=138
< 'float'=150
< 'new'=201
< ':'=163
< 'for'=166
< '.'=117
< '*'=118
< 'short'=147
< '}'=133
< '~'=199
< 'finally'=170
< 'break'=174
< '%'=196
< 'final'=123
< ';'=114
< 'synchronized'=141
< 'default'=162
< ']'=137
< 'true'=159
< 'false'=160
< '&'=131
< ','=129
< '&&'=187
< 'int'=148
< '&='=182
< 'while'=167
< 'this'=157
< 'continue'=175
< '['=136
< '/'=195
< '^'=189
< 'long'=149
< 'private'=121
< '|'=188
< 'return'=172
< ')'=155
< '=='=190
< 'static'=116
< 'implements'=127
< '@'=161
< 'throw'=173
< 'protected'=120
< 'import'=115
< '!'=200
< 'if'=164
< 'char'=145
< '+='=178
< 'switch'=171
< '('=154
< 'transient'=142
< 'byte'=146
< 'extends'=126
< '--'=198
< '^='=184
< 'class'=125
< '+'=193
< 'null'=158
< '...'=156
< 'public'=119
< 'abstract'=122
diff -r -N code-worker/tasks/clonedigger/java_antlr/MyAstNodeAdaptor.java code-worker/code-worker/tasks/clonedigger/java_antlr/MyAstNodeAdaptor.java
1,8d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< class MyAstNodeAdaptor extends CommonTreeAdaptor {
<     public Object create(Token t) {
< 	return new MyAstNode(t);
<     }
< };
diff -r -N code-worker/tasks/clonedigger/java_antlr/MyAstNode.java code-worker/code-worker/tasks/clonedigger/java_antlr/MyAstNode.java
1,11d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< import java.io.*;
< 
< public class MyAstNode extends CommonTree {
<     boolean is_statement = false;
<     public MyAstNode(Token t) {
< 	super(t);
<     }
< }
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/all-wcprops
1,47d0
< K 25
< svn:wc:ra_dav:version-url
< V 62
< /svnroot/clonedigger/!svn/ver/194/trunk/clonedigger/java_antlr
< END
< MyAstNode.java
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/java_antlr/MyAstNode.java
< END
< TreeProducer.java
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/java_antlr/TreeProducer.java
< END
< build_jar.sh
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/java_antlr/build_jar.sh
< END
< JavaAST.tokens
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/java_antlr/JavaAST.tokens
< END
< JavaAST.g
< K 25
< svn:wc:ra_dav:version-url
< V 72
< /svnroot/clonedigger/!svn/ver/194/trunk/clonedigger/java_antlr/JavaAST.g
< END
< MyAstNodeAdaptor.java
< K 25
< svn:wc:ra_dav:version-url
< V 83
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/java_antlr/MyAstNodeAdaptor.java
< END
< TreeProducer.jar
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/194/trunk/clonedigger/java_antlr/TreeProducer.jar
< END
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/entries code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/entries
1,266d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/java_antlr
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2009-02-15T12:09:41.820474Z
< 194
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< MyAstNode.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< 27e85f308359d91397fb04627a0cdcd9
< 2008-04-24T20:49:04.917217Z
< 18
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 214
< 
< TreeProducer.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< 4aa9056300dfeeee43b336bb4f146786
< 2008-05-13T10:31:51.861674Z
< 36
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3401
< 
< build_jar.sh
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< 5548ac8e2673ef46bded465736aaf874
< 2008-04-24T20:49:04.917217Z
< 18
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 87
< 
< JavaAST.tokens
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< d2baa991e56aed1e5bbef3916012c68a
< 2008-04-24T20:49:04.917217Z
< 18
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 4248
< 
< JavaAST.g
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< e9f014e625f38410f68b8c1598ca34fb
< 2009-02-15T12:09:41.820474Z
< 194
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 42016
< 
< MyAstNodeAdaptor.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< fd6fe69efe042f7870d0bd8d1dab83d8
< 2008-04-24T20:49:04.917217Z
< 18
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 188
< 
< TreeProducer.jar
< file
< 
< 
< 
< 
< 2011-07-05T05:47:50.000000Z
< 0b9295aee9322fc0d5f0aa27785bc163
< 2009-02-15T12:09:41.820474Z
< 194
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 332412
< 
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/prop-base/build_jar.sh.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/prop-base/build_jar.sh.svn-base
1,5d0
< K 14
< svn:executable
< V 1
< *
< END
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/prop-base/TreeProducer.jar.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/prop-base/TreeProducer.jar.svn-base
1,5d0
< K 13
< svn:mime-type
< V 24
< application/octet-stream
< END
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/text-base/build_jar.sh.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/build_jar.sh.svn-base
1,4d0
< java org.antlr.Tool JavaAST.g
< javac *.java
< jar -cf TreeProducer.jar *.class
< rm *.class
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/text-base/JavaAST.g.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/JavaAST.g.svn-base
1,1326d0
< /** A Java 1.5 grammar for ANTLR v3 derived from the spec
<  *
<  *  This is a very close representation of the spec; the changes
<  *  are comestic (remove left recursion) and also fixes (the spec
<  *  isn't exactly perfect).  I have run this on the 1.4.2 source
<  *  and some nasty looking enums from 1.5, but have not really
<  *  tested for 1.5 compatibility.
<  *
<  *  I built this with: java -Xmx100M org.antlr.Tool java.g 
<  *  and got two errors that are ok (for now):
<  *  java.g:691:9: Decision can match input such as
<  *    "'0'..'9'{'E', 'e'}{'+', '-'}'0'..'9'{'D', 'F', 'd', 'f'}"
<  *    using multiple alternatives: 3, 4
<  *  As a result, alternative(s) 4 were disabled for that input
<  *  java.g:734:35: Decision can match input such as "{'$', 'A'..'Z',
<  *    '_', 'a'..'z', '\u00C0'..'\u00D6', '\u00D8'..'\u00F6',
<  *    '\u00F8'..'\u1FFF', '\u3040'..'\u318F', '\u3300'..'\u337F',
<  *    '\u3400'..'\u3D2D', '\u4E00'..'\u9FFF', '\uF900'..'\uFAFF'}"
<  *    using multiple alternatives: 1, 2
<  *  As a result, alternative(s) 2 were disabled for that input
<  *
<  *  You can turn enum on/off as a keyword :)
<  *
<  *  Version 1.0 -- initial release July 5, 2006 (requires 3.0b2 or higher)
<  *
<  *  Primary author: Terence Parr, July 2006
<  *
<  *  Version 1.0.1 -- corrections by Koen Vanderkimpen & Marko van Dooren,
<  *      October 25, 2006;
<  *      fixed normalInterfaceDeclaration: now uses typeParameters instead
<  *          of typeParameter (according to JLS, 3rd edition)
<  *      fixed castExpression: no longer allows expression next to type
<  *          (according to semantics in JLS, in contrast with syntax in JLS)
<  *
<  *  Version 1.0.2 -- Terence Parr, Nov 27, 2006
<  *      java spec I built this from had some bizarre for-loop control.
<  *          Looked weird and so I looked elsewhere...Yep, it's messed up.
<  *          simplified.
<  *
<  *  Version 1.0.3 -- Chris Hogue, Feb 26, 2007
<  *      Factored out an annotationName rule and used it in the annotation rule.
<  *          Not sure why, but typeName wasn't recognizing references to inner
<  *          annotations (e.g. @InterfaceName.InnerAnnotation())
<  *      Factored out the elementValue section of an annotation reference.  Created 
<  *          elementValuePair and elementValuePairs rules, then used them in the 
<  *          annotation rule.  Allows it to recognize annotation references with 
<  *          multiple, comma separated attributes.
<  *      Updated elementValueArrayInitializer so that it allows multiple elements.
<  *          (It was only allowing 0 or 1 element).
<  *      Updated localVariableDeclaration to allow annotations.  Interestingly the JLS
<  *          doesn't appear to indicate this is legal, but it does work as of at least
<  *          JDK 1.5.0_06.
<  *      Moved the Identifier portion of annotationTypeElementRest to annotationMethodRest.
<  *          Because annotationConstantRest already references variableDeclarator which 
<  *          has the Identifier portion in it, the parser would fail on constants in 
<  *          annotation definitions because it expected two identifiers.  
<  *      Added optional trailing ';' to the alternatives in annotationTypeElementRest.
<  *          Wouldn't handle an inner interface that has a trailing ';'.
<  *      Swapped the expression and type rule reference order in castExpression to 
<  *          make it check for genericized casts first.  It was failing to recognize a
<  *          statement like  "Class<Byte> TYPE = (Class<Byte>)...;" because it was seeing
<  *          'Class<Byte' in the cast expression as a less than expression, then failing 
<  *          on the '>'.
<  *      Changed createdName to use typeArguments instead of nonWildcardTypeArguments.
<  *          Again, JLS doesn't seem to allow this, but java.lang.Class has an example of
<  *          of this construct.
<  *      Changed the 'this' alternative in primary to allow 'identifierSuffix' rather than
<  *          just 'arguments'.  The case it couldn't handle was a call to an explicit
<  *          generic method invocation (e.g. this.<E>doSomething()).  Using identifierSuffix
<  *          may be overly aggressive--perhaps should create a more constrained thisSuffix rule?
<  *      
<  *  Version 1.0.4 -- Hiroaki Nakamura, May 3, 2007
<  *
<  *  Fixed formalParameterDecls, localVariableDeclaration, forInit,
<  *  and forVarControl to use variableModifier* not 'final'? (annotation)?
<  *
<  *  Version 1.0.5 -- Terence, June 21, 2007
<  *  --a[i].foo didn't work. Fixed unaryExpression
<  *
<  *  Version 1.0.6 -- John Ridgway, March 17, 2008
<  *      Made "assert" a switchable keyword like "enum".
<  *      Fixed compilationUnit to disallow "annotation importDeclaration ...".
<  *      Changed "Identifier ('.' Identifier)*" to "qualifiedName" in more 
<  *          places.
<  *      Changed modifier* and/or variableModifier* to classOrInterfaceModifiers,
<  *          modifiers or variableModifiers, as appropriate.
<  *      Renamed "bound" to "typeBound" to better match language in the JLS.
<  *      Added "memberDeclaration" which rewrites to methodDeclaration or 
<  *      fieldDeclaration and pulled type into memberDeclaration.  So we parse 
<  *          type and then move on to decide whether we're dealing with a field
<  *          or a method.
<  *      Modified "constructorDeclaration" to use "constructorBody" instead of
<  *          "methodBody".  constructorBody starts with explicitConstructorInvocation,
<  *          then goes on to blockStatement*.  Pulling explicitConstructorInvocation
<  *          out of expressions allowed me to simplify "primary".
<  *      Changed variableDeclarator to simplify it.
<  *      Changed type to use classOrInterfaceType, thus simplifying it; of course
<  *          I then had to add classOrInterfaceType, but it is used in several 
<  *          places.
<  *      Fixed annotations, old version allowed "@X(y,z)", which is illegal.
<  *      Added optional comma to end of "elementValueArrayInitializer"; as per JLS.
<  *      Changed annotationTypeElementRest to use normalClassDeclaration and 
<  *          normalInterfaceDeclaration rather than classDeclaration and 
<  *          interfaceDeclaration, thus getting rid of a couple of grammar ambiguities.
<  *      Split localVariableDeclaration into localVariableDeclarationStatement
<  *          (includes the terminating semi-colon) and localVariableDeclaration.  
<  *          This allowed me to use localVariableDeclaration in "forInit" clauses,
<  *           simplifying them.
<  *      Changed switchBlockStatementGroup to use multiple labels.  This adds an
<  *          ambiguity, but if one uses appropriately greedy parsing it yields the
<  *           parse that is closest to the meaning of the switch statement.
<  *      Renamed "forVarControl" to "enhancedForControl" -- JLS language.
<  *      Added semantic predicates to test for shift operations rather than other
<  *          things.  Thus, for instance, the string "< <" will never be treated
<  *          as a left-shift operator.
<  *      In "creator" we rule out "nonWildcardTypeArguments" on arrayCreation, 
<  *          which are illegal.
<  *      Moved "nonWildcardTypeArguments into innerCreator.
<  *      Removed 'super' superSuffix from explicitGenericInvocation, since that
<  *          is only used in explicitConstructorInvocation at the beginning of a
<  *           constructorBody.  (This is part of the simplification of expressions
<  *           mentioned earlier.)
<  *      Simplified primary (got rid of those things that are only used in
<  *          explicitConstructorInvocation).
<  *      Lexer -- removed "Exponent?" from FloatingPointLiteral choice 4, since it
<  *          led to an ambiguity.
<  *
<  *      This grammar successfully parses every .java file in the JDK 1.5 source 
<  *          tree (excluding those whose file names include '-', which are not
<  *          valid Java compilation units).
<  *
<  *  Version 1.0.6.CD -- Peter Bulychev, April 25, 2008
<  *	Small modifications for supporting Clone Digger
<  *
<  *  Known remaining problems:
<  *      "Letter" and "JavaIDDigit" are wrong.  The actual specification of
<  *      "Letter" should be "a character for which the method
<  *      Character.isJavaIdentifierStart(int) returns true."  A "Java 
<  *      letter-or-digit is a character for which the method 
<  *      Character.isJavaIdentifierPart(int) returns true."
<  */
< grammar JavaAST;
< options {
<     k=2; 
<     backtrack=true; 
<     memoize=true;
<     output=AST;
<     ASTLabelType=MyAstNode;
< }
< 
< tokens {
<     COMPILATION_UNIT;
<     PACKAGE_DECLARATION;
<     SINGLE_TYPE_IMPORT_DECLARATION;
<     TYPE_IMPORT_ON_DEMAND_DECLARATION;
<     SINGLE_STATIC_IMPORT_DECLARATION;
<     STATIC_IMPORT_ON_DEMAND_DECLARATION;
<     MODIFIERS;
<     CLASS_DECLARATION;
<     TYPE_PARAMETERS;
<     TYPE_PARAMETER;
<     TYPE_BOUND;
<     ENUM_DECLARATION;
<     ENUM_BODY;
<     ENUM_CONSTANTS;
<     ENUM_CONSTANT;
<     ENUM_BODY_DECLARATIONS;
<     INTERFACE_DECLARATION;
<     CLASS_BODY;
<     INTERFACE_BODY;
<     STATIC_INITIALIZER;
<     INSTANCE_INITIALIZER;
<     VOID;
<     FIELD_DECLARATION;
<     METHOD_DECLARATION;
<     ABSTRACT_METHOD_DECLARATION;
<     CONSTRUCTOR_DECLARATION;
<     VARIABLE_DECLARATOR;
<     CONSTANT_DECLARATION;
<     ARRAY_OF;
<     ARRAY_INITIALIZER;
<     CONSTRUCTOR_BODY;
<     INSTANTIATION;
<     SELECT;
<     TYPE_ARGUMENTS;
<     WILDCARD;
<     FORMAL_PARAMETERS;
<     FORMAL_PARAMETER;
<     LAST_FORMAL_PARAMETER;
<     ALTERNATE_CONSTRUCTOR_INVOCATION;
<     UNQUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION;
<     QUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION;
<     NORMAL_ANNOTATION;
<     SINGLE_ELEMENT_ANNOTATION;
<     MARKER_ANNOTATION;
<     ELEMENT_VALUE_PAIR;
<     ELEMENT_VALUE_ARRAY_INITIALIZER;
<     ANNOTATION_INTERFACE;
<     ANNOTATION_TYPE_BODY;
<     ANNOTATION_METHOD;
<     BLOCK;
<     LOCAL_VARIABLE_DECLARATION;
<     ASSERT_STATEMENT;
<     EMPTY_STATEMENT;
<     EXPRESSION_STATEMENT;
<     SWITCH_BLOCK_STATEMENT_GROUP;
<     BASIC_FOR_CONTROL;
<     FOR_INIT_DECLARATION;
<     FOR_INIT_EXPRESSION_LIST;
<     ENHANCED_FOR_CONTROL;
<     FOR_UPDATE;
<     EXPRESSION_LIST;
<     LEFT_SHIFT_ASSIGN;
<     UNSIGNED_RIGHT_SHIFT_ASSIGN;
<     SIGNED_RIGHT_SHIFT_ASSIGN;
<     LESS_THAN_OR_EQUAL_TO;
<     GREATER_THAN_OR_EQUAL_TO;
<     LEFT_SHIFT;
<     UNSIGNED_RIGHT_SHIFT;
<     SIGNED_RIGHT_SHIFT;
<     PREFIX_EXPRESSION;
<     POST_INCREMENT_EXPRESSION;
<     POST_DECREMENT_EXPRESSION;
<     CAST;
<     THIS;
<     UNQUALIFIED_SUPER;
<     CLASS_DESIGNATOR;
<     ARRAY_ACCESS;
<     CALL;
<     QUALIFIED_THIS;
<     QUALIFIED_SUPER;
<     UNQUALIFIED_CLASS_INSTANCE_CREATION;
<     QUALIFIED_CLASS_INSTANCE_CREATION;
<     NEW_INITIALIZED_ARRAY;
<     NEW_ARRAY;
<     EXPLICIT_GENERIC_INVOCATIONS;
<     NON_WILD_TYPE_ARGUMENTS;
<     INNER_THIS;
<     ARGUMENTS;
< }
< 
< @lexer::members {
<   protected boolean enumIsKeyword = true;
<   protected boolean assertIsKeyword = true;
< }
< 
< // starting point for parsing a java file
< /* The annotations are separated out to make parsing faster, but must be associated with
<    a packageDeclaration or a typeDeclaration (and not an empty one). */
< compilationUnit
<     :   ('@')=> annotations
<         (   packageDeclaration[$annotations.tree] importDeclaration* typeDeclaration*
<             -> ^(COMPILATION_UNIT packageDeclaration importDeclaration* typeDeclaration*)
<         |   classOrInterfaceDeclaration[$annotations.tree] typeDeclaration*
<             -> ^(COMPILATION_UNIT classOrInterfaceDeclaration typeDeclaration*)
<        )
<     |   (packageDeclaration[null])? importDeclaration* typeDeclaration*
<         -> ^(COMPILATION_UNIT packageDeclaration? importDeclaration* typeDeclaration*)
<     ;
< 
< packageDeclaration[Tree annotations]
<     :   'package' qualifiedName ';'
<         -> ^(PACKAGE_DECLARATION {annotations} qualifiedName)
<     ;
<     
< importDeclaration
<     :   'import' (staticModifier='static')? qualifiedName ('.' wildcard='*')? ';'
<         -> {staticModifier == null && wildcard == null}?
<             ^(SINGLE_TYPE_IMPORT_DECLARATION qualifiedName)
<         -> {staticModifier == null && wildcard != null}?
<             ^(TYPE_IMPORT_ON_DEMAND_DECLARATION qualifiedName)
<         -> {staticModifier != null && wildcard == null}?
<             ^(SINGLE_STATIC_IMPORT_DECLARATION qualifiedName)
<         -> /*{staticModifier != null && wildcard != null}? */
<             ^(STATIC_IMPORT_ON_DEMAND_DECLARATION qualifiedName)
<     ;
<     
< typeDeclaration
<     :   classOrInterfaceDeclaration[null]
<     |   ';'
<         ->
<     ;
<     
< classOrInterfaceDeclaration[Tree annotations]
<     :   classOrInterfaceModifiers[annotations]! (classDeclaration[$classOrInterfaceModifiers.tree] | interfaceDeclaration[$classOrInterfaceModifiers.tree])
<     ;
<     
< classOrInterfaceModifiers[Tree annotations]
<     :   classOrInterfaceModifier*
<         -> ^(MODIFIERS {annotations} classOrInterfaceModifier*)
<     ;
< 
< classOrInterfaceModifier
<     :   annotation   // class or interface
<     |   'public'     // class or interface
<     |   'protected'  // class or interface
<     |   'private'    // class or interface
<     |   'abstract'   // class or interface
<     |   'static'     // class or interface
<     |   'final'      // class only -- does not apply to interfaces
<     |   'strictfp'   // class or interface
<     ;
< 
< modifiers
<     :   modifier*
<         -> ^(MODIFIERS modifier*)
<     ;
< 
< classDeclaration[Tree modifiers]
<     :   normalClassDeclaration[modifiers]
<     |   enumDeclaration[modifiers]
<     ;
<     
< normalClassDeclaration[Tree modifiers]
< @after {retval.tree.is_statement = true;}
<     :   'class' identifier (typeParameters)?
<         (extendsPhrase)?
<         (implementsPhrase)?
<         classBody
<         -> ^(CLASS_DECLARATION {modifiers} identifier typeParameters? extendsPhrase? implementsPhrase? classBody)
<     ;
< 
< extendsPhrase
<     :   'extends' type
<         -> ^('extends' type)
<     ;
< 
< implementsPhrase
<     :   'implements' typeList
<         -> ^('implements' typeList)
<     ;
< 
< typeParameters
<     :   '<' typeParameter (',' typeParameter)* '>'
<         -> ^(TYPE_PARAMETERS typeParameter+)
<     ;
< 
< typeParameter
<     :   identifier ('extends' typeBound)?
<         -> ^(TYPE_PARAMETER identifier typeBound?)
<     ;
<         
< typeBound
<     :   type ('&' type)*
<         -> ^(TYPE_BOUND type+)
<     ;
< 
< enumDeclaration[Tree modifiers]
<     :   ENUM identifier (implementsPhrase)? enumBody
<         -> ^(ENUM_DECLARATION {modifiers} identifier implementsPhrase? enumBody)
<     ;
< 
< enumBody
<     :   '{' enumConstants? ','? enumBodyDeclarations? '}'
<         -> ^(ENUM_BODY enumConstants? enumBodyDeclarations?)
<     ;
< 
< enumConstants
<     :   enumConstant (',' enumConstant)*
<         -> ^(ENUM_CONSTANTS enumConstant+)
<     ;
<     
< enumConstant
<     :   annotations? identifier (arguments)? (classBody)?
<         -> ^(ENUM_CONSTANT annotations? identifier arguments? classBody?)
<     ;
<     
< enumBodyDeclarations
<     :   ';' (classBodyDeclaration)*
<         -> ^(ENUM_BODY_DECLARATIONS classBodyDeclaration*)
<     ;
<     
< interfaceDeclaration[Tree modifiers]
<     :   normalInterfaceDeclaration[modifiers]
<     |   annotationTypeDeclaration[modifiers]
<     ;
<     
< normalInterfaceDeclaration[Tree modifiers]
<     :   'interface' identifier typeParameters? (extendsInterfaces)? interfaceBody
<         -> ^(INTERFACE_DECLARATION {modifiers} identifier typeParameters? extendsInterfaces? interfaceBody)
<     ;
< 
< extendsInterfaces
<     :   'extends' typeList
<         -> ^('extends' typeList)
<     ;
<     
< typeList
<     :   type (','! type)*
<     ;
<     
< classBody
<     :   '{' classBodyDeclaration* '}'
<         -> ^(CLASS_BODY classBodyDeclaration*)
<     ;
<     
< interfaceBody
<     :   '{' interfaceBodyDeclaration* '}'
<         -> ^(INTERFACE_BODY interfaceBodyDeclaration*)
<     ;
< 
< classBodyDeclaration
<     :   ';'
<         ->
<     |   'static' block
<         -> ^(STATIC_INITIALIZER block)
<     |   block
<         -> ^(INSTANCE_INITIALIZER block)
<     |   modifiers! memberDecl[$modifiers.tree]
<     ;
<     
< memberDecl[Tree modifiers]
<     :   genericMethodOrConstructorDecl[modifiers]
<     |   memberDeclaration[modifiers]
<     |   'void' identifier voidMethodDeclaratorRest[modifiers, $identifier.tree]
<         -> voidMethodDeclaratorRest
<     |   identifier constructorDeclaratorRest[modifiers, null, $identifier.tree]
<         -> constructorDeclaratorRest
<     |   interfaceDeclaration[modifiers]
<     |   classDeclaration[modifiers]
<     ;
<     
< memberDeclaration[Tree modifiers]
<     :   type! (methodDeclaration[modifiers, $type.tree]
<               | fieldDeclaration[modifiers, $type.tree])
<     ;
< 
< genericMethodOrConstructorDecl[Tree modifiers]
<     :   typeParameters! genericMethodOrConstructorRest[modifiers, $typeParameters.tree]
<     ;
<     
< genericMethodOrConstructorRest[Tree modifiers, Tree typeParameters]
<     :   rt=resultType! identifier! 
<         methodDeclaratorRest[modifiers, typeParameters, $rt.tree, $identifier.tree]
<     |   identifier! constructorDeclaratorRest[modifiers, typeParameters, $identifier.tree]
<     ;
< 
< resultType 
<     :   type
<     |   'void' -> VOID
<     ;
< 
< methodDeclaration[Tree modifiers, Tree returnType]
<     :   identifier! methodDeclaratorRest[modifiers, returnType, null, $identifier.tree]
<     ;
< 
< fieldDeclaration[Tree modifiers, Tree fieldType]
<     :   variableDeclarators ';'
<         -> ^(FIELD_DECLARATION {modifiers} {fieldType} variableDeclarators)
<     ;
<         
< interfaceBodyDeclaration
<     :   modifiers! interfaceMemberDecl[$modifiers.tree]
<     |   ';'!
<     ;
< 
< interfaceMemberDecl[Tree modifiers]
<     :   interfaceMethodOrFieldDecl[modifiers]
<     |   interfaceGenericMethodDecl[modifiers]
<     |   'void'! identifier! voidInterfaceMethodDeclaratorRest[modifiers, $identifier.tree]
<     |   interfaceDeclaration[ modifiers]
<     |   classDeclaration[modifiers]
<     ;
<     
< interfaceMethodOrFieldDecl[Tree modifiers]
<     :   t=type! identifier! interfaceMethodOrFieldRest[modifiers, t.tree, $identifier.tree]
<     ;
<     
< interfaceMethodOrFieldRest[Tree modifiers, Tree type, Tree identifier]
<     :   constantDeclaratorsRest[modifiers, type, identifier] ';'!
<     |   interfaceMethodDeclaratorRest[modifiers, null, type, identifier]
<     ;
< 
< /* This converts obsolete post-formal '[]' array specifiers to array specifiers on the
<    return type in the AST. */    
< methodDeclaratorRest[Tree modifiers, Tree type, Tree typeParameters, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters 
<         ( '[' ']'
<           { type = (Tree)adaptor.becomeRoot(adaptor.create(ARRAY_OF, "ARRAY_OF"), type); }
<         )*
<         (throwsPhrase)?
<         (  methodBody
<             -> ^(METHOD_DECLARATION {modifiers} {$type} {typeParameters} {identifier}
<                  formalParameters (throwsPhrase)? methodBody)
<         |   ';'
<             -> ^(METHOD_DECLARATION {modifiers} {$type} {typeParameters} {identifier}
<                  formalParameters (throwsPhrase)?)
<         )
<     ;
< 
< throwsPhrase
<     :   'throws' qualifiedNameList -> ^('throws' qualifiedNameList)
<     ;
<     
< voidMethodDeclaratorRest[Tree modifiers, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters (throwsPhrase)?
<         (  methodBody
<             -> ^(METHOD_DECLARATION {modifiers} VOID {identifier} formalParameters 
<                 (throwsPhrase)? methodBody)
<         |   ';'
<             -> ^(METHOD_DECLARATION {modifiers} VOID {identifier} formalParameters 
<                 (throwsPhrase)?)
<        )
<     ;
<     
< interfaceMethodDeclaratorRest[Tree modifiers, Tree typeParameters, Tree type, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters 
<         ('[' ']'
<             { type = (Tree)adaptor.becomeRoot(adaptor.create(ARRAY_OF, "ARRAY_OF"), type); })*
<         (throwsPhrase)? ';'
<         -> ^(ABSTRACT_METHOD_DECLARATION {modifiers} {typeParameters} {type} {identifier} formalParameters (throwsPhrase)?)
<     ;
<     
< interfaceGenericMethodDecl[Tree modifiers]
<     :   typeParameters! rt=resultType! identifier!
<         interfaceMethodDeclaratorRest[modifiers, $typeParameters.tree, rt.tree, $identifier.tree]
<     ;
<     
< voidInterfaceMethodDeclaratorRest[Tree modifiers, Tree identifier]
< @after {retval.tree.is_statement = true;}
<     :   formalParameters (throwsPhrase)? ';'
<         -> ^(ABSTRACT_METHOD_DECLARATION {modifiers} VOID {identifier} formalParameters (throwsPhrase)?)
<     ;
<     
< constructorDeclaratorRest[Tree modifiers, Tree typeParameters, Tree identifier]
<     :   formalParameters (throwsPhrase)? constructorBody
<         -> ^(CONSTRUCTOR_DECLARATION {modifiers} {typeParameters} {identifier}
<              formalParameters (throwsPhrase)? constructorBody)
<     ;
< 
< constantDeclarator[Tree modifiers, Tree type]
<     :   identifier! constantDeclaratorRest[modifiers, type, $identifier.tree]
<     ;
<     
< variableDeclarators
<     :   variableDeclarator (',' variableDeclarator)*
<         -> variableDeclarator+
<     ;
< 
< variableDeclarator
<     :   variableDeclaratorId ('=' variableInitializer)?
<         -> ^(VARIABLE_DECLARATOR variableDeclaratorId variableInitializer?)
<     ;
<     
< constantDeclaratorsRest[Tree modifiers, Tree type, Tree identifier]
<     :   constantDeclaratorRest[modifiers, type, identifier] (','! constantDeclarator[modifiers, type])*
<     ;
< 
< constantDeclaratorRest[Tree modifiers, Tree type, Tree identifier]
<     :   ('[' ']'
<             { type = (Tree)adaptor.becomeRoot(adaptor.create(ARRAY_OF, "ARRAY_OF"), type); })*
<         '=' variableInitializer
<         -> ^(CONSTANT_DECLARATION {modifiers} {type} {identifier} variableInitializer)
<         ;
<     
< variableDeclaratorId
<     :   (identifier -> identifier) 
<         ('[' ']' -> ^(ARRAY_OF $variableDeclaratorId) )*
<     ;
< 
< variableInitializer
<     :   arrayInitializer
<     |   expression
<     ;
<         
< arrayInitializer
<     :   '{' (variableInitializer (',' variableInitializer)* (',')? )? '}'
<         -> ^(ARRAY_INITIALIZER variableInitializer*)
<     ;
< 
< modifier
<     :   annotation
<     |   'public'
<     |   'protected'
<     |   'private'
<     |   'static'
<     |   'abstract'
<     |   'final'
<     |   'native'
<     |   'synchronized'
<     |   'transient'
<     |   'volatile'
<     |   'strictfp'
<     ;
< 
< packageOrTypeName
<     :   qualifiedName
<     ;
< 
< enumConstantName
<     :   identifier
<     ;
< 
< typeName
<     :   qualifiedName
<     ;
< 
< // 4.1 -- The Kinds of Types and Values
< type
< 	:	( classOrInterfaceType -> classOrInterfaceType )
<         ( '[' ']' -> ^(ARRAY_OF $type) )*
< 	|	( primitiveType -> primitiveType )
<         ( '[' ']' -> ^(ARRAY_OF $type) )*
< 	;
< 
< classOrInterfaceType
< 	:	( identifier -> identifier )
<         ( typeArguments -> ^(INSTANTIATION $classOrInterfaceType typeArguments) )?
<         ( ( '.' identifier -> ^(SELECT $classOrInterfaceType identifier) )
<           (typeArguments -> ^(INSTANTIATION $classOrInterfaceType typeArguments) )? 
<         )*
< 	;
< 
< primitiveType
<     :   'boolean'
<     |   'char'
<     |   'byte'
<     |   'short'
<     |   'int'
<     |   'long'
<     |   'float'
<     |   'double'
<     ;
< 
< variableModifier
<     :   'final'
<     |   annotation
<     ;
< 
< typeArguments
<     :   '<' typeArgument (',' typeArgument)* '>'
<         -> ^(TYPE_ARGUMENTS typeArgument+)
<     ;
<     
< typeArgument
<     :   type
<         -> type
<     |   '?' ((kind='extends' | kind='super') type)?
<         -> ^(WILDCARD $kind? type?)
<     ;
<     
< qualifiedNameList
<     :   qualifiedName (','! qualifiedName)*
<     ;
< 
< formalParameters
<     :   '(' formalParameterDecls? ')'
<         -> ^(FORMAL_PARAMETERS formalParameterDecls?)
<     ;
<     
< formalParameterDecls
<     :   variableModifiers! pType=type! formalParameterDeclsRest[$variableModifiers.tree, pType.tree]
<     ;
<     
< formalParameterDeclsRest[Tree modifiers, Tree type]
<     :   variableDeclaratorId 
<         (',' formalParameterDecls
<             -> ^(FORMAL_PARAMETER {modifiers} {type} variableDeclaratorId) formalParameterDecls
<         |
<             -> ^(FORMAL_PARAMETER {modifiers} {type} variableDeclaratorId)
<         )
<     |   '...' variableDeclaratorId
<         -> ^(LAST_FORMAL_PARAMETER {modifiers} {type} variableDeclaratorId)
<     ;
<     
< methodBody
<     :   block
<     ;
< 
< constructorBody
<     :   '{' explicitConstructorInvocation? blockStatement* '}'
<         -> ^(CONSTRUCTOR_BODY explicitConstructorInvocation? blockStatement*)
<     ;
< 
< explicitConstructorInvocation
<     :   (nonWildcardTypeArguments)?
<         ( ( 'this' arguments ';' 
<             -> ^(ALTERNATE_CONSTRUCTOR_INVOCATION nonWildcardTypeArguments? arguments) )
<         | ( 'super' arguments ';'
<             -> ^(UNQUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION nonWildcardTypeArguments? arguments) )
<         )
<     |   primary '.' nonWildcardTypeArguments? 'super' arguments ';'
<         -> ^(QUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION primary nonWildcardTypeArguments? arguments)
<     ;
< 
< 
< qualifiedName
<     :   (identifier->identifier)
<         ('.' identifier -> ^(SELECT $qualifiedName identifier))*
<     ;
<     
< literal 
<     :   integerLiteral
<     |   FloatingPointLiteral
<     |   CharacterLiteral
<     |   StringLiteral
<     |   booleanLiteral
<     |   'null'
<     ;
< 
< integerLiteral
<     :   HexLiteral
<     |   OctalLiteral
<     |   DecimalLiteral
<     ;
< 
< booleanLiteral
<     :   'true'
<     |   'false'
<     ;
< 
< // ANNOTATIONS
< 
< annotations
<     :   annotation+
<     ;
< 
< annotation
<     :   '@' annotationName 
<         ( '(' ( elementValuePairs
<                 -> ^(NORMAL_ANNOTATION annotationName elementValuePairs)
<               | elementValue 
<                 -> ^(SINGLE_ELEMENT_ANNOTATION annotationName elementValue)
<               )? 
<           ')'
<         | // Nothing
<           -> ^(MARKER_ANNOTATION annotationName)
<         )
<     ;
<     
< annotationName
<     :   (identifier -> identifier)
<         ('.' id=identifier -> ^(SELECT $annotationName $id))*
<     ;
< 
< elementValuePairs
<     :   elementValuePair (',' elementValuePair)*
<         -> elementValuePair+
<     ;
< 
< elementValuePair
<     :   identifier '=' elementValue
<         -> ^(ELEMENT_VALUE_PAIR identifier elementValue)
<     ;
<     
< elementValue
<     :   conditionalExpression
<     |   annotation
<     |   elementValueArrayInitializer
<     ;
<     
< elementValueArrayInitializer
<     :   '{' (elementValue (',' elementValue)*)? (',')? '}'
<         -> ^(ELEMENT_VALUE_ARRAY_INITIALIZER elementValue+)
<     ;
<     
< annotationTypeDeclaration[Tree modifiers]
<     :   '@' 'interface' identifier annotationTypeBody
<         -> ^(ANNOTATION_INTERFACE {modifiers} identifier annotationTypeBody)
<     ;
<     
< annotationTypeBody
<     :   '{' (annotationTypeElementDeclaration)* '}'
<         -> ^(ANNOTATION_TYPE_BODY annotationTypeElementDeclaration*)
<     ;
<     
< annotationTypeElementDeclaration
<     :   modifiers! annotationTypeElementRest[$modifiers.tree]
<     ;
<     
< annotationTypeElementRest[Tree modifiers]
<     :   type annotationMethodOrConstantRest[modifiers, $type.tree] ';'
<         -> annotationMethodOrConstantRest
<     |   normalClassDeclaration[modifiers] ';'!?
<     |   normalInterfaceDeclaration[modifiers] ';'!?
<     |   enumDeclaration[modifiers] ';'!?
<     |   annotationTypeDeclaration[modifiers] ';'!?
<     ;
<     
< annotationMethodOrConstantRest[Tree modifiers, Tree type]
<     :   annotationMethodRest[modifiers, type]
<     |   annotationConstantRest[modifiers, type]
<     ;
<     
< annotationMethodRest[Tree modifiers, Tree type]
<     :   identifier '(' ')' (defaultValue)?
<         -> ^(ANNOTATION_METHOD {modifiers} {type} identifier defaultValue?)
<     ;
<     
< annotationConstantRest[Tree modifiers, Tree type]
<     :   variableDeclarators
<         -> ^(FIELD_DECLARATION {$modifiers} {$type} variableDeclarators)
<     ;
<     
< defaultValue
<     :   'default' elementValue
<         -> ^('default' elementValue)
<     ;
< 
< // STATEMENTS / BLOCKS
< 
< block
< @after {retval.tree.is_statement = true;}
<     :   '{' blockStatement* '}'
<         -> ^(BLOCK blockStatement*)
<     ;
<     
< blockStatement
<     :   localVariableDeclarationStatement
<     |   classOrInterfaceDeclaration[null]
<     |   statement
<     ;
<     
< localVariableDeclarationStatement
<     :    localVariableDeclaration ';'!
<     ;
< 
< localVariableDeclaration
< @after {retval.tree.is_statement = true;}
<     :   variableModifiers type variableDeclarators
<         -> ^(LOCAL_VARIABLE_DECLARATION variableModifiers type variableDeclarators)
<     ;
<     
< variableModifiers
<     :   variableModifier*
<         -> ^(MODIFIERS variableModifier*)
<     ;
< 
< statement
< @after {retval.tree.is_statement = true;}
<     : block
<     |   ASSERT e1=expression (':' e2=expression)? ';'
<         -> ^(ASSERT_STATEMENT $e1 $e2?)
<     |   'if' parExpression statement (options {k=1;}:'else' statement)?
<         -> ^('if' parExpression statement+)
<     |   'for' '(' forControl ')' statement
<         -> ^('for' forControl statement)
<     |   'while'^ parExpression statement
<         -> ^('while' parExpression statement)
<     |   'do' statement 'while' parExpression ';'
<         -> ^('do' statement parExpression)
<     |   'try' tryBlock=block
<         ( catches 'finally' finallyBlock=block
<             -> ^('try' $tryBlock catches ^('finally' $finallyBlock))
<         | catches
<             -> ^('try' $tryBlock catches)
<         |   'finally' finallyBlock=block
<             -> ^('try' $tryBlock ^('finally' $finallyBlock))
<         )
<     |   'switch' parExpression '{' switchBlockStatementGroups '}'
<         -> ^('switch' parExpression switchBlockStatementGroups)
<     |   'synchronized' parExpression block
<         -> ^('synchronized' parExpression block)
<     |   'return' expression? ';'
<         -> ^('return' expression?)
<     |   'throw' expression ';'
<         -> ^('throw' expression)
<     |   'break' identifier? ';'
<         -> ^('break' identifier?)
<     |   'continue' identifier? ';'
<         -> ^('continue' identifier?)
<     |   ';' 
<         -> EMPTY_STATEMENT
<     |   statementExpression ';'
<         -> ^(EXPRESSION_STATEMENT statementExpression)
<     |   identifier ':' statement
<         -> ^(':' identifier statement)
<     ;
<     
< catches
<     :   catchClause (catchClause)*
<     ;
<     
< catchClause
<     :   'catch' '(' formalParameter ')' block
<         -> ^('catch' formalParameter block)
<     ;
< 
< formalParameter
<     :   variableModifiers type variableDeclaratorId
<         -> ^(FORMAL_PARAMETER variableModifiers type variableDeclaratorId)
<     ;
<         
< switchBlockStatementGroups
<     :   (switchBlockStatementGroup)*
<     ;
<     
< /* The change here (switchLabel -> switchLabel+) technically makes this grammar
<    ambiguous; but with appropriately greedy parsing it yields the most
<    appropriate AST, one in which each group, except possibly the last one, has
<    labels and statements. */
< switchBlockStatementGroup
<     :   switchLabel+ blockStatement*
<         -> ^(SWITCH_BLOCK_STATEMENT_GROUP switchLabel+ blockStatement*)
<     ;
<     
< switchLabel
<     :   'case'^ constantExpression ':'!
<     |   'case'^ enumConstantName ':'!
<     |   'default'^ ':'!
<     ;
<     
< forControl
< options {k=3;} // be efficient for common case: for (ID ID : ID) ...
<     :   enhancedForControl
<     |   forInit? ';' expression? ';' forUpdate?
<         -> ^(BASIC_FOR_CONTROL forInit? ';' expression? ';' forUpdate?)
<     ;
< 
< forInit
<     :   localVariableDeclaration
<         -> ^(FOR_INIT_DECLARATION localVariableDeclaration)
<     |   expressionList
<         -> ^(FOR_INIT_EXPRESSION_LIST expressionList)
<     ;
<     
< enhancedForControl
<     :   variableModifiers type identifier ':' expression
<         -> ^(ENHANCED_FOR_CONTROL variableModifiers type identifier expression)
<     ;
< 
< forUpdate
<     :   expressionList
<         -> ^(FOR_UPDATE expressionList)
<     ;
< 
< // EXPRESSIONS
< 
< parExpression
<     :   '('! expression ')'!
<     ;
<     
< expressionList
<     :   expression (',' expression)*
<         -> ^(EXPRESSION_LIST expression+)
<     ;
< 
< statementExpression
<     :   expression
<     ;
<     
< constantExpression
<     :   expression
<     ;
<     
< expression
<     :   conditionalExpression (assignmentOperator^ expression)?
<     ;
<     
< assignmentOperator
<     :   '='
<     |   '+='
<     |   '-='
<     |   '*='
<     |   '/='
<     |   '&='
<     |   '|='
<     |   '^='
<     |   '%='
<     |   ('<' '<' '=')=> t1='<' t2='<' t3='=' 
<         { $t1.getLine() == $t2.getLine() &&
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() && 
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() }?
<         -> LEFT_SHIFT_ASSIGN
<     |   ('>' '>' '>' '=')=> t1='>' t2='>' t3='>' t4='='
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() &&
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() &&
<           $t3.getLine() == $t4.getLine() && 
<           $t3.getCharPositionInLine() + 1 == $t4.getCharPositionInLine() }?
<         -> UNSIGNED_RIGHT_SHIFT_ASSIGN
<     |   ('>' '>' '=')=> t1='>' t2='>' t3='='
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() && 
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() }?
<         -> SIGNED_RIGHT_SHIFT_ASSIGN
<     ;
< 
< conditionalExpression
<     :   conditionalOrExpression ( '?'^ expression ':'! expression )?
<     ;
< 
< conditionalOrExpression
<     :   conditionalAndExpression ( '||'^ conditionalAndExpression )*
<     ;
< 
< conditionalAndExpression
<     :   inclusiveOrExpression ('&&'^ inclusiveOrExpression)*
<     ;
< 
< inclusiveOrExpression
<     :   exclusiveOrExpression ('|'^ exclusiveOrExpression)*
<     ;
< 
< exclusiveOrExpression
<     :   andExpression ('^'^ andExpression)*
<     ;
< 
< andExpression
<     :   equalityExpression ('&'^ equalityExpression)*
<     ;
< 
< equalityExpression
<     :   instanceOfExpression (('==' | '!=')^ instanceOfExpression)*
<     ;
< 
< instanceOfExpression
<     :   relationalExpression ('instanceof'^ type)?
<     ;
< 
< relationalExpression
<     :   shiftExpression (relationalOp^ shiftExpression)*
<     ;
<     
< relationalOp
<     :   ('<' '=')=> t1='<' t2='=' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> LESS_THAN_OR_EQUAL_TO
<     |   ('>' '=')=> t1='>' t2='=' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> GREATER_THAN_OR_EQUAL_TO
<     |   '<' 
<     |   '>' 
<     ;
< 
< shiftExpression
<     :   additiveExpression (shiftOp^ additiveExpression)*
<     ;
< 
< shiftOp
<     :   ('<' '<')=> t1='<' t2='<' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> LEFT_SHIFT
<     |   ('>' '>' '>')=> t1='>' t2='>' t3='>' 
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() &&
<           $t2.getLine() == $t3.getLine() && 
<           $t2.getCharPositionInLine() + 1 == $t3.getCharPositionInLine() }?
<         -> UNSIGNED_RIGHT_SHIFT
<     |   ('>' '>')=> t1='>' t2='>'
<         { $t1.getLine() == $t2.getLine() && 
<           $t1.getCharPositionInLine() + 1 == $t2.getCharPositionInLine() }?
<         -> SIGNED_RIGHT_SHIFT 
<     ;
< 
< 
< additiveExpression
<     :   multiplicativeExpression (('+' | '-')^ multiplicativeExpression)*
<     ;
< 
< multiplicativeExpression
<     :   unaryExpression (('*' | '/' | '%')^ unaryExpression)*
<     ;
<     
< unaryExpression
<     :   '+' unaryExpression
<         -> ^(PREFIX_EXPRESSION '+' unaryExpression)
<     |   '-' unaryExpression
<         -> ^(PREFIX_EXPRESSION '-' unaryExpression)
<     |   '++' unaryExpression
<         -> ^(PREFIX_EXPRESSION '++' unaryExpression)
<     |   '--' unaryExpression
<         -> ^(PREFIX_EXPRESSION '--' unaryExpression)
<     |   unaryExpressionNotPlusMinus
<     ;
< 
< unaryExpressionNotPlusMinus
<     :   '~' unaryExpression     -> ^(PREFIX_EXPRESSION '~' unaryExpression)
<     |   '!' unaryExpression     -> ^(PREFIX_EXPRESSION '!' unaryExpression)
<     |   castExpression
<     |   ( primary -> primary )
<         ( (selector[null])=> selector[$unaryExpressionNotPlusMinus.tree]
<             -> selector )*
<         (  ( '++' -> ^(POST_INCREMENT_EXPRESSION $unaryExpressionNotPlusMinus )
<            | '--' -> ^(POST_DECREMENT_EXPRESSION $unaryExpressionNotPlusMinus )
<            ) )?
<     ;
< 
< castExpression
<     :  '(' primitiveType ')' unaryExpression
<         -> ^(CAST primitiveType unaryExpression)
<     |  '(' (type | expression) ')' unaryExpressionNotPlusMinus
<         -> ^(CAST type? expression? unaryExpressionNotPlusMinus)
<     ;
< 
< primary
<     :   parExpression
<     |   ( 'this' -> THIS)
<         ( '.' identifier -> ^(SELECT $primary identifier) )*
<         ( (identifierSuffix[null])=> identifierSuffix[$primary.tree] -> identifierSuffix )?
<     |   ( 'super' -> UNQUALIFIED_SUPER ) 
<         superSuffix[$primary.tree] -> superSuffix
<     |   literal
<     |   'new' creator
<         -> creator
<     |   ( identifier -> identifier )
<         ( '.' identifier -> ^(SELECT $primary identifier) )*
<         ( (identifierSuffix[null])=> identifierSuffix[$primary.tree] -> identifierSuffix )?
<     |   ( primitiveType -> primitiveType )
<         ( '[' ']' -> ^(ARRAY_OF $primary) )*
<         '.' 'class' -> ^(CLASS_DESIGNATOR $primary)
<     |   'void' '.' 'class'
<         -> ^(CLASS_DESIGNATOR VOID)
<     ;
< 
< identifierSuffix[Tree expr]
<     :   ( '[' ']' -> ^(ARRAY_OF {expr}))
<         ( '[' ']' -> ^(ARRAY_OF $identifierSuffix) )*
<         ( '.' 'class' -> ^(CLASS_DESIGNATOR $identifierSuffix) )
<     |   (-> {expr})
<         ('[' expression ']' -> ^(ARRAY_ACCESS $identifierSuffix expression))+
<     |   arguments
<         -> ^(CALL {expr} arguments)
<     |   '.' 'class'
<         -> ^(CLASS_DESIGNATOR {expr})
<     |   '.' explicitGenericInvocation[expr]
<         -> explicitGenericInvocation
<     |   '.' 'this'
<         -> ^(QUALIFIED_THIS {expr})
<     |   '.' 'super' arguments
<         -> ^(CALL ^(QUALIFIED_SUPER {expr}) arguments)
<     |   '.' 'new' innerCreator[expr]
<         -> innerCreator
<     ;
< 
< creator
<     :   nonWildcardTypeArguments createdName classCreatorRest
<         -> ^(UNQUALIFIED_CLASS_INSTANCE_CREATION nonWildcardTypeArguments createdName classCreatorRest)
<     |   createdName
<         (   (arrayCreatorRest[$createdName.tree]
<             -> arrayCreatorRest)
<         |   classCreatorRest
<             -> ^(UNQUALIFIED_CLASS_INSTANCE_CREATION createdName classCreatorRest)
<         )
<     ;
< 
< createdName
<     :   classOrInterfaceType
<     |   primitiveType
<     ;
<     
< innerCreator[Tree expr]
<     :   (nonWildcardTypeArguments)? identifier classCreatorRest
<         -> ^(QUALIFIED_CLASS_INSTANCE_CREATION {expr} nonWildcardTypeArguments? identifier classCreatorRest)
<     ;
< 
< arrayCreatorRest[Tree name]
<     :   
<         dims arrayInitializer
<         -> ^(NEW_INITIALIZED_ARRAY {$name} dims arrayInitializer)
<     |   '[' dimExprs+=expression ']' ('[' dimExprs+=expression ']')* dims?
<         -> ^(NEW_ARRAY {$name} $dimExprs dims?)
<     ;
< 
< dims
<     :   (result+='[' ']')+
<         -> $result
<     ;
< 
< classCreatorRest
<     :   arguments classBody?
<     ;
<     
< explicitGenericInvocation[Tree expr]
<     :   nonWildcardTypeArguments identifier arguments
<         -> ^(EXPLICIT_GENERIC_INVOCATIONS {expr} nonWildcardTypeArguments identifier arguments)
<     ;
<     
< nonWildcardTypeArguments
<     :   '<' typeList '>'
<         -> ^(NON_WILD_TYPE_ARGUMENTS typeList)
<     ;
<     
< selector[Tree expr]
<     :   ('.' identifier -> ^(SELECT {expr} identifier))
<         (arguments -> ^(CALL $selector arguments))?
<     |   '.' 'this'
<         -> ^(INNER_THIS {expr})
<     |   ( '.' 'super' -> ^(QUALIFIED_SUPER {expr}) )
<         superSuffix[$selector.tree]
<         -> superSuffix
<     |   '.' 'new' innerCreator[expr]
<         -> innerCreator
<     |   '[' expression ']'
<         -> ^(ARRAY_ACCESS {expr} expression)
<     ;
<     
< superSuffix[Tree expr]
<     :   arguments
<         -> ^(CALL {expr} arguments)
<     |   ('.' identifier -> ^(SELECT {$expr} identifier))
<         ( arguments -> ^(CALL $superSuffix arguments))?
<     ;
< 
< arguments
<     :   '(' expressionList? ')'
<         -> ^(ARGUMENTS expressionList?)
<     ;
< 
< identifier
<     :   Identifier
<     ;
< 
< // LEXER
< 
< HexLiteral : '0' ('x'|'X') HexDigit+ IntegerTypeSuffix? ;
< 
< DecimalLiteral : ('0' | '1'..'9' '0'..'9'*) IntegerTypeSuffix? ;
< 
< OctalLiteral : '0' ('0'..'7')+ IntegerTypeSuffix? ;
< 
< fragment
< HexDigit : ('0'..'9'|'a'..'f'|'A'..'F') ;
< 
< fragment
< IntegerTypeSuffix : ('l'|'L') ;
< 
< FloatingPointLiteral
<     :   ('0'..'9')+ '.' ('0'..'9')* Exponent? FloatTypeSuffix?
<     |   '.' ('0'..'9')+ Exponent? FloatTypeSuffix?
<     |   ('0'..'9')+ Exponent FloatTypeSuffix?
<     |   ('0'..'9')+ FloatTypeSuffix
<     ;
< 
< fragment
< Exponent : ('e'|'E') ('+'|'-')? ('0'..'9')+ ;
< 
< fragment
< FloatTypeSuffix : ('f'|'F'|'d'|'D') ;
< 
< CharacterLiteral
<     :   '\'' ( EscapeSequence | ~('\''|'\\') ) '\''
<     ;
< 
< StringLiteral
<     :  '"' ( EscapeSequence | ~('\\'|'"') )* '"'
<     ;
< 
< fragment
< EscapeSequence
<     :   '\\' ('b'|'t'|'n'|'f'|'r'|'\"'|'\''|'\\')
<     |   UnicodeEscape
<     |   OctalEscape
<     ;
< 
< fragment
< OctalEscape
<     :   '\\' ('0'..'3') ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7')
<     ;
< 
< fragment
< UnicodeEscape
<     :   '\\' 'u' HexDigit HexDigit HexDigit HexDigit
<     ;
< 
< ENUM:   'enum' {if (!enumIsKeyword) $type=Identifier;}
<     ;
<     
< ASSERT
<     :   'assert' {if (!assertIsKeyword) $type=Identifier;}
<     ;
<     
< Identifier 
<     :   Letter (Letter|JavaIDDigit)*
<     ;
< 
< /**I found this char range in JavaCC's grammar, but Letter and Digit overlap.
<    Still works, but...
<  */
< fragment
< Letter
<     :  '\u0024' |
<        '\u0041'..'\u005a' |
<        '\u005f' |
<        '\u0061'..'\u007a' |
<        '\u00c0'..'\u00d6' |
<        '\u00d8'..'\u00f6' |
<        '\u00f8'..'\u00ff' |
<        '\u0100'..'\u1fff' |
<        '\u3040'..'\u318f' |
<        '\u3300'..'\u337f' |
<        '\u3400'..'\u3d2d' |
<        '\u4e00'..'\u9fff' |
<        '\uf900'..'\ufaff'
<     ;
< 
< fragment
< JavaIDDigit
<     :  '\u0030'..'\u0039' |
<        '\u0660'..'\u0669' |
<        '\u06f0'..'\u06f9' |
<        '\u0966'..'\u096f' |
<        '\u09e6'..'\u09ef' |
<        '\u0a66'..'\u0a6f' |
<        '\u0ae6'..'\u0aef' |
<        '\u0b66'..'\u0b6f' |
<        '\u0be7'..'\u0bef' |
<        '\u0c66'..'\u0c6f' |
<        '\u0ce6'..'\u0cef' |
<        '\u0d66'..'\u0d6f' |
<        '\u0e50'..'\u0e59' |
<        '\u0ed0'..'\u0ed9' |
<        '\u1040'..'\u1049'
<    ;
< 
< WS  :  (' '|'\r'|'\t'|'\u000C'|'\n') {$channel=HIDDEN;}
<     ;
< 
< COMMENT
<     :   '/*' (options {greedy=false;} : .)* '*/' {$channel=HIDDEN;}
<     ;
< 
< LINE_COMMENT
<     : '//' ~('\n'|'\r')* '\r'? '\n' {$channel=HIDDEN;}
<     ;
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/text-base/JavaAST.tokens.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/JavaAST.tokens.svn-base
1,287d0
< T__197=197
< FORMAL_PARAMETERS=39
< T__139=139
< PACKAGE_DECLARATION=5
< T__174=174
< HexDigit=101
< TYPE_ARGUMENTS=37
< T__196=196
< T__144=144
< T__122=122
< T__115=115
< ANNOTATION_INTERFACE=50
< T__137=137
< SIGNED_RIGHT_SHIFT=72
< UNSIGNED_RIGHT_SHIFT_ASSIGN=66
< T__140=140
< ENHANCED_FOR_CONTROL=62
< Letter=108
< COMPILATION_UNIT=4
< INTERFACE_DECLARATION=20
< LEFT_SHIFT=70
< CLASS_DESIGNATOR=79
< TYPE_BOUND=14
< CLASS_BODY=21
< T__138=138
< SELECT=36
< CONSTRUCTOR_DECLARATION=29
< T__173=173
< T__119=119
< CLASS_DECLARATION=11
< ASSERT=99
< MARKER_ANNOTATION=47
< EXPRESSION_STATEMENT=57
< T__198=198
< T__142=142
< T__176=176
< FloatTypeSuffix=104
< T__118=118
< T__135=135
< T__113=113
< ENUM_BODY=16
< FORMAL_PARAMETER=40
< IntegerTypeSuffix=102
< ARGUMENTS=91
< T__156=156
< NEW_ARRAY=87
< WS=110
< T__159=159
< T__177=177
< UNQUALIFIED_SUPER=78
< T__158=158
< NON_WILD_TYPE_ARGUMENTS=89
< LOCAL_VARIABLE_DECLARATION=54
< UnicodeEscape=106
< T__157=157
< ENUM_DECLARATION=15
< T__201=201
< T__114=114
< SINGLE_ELEMENT_ANNOTATION=46
< MODIFIERS=10
< T__143=143
< UNQUALIFIED_CLASS_INSTANCE_CREATION=84
< T__193=193
< T__141=141
< EMPTY_STATEMENT=56
< ENUM_BODY_DECLARATIONS=19
< OctalLiteral=97
< T__167=167
< T__194=194
< CAST=76
< EXPRESSION_LIST=64
< T__191=191
< TYPE_IMPORT_ON_DEMAND_DECLARATION=7
< SWITCH_BLOCK_STATEMENT_GROUP=58
< BLOCK=53
< UNSIGNED_RIGHT_SHIFT=71
< T__192=192
< EscapeSequence=105
< INTERFACE_BODY=22
< NEW_INITIALIZED_ARRAY=86
< SINGLE_STATIC_IMPORT_DECLARATION=8
< TYPE_PARAMETERS=12
< ELEMENT_VALUE_PAIR=48
< FloatingPointLiteral=93
< T__175=175
< ARRAY_OF=32
< T__117=117
< CONSTRUCTOR_BODY=34
< COMMENT=111
< T__199=199
< T__172=172
< STATIC_IMPORT_ON_DEMAND_DECLARATION=9
< THIS=77
< JavaIDDigit=109
< T__170=170
< T__136=136
< NORMAL_ANNOTATION=45
< T__116=116
< T__171=171
< CALL=81
< T__189=189
< OctalEscape=107
< T__134=134
< T__195=195
< PREFIX_EXPRESSION=73
< FOR_INIT_DECLARATION=60
< T__162=162
< FOR_INIT_EXPRESSION_LIST=61
< FIELD_DECLARATION=26
< INSTANTIATION=35
< T__160=160
< T__123=123
< T__145=145
< POST_INCREMENT_EXPRESSION=74
< T__187=187
< GREATER_THAN_OR_EQUAL_TO=69
< CONSTANT_DECLARATION=31
< T__186=186
< ELEMENT_VALUE_ARRAY_INITIALIZER=49
< T__181=181
< SINGLE_TYPE_IMPORT_DECLARATION=6
< T__128=128
< STATIC_INITIALIZER=23
< BASIC_FOR_CONTROL=59
< ENUM_CONSTANTS=17
< LAST_FORMAL_PARAMETER=41
< T__161=161
< T__168=168
< T__150=150
< Identifier=100
< QUALIFIED_THIS=82
< ENUM_CONSTANT=18
< ANNOTATION_METHOD=52
< T__182=182
< T__165=165
< T__130=130
< T__151=151
< LINE_COMMENT=112
< QUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION=44
< METHOD_DECLARATION=27
< HexLiteral=96
< T__125=125
< T__149=149
< T__166=166
< DecimalLiteral=98
< T__132=132
< ARRAY_INITIALIZER=33
< INNER_THIS=90
< LESS_THAN_OR_EQUAL_TO=68
< POST_DECREMENT_EXPRESSION=75
< T__190=190
< T__124=124
< T__131=131
< T__169=169
< QUALIFIED_SUPER=83
< ALTERNATE_CONSTRUCTOR_INVOCATION=42
< T__126=126
< T__148=148
< INSTANCE_INITIALIZER=24
< UNQUALIFIED_SUPERCLASS_CONSTRUCTOR_INVOCATION=43
< T__188=188
< T__200=200
< TYPE_PARAMETER=13
< T__127=127
< VOID=25
< T__183=183
< T__133=133
< ARRAY_ACCESS=80
< T__164=164
< T__120=120
< ENUM=92
< T__163=163
< Exponent=103
< T__153=153
< SIGNED_RIGHT_SHIFT_ASSIGN=67
< T__185=185
< CharacterLiteral=94
< T__178=178
< WILDCARD=38
< LEFT_SHIFT_ASSIGN=65
< StringLiteral=95
< T__129=129
< T__180=180
< EXPLICIT_GENERIC_INVOCATIONS=88
< T__152=152
< VARIABLE_DECLARATOR=30
< ANNOTATION_TYPE_BODY=51
< T__121=121
< QUALIFIED_CLASS_INSTANCE_CREATION=85
< FOR_UPDATE=63
< ASSERT_STATEMENT=55
< T__147=147
< T__179=179
< T__154=154
< ABSTRACT_METHOD_DECLARATION=28
< T__184=184
< T__155=155
< T__146=146
< '<'=128
< '-='=179
< 'interface'=134
< '>'=130
< 'case'=177
< 'try'=169
< 'boolean'=144
< 'else'=165
< '/='=181
< 'package'=113
< '-'=194
< '?'=152
< '!='=191
< '%='=185
< 'do'=168
< '||'=186
< 'double'=151
< '='=139
< '*='=180
< 'volatile'=143
< 'instanceof'=192
< 'super'=153
< 'strictfp'=124
< '|='=183
< 'native'=140
< '++'=197
< '{'=132
< 'void'=135
< 'catch'=176
< 'throws'=138
< 'float'=150
< 'new'=201
< ':'=163
< 'for'=166
< '.'=117
< '*'=118
< 'short'=147
< '}'=133
< '~'=199
< 'finally'=170
< 'break'=174
< '%'=196
< 'final'=123
< ';'=114
< 'synchronized'=141
< 'default'=162
< ']'=137
< 'true'=159
< 'false'=160
< '&'=131
< ','=129
< '&&'=187
< 'int'=148
< '&='=182
< 'while'=167
< 'this'=157
< 'continue'=175
< '['=136
< '/'=195
< '^'=189
< 'long'=149
< 'private'=121
< '|'=188
< 'return'=172
< ')'=155
< '=='=190
< 'static'=116
< 'implements'=127
< '@'=161
< 'throw'=173
< 'protected'=120
< 'import'=115
< '!'=200
< 'if'=164
< 'char'=145
< '+='=178
< 'switch'=171
< '('=154
< 'transient'=142
< 'byte'=146
< 'extends'=126
< '--'=198
< '^='=184
< 'class'=125
< '+'=193
< 'null'=158
< '...'=156
< 'public'=119
< 'abstract'=122
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/text-base/MyAstNodeAdaptor.java.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/MyAstNodeAdaptor.java.svn-base
1,8d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< class MyAstNodeAdaptor extends CommonTreeAdaptor {
<     public Object create(Token t) {
< 	return new MyAstNode(t);
<     }
< };
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/text-base/MyAstNode.java.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/MyAstNode.java.svn-base
1,11d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< import java.io.*;
< 
< public class MyAstNode extends CommonTree {
<     boolean is_statement = false;
<     public MyAstNode(Token t) {
< 	super(t);
<     }
< }
Binary files code-worker/tasks/clonedigger/java_antlr/.svn/text-base/TreeProducer.jar.svn-base and code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/TreeProducer.jar.svn-base differ
diff -r -N code-worker/tasks/clonedigger/java_antlr/.svn/text-base/TreeProducer.java.svn-base code-worker/code-worker/tasks/clonedigger/java_antlr/.svn/text-base/TreeProducer.java.svn-base
1,107d0
< /*  Copyright 2008 Peter Bulychev
<  *
<  *  This file is part of Clone Digger.
<  *
<  *  Clone Digger is free software: you can redistribute it and/or modify
<  *  it under the terms of the GNU General Public License as published by
<  *  the Free Software Foundation, either version 3 of the License, or
<  *  (at your option) any later version.
<  *
<  *  Clone Digger is distributed in the hope that it will be useful,
<  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
<  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<  *  GNU General Public License for more details.
<  *
<  *  You should have received a copy of the GNU General Public License
<  *  along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
<  */
< import org.antlr.runtime.*;
< import org.antlr.stringtemplate.*;
< import org.antlr.runtime.tree.*;
< import java.lang.reflect.*;
< import java.io.*;
< import java.util.*;
< import java.text.*;
< import java.lang.*;
< 
< public class TreeProducer
< {
<     public TreeProducer ()
<     {
< 	super ();
<     }
< 
<     /*
<      * forXml function was taken from http://www.javapractices.com/topic/TopicAction.do?Id=96
<      * the license is: http://creativecommons.org/licenses/by/3.0/
<      */
<     public static String forXML (String aText)
<     {
< 	final StringBuilder result = new StringBuilder ();
< 	final StringCharacterIterator iterator =
< 	    new StringCharacterIterator (aText);
< 	char character = iterator.current ();
< 	while (character != CharacterIterator.DONE)
< 	{
< 	    if (character == '<')
< 	    {
< 		result.append ("&lt;");
< 	    }
< 	    else if (character == '>')
< 	    {
< 		result.append ("&gt;");
< 	    }
< 	    else if (character == '\"')
< 	    {
< 		result.append ("&quot;");
< 	    }
< 	    else if (character == '\'')
< 	    {
< 		result.append ("&#039;");
< 	    }
< 	    else if (character == '&')
< 	    {
< 		result.append ("&amp;");
< 	    }
< 	    else
< 	    {
< 		//the char is not a special one
< 		//        //add it to the result as is
< 		result.append (character);
< 	    }
< 	    character = iterator.next ();
< 	}
< 	return result.toString ();
<     }
<     //                                      }
< 
<     public static void printTree (MyAstNode tree, PrintWriter outputStream,	String indent)
< {
<     String xml_node_name = (tree.is_statement?"statement_node":"node");
<     outputStream.println (indent + "<" + xml_node_name + " name=\"" + forXML ("" + tree) + "\"" + 
< 	    " line_number=\"" + tree.getLine () + "\" " + 
< 	    "start=\"" +  ((CommonToken) tree.token).getStartIndex() + "\" " + 
< 	    "stop=\"" + ((CommonToken) tree.token).getStopIndex() + "\">");
<     for (int i = 0; i < tree.getChildCount (); i += 1)
<     {
< 	printTree ((MyAstNode )tree.getChild (i), outputStream, indent + "  ");
<     }
<     outputStream.println (indent + "</"+xml_node_name+">");
< }
< 
< public static void main (String[]args) throws Exception
< {
<     ANTLRFileStream input = new ANTLRFileStream (args[0]);
<     JavaASTLexer lexer = new JavaASTLexer (input);
<     CommonTokenStream tokens = new CommonTokenStream (lexer);
<     JavaASTParser parser = new JavaASTParser (tokens);
<     MyAstNodeAdaptor adaptor = new MyAstNodeAdaptor ();
<     parser.setTreeAdaptor (adaptor);
<     MyAstNode tree = (MyAstNode) parser.compilationUnit ().getTree ();
<     PrintWriter outputStream =
< 	new PrintWriter (new FileWriter (args[1], false));
<     outputStream.println ("<?xml version=\"1.0\" ?>");
<     printTree (tree, outputStream, "");
<     outputStream.close ();
< }
< }
Binary files code-worker/tasks/clonedigger/java_antlr/TreeProducer.jar and code-worker/code-worker/tasks/clonedigger/java_antlr/TreeProducer.jar differ
diff -r -N code-worker/tasks/clonedigger/java_antlr/TreeProducer.java code-worker/code-worker/tasks/clonedigger/java_antlr/TreeProducer.java
1,107d0
< /*  Copyright 2008 Peter Bulychev
<  *
<  *  This file is part of Clone Digger.
<  *
<  *  Clone Digger is free software: you can redistribute it and/or modify
<  *  it under the terms of the GNU General Public License as published by
<  *  the Free Software Foundation, either version 3 of the License, or
<  *  (at your option) any later version.
<  *
<  *  Clone Digger is distributed in the hope that it will be useful,
<  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
<  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<  *  GNU General Public License for more details.
<  *
<  *  You should have received a copy of the GNU General Public License
<  *  along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
<  */
< import org.antlr.runtime.*;
< import org.antlr.stringtemplate.*;
< import org.antlr.runtime.tree.*;
< import java.lang.reflect.*;
< import java.io.*;
< import java.util.*;
< import java.text.*;
< import java.lang.*;
< 
< public class TreeProducer
< {
<     public TreeProducer ()
<     {
< 	super ();
<     }
< 
<     /*
<      * forXml function was taken from http://www.javapractices.com/topic/TopicAction.do?Id=96
<      * the license is: http://creativecommons.org/licenses/by/3.0/
<      */
<     public static String forXML (String aText)
<     {
< 	final StringBuilder result = new StringBuilder ();
< 	final StringCharacterIterator iterator =
< 	    new StringCharacterIterator (aText);
< 	char character = iterator.current ();
< 	while (character != CharacterIterator.DONE)
< 	{
< 	    if (character == '<')
< 	    {
< 		result.append ("&lt;");
< 	    }
< 	    else if (character == '>')
< 	    {
< 		result.append ("&gt;");
< 	    }
< 	    else if (character == '\"')
< 	    {
< 		result.append ("&quot;");
< 	    }
< 	    else if (character == '\'')
< 	    {
< 		result.append ("&#039;");
< 	    }
< 	    else if (character == '&')
< 	    {
< 		result.append ("&amp;");
< 	    }
< 	    else
< 	    {
< 		//the char is not a special one
< 		//        //add it to the result as is
< 		result.append (character);
< 	    }
< 	    character = iterator.next ();
< 	}
< 	return result.toString ();
<     }
<     //                                      }
< 
<     public static void printTree (MyAstNode tree, PrintWriter outputStream,	String indent)
< {
<     String xml_node_name = (tree.is_statement?"statement_node":"node");
<     outputStream.println (indent + "<" + xml_node_name + " name=\"" + forXML ("" + tree) + "\"" + 
< 	    " line_number=\"" + tree.getLine () + "\" " + 
< 	    "start=\"" +  ((CommonToken) tree.token).getStartIndex() + "\" " + 
< 	    "stop=\"" + ((CommonToken) tree.token).getStopIndex() + "\">");
<     for (int i = 0; i < tree.getChildCount (); i += 1)
<     {
< 	printTree ((MyAstNode )tree.getChild (i), outputStream, indent + "  ");
<     }
<     outputStream.println (indent + "</"+xml_node_name+">");
< }
< 
< public static void main (String[]args) throws Exception
< {
<     ANTLRFileStream input = new ANTLRFileStream (args[0]);
<     JavaASTLexer lexer = new JavaASTLexer (input);
<     CommonTokenStream tokens = new CommonTokenStream (lexer);
<     JavaASTParser parser = new JavaASTParser (tokens);
<     MyAstNodeAdaptor adaptor = new MyAstNodeAdaptor ();
<     parser.setTreeAdaptor (adaptor);
<     MyAstNode tree = (MyAstNode) parser.compilationUnit ().getTree ();
<     PrintWriter outputStream =
< 	new PrintWriter (new FileWriter (args[1], false));
<     outputStream.println ("<?xml version=\"1.0\" ?>");
<     printTree (tree, outputStream, "");
<     outputStream.close ();
< }
< }
diff -r -N code-worker/tasks/clonedigger/java_antlr.py code-worker/code-worker/tasks/clonedigger/java_antlr.py
1,74d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>. 
< 
< import os
< import xml.parsers.expat
< 
< from abstract_syntax_tree import *
< 
< class JavaANTLRSourceFile (SourceFile):
<     extension = 'java'
<     size_threshold = 10
<     distance_threshold = 7
<     def __init__(self, file_name):
<         SourceFile.__init__(self, file_name)
<         class ExpatHandler:
<             def __init__(self, start_node, parent):
<                 self.parent = parent
<                 self.stack = [start_node]
<             def start_element(expat_self, xml_node_name, attrs):
<                 line_number = int(attrs["line_number"])-1
<                 line_numbers = [line_number]
<                 if line_numbers == [-1]:
<                     line_numbers = []
<                 name = attrs["name"]
<                 r = AbstractSyntaxTree(name, line_numbers, self)
<                 if xml_node_name == "statement_node":
<                     r.markAsStatement()
<                 else:
<                     assert(xml_node_name == "node")
<                 expat_self.stack[-1].addChild(r)                
<                 expat_self.stack.append(r)
<             def end_element(self, name):
<                 self.stack.pop()
< 
<         tree_file_name  = 'temporary_ast.xml'
<         producer_class_path = os.path.join('.','java_antlr', 'TreeProducer.jar')
<         antlr_class_path = os.path.join('.','antlr_runtime','runtime-2008-01-10.16.jar')
<         if os.name in ['mac', 'posix']:
<             class_path_delimeter = ':'
<         elif os.name in ['nt', 'dos', 'ce']:
<             class_path_delimeter = ';'
<         else:
<             print 'unsupported OS'
<             assert(0)
<         if os.system('java -classpath ' + producer_class_path + class_path_delimeter + antlr_class_path + ' TreeProducer %s %s 2>err.log' %(file_name, tree_file_name)):
<             f = open('err.log')
<             s = f.read()
<             f.close()
<             raise s
<         
<         self._tree = AbstractSyntaxTree('program')
<         handler = ExpatHandler(self._tree, self)
<         p = xml.parsers.expat.ParserCreate()
<         p.StartElementHandler = handler.start_element
<         p.EndElementHandler = handler.end_element
<         f = open(tree_file_name)
<         p.ParseFile(f)
<         f.close()
<         os.remove(tree_file_name)
diff -r -N code-worker/tasks/clonedigger/js_antlr/build_jar.sh code-worker/code-worker/tasks/clonedigger/js_antlr/build_jar.sh
1,4d0
< java org.antlr.Tool JavaScript.g
< javac *.java
< jar -cf TreeProducer.jar *.class
< rm *.class
diff -r -N code-worker/tasks/clonedigger/js_antlr/JavaScript.g code-worker/code-worker/tasks/clonedigger/js_antlr/JavaScript.g
1,1538d0
< /*
< 
< Updated by Haoyu Bai:
<     Add Clone Digger specific things and change define of 'block' from 'statement' to 'sourceElement' since functionDeclartion can inline of code.
< 
< Copyrights 2008 Xebic Reasearch BV. All rights reserved (see license.txt).
< Owner : Patrick Hulsmeijer.
< 
< This ANTLR 3 LL(*) grammar is based on Ecma-262 3rd edition (JavaScript 1.5, JScript 5.5). 
< The annotations refer to the "A Grammar Summary" section (e.g. A.1 Lexical Grammar) and the numbers in parenthesis to the paragraph numbers (e.g. (7.8) ).
< This document is best viewed with ANTLRWorks (www.antlr.org).
< 
< 
< The major challenges faced in defining this grammar were:
< 
< -1- Ambiguity surrounding the DIV sign in relation to the multiplicative expression and the regular expression literal.
< This is solved with some lexer driven magic: a gated semantical predicate turns the recognition of regular expressions on or off, based on the
< value of the RegularExpressionsEnabled property. When regular expressions are enabled they take precedence over division expressions. The decision whether
< regular expressions are enabled is based on the heuristics that the previous token can be considered as last token of a left-hand-side operand of a division.
< 
< -2- Automatic semicolon insertion.
< This is solved within the parser. The semicolons are not physically inserted but the situations in which they should are recognized and treated as if they were.
< The physical insertion of semicolons would be undesirable because of several reasons:
< - performance degration because of how ANTLR handles tokens in token streams
< - the alteration of the input, which we need to have unchanged
< - it is superfluous being of no interest to AST construction
< 
< -3- Unicode identifiers
< Because ANTLR couldn't handle the unicode tables defined in the specification well and for performance reasons unicode identifiers are implemented as an action 
< driven alternative to ASCII identifiers. First the ASCII version is tried that is defined in detail in this grammar and then the unicode alternative is tried action driven.
< Because of the fact that the ASCII version is defined in detail the mTokens switch generation in the lexer can predict identifiers appropriately.
< For details see the identifier rules.
< 
< 
< The minor challenges were related to converting the grammar to an ANTLR LL(*) grammar:
< - Resolving the ambiguity between functionDeclaration vs functionExpression and block vs objectLiteral stemming from the expressionStatement production.
< - Left recursive nature of the left hand side expressions.
< - The assignmentExpression production.
< - The forStatement production.
< The grammar was kept as close as possible to the grammar in the "A Grammar Summary" section of Ecma-262.
< 
< */
< 
< grammar JavaScript ;
< 
< options
< {
< 	output = AST ;
<     memoize = true ;
< 	language = Java ;
<     ASTLabelType=MyAstNode;
< }
< 
< tokens
< {
< // Reserved words
< 	NULL		= 'null' ;
< 	TRUE		= 'true' ;
< 	FALSE		= 'false' ;
< 
< // Keywords
< 	BREAK		= 'break' ;
< 	CASE		= 'case' ;
< 	CATCH 		= 'catch' ;
< 	CONTINUE 	= 'continue' ;
< 	DEFAULT		= 'default' ;
< 	DELETE		= 'delete' ;
< 	DO 		= 'do' ;
< 	ELSE 		= 'else' ;
< 	FINALLY 	= 'finally' ;
< 	FOR 		= 'for' ;
< 	FUNCTION 	= 'function' ;
< 	IF 		= 'if' ;
< 	IN 		= 'in' ;
< 	INSTANCEOF 	= 'instanceof' ;
< 	NEW 		= 'new' ;
< 	RETURN 		= 'return' ;
< 	SWITCH 		= 'switch' ;
< 	THIS 		= 'this' ;
< 	THROW 		= 'throw' ;
< 	TRY 		= 'try' ;
< 	TYPEOF 		= 'typeof' ;
< 	VAR 		= 'var' ;
< 	VOID 		= 'void' ;
< 	WHILE 		= 'while' ;
< 	WITH 		= 'with' ;
< 
< // Future reserved words
< 	ABSTRACT	= 'abstract' ;
< 	BOOLEAN 	= 'boolean' ;
< 	BYTE 		= 'byte' ;
< 	CHAR 		= 'char' ;
< 	CLASS 		= 'class' ;
< 	CONST 		= 'const' ;
< 	DEBUGGER 	= 'debugger' ;
< 	DOUBLE		= 'double' ;
< 	ENUM 		= 'enum' ;
< 	EXPORT 		= 'export' ;
< 	EXTENDS		= 'extends' ;
< 	FINAL 		= 'final' ;
< 	FLOAT 		= 'float' ;
< 	GOTO 		= 'goto' ;
< 	IMPLEMENTS 	= 'implements' ;
< 	IMPORT		= 'import' ;
< 	INT 		= 'int' ;
< 	INTERFACE 	= 'interface' ;
< 	LONG 		= 'long' ;
< 	NATIVE 		= 'native' ;
< 	PACKAGE 	= 'package' ;
< 	PRIVATE 	= 'private' ;
< 	PROTECTED 	= 'protected' ;
< 	PUBLIC		= 'public' ;
< 	SHORT 		= 'short' ;
< 	STATIC 		= 'static' ;
< 	SUPER 		= 'super' ;
< 	SYNCHRONIZED 	= 'synchronized' ;
< 	THROWS 		= 'throws' ;
< 	TRANSIENT 	= 'transient' ;
< 	VOLATILE 	= 'volatile' ;
< 
< // Punctuators
< 	LBRACE		= '{' ;
< 	RBRACE		= '}' ;
< 	LPAREN		= '(' ;
< 	RPAREN		= ')' ;
< 	LBRACK		= '[' ;
< 	RBRACK		= ']' ;
< 	DOT		= '.' ;
< 	SEMIC		= ';' ;
< 	COMMA		= ',' ;
< 	LT		= '<' ;
< 	GT		= '>' ;
< 	LTE		= '<=' ;
< 	GTE		= '>=' ;
< 	EQ		= '==' ;
< 	NEQ		= '!=' ;
< 	SAME		= '===' ;
< 	NSAME		= '!==' ;
< 	ADD		= '+' ;
< 	SUB		= '-' ;
< 	MUL		= '*' ;
< 	MOD		= '%' ;
< 	INC		= '++' ;
< 	DEC		= '--' ;
< 	SHL		= '<<' ;
< 	SHR		= '>>' ;
< 	SHU		= '>>>' ;
< 	AND		= '&' ;
< 	OR		= '|' ;
< 	XOR		= '^' ;
< 	NOT		= '!' ;
< 	INV		= '~' ;
< 	LAND		= '&&' ;
< 	LOR		= '||' ;
< 	QUE		= '?' ;
< 	COLON		= ':' ;
< 	ASSIGN		= '=' ;
< 	ADDASS		= '+=' ;
< 	SUBASS		= '-=' ;
< 	MULASS		= '*=' ;
< 	MODASS		= '%=' ;
< 	SHLASS		= '<<=' ;
< 	SHRASS		= '>>=' ;
< 	SHUASS		= '>>>=' ;
< 	ANDASS		= '&=' ;
< 	ORASS		= '|=' ;
< 	XORASS		= '^=' ;
< 	DIV		= '/' ;
< 	DIVASS		= '/=' ;
< 	
< // Imaginary
< 	ARGS ;
< 	ARRAY ;
< 	BLOCK ;
< 	BYFIELD ;
< 	BYINDEX ;
< 	CALL ;
< 	CEXPR ;
< 	EXPR ;
< 	FORITER ;
< 	FORSTEP ;
< 	ITEM ;
< 	LABELLED ;
< 	NAMEDVALUE ;
< 	NEG ;
< 	OBJECT ;
< 	PAREXPR ;
< 	PDEC ;
< 	PINC ;
< 	POS ;
< }
< 
< @lexer::members
< {
< private Token last;
< 
< private final boolean areRegularExpressionsEnabled()
< {
< 	if (last == null)
< 	{
< 		return true;
< 	}
< 	switch (last.getType())
< 	{
< 	// identifier
< 		case Identifier:
< 	// literals
< 		case NULL:
< 		case TRUE:
< 		case FALSE:
< 		case THIS:
< 		case OctalIntegerLiteral:
< 		case DecimalLiteral:
< 		case HexIntegerLiteral:
< 		case StringLiteral:
< 	// member access ending 
< 		case RBRACK:
< 	// function call or nested expression ending
< 		case RPAREN:
< 			return false;
< 	// otherwise OK
< 		default:
< 			return true;
< 	}
< }
< 	
< private final void consumeIdentifierUnicodeStart() throws RecognitionException, NoViableAltException
< {
< 	int ch = input.LA(1);
< 	if (isIdentifierStartUnicode(ch))
< 	{
< 		matchAny();
< 		do
< 		{
< 			ch = input.LA(1);
< 			if (ch == '$' || (ch >= '0' && ch <= '9') || (ch >= 'A' && ch <= 'Z') || ch == '\\' || ch == '_' || (ch >= 'a' && ch <= 'z') || isIdentifierPartUnicode(ch))
< 			{
< 				mIdentifierPart();
< 			}
< 			else
< 			{
< 				return;
< 			}
< 		}
< 		while (true);
< 	}
< 	else
< 	{
< 		throw new NoViableAltException();
< 	}
< }
< 	
< private final boolean isIdentifierPartUnicode(int ch)
< {
< 	return Character.isJavaIdentifierPart(ch);
< }
< 	
< private final boolean isIdentifierStartUnicode(int ch)
< {
< 	return Character.isJavaIdentifierStart(ch);
< }
< 
< public Token nextToken()
< {
< 	Token result = super.nextToken();
< 	if (result.getChannel() == Token.DEFAULT_CHANNEL)
< 	{
< 		last = result;
< 	}
< 	return result;		
< }
< }
< 
< @parser::members
< {
< private final boolean isLeftHandSideAssign(RuleReturnScope lhs, Object[] cached)
< {
< 	if (cached[0] != null)
< 	{
< 		return ((Boolean)cached[0]).booleanValue();
< 	}
< 	
< 	boolean result;
< 	if (isLeftHandSideExpression(lhs))
< 	{
< 		switch (input.LA(1))
< 		{
< 			case ASSIGN:
< 			case MULASS:
< 			case DIVASS:
< 			case MODASS:
< 			case ADDASS:
< 			case SUBASS:
< 			case SHLASS:
< 			case SHRASS:
< 			case SHUASS:
< 			case ANDASS:
< 			case XORASS:
< 			case ORASS:
< 				result = true;
< 				break;
< 			default:
< 				result = false;
< 				break;
< 		}
< 	}
< 	else
< 	{
< 		result = false;
< 	}
< 	
< 	cached[0] = new Boolean(result);
< 	return result;
< }
< 
< private final static boolean isLeftHandSideExpression(RuleReturnScope lhs)
< {
< 	if (lhs.getTree() == null) // e.g. during backtracking
< 	{
< 		return true;
< 	}
< 	else
< 	{
< 		switch (((Tree)lhs.getTree()).getType())
< 		{
< 		// primaryExpression
< 			case THIS:
< 			case Identifier:
< 			case NULL:
< 			case TRUE:
< 			case FALSE:
< 			case DecimalLiteral:
< 			case OctalIntegerLiteral:
< 			case HexIntegerLiteral:
< 			case StringLiteral:
< 			case RegularExpressionLiteral:
< 			case ARRAY:
< 			case OBJECT:
< 			case PAREXPR:
< 		// functionExpression
< 			case FUNCTION:
< 		// newExpression
< 			case NEW:
< 		// leftHandSideExpression
< 			case CALL:
< 			case BYFIELD:
< 			case BYINDEX:
< 				return true;
< 			
< 			default:
< 				return false;
< 		}
< 	}
< }
< 	
< private final boolean isLeftHandSideIn(RuleReturnScope lhs, Object[] cached)
< {
< 	if (cached[0] != null)
< 	{
< 		return ((Boolean)cached[0]).booleanValue();
< 	}
< 	
< 	boolean result = isLeftHandSideExpression(lhs) && (input.LA(1) == IN);
< 	cached[0] = new Boolean(result);
< 	return result;
< }
< 
< private final void promoteEOL(ParserRuleReturnScope rule)
< {
< 	// Get current token and its type (the possibly offending token).
< 	Token lt = input.LT(1);
< 	int la = lt.getType();
< 	
< 	// We only need to promote an EOL when the current token is offending (not a SEMIC, EOF, RBRACE, EOL or MultiLineComment).
< 	// EOL and MultiLineComment are not offending as they're already promoted in a previous call to this method.
< 	// Promoting an EOL means switching it from off channel to on channel.
< 	// A MultiLineComment gets promoted when it contains an EOL.
< 	if (!(la == SEMIC || la == EOF || la == RBRACE || la == EOL || la == MultiLineComment))
< 	{
< 		// Start on the possition before the current token and scan backwards off channel tokens until the previous on channel token.
< 		for (int ix = lt.getTokenIndex() - 1; ix > 0; ix--)
< 		{
< 			lt = input.get(ix);
< 			if (lt.getChannel() == Token.DEFAULT_CHANNEL)
< 			{
< 				// On channel token found: stop scanning.
< 				break;
< 			}
< 			else if (lt.getType() == EOL || (lt.getType() == MultiLineComment && lt.getText().matches("/.*\r\n|\r|\n")))
< 			{
< 				// We found our EOL: promote the token to on channel, position the input on it and reset the rule start.
< 				lt.setChannel(Token.DEFAULT_CHANNEL);
< 				input.seek(lt.getTokenIndex());
< 				if (rule != null)
< 				{
< 					rule.start = lt;
< 				}
< 				break;
< 			}
< 		}
< 	}
< }	
< }
< 
< //
< // $<	A.1 Lexical Grammar (7)
< //
< 
< // Added for lexing purposes
< 
< fragment BSLASH
< 	: '\\'
< 	;
< 	
< fragment DQUOTE
< 	: '"'
< 	;
< 	
< fragment SQUOTE
< 	: '\''
< 	;
< 
< // $<	Whitespace (7.2)
< 
< fragment TAB
< 	: '\u0009'
< 	;
< 
< fragment VT // Vertical TAB
< 	: '\u000b'
< 	;
< 
< fragment FF // Form Feed
< 	: '\u000c'
< 	;
< 
< fragment SP // Space
< 	: '\u0020'
< 	;
< 
< fragment NBSP // Non-Breaking Space
< 	: '\u00a0'
< 	;
< 
< fragment USP // Unicode Space Separator (rest of Unicode category Zs)
< 	: '\u1680'  // OGHAM SPACE MARK
< 	| '\u180E'  // MONGOLIAN VOWEL SEPARATOR
< 	| '\u2000'  // EN QUAD
< 	| '\u2001'  // EM QUAD
< 	| '\u2002'  // EN SPACE
< 	| '\u2003'  // EM SPACE
< 	| '\u2004'  // THREE-PER-EM SPACE
< 	| '\u2005'  // FOUR-PER-EM SPACE
< 	| '\u2006'  // SIX-PER-EM SPACE
< 	| '\u2007'  // FIGURE SPACE
< 	| '\u2008'  // PUNCTUATION SPACE
< 	| '\u2009'  // THIN SPACE
< 	| '\u200A'  // HAIR SPACE
< 	| '\u202F'  // NARROW NO-BREAK SPACE
< 	| '\u205F'  // MEDIUM MATHEMATICAL SPACE
< 	| '\u3000'  // IDEOGRAPHIC SPACE
< 	;
< 
< WhiteSpace
< 	: ( TAB | VT | FF | SP | NBSP | USP )+ { $channel = HIDDEN; }
< 	;
< 
< // $>
< 
< // $<	Line terminators (7.3)
< 
< fragment LF // Line Feed
< 	: '\n'
< 	;
< 
< fragment CR // Carriage Return
< 	: '\r'
< 	;
< 
< fragment LS // Line Separator
< 	: '\u2028'
< 	;
< 
< fragment PS // Paragraph Separator
< 	: '\u2029'
< 	;
< 
< fragment LineTerminator
< 	: CR | LF | LS | PS
< 	;
< 		
< EOL
< 	: ( ( CR LF? ) | LF | LS | PS ) { $channel = HIDDEN; }
< 	;
< // $>
< 
< // $<	Comments (7.4)
< 
< MultiLineComment
< 	: '/*' ( options { greedy = false; } : . )* '*/' { $channel = HIDDEN; }
< 	;
< 
< SingleLineComment
< 	: '//' ( ~( LineTerminator ) )* { $channel = HIDDEN; }
< 	;
< 
< // $>
< 
< // $<	Tokens (7.5)
< 
< token
< 	: reservedWord
< 	| Identifier
< 	| punctuator
< 	| numericLiteral
< 	| StringLiteral
< 	;
< 
< // $<	Reserved words (7.5.1)
< 
< reservedWord
< 	: keyword
< 	| futureReservedWord
< 	| NULL
< 	| booleanLiteral
< 	;
< 
< // $>
< 	
< // $<	Keywords (7.5.2)
< 
< keyword
< 	: BREAK
< 	| CASE
< 	| CATCH
< 	| CONTINUE
< 	| DEFAULT
< 	| DELETE
< 	| DO
< 	| ELSE
< 	| FINALLY
< 	| FOR
< 	| FUNCTION
< 	| IF
< 	| IN
< 	| INSTANCEOF
< 	| NEW
< 	| RETURN
< 	| SWITCH
< 	| THIS
< 	| THROW
< 	| TRY
< 	| TYPEOF
< 	| VAR
< 	| VOID
< 	| WHILE
< 	| WITH
< 	;
< 
< // $>
< 
< // $<	Future reserved words (7.5.3)
< 
< futureReservedWord
< 	: ABSTRACT
< 	| BOOLEAN
< 	| BYTE
< 	| CHAR
< 	| CLASS
< 	| CONST
< 	| DEBUGGER
< 	| DOUBLE
< 	| ENUM
< 	| EXPORT
< 	| EXTENDS
< 	| FINAL
< 	| FLOAT
< 	| GOTO
< 	| IMPLEMENTS
< 	| IMPORT
< 	| INT
< 	| INTERFACE
< 	| LONG
< 	| NATIVE
< 	| PACKAGE
< 	| PRIVATE
< 	| PROTECTED
< 	| PUBLIC
< 	| SHORT
< 	| STATIC
< 	| SUPER
< 	| SYNCHRONIZED
< 	| THROWS
< 	| TRANSIENT
< 	| VOLATILE
< 	;
< 
< // $>
< 
< // $>
< 	
< // $<	Identifiers (7.6)
< 
< fragment IdentifierStartASCII
< 	: 'a'..'z' | 'A'..'Z'
< 	| '$'
< 	| '_'
< 	| BSLASH 'u' HexDigit HexDigit HexDigit HexDigit // UnicodeEscapeSequence
< 	;
< 
< /*
< The first two alternatives define how ANTLR can match ASCII characters which can be considered as part of an identifier.
< The last alternative matches other characters in the unicode range that can be sonsidered as part of an identifier.
< */
< fragment IdentifierPart
< 	: DecimalDigit
< 	| IdentifierStartASCII
< 	| { isIdentifierPartUnicode(input.LA(1)) }? { matchAny(); }
< 	;
< 
< fragment IdentifierNameASCIIStart
< 	: IdentifierStartASCII IdentifierPart*
< 	;
< 
< /*
< The second alternative acts as an action driven fallback to evaluate other characters in the unicode range than the ones in the ASCII subset.
< Due to the first alternative this grammar defines enough so that ANTLR can generate a lexer that correctly predicts identifiers with characters in the ASCII range.
< In that way keywords, other reserved words and ASCII identifiers are recognized with standard ANTLR driven logic. When the first character for an identifier fails to 
< match this ASCII definition, the lexer calls consumeIdentifierUnicodeStart because of the action in the alternative. This method checks whether the character matches 
< as first character in ranges other than ASCII and consumes further characters belonging to the identifier with help of mIdentifierPart generated out of the 
< IdentifierPart rule above.
< */
< Identifier
< 	: IdentifierNameASCIIStart
< 	| { consumeIdentifierUnicodeStart(); }
< 	;
< 
< // $>
< 
< // $<	Punctuators (7.7)
< 
< punctuator
< 	: LBRACE
< 	| RBRACE
< 	| LPAREN
< 	| RPAREN
< 	| LBRACK
< 	| RBRACK
< 	| DOT
< 	| SEMIC
< 	| COMMA
< 	| LT
< 	| GT
< 	| LTE
< 	| GTE
< 	| EQ
< 	| NEQ
< 	| SAME
< 	| NSAME
< 	| ADD
< 	| SUB
< 	| MUL
< 	| MOD
< 	| INC
< 	| DEC
< 	| SHL
< 	| SHR
< 	| SHU
< 	| AND
< 	| OR
< 	| XOR
< 	| NOT
< 	| INV
< 	| LAND
< 	| LOR
< 	| QUE
< 	| COLON
< 	| ASSIGN
< 	| ADDASS
< 	| SUBASS
< 	| MULASS
< 	| MODASS
< 	| SHLASS
< 	| SHRASS
< 	| SHUASS
< 	| ANDASS
< 	| ORASS
< 	| XORASS
< 	| DIV
< 	| DIVASS
< 	;
< 
< // $>
< 
< // $<	Literals (7.8)
< 
< literal
< 	: NULL
< 	| booleanLiteral
< 	| numericLiteral
< 	| StringLiteral
< 	| RegularExpressionLiteral
< 	;
< 
< booleanLiteral
< 	: TRUE
< 	| FALSE
< 	;
< 
< // $<	Numeric literals (7.8.3)
< 
< /*
< Note: octal literals are described in the B Compatibility section.
< These are removed from the standards but are here for backwards compatibility with earlier ECMAScript definitions.
< */
< 
< fragment DecimalDigit
< 	: '0'..'9'
< 	;
< 
< fragment HexDigit
< 	: DecimalDigit | 'a'..'f' | 'A'..'F'
< 	;
< 
< fragment OctalDigit
< 	: '0'..'7'
< 	;
< 
< fragment ExponentPart
< 	: ( 'e' | 'E' ) ( '+' | '-' )? DecimalDigit+
< 	;
< 
< fragment DecimalIntegerLiteral
< 	: '0'
< 	| '1'..'9' DecimalDigit*
< 	;
< 
< DecimalLiteral
< 	: DecimalIntegerLiteral '.' DecimalDigit* ExponentPart?
< 	| '.' DecimalDigit+ ExponentPart?
< 	| DecimalIntegerLiteral ExponentPart?
< 	;
< 
< OctalIntegerLiteral
< 	: '0' OctalDigit+
< 	;
< 
< HexIntegerLiteral
< 	: ( '0x' | '0X' ) HexDigit+
< 	;
< 
< numericLiteral
< 	: DecimalLiteral
< 	| OctalIntegerLiteral
< 	| HexIntegerLiteral
< 	;
< 
< // $>
< 
< // $<	String literals (7.8.4)
< 
< /*
< Note: octal escape sequences are described in the B Compatibility section.
< These are removed from the standards but are here for backwards compatibility with earlier ECMAScript definitions.
< */
< 	
< fragment CharacterEscapeSequence
< 	: ~( DecimalDigit | 'x' | 'u' | LineTerminator ) // Concatenation of SingleEscapeCharacter and NonEscapeCharacter
< 	;
< 
< fragment ZeroToThree
< 	: '0'..'3'
< 	;
< 	
< fragment OctalEscapeSequence
< 	: OctalDigit
< 	| ZeroToThree OctalDigit
< 	| '4'..'7' OctalDigit
< 	| ZeroToThree OctalDigit OctalDigit
< 	;
< 	
< fragment HexEscapeSequence
< 	: 'x' HexDigit HexDigit
< 	;
< 	
< fragment UnicodeEscapeSequence
< 	: 'u' HexDigit HexDigit HexDigit HexDigit
< 	;
< 
< fragment EscapeSequence
< 	:
< 	BSLASH 
< 	(
< 		CharacterEscapeSequence 
< 		| OctalEscapeSequence
< 		| HexEscapeSequence
< 		| UnicodeEscapeSequence
< 	)
< 	;
< 
< StringLiteral
< 	: SQUOTE ( ~( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* SQUOTE
< 	| DQUOTE ( ~( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* DQUOTE
< 	;
< 
< // $>
< 
< // $<	Regular expression literals (7.8.5)
< 
< fragment BackslashSequence
< 	: BSLASH ~( LineTerminator )
< 	;
< 
< fragment RegularExpressionFirstChar
< 	: ~ ( LineTerminator | MUL | BSLASH | DIV )
< 	| BackslashSequence
< 	;
< 
< fragment RegularExpressionChar
< 	: ~ ( LineTerminator | BSLASH | DIV )
< 	| BackslashSequence
< 	;
< 
< RegularExpressionLiteral
< 	: { areRegularExpressionsEnabled() }?=> DIV RegularExpressionFirstChar RegularExpressionChar* DIV IdentifierPart*
< 	;
< 
< // $>
< 
< // $>
< 
< // $>
< 
< //
< // $<	A.3 Expressions (11)
< //
< 
< // $<Primary expressions (11.1)
< 
< primaryExpression
< 	: THIS
< 	| Identifier
< 	| literal
< 	| arrayLiteral
< 	| objectLiteral
< 	| lpar=LPAREN expression RPAREN -> ^( PAREXPR[$lpar, "PAREXPR"] expression )
< 	;
< 
< arrayLiteral
< 	: lb=LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK
< 	-> ^( ARRAY[$lb, "ARRAY"] arrayItem* )
< 	;
< 
< arrayItem
< 	: ( expr=assignmentExpression | { input.LA(1) == COMMA }? )
< 	-> ^( ITEM $expr? )
< 	;
< 
< objectLiteral
< 	: lb=LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE
< 	-> ^( OBJECT[$lb, "OBJECT"] nameValuePair* )
< 	;
< 	
< nameValuePair
< 	: propertyName COLON assignmentExpression
< 	-> ^( NAMEDVALUE propertyName assignmentExpression )
< 	;
< 
< propertyName
< 	: Identifier
< 	| StringLiteral
< 	| numericLiteral
< 	;
< 
< // $>
< 
< // $<Left-hand-side expressions (11.2)
< 
< /*
< Refactored some rules to make them LL(*) compliant:
< all the expressions surrounding member selection and calls have been moved to leftHandSideExpression to make them right recursive
< */
< 
< memberExpression
< 	: primaryExpression
< 	| functionExpression
< 	| newExpression
< 	;
< 
< newExpression
< 	: NEW^ primaryExpression
<     | NEW^ functionExpression
< 	;
< 
< 	
< arguments
< 	: LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN
< 	-> ^( ARGS assignmentExpression* )
< 	;
< 	
< leftHandSideExpression
< 	:
< 	(
< 		memberExpression 		-> memberExpression
< 	)
< 	(
< 		arguments			-> ^( CALL $leftHandSideExpression arguments )
< 		| LBRACK expression RBRACK	-> ^( BYINDEX $leftHandSideExpression expression )
< 		| DOT Identifier		-> ^( BYFIELD $leftHandSideExpression Identifier )
< 	)*
< 	;
< 
< // $>
< 
< // $<Postfix expressions (11.3)
< 
< /*
< The specification states that there are no line terminators allowed before the postfix operators.
< This is enforced by the call to promoteEOL in the action before ( INC | DEC ).
< We only must promote EOLs when the la is INC or DEC because this production is chained as all expression rules.
< In other words: only promote EOL when we are really in a postfix expression. A check on the la will ensure this.
< */
< postfixExpression
< 	: leftHandSideExpression { if (input.LA(1) == INC || input.LA(1) == DEC) promoteEOL(null); } ( postfixOperator^ )?
< 	;
< 	
< postfixOperator
< 	: op=INC { $op.setType(PINC); }
< 	| op=DEC { $op.setType(PDEC); }
< 	;
< 
< // $>
< 
< // $<Unary operators (11.4)
< 
< unaryExpression
< 	: postfixExpression
< 	| unaryOperator^ unaryExpression
< 	;
< 	
< unaryOperator
< 	: DELETE
< 	| VOID
< 	| TYPEOF
< 	| INC
< 	| DEC
< 	| op=ADD { $op.setType(POS); }
< 	| op=SUB { $op.setType(NEG); }
< 	| INV
< 	| NOT
< 	;
< 
< // $>
< 
< // $<Multiplicative operators (11.5)
< 
< multiplicativeExpression
< 	: unaryExpression ( ( MUL | DIV | MOD )^ unaryExpression )*
< 	;
< 
< // $>
< 
< // $<Additive operators (11.6)
< 
< additiveExpression
< 	: multiplicativeExpression ( ( ADD | SUB )^ multiplicativeExpression )*
< 	;
< 
< // $>
< 	
< // $<Bitwise shift operators (11.7)
< 
< shiftExpression
< 	: additiveExpression ( ( SHL | SHR | SHU )^ additiveExpression )*
< 	;
< 
< // $>
< 	
< // $<Relational operators (11.8)
< 
< relationalExpression
< 	: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN )^ shiftExpression )*
< 	;
< 
< relationalExpressionNoIn
< 	: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF )^ shiftExpression )*
< 	;
< 
< // $>
< 	
< // $<Equality operators (11.9)
< 
< equalityExpression
< 	: relationalExpression ( ( EQ | NEQ | SAME | NSAME )^ relationalExpression )*
< 	;
< 
< equalityExpressionNoIn
< 	: relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME )^ relationalExpressionNoIn )*
< 	;
< 
< // $>
< 		
< // $<Binary bitwise operators (11.10)
< 
< bitwiseANDExpression
< 	: equalityExpression ( AND^ equalityExpression )*
< 	;
< 
< bitwiseANDExpressionNoIn
< 	: equalityExpressionNoIn ( AND^ equalityExpressionNoIn )*
< 	;
< 		
< bitwiseXORExpression
< 	: bitwiseANDExpression ( XOR^ bitwiseANDExpression )*
< 	;
< 		
< bitwiseXORExpressionNoIn
< 	: bitwiseANDExpressionNoIn ( XOR^ bitwiseANDExpressionNoIn )*
< 	;
< 	
< bitwiseORExpression
< 	: bitwiseXORExpression ( OR^ bitwiseXORExpression )*
< 	;
< 	
< bitwiseORExpressionNoIn
< 	: bitwiseXORExpressionNoIn ( OR^ bitwiseXORExpressionNoIn )*
< 	;
< 
< // $>
< 	
< // $<Binary logical operators (11.11)
< 
< logicalANDExpression
< 	: bitwiseORExpression ( LAND^ bitwiseORExpression )*
< 	;
< 
< logicalANDExpressionNoIn
< 	: bitwiseORExpressionNoIn ( LAND^ bitwiseORExpressionNoIn )*
< 	;
< 	
< logicalORExpression
< 	: logicalANDExpression ( LOR^ logicalANDExpression )*
< 	;
< 	
< logicalORExpressionNoIn
< 	: logicalANDExpressionNoIn ( LOR^ logicalANDExpressionNoIn )*
< 	;
< 
< // $>
< 	
< // $<Conditional operator (11.12)
< 
< conditionalExpression
< 	: logicalORExpression ( QUE^ assignmentExpression COLON! assignmentExpression )?
< 	;
< 
< conditionalExpressionNoIn
< 	: logicalORExpressionNoIn ( QUE^ assignmentExpressionNoIn COLON! assignmentExpressionNoIn )?
< 	;
< 	
< // $>
< 
< // $<Assignment operators (11.13)
< 
< /*
< The specification defines the AssignmentExpression rule as follows:
< AssignmentExpression :
< 	ConditionalExpression 
< 	LeftHandSideExpression AssignmentOperator AssignmentExpression
< This rule has a LL(*) conflict. Resolving this with a syntactical predicate will yield something like this:
< 
< assignmentExpression
< 	: ( leftHandSideExpression assignmentOperator )=> leftHandSideExpression assignmentOperator^ assignmentExpression
< 	| conditionalExpression
< 	;
< assignmentOperator
< 	: ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS
< 	;
< 	
< But that didn't seem to work. Terence Par writes in his book that LL(*) conflicts in general can best be solved with auto backtracking. But that would be 
< a performance killer for such a heavy used rule.
< The solution I came up with is to always invoke the conditionalExpression first and than decide what to do based on the result of that rule.
< When the rule results in a Tree that can't be coming from a left hand side expression, then we're done.
< When it results in a Tree that is coming from a left hand side expression and the LA(1) is an assignment operator then parse the assignment operator
< followed by the right recursive call.
< */
< assignmentExpression
< @init
< {
< 	Object[] isLhs = new Object[1];
< }
< 	: lhs=conditionalExpression
< 	( { isLeftHandSideAssign(lhs, isLhs) }? assignmentOperator^ assignmentExpression )?	
< 	;
< 
< assignmentOperator
< 	: ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS
< 	;
< 
< assignmentExpressionNoIn
< @init
< {
< 	Object[] isLhs = new Object[1];
< }
< 	: lhs=conditionalExpressionNoIn
< 	( { isLeftHandSideAssign(lhs, isLhs) }? assignmentOperator^ assignmentExpressionNoIn )?
< 	;
< 	
< // $>
< 	
< // $<Comma operator (11.14)
< 
< expression
< 	: exprs+=assignmentExpression ( COMMA exprs+=assignmentExpression )*
< 	-> { $exprs.size() > 1 }? ^( CEXPR $exprs+ )
< 	-> $exprs
< 	;
< 
< expressionNoIn
< 	: exprs+=assignmentExpressionNoIn ( COMMA exprs+=assignmentExpressionNoIn )*
< 	-> { $exprs.size() > 1 }? ^( CEXPR $exprs+ )
< 	-> $exprs
< 	;
< 
< // $>
< 
< // $>
< 	
< //
< // $<	A.4 Statements (12)
< //
< 
< /*
< This rule handles semicolons reported by the lexer and situations where the ECMA 3 specification states there should be semicolons automaticly inserted.
< The auto semicolons are not actually inserted but this rule behaves as if they were.
< 
< In the following situations an ECMA 3 parser should auto insert absent but grammaticly required semicolons:
< - the current token is a right brace
< - the current token is the end of file (EOF) token
< - there is at least one end of line (EOL) token between the current token and the previous token.
< 
< The RBRACE is handled by matching it but not consuming it.
< The EOF needs no further handling because it is not consumed by default.
< The EOL situation is handled by promoting the EOL or MultiLineComment with an EOL present from off channel to on channel
< and thus making it parseable instead of handling it as white space. This promoting is done in the action promoteEOL.
< */
< semic
< @init
< {
< 	// Mark current position so we can unconsume a RBRACE.
< 	int marker = input.mark();
< 	// Promote EOL if appropriate	
< 	promoteEOL(retval);
< }
< 	: SEMIC
< 	| EOF
< 	| RBRACE { input.rewind(marker); }
< 	| EOL | MultiLineComment // (with EOL in it)
< 	;
< 
< /*
< To solve the ambiguity between block and objectLiteral via expressionStatement all but the block alternatives have been moved to statementTail.
< Now when k = 1 and a semantical predicate is defined ANTLR generates code that always will prefer block when the LA(1) is a LBRACE.
< This will result in the same behaviour that is described in the specification under 12.4 on the expressionStatement rule.
< */
< statement
< options
< {
< 	k = 1 ;
< }
< @after {
<         if(retval.tree != null)
<             retval.tree.is_statement = true;
<     }
< 	: { input.LA(1) == LBRACE }? block
< 	| statementTail
< 	;
< 	
< statementTail
< 	: variableStatement
< 	| emptyStatement
< 	| expressionStatement
< 	| ifStatement
< 	| iterationStatement
< 	| continueStatement
< 	| breakStatement
< 	| returnStatement
< 	| withStatement
< 	| labelledStatement
< 	| switchStatement
< 	| throwStatement
< 	| tryStatement
< 	;
< 
< // $<Block (12.1)
< 
< block
< 	: lb=LBRACE sourceElement* RBRACE
< 	-> ^( BLOCK[$lb, "BLOCK"] sourceElement* )
< 	;
< 
< // $>
< 	
< // $<Variable statement 12.2)
< 
< variableStatement
< 	: VAR variableDeclaration ( COMMA variableDeclaration )* semic
< 	-> ^( VAR variableDeclaration+ )
< 	;
< 
< variableDeclaration
< 	: Identifier ( ASSIGN^ assignmentExpression )?
< 	;
< 	
< variableDeclarationNoIn
< 	: Identifier ( ASSIGN^ assignmentExpressionNoIn )?
< 	;
< 
< // $>
< 	
< // $<Empty statement (12.3)
< 
< emptyStatement
< 	: SEMIC!
< 	;
< 
< // $>
< 	
< // $<Expression statement (12.4)
< 
< /*
< The look ahead check on LBRACE and FUNCTION the specification mentions has been left out and its function, resolving the ambiguity between:
< - functionExpression and functionDeclaration
< - block and objectLiteral
< are moved to the statement and sourceElement rules.
< */
< expressionStatement
< 	: expression semic!
< 	;
< 
< // $>
< 	
< // $<The if statement (12.5)
< 
< ifStatement
< // The predicate is there just to get rid of the warning. ANTLR will handle the dangling else just fine.
< 	: IF LPAREN expression RPAREN statement ( { input.LA(1) == ELSE }? ELSE statement )?
< 	-> ^( IF expression statement+ )
< 	;
< 
< // $>
< 	
< // $<Iteration statements (12.6)
< 
< iterationStatement
< 	: doStatement
< 	| whileStatement
< 	| forStatement
< 	;
< 	
< doStatement
< 	: DO statement WHILE LPAREN expression RPAREN semic
< 	-> ^( DO statement expression )
< 	;
< 	
< whileStatement
< 	: WHILE^ LPAREN! expression RPAREN! statement
< 	;
< 
< /*
< The forStatement production is refactored considerably as the specification contains a very none LL(*) compliant definition.
< The initial version was like this:	
< 
< forStatement
< 	: FOR^ LPAREN! forControl RPAREN! statement
< 	;
< forControl
< options
< {
< 	backtrack = true ;
< 	//k = 3 ;
< }
< 	: stepClause
< 	| iterationClause
< 	;
< stepClause
< options
< {
< 	memoize = true ;
< }
< 	: ( ex1=expressionNoIn | var=VAR variableDeclarationNoIn ( COMMA variableDeclarationNoIn )* )? SEMIC ex2=expression? SEMIC ex3=expression?
< 	-> { $var != null }? ^( FORSTEP ^( VAR[$var] variableDeclarationNoIn+ ) ^( EXPR $ex2? ) ^( EXPR $ex3? ) )
< 	-> ^( FORSTEP ^( EXPR $ex1? ) ^( EXPR $ex2? ) ^( EXPR $ex3? ) )
< 	;
< iterationClause
< options
< {
< 	memoize = true ;
< }
< 	: ( leftHandSideExpression | var=VAR variableDeclarationNoIn ) IN expression
< 	-> { $var != null }? ^( FORITER ^( VAR[$var] variableDeclarationNoIn ) ^( EXPR expression ) )
< 	-> ^( FORITER ^( EXPR leftHandSideExpression ) ^( EXPR expression ) )
< 	;
< 	
< But this completely relies on the backtrack feature and capabilities of ANTLR. 
< Furthermore backtracking seemed to have 3 major drawbacks:
< - the performance cost of backtracking is considerably
< - didn't seem to work well with ANTLRWorks
< - when introducing a k value to optimize the backtracking away, ANTLR runs out of heap space
< */
< forStatement
< 	: FOR^ LPAREN! forControl RPAREN! statement
< 	;
< 
< forControl
< 	: forControlVar
< 	| forControlExpression
< 	| forControlSemic
< 	;
< 
< forControlVar
< 	: VAR variableDeclarationNoIn
< 	(
< 		(
< 			IN expression
< 			-> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) )
< 		)
< 		|
< 		(
< 			( COMMA variableDeclarationNoIn )* SEMIC ex1=expression? SEMIC ex2=expression?
< 			-> ^( FORSTEP ^( VAR variableDeclarationNoIn+ ) ^( EXPR $ex1? ) ^( EXPR $ex2? ) )
< 		)
< 	)
< 	;
< 
< forControlExpression
< @init
< {
< 	Object[] isLhs = new Object[1];
< }
< 	: ex1=expressionNoIn
< 	( 
< 		{ isLeftHandSideIn(ex1, isLhs) }? (
< 			IN ex2=expression
< 			-> ^( FORITER ^( EXPR $ex1 ) ^( EXPR $ex2 ) )
< 		)
< 		|
< 		(
< 			SEMIC ex2=expression? SEMIC ex3=expression?
< 			-> ^( FORSTEP ^( EXPR $ex1 ) ^( EXPR $ex2? ) ^( EXPR $ex3? ) )
< 		)
< 	)
< 	;
< 
< forControlSemic
< 	: SEMIC ex1=expression? SEMIC ex2=expression?
< 	-> ^( FORSTEP ^( EXPR ) ^( EXPR $ex1? ) ^( EXPR $ex2? ) )
< 	;
< 
< // $>
< 	
< // $<The continue statement (12.7)
< 
< /*
< The action with the call to promoteEOL after CONTINUE is to enforce the semicolon insertion rule of the specification that there are
< no line terminators allowed beween CONTINUE and the optional identifier.
< As an optimization we check the la first to decide whether there is an identier following.
< */
< continueStatement
< 	: CONTINUE^ { if (input.LA(1) == Identifier) promoteEOL(null); } Identifier? semic!
< 	;
< 
< // $>
< 	
< // $<The break statement (12.8)
< 
< /*
< The action with the call to promoteEOL after BREAK is to enforce the semicolon insertion rule of the specification that there are
< no line terminators allowed beween BREAK and the optional identifier.
< As an optimization we check the la first to decide whether there is an identier following.
< */
< breakStatement
< 	: BREAK^ { if (input.LA(1) == Identifier) promoteEOL(null); } Identifier? semic!
< 	;
< 
< // $>
< 	
< // $<The return statement (12.9)
< 
< /*
< The action calling promoteEOL after RETURN ensures that there are no line terminators between RETURN and the optional expression as the specification states.
< When there are these get promoted to on channel and thus virtual semicolon wannabees.
< So the folowing code:
< 
< return
< 1
< 
< will be parsed as:
< 
< return;
< 1;
< */
< returnStatement
< 	: RETURN^ { promoteEOL(null); } expression? semic!
< 	;
< 
< // $>
< 	
< // $<The with statement (12.10)
< 
< withStatement
< 	: WITH^ LPAREN! expression RPAREN! statement
< 	;
< 
< // $>
< 	
< // $<The switch statement (12.11)
< 
< switchStatement
< @init
< {
< 	int defaultClauseCount = 0;
< }
< 	: SWITCH LPAREN expression RPAREN LBRACE ( { defaultClauseCount == 0 }?=> defaultClause { defaultClauseCount++; } | caseClause )* RBRACE
< 	-> ^( SWITCH expression defaultClause? caseClause* )
< 	;
< 
< caseClause
< 	: CASE^ expression COLON! statement*
< 	;
< 	
< defaultClause
< 	: DEFAULT^ COLON! statement*
< 	;
< 
< // $>
< 	
< // $<Labelled statements (12.12)
< 
< labelledStatement
< 	: Identifier COLON statement
< 	-> ^( LABELLED Identifier statement )
< 	;
< 
< // $>
< 	
< // $<The throw statement (12.13)
< 
< /*
< The action calling promoteEOL after THROW ensures that there are no line terminators between THROW and the expression as the specification states.
< When there are line terminators these get promoted to on channel and thus to virtual semicolon wannabees.
< So the folowing code:
< 
< throw
< new Error()
< 
< will be parsed as:
< 
< throw;
< new Error();
< 
< which will yield a recognition exception!
< */
< throwStatement
< 	: THROW^ { promoteEOL(null); } expression semic!
< 	;
< 
< // $>
< 	
< // $<The try statement (12.14)
< 
< tryStatement
< 	: TRY^ block ( catchClause finallyClause? | finallyClause )
< 	;
< 	
< catchClause
< 	: CATCH^ LPAREN! Identifier RPAREN! block
< 	;
< 	
< finallyClause
< 	: FINALLY^ block
< 	;
< 
< // $>
< 
< // $>
< 
< //
< // $<	A.5 Functions and Programs (13, 14)
< //
< 
< // $<	Function Definition (13)
< 
< functionDeclaration
< 	: FUNCTION name=Identifier formalParameterList functionBody
< 	-> ^( FUNCTION $name formalParameterList functionBody )
< 	;
< 
< functionExpression
< 	: FUNCTION name=Identifier? formalParameterList functionBody
< 	-> ^( FUNCTION $name? formalParameterList functionBody )
< 	;
< 
< formalParameterList
< 	: LPAREN ( args+=Identifier ( COMMA args+=Identifier )* )? RPAREN
< 	-> ^( ARGS $args* )
< 	;
< 
< functionBody
< 	: lb=LBRACE sourceElement* RBRACE
< 	-> ^( BLOCK[$lb, "BLOCK"] sourceElement* )
< 	;
< 
< // $>
< 	
< // $<	Program (14)
< 
< program
< 	: sourceElement*
< 	;
< 
< /*
< By setting k  to 1 for this rule and adding the semantical predicate ANTRL will generate code that will always prefer functionDeclararion over functionExpression
< here and therefor remove the ambiguity between these to production.
< This will result in the same behaviour that is described in the specification under 12.4 on the expressionStatement rule.
< */
< sourceElement
< options
< {
< 	k = 1 ;
< }
< 	: { input.LA(1) == FUNCTION }? functionDeclaration
< 	| statement
< 	;
< 
< // $>
< 
< // $>
diff -r -N code-worker/tasks/clonedigger/js_antlr/JavaScriptLexer.java code-worker/code-worker/tasks/clonedigger/js_antlr/JavaScriptLexer.java
1,5955d0
< // $ANTLR 3.1.1 JavaScript.g 2009-03-06 21:11:54
< 
< import org.antlr.runtime.*;
< import java.util.Stack;
< import java.util.List;
< import java.util.ArrayList;
< 
< public class JavaScriptLexer extends Lexer {
<     public static final int COMMA=71;
<     public static final int CONST=37;
<     public static final int BackslashSequence=168;
<     public static final int RegularExpressionLiteral=155;
<     public static final int ARGS=111;
<     public static final int ARRAY=112;
<     public static final int LF=140;
<     public static final int SYNCHRONIZED=59;
<     public static final int HexDigit=150;
<     public static final int DOUBLE=39;
<     public static final int EXPR=118;
<     public static final int ADDASS=99;
<     public static final int DecimalDigit=152;
<     public static final int FALSE=6;
<     public static final int USP=138;
<     public static final int ABSTRACT=32;
<     public static final int SP=136;
<     public static final int SEMIC=70;
<     public static final int IMPORT=47;
<     public static final int DQUOTE=131;
<     public static final int PACKAGE=52;
<     public static final int MODASS=102;
<     public static final int SHR=87;
<     public static final int SQUOTE=132;
<     public static final int CONTINUE=10;
<     public static final int DOT=69;
<     public static final int PRIVATE=53;
<     public static final int MultiLineComment=146;
<     public static final int AND=89;
<     public static final int HexIntegerLiteral=161;
<     public static final int FUNCTION=17;
<     public static final int DIVASS=110;
<     public static final int RegularExpressionFirstChar=169;
<     public static final int GTE=75;
<     public static final int OctalEscapeSequence=164;
<     public static final int HexEscapeSequence=165;
<     public static final int SingleLineComment=147;
<     public static final int RPAREN=66;
<     public static final int POS=129;
<     public static final int UnicodeEscapeSequence=166;
<     public static final int IdentifierStartASCII=151;
<     public static final int FINALLY=15;
<     public static final int IdentifierNameASCIIStart=154;
<     public static final int EXTENDS=42;
<     public static final int IdentifierPart=153;
<     public static final int SUPER=58;
<     public static final int Identifier=148;
<     public static final int SAME=78;
<     public static final int CHAR=35;
<     public static final int NEW=21;
<     public static final int EQ=76;
<     public static final int LT=72;
<     public static final int FINAL=43;
<     public static final int SUBASS=100;
<     public static final int VT=134;
<     public static final int LAND=94;
<     public static final int LBRACK=67;
<     public static final int CATCH=9;
<     public static final int STATIC=57;
<     public static final int CASE=8;
<     public static final int MUL=82;
<     public static final int INTERFACE=49;
<     public static final int ExponentPart=157;
<     public static final int INV=93;
<     public static final int BOOLEAN=33;
<     public static final int ELSE=14;
<     public static final int CharacterEscapeSequence=162;
<     public static final int BSLASH=130;
<     public static final int SHLASS=103;
<     public static final int DecimalLiteral=159;
<     public static final int BREAK=7;
<     public static final int NULL=4;
<     public static final int XOR=91;
<     public static final int COLON=97;
<     public static final int DIV=109;
<     public static final int ORASS=107;
<     public static final int TRUE=5;
<     public static final int ADD=80;
<     public static final int THROW=25;
<     public static final int SHORT=56;
<     public static final int LABELLED=122;
<     public static final int CR=141;
<     public static final int RegularExpressionChar=170;
<     public static final int PUBLIC=55;
<     public static final int SHL=86;
<     public static final int LONG=50;
<     public static final int LOR=95;
<     public static final int TYPEOF=27;
<     public static final int INC=84;
<     public static final int TRANSIENT=61;
<     public static final int FLOAT=44;
<     public static final int TAB=133;
<     public static final int THROWS=60;
<     public static final int ZeroToThree=163;
<     public static final int FF=135;
<     public static final int FORITER=119;
<     public static final int MOD=83;
<     public static final int GOTO=45;
<     public static final int EXPORT=41;
<     public static final int OR=90;
<     public static final int MULASS=101;
<     public static final int LBRACE=63;
<     public static final int RBRACE=64;
<     public static final int BLOCK=113;
<     public static final int PROTECTED=54;
<     public static final int ANDASS=106;
<     public static final int SHU=88;
<     public static final int LineTerminator=144;
<     public static final int PAREXPR=126;
<     public static final int EscapeSequence=167;
<     public static final int INT=48;
<     public static final int LS=142;
<     public static final int ASSIGN=98;
<     public static final int CEXPR=117;
<     public static final int INSTANCEOF=20;
<     public static final int VOID=29;
<     public static final int LPAREN=65;
<     public static final int WhiteSpace=139;
<     public static final int XORASS=108;
<     public static final int NEQ=77;
<     public static final int QUE=96;
<     public static final int NAMEDVALUE=123;
<     public static final int ENUM=40;
<     public static final int DEBUGGER=38;
<     public static final int PS=143;
<     public static final int DELETE=12;
<     public static final int OBJECT=125;
<     public static final int DO=13;
<     public static final int IMPLEMENTS=46;
<     public static final int SWITCH=23;
<     public static final int WHILE=30;
<     public static final int OctalIntegerLiteral=160;
<     public static final int BYINDEX=115;
<     public static final int FORSTEP=120;
<     public static final int PINC=128;
<     public static final int OctalDigit=156;
<     public static final int GT=73;
<     public static final int StringLiteral=149;
<     public static final int DecimalIntegerLiteral=158;
<     public static final int SHRASS=104;
<     public static final int ITEM=121;
<     public static final int THIS=24;
<     public static final int SHUASS=105;
<     public static final int WITH=31;
<     public static final int IN=19;
<     public static final int LTE=74;
<     public static final int VAR=28;
<     public static final int CLASS=36;
<     public static final int NATIVE=51;
<     public static final int DEC=85;
<     public static final int RETURN=22;
<     public static final int BYTE=34;
<     public static final int VOLATILE=62;
<     public static final int IF=18;
<     public static final int EOF=-1;
<     public static final int EOL=145;
<     public static final int CALL=116;
<     public static final int NBSP=137;
<     public static final int FOR=16;
<     public static final int RBRACK=68;
<     public static final int DEFAULT=11;
<     public static final int NEG=124;
<     public static final int SUB=81;
<     public static final int TRY=26;
<     public static final int NOT=92;
<     public static final int BYFIELD=114;
<     public static final int PDEC=127;
<     public static final int NSAME=79;
< 
<     private Token last;
< 
<     private final boolean areRegularExpressionsEnabled()
<     {
<     	if (last == null)
<     	{
<     		return true;
<     	}
<     	switch (last.getType())
<     	{
<     	// identifier
<     		case Identifier:
<     	// literals
<     		case NULL:
<     		case TRUE:
<     		case FALSE:
<     		case THIS:
<     		case OctalIntegerLiteral:
<     		case DecimalLiteral:
<     		case HexIntegerLiteral:
<     		case StringLiteral:
<     	// member access ending 
<     		case RBRACK:
<     	// function call or nested expression ending
<     		case RPAREN:
<     			return false;
<     	// otherwise OK
<     		default:
<     			return true;
<     	}
<     }
<     	
<     private final void consumeIdentifierUnicodeStart() throws RecognitionException, NoViableAltException
<     {
<     	int ch = input.LA(1);
<     	if (isIdentifierStartUnicode(ch))
<     	{
<     		matchAny();
<     		do
<     		{
<     			ch = input.LA(1);
<     			if (ch == '$' || (ch >= '0' && ch <= '9') || (ch >= 'A' && ch <= 'Z') || ch == '\\' || ch == '_' || (ch >= 'a' && ch <= 'z') || isIdentifierPartUnicode(ch))
<     			{
<     				mIdentifierPart();
<     			}
<     			else
<     			{
<     				return;
<     			}
<     		}
<     		while (true);
<     	}
<     	else
<     	{
<     		throw new NoViableAltException();
<     	}
<     }
<     	
<     private final boolean isIdentifierPartUnicode(int ch)
<     {
<     	return Character.isJavaIdentifierPart(ch);
<     }
<     	
<     private final boolean isIdentifierStartUnicode(int ch)
<     {
<     	return Character.isJavaIdentifierStart(ch);
<     }
< 
<     public Token nextToken()
<     {
<     	Token result = super.nextToken();
<     	if (result.getChannel() == Token.DEFAULT_CHANNEL)
<     	{
<     		last = result;
<     	}
<     	return result;		
<     }
< 
< 
<     // delegates
<     // delegators
< 
<     public JavaScriptLexer() {;} 
<     public JavaScriptLexer(CharStream input) {
<         this(input, new RecognizerSharedState());
<     }
<     public JavaScriptLexer(CharStream input, RecognizerSharedState state) {
<         super(input,state);
< 
<     }
<     public String getGrammarFileName() { return "JavaScript.g"; }
< 
<     // $ANTLR start "NULL"
<     public final void mNULL() throws RecognitionException {
<         try {
<             int _type = NULL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:87:6: ( 'null' )
<             // JavaScript.g:87:8: 'null'
<             {
<             match("null"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NULL"
< 
<     // $ANTLR start "TRUE"
<     public final void mTRUE() throws RecognitionException {
<         try {
<             int _type = TRUE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:88:6: ( 'true' )
<             // JavaScript.g:88:8: 'true'
<             {
<             match("true"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TRUE"
< 
<     // $ANTLR start "FALSE"
<     public final void mFALSE() throws RecognitionException {
<         try {
<             int _type = FALSE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:89:7: ( 'false' )
<             // JavaScript.g:89:9: 'false'
<             {
<             match("false"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FALSE"
< 
<     // $ANTLR start "BREAK"
<     public final void mBREAK() throws RecognitionException {
<         try {
<             int _type = BREAK;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:90:7: ( 'break' )
<             // JavaScript.g:90:9: 'break'
<             {
<             match("break"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BREAK"
< 
<     // $ANTLR start "CASE"
<     public final void mCASE() throws RecognitionException {
<         try {
<             int _type = CASE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:91:6: ( 'case' )
<             // JavaScript.g:91:8: 'case'
<             {
<             match("case"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CASE"
< 
<     // $ANTLR start "CATCH"
<     public final void mCATCH() throws RecognitionException {
<         try {
<             int _type = CATCH;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:92:7: ( 'catch' )
<             // JavaScript.g:92:9: 'catch'
<             {
<             match("catch"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CATCH"
< 
<     // $ANTLR start "CONTINUE"
<     public final void mCONTINUE() throws RecognitionException {
<         try {
<             int _type = CONTINUE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:93:10: ( 'continue' )
<             // JavaScript.g:93:12: 'continue'
<             {
<             match("continue"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CONTINUE"
< 
<     // $ANTLR start "DEFAULT"
<     public final void mDEFAULT() throws RecognitionException {
<         try {
<             int _type = DEFAULT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:94:9: ( 'default' )
<             // JavaScript.g:94:11: 'default'
<             {
<             match("default"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DEFAULT"
< 
<     // $ANTLR start "DELETE"
<     public final void mDELETE() throws RecognitionException {
<         try {
<             int _type = DELETE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:95:8: ( 'delete' )
<             // JavaScript.g:95:10: 'delete'
<             {
<             match("delete"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DELETE"
< 
<     // $ANTLR start "DO"
<     public final void mDO() throws RecognitionException {
<         try {
<             int _type = DO;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:96:4: ( 'do' )
<             // JavaScript.g:96:6: 'do'
<             {
<             match("do"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DO"
< 
<     // $ANTLR start "ELSE"
<     public final void mELSE() throws RecognitionException {
<         try {
<             int _type = ELSE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:97:6: ( 'else' )
<             // JavaScript.g:97:8: 'else'
<             {
<             match("else"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ELSE"
< 
<     // $ANTLR start "FINALLY"
<     public final void mFINALLY() throws RecognitionException {
<         try {
<             int _type = FINALLY;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:98:9: ( 'finally' )
<             // JavaScript.g:98:11: 'finally'
<             {
<             match("finally"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FINALLY"
< 
<     // $ANTLR start "FOR"
<     public final void mFOR() throws RecognitionException {
<         try {
<             int _type = FOR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:99:5: ( 'for' )
<             // JavaScript.g:99:7: 'for'
<             {
<             match("for"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FOR"
< 
<     // $ANTLR start "FUNCTION"
<     public final void mFUNCTION() throws RecognitionException {
<         try {
<             int _type = FUNCTION;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:100:10: ( 'function' )
<             // JavaScript.g:100:12: 'function'
<             {
<             match("function"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FUNCTION"
< 
<     // $ANTLR start "IF"
<     public final void mIF() throws RecognitionException {
<         try {
<             int _type = IF;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:101:4: ( 'if' )
<             // JavaScript.g:101:6: 'if'
<             {
<             match("if"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IF"
< 
<     // $ANTLR start "IN"
<     public final void mIN() throws RecognitionException {
<         try {
<             int _type = IN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:102:4: ( 'in' )
<             // JavaScript.g:102:6: 'in'
<             {
<             match("in"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IN"
< 
<     // $ANTLR start "INSTANCEOF"
<     public final void mINSTANCEOF() throws RecognitionException {
<         try {
<             int _type = INSTANCEOF;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:103:12: ( 'instanceof' )
<             // JavaScript.g:103:14: 'instanceof'
<             {
<             match("instanceof"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INSTANCEOF"
< 
<     // $ANTLR start "NEW"
<     public final void mNEW() throws RecognitionException {
<         try {
<             int _type = NEW;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:104:5: ( 'new' )
<             // JavaScript.g:104:7: 'new'
<             {
<             match("new"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NEW"
< 
<     // $ANTLR start "RETURN"
<     public final void mRETURN() throws RecognitionException {
<         try {
<             int _type = RETURN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:105:8: ( 'return' )
<             // JavaScript.g:105:10: 'return'
<             {
<             match("return"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RETURN"
< 
<     // $ANTLR start "SWITCH"
<     public final void mSWITCH() throws RecognitionException {
<         try {
<             int _type = SWITCH;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:106:8: ( 'switch' )
<             // JavaScript.g:106:10: 'switch'
<             {
<             match("switch"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SWITCH"
< 
<     // $ANTLR start "THIS"
<     public final void mTHIS() throws RecognitionException {
<         try {
<             int _type = THIS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:107:6: ( 'this' )
<             // JavaScript.g:107:8: 'this'
<             {
<             match("this"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "THIS"
< 
<     // $ANTLR start "THROW"
<     public final void mTHROW() throws RecognitionException {
<         try {
<             int _type = THROW;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:108:7: ( 'throw' )
<             // JavaScript.g:108:9: 'throw'
<             {
<             match("throw"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "THROW"
< 
<     // $ANTLR start "TRY"
<     public final void mTRY() throws RecognitionException {
<         try {
<             int _type = TRY;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:109:5: ( 'try' )
<             // JavaScript.g:109:7: 'try'
<             {
<             match("try"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TRY"
< 
<     // $ANTLR start "TYPEOF"
<     public final void mTYPEOF() throws RecognitionException {
<         try {
<             int _type = TYPEOF;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:110:8: ( 'typeof' )
<             // JavaScript.g:110:10: 'typeof'
<             {
<             match("typeof"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TYPEOF"
< 
<     // $ANTLR start "VAR"
<     public final void mVAR() throws RecognitionException {
<         try {
<             int _type = VAR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:111:5: ( 'var' )
<             // JavaScript.g:111:7: 'var'
<             {
<             match("var"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VAR"
< 
<     // $ANTLR start "VOID"
<     public final void mVOID() throws RecognitionException {
<         try {
<             int _type = VOID;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:112:6: ( 'void' )
<             // JavaScript.g:112:8: 'void'
<             {
<             match("void"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VOID"
< 
<     // $ANTLR start "WHILE"
<     public final void mWHILE() throws RecognitionException {
<         try {
<             int _type = WHILE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:113:7: ( 'while' )
<             // JavaScript.g:113:9: 'while'
<             {
<             match("while"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "WHILE"
< 
<     // $ANTLR start "WITH"
<     public final void mWITH() throws RecognitionException {
<         try {
<             int _type = WITH;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:114:6: ( 'with' )
<             // JavaScript.g:114:8: 'with'
<             {
<             match("with"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "WITH"
< 
<     // $ANTLR start "ABSTRACT"
<     public final void mABSTRACT() throws RecognitionException {
<         try {
<             int _type = ABSTRACT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:115:10: ( 'abstract' )
<             // JavaScript.g:115:12: 'abstract'
<             {
<             match("abstract"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ABSTRACT"
< 
<     // $ANTLR start "BOOLEAN"
<     public final void mBOOLEAN() throws RecognitionException {
<         try {
<             int _type = BOOLEAN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:116:9: ( 'boolean' )
<             // JavaScript.g:116:11: 'boolean'
<             {
<             match("boolean"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BOOLEAN"
< 
<     // $ANTLR start "BYTE"
<     public final void mBYTE() throws RecognitionException {
<         try {
<             int _type = BYTE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:117:6: ( 'byte' )
<             // JavaScript.g:117:8: 'byte'
<             {
<             match("byte"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BYTE"
< 
<     // $ANTLR start "CHAR"
<     public final void mCHAR() throws RecognitionException {
<         try {
<             int _type = CHAR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:118:6: ( 'char' )
<             // JavaScript.g:118:8: 'char'
<             {
<             match("char"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CHAR"
< 
<     // $ANTLR start "CLASS"
<     public final void mCLASS() throws RecognitionException {
<         try {
<             int _type = CLASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:119:7: ( 'class' )
<             // JavaScript.g:119:9: 'class'
<             {
<             match("class"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CLASS"
< 
<     // $ANTLR start "CONST"
<     public final void mCONST() throws RecognitionException {
<         try {
<             int _type = CONST;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:120:7: ( 'const' )
<             // JavaScript.g:120:9: 'const'
<             {
<             match("const"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CONST"
< 
<     // $ANTLR start "DEBUGGER"
<     public final void mDEBUGGER() throws RecognitionException {
<         try {
<             int _type = DEBUGGER;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:121:10: ( 'debugger' )
<             // JavaScript.g:121:12: 'debugger'
<             {
<             match("debugger"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DEBUGGER"
< 
<     // $ANTLR start "DOUBLE"
<     public final void mDOUBLE() throws RecognitionException {
<         try {
<             int _type = DOUBLE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:122:8: ( 'double' )
<             // JavaScript.g:122:10: 'double'
<             {
<             match("double"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DOUBLE"
< 
<     // $ANTLR start "ENUM"
<     public final void mENUM() throws RecognitionException {
<         try {
<             int _type = ENUM;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:123:6: ( 'enum' )
<             // JavaScript.g:123:8: 'enum'
<             {
<             match("enum"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ENUM"
< 
<     // $ANTLR start "EXPORT"
<     public final void mEXPORT() throws RecognitionException {
<         try {
<             int _type = EXPORT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:124:8: ( 'export' )
<             // JavaScript.g:124:10: 'export'
<             {
<             match("export"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EXPORT"
< 
<     // $ANTLR start "EXTENDS"
<     public final void mEXTENDS() throws RecognitionException {
<         try {
<             int _type = EXTENDS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:125:9: ( 'extends' )
<             // JavaScript.g:125:11: 'extends'
<             {
<             match("extends"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EXTENDS"
< 
<     // $ANTLR start "FINAL"
<     public final void mFINAL() throws RecognitionException {
<         try {
<             int _type = FINAL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:126:7: ( 'final' )
<             // JavaScript.g:126:9: 'final'
<             {
<             match("final"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FINAL"
< 
<     // $ANTLR start "FLOAT"
<     public final void mFLOAT() throws RecognitionException {
<         try {
<             int _type = FLOAT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:127:7: ( 'float' )
<             // JavaScript.g:127:9: 'float'
<             {
<             match("float"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FLOAT"
< 
<     // $ANTLR start "GOTO"
<     public final void mGOTO() throws RecognitionException {
<         try {
<             int _type = GOTO;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:128:6: ( 'goto' )
<             // JavaScript.g:128:8: 'goto'
<             {
<             match("goto"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "GOTO"
< 
<     // $ANTLR start "IMPLEMENTS"
<     public final void mIMPLEMENTS() throws RecognitionException {
<         try {
<             int _type = IMPLEMENTS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:129:12: ( 'implements' )
<             // JavaScript.g:129:14: 'implements'
<             {
<             match("implements"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IMPLEMENTS"
< 
<     // $ANTLR start "IMPORT"
<     public final void mIMPORT() throws RecognitionException {
<         try {
<             int _type = IMPORT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:130:8: ( 'import' )
<             // JavaScript.g:130:10: 'import'
<             {
<             match("import"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IMPORT"
< 
<     // $ANTLR start "INT"
<     public final void mINT() throws RecognitionException {
<         try {
<             int _type = INT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:131:5: ( 'int' )
<             // JavaScript.g:131:7: 'int'
<             {
<             match("int"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INT"
< 
<     // $ANTLR start "INTERFACE"
<     public final void mINTERFACE() throws RecognitionException {
<         try {
<             int _type = INTERFACE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:132:11: ( 'interface' )
<             // JavaScript.g:132:13: 'interface'
<             {
<             match("interface"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INTERFACE"
< 
<     // $ANTLR start "LONG"
<     public final void mLONG() throws RecognitionException {
<         try {
<             int _type = LONG;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:133:6: ( 'long' )
<             // JavaScript.g:133:8: 'long'
<             {
<             match("long"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LONG"
< 
<     // $ANTLR start "NATIVE"
<     public final void mNATIVE() throws RecognitionException {
<         try {
<             int _type = NATIVE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:134:8: ( 'native' )
<             // JavaScript.g:134:10: 'native'
<             {
<             match("native"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NATIVE"
< 
<     // $ANTLR start "PACKAGE"
<     public final void mPACKAGE() throws RecognitionException {
<         try {
<             int _type = PACKAGE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:135:9: ( 'package' )
<             // JavaScript.g:135:11: 'package'
<             {
<             match("package"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PACKAGE"
< 
<     // $ANTLR start "PRIVATE"
<     public final void mPRIVATE() throws RecognitionException {
<         try {
<             int _type = PRIVATE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:136:9: ( 'private' )
<             // JavaScript.g:136:11: 'private'
<             {
<             match("private"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PRIVATE"
< 
<     // $ANTLR start "PROTECTED"
<     public final void mPROTECTED() throws RecognitionException {
<         try {
<             int _type = PROTECTED;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:137:11: ( 'protected' )
<             // JavaScript.g:137:13: 'protected'
<             {
<             match("protected"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PROTECTED"
< 
<     // $ANTLR start "PUBLIC"
<     public final void mPUBLIC() throws RecognitionException {
<         try {
<             int _type = PUBLIC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:138:8: ( 'public' )
<             // JavaScript.g:138:10: 'public'
<             {
<             match("public"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PUBLIC"
< 
<     // $ANTLR start "SHORT"
<     public final void mSHORT() throws RecognitionException {
<         try {
<             int _type = SHORT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:139:7: ( 'short' )
<             // JavaScript.g:139:9: 'short'
<             {
<             match("short"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHORT"
< 
<     // $ANTLR start "STATIC"
<     public final void mSTATIC() throws RecognitionException {
<         try {
<             int _type = STATIC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:140:8: ( 'static' )
<             // JavaScript.g:140:10: 'static'
<             {
<             match("static"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "STATIC"
< 
<     // $ANTLR start "SUPER"
<     public final void mSUPER() throws RecognitionException {
<         try {
<             int _type = SUPER;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:141:7: ( 'super' )
<             // JavaScript.g:141:9: 'super'
<             {
<             match("super"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SUPER"
< 
<     // $ANTLR start "SYNCHRONIZED"
<     public final void mSYNCHRONIZED() throws RecognitionException {
<         try {
<             int _type = SYNCHRONIZED;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:142:14: ( 'synchronized' )
<             // JavaScript.g:142:16: 'synchronized'
<             {
<             match("synchronized"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SYNCHRONIZED"
< 
<     // $ANTLR start "THROWS"
<     public final void mTHROWS() throws RecognitionException {
<         try {
<             int _type = THROWS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:143:8: ( 'throws' )
<             // JavaScript.g:143:10: 'throws'
<             {
<             match("throws"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "THROWS"
< 
<     // $ANTLR start "TRANSIENT"
<     public final void mTRANSIENT() throws RecognitionException {
<         try {
<             int _type = TRANSIENT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:144:11: ( 'transient' )
<             // JavaScript.g:144:13: 'transient'
<             {
<             match("transient"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TRANSIENT"
< 
<     // $ANTLR start "VOLATILE"
<     public final void mVOLATILE() throws RecognitionException {
<         try {
<             int _type = VOLATILE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:145:10: ( 'volatile' )
<             // JavaScript.g:145:12: 'volatile'
<             {
<             match("volatile"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VOLATILE"
< 
<     // $ANTLR start "LBRACE"
<     public final void mLBRACE() throws RecognitionException {
<         try {
<             int _type = LBRACE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:146:8: ( '{' )
<             // JavaScript.g:146:10: '{'
<             {
<             match('{'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LBRACE"
< 
<     // $ANTLR start "RBRACE"
<     public final void mRBRACE() throws RecognitionException {
<         try {
<             int _type = RBRACE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:147:8: ( '}' )
<             // JavaScript.g:147:10: '}'
<             {
<             match('}'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RBRACE"
< 
<     // $ANTLR start "LPAREN"
<     public final void mLPAREN() throws RecognitionException {
<         try {
<             int _type = LPAREN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:148:8: ( '(' )
<             // JavaScript.g:148:10: '('
<             {
<             match('('); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LPAREN"
< 
<     // $ANTLR start "RPAREN"
<     public final void mRPAREN() throws RecognitionException {
<         try {
<             int _type = RPAREN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:149:8: ( ')' )
<             // JavaScript.g:149:10: ')'
<             {
<             match(')'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RPAREN"
< 
<     // $ANTLR start "LBRACK"
<     public final void mLBRACK() throws RecognitionException {
<         try {
<             int _type = LBRACK;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:150:8: ( '[' )
<             // JavaScript.g:150:10: '['
<             {
<             match('['); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LBRACK"
< 
<     // $ANTLR start "RBRACK"
<     public final void mRBRACK() throws RecognitionException {
<         try {
<             int _type = RBRACK;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:151:8: ( ']' )
<             // JavaScript.g:151:10: ']'
<             {
<             match(']'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RBRACK"
< 
<     // $ANTLR start "DOT"
<     public final void mDOT() throws RecognitionException {
<         try {
<             int _type = DOT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:152:5: ( '.' )
<             // JavaScript.g:152:7: '.'
<             {
<             match('.'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DOT"
< 
<     // $ANTLR start "SEMIC"
<     public final void mSEMIC() throws RecognitionException {
<         try {
<             int _type = SEMIC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:153:7: ( ';' )
<             // JavaScript.g:153:9: ';'
<             {
<             match(';'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SEMIC"
< 
<     // $ANTLR start "COMMA"
<     public final void mCOMMA() throws RecognitionException {
<         try {
<             int _type = COMMA;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:154:7: ( ',' )
<             // JavaScript.g:154:9: ','
<             {
<             match(','); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "COMMA"
< 
<     // $ANTLR start "LT"
<     public final void mLT() throws RecognitionException {
<         try {
<             int _type = LT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:155:4: ( '<' )
<             // JavaScript.g:155:6: '<'
<             {
<             match('<'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LT"
< 
<     // $ANTLR start "GT"
<     public final void mGT() throws RecognitionException {
<         try {
<             int _type = GT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:156:4: ( '>' )
<             // JavaScript.g:156:6: '>'
<             {
<             match('>'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "GT"
< 
<     // $ANTLR start "LTE"
<     public final void mLTE() throws RecognitionException {
<         try {
<             int _type = LTE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:157:5: ( '<=' )
<             // JavaScript.g:157:7: '<='
<             {
<             match("<="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LTE"
< 
<     // $ANTLR start "GTE"
<     public final void mGTE() throws RecognitionException {
<         try {
<             int _type = GTE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:158:5: ( '>=' )
<             // JavaScript.g:158:7: '>='
<             {
<             match(">="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "GTE"
< 
<     // $ANTLR start "EQ"
<     public final void mEQ() throws RecognitionException {
<         try {
<             int _type = EQ;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:159:4: ( '==' )
<             // JavaScript.g:159:6: '=='
<             {
<             match("=="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EQ"
< 
<     // $ANTLR start "NEQ"
<     public final void mNEQ() throws RecognitionException {
<         try {
<             int _type = NEQ;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:160:5: ( '!=' )
<             // JavaScript.g:160:7: '!='
<             {
<             match("!="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NEQ"
< 
<     // $ANTLR start "SAME"
<     public final void mSAME() throws RecognitionException {
<         try {
<             int _type = SAME;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:161:6: ( '===' )
<             // JavaScript.g:161:8: '==='
<             {
<             match("==="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SAME"
< 
<     // $ANTLR start "NSAME"
<     public final void mNSAME() throws RecognitionException {
<         try {
<             int _type = NSAME;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:162:7: ( '!==' )
<             // JavaScript.g:162:9: '!=='
<             {
<             match("!=="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NSAME"
< 
<     // $ANTLR start "ADD"
<     public final void mADD() throws RecognitionException {
<         try {
<             int _type = ADD;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:163:5: ( '+' )
<             // JavaScript.g:163:7: '+'
<             {
<             match('+'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ADD"
< 
<     // $ANTLR start "SUB"
<     public final void mSUB() throws RecognitionException {
<         try {
<             int _type = SUB;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:164:5: ( '-' )
<             // JavaScript.g:164:7: '-'
<             {
<             match('-'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SUB"
< 
<     // $ANTLR start "MUL"
<     public final void mMUL() throws RecognitionException {
<         try {
<             int _type = MUL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:165:5: ( '*' )
<             // JavaScript.g:165:7: '*'
<             {
<             match('*'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MUL"
< 
<     // $ANTLR start "MOD"
<     public final void mMOD() throws RecognitionException {
<         try {
<             int _type = MOD;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:166:5: ( '%' )
<             // JavaScript.g:166:7: '%'
<             {
<             match('%'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MOD"
< 
<     // $ANTLR start "INC"
<     public final void mINC() throws RecognitionException {
<         try {
<             int _type = INC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:167:5: ( '++' )
<             // JavaScript.g:167:7: '++'
<             {
<             match("++"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INC"
< 
<     // $ANTLR start "DEC"
<     public final void mDEC() throws RecognitionException {
<         try {
<             int _type = DEC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:168:5: ( '--' )
<             // JavaScript.g:168:7: '--'
<             {
<             match("--"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DEC"
< 
<     // $ANTLR start "SHL"
<     public final void mSHL() throws RecognitionException {
<         try {
<             int _type = SHL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:169:5: ( '<<' )
<             // JavaScript.g:169:7: '<<'
<             {
<             match("<<"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHL"
< 
<     // $ANTLR start "SHR"
<     public final void mSHR() throws RecognitionException {
<         try {
<             int _type = SHR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:170:5: ( '>>' )
<             // JavaScript.g:170:7: '>>'
<             {
<             match(">>"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHR"
< 
<     // $ANTLR start "SHU"
<     public final void mSHU() throws RecognitionException {
<         try {
<             int _type = SHU;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:171:5: ( '>>>' )
<             // JavaScript.g:171:7: '>>>'
<             {
<             match(">>>"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHU"
< 
<     // $ANTLR start "AND"
<     public final void mAND() throws RecognitionException {
<         try {
<             int _type = AND;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:172:5: ( '&' )
<             // JavaScript.g:172:7: '&'
<             {
<             match('&'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "AND"
< 
<     // $ANTLR start "OR"
<     public final void mOR() throws RecognitionException {
<         try {
<             int _type = OR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:173:4: ( '|' )
<             // JavaScript.g:173:6: '|'
<             {
<             match('|'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OR"
< 
<     // $ANTLR start "XOR"
<     public final void mXOR() throws RecognitionException {
<         try {
<             int _type = XOR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:174:5: ( '^' )
<             // JavaScript.g:174:7: '^'
<             {
<             match('^'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "XOR"
< 
<     // $ANTLR start "NOT"
<     public final void mNOT() throws RecognitionException {
<         try {
<             int _type = NOT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:175:5: ( '!' )
<             // JavaScript.g:175:7: '!'
<             {
<             match('!'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NOT"
< 
<     // $ANTLR start "INV"
<     public final void mINV() throws RecognitionException {
<         try {
<             int _type = INV;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:176:5: ( '~' )
<             // JavaScript.g:176:7: '~'
<             {
<             match('~'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INV"
< 
<     // $ANTLR start "LAND"
<     public final void mLAND() throws RecognitionException {
<         try {
<             int _type = LAND;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:177:6: ( '&&' )
<             // JavaScript.g:177:8: '&&'
<             {
<             match("&&"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LAND"
< 
<     // $ANTLR start "LOR"
<     public final void mLOR() throws RecognitionException {
<         try {
<             int _type = LOR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:178:5: ( '||' )
<             // JavaScript.g:178:7: '||'
<             {
<             match("||"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LOR"
< 
<     // $ANTLR start "QUE"
<     public final void mQUE() throws RecognitionException {
<         try {
<             int _type = QUE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:179:5: ( '?' )
<             // JavaScript.g:179:7: '?'
<             {
<             match('?'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "QUE"
< 
<     // $ANTLR start "COLON"
<     public final void mCOLON() throws RecognitionException {
<         try {
<             int _type = COLON;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:180:7: ( ':' )
<             // JavaScript.g:180:9: ':'
<             {
<             match(':'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "COLON"
< 
<     // $ANTLR start "ASSIGN"
<     public final void mASSIGN() throws RecognitionException {
<         try {
<             int _type = ASSIGN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:181:8: ( '=' )
<             // JavaScript.g:181:10: '='
<             {
<             match('='); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ASSIGN"
< 
<     // $ANTLR start "ADDASS"
<     public final void mADDASS() throws RecognitionException {
<         try {
<             int _type = ADDASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:182:8: ( '+=' )
<             // JavaScript.g:182:10: '+='
<             {
<             match("+="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ADDASS"
< 
<     // $ANTLR start "SUBASS"
<     public final void mSUBASS() throws RecognitionException {
<         try {
<             int _type = SUBASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:183:8: ( '-=' )
<             // JavaScript.g:183:10: '-='
<             {
<             match("-="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SUBASS"
< 
<     // $ANTLR start "MULASS"
<     public final void mMULASS() throws RecognitionException {
<         try {
<             int _type = MULASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:184:8: ( '*=' )
<             // JavaScript.g:184:10: '*='
<             {
<             match("*="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MULASS"
< 
<     // $ANTLR start "MODASS"
<     public final void mMODASS() throws RecognitionException {
<         try {
<             int _type = MODASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:185:8: ( '%=' )
<             // JavaScript.g:185:10: '%='
<             {
<             match("%="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MODASS"
< 
<     // $ANTLR start "SHLASS"
<     public final void mSHLASS() throws RecognitionException {
<         try {
<             int _type = SHLASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:186:8: ( '<<=' )
<             // JavaScript.g:186:10: '<<='
<             {
<             match("<<="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHLASS"
< 
<     // $ANTLR start "SHRASS"
<     public final void mSHRASS() throws RecognitionException {
<         try {
<             int _type = SHRASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:187:8: ( '>>=' )
<             // JavaScript.g:187:10: '>>='
<             {
<             match(">>="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHRASS"
< 
<     // $ANTLR start "SHUASS"
<     public final void mSHUASS() throws RecognitionException {
<         try {
<             int _type = SHUASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:188:8: ( '>>>=' )
<             // JavaScript.g:188:10: '>>>='
<             {
<             match(">>>="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHUASS"
< 
<     // $ANTLR start "ANDASS"
<     public final void mANDASS() throws RecognitionException {
<         try {
<             int _type = ANDASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:189:8: ( '&=' )
<             // JavaScript.g:189:10: '&='
<             {
<             match("&="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ANDASS"
< 
<     // $ANTLR start "ORASS"
<     public final void mORASS() throws RecognitionException {
<         try {
<             int _type = ORASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:190:7: ( '|=' )
<             // JavaScript.g:190:9: '|='
<             {
<             match("|="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ORASS"
< 
<     // $ANTLR start "XORASS"
<     public final void mXORASS() throws RecognitionException {
<         try {
<             int _type = XORASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:191:8: ( '^=' )
<             // JavaScript.g:191:10: '^='
<             {
<             match("^="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "XORASS"
< 
<     // $ANTLR start "DIV"
<     public final void mDIV() throws RecognitionException {
<         try {
<             int _type = DIV;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:192:5: ( '/' )
<             // JavaScript.g:192:7: '/'
<             {
<             match('/'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DIV"
< 
<     // $ANTLR start "DIVASS"
<     public final void mDIVASS() throws RecognitionException {
<         try {
<             int _type = DIVASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:193:8: ( '/=' )
<             // JavaScript.g:193:10: '/='
<             {
<             match("/="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DIVASS"
< 
<     // $ANTLR start "BSLASH"
<     public final void mBSLASH() throws RecognitionException {
<         try {
<             // JavaScript.g:412:2: ( '\\\\' )
<             // JavaScript.g:412:4: '\\\\'
<             {
<             match('\\'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BSLASH"
< 
<     // $ANTLR start "DQUOTE"
<     public final void mDQUOTE() throws RecognitionException {
<         try {
<             // JavaScript.g:416:2: ( '\"' )
<             // JavaScript.g:416:4: '\"'
<             {
<             match('\"'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DQUOTE"
< 
<     // $ANTLR start "SQUOTE"
<     public final void mSQUOTE() throws RecognitionException {
<         try {
<             // JavaScript.g:420:2: ( '\\'' )
<             // JavaScript.g:420:4: '\\''
<             {
<             match('\''); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SQUOTE"
< 
<     // $ANTLR start "TAB"
<     public final void mTAB() throws RecognitionException {
<         try {
<             // JavaScript.g:426:2: ( '\\u0009' )
<             // JavaScript.g:426:4: '\\u0009'
<             {
<             match('\t'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TAB"
< 
<     // $ANTLR start "VT"
<     public final void mVT() throws RecognitionException {
<         try {
<             // JavaScript.g:430:2: ( '\\u000b' )
<             // JavaScript.g:430:4: '\\u000b'
<             {
<             match('\u000B'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VT"
< 
<     // $ANTLR start "FF"
<     public final void mFF() throws RecognitionException {
<         try {
<             // JavaScript.g:434:2: ( '\\u000c' )
<             // JavaScript.g:434:4: '\\u000c'
<             {
<             match('\f'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FF"
< 
<     // $ANTLR start "SP"
<     public final void mSP() throws RecognitionException {
<         try {
<             // JavaScript.g:438:2: ( '\\u0020' )
<             // JavaScript.g:438:4: '\\u0020'
<             {
<             match(' '); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SP"
< 
<     // $ANTLR start "NBSP"
<     public final void mNBSP() throws RecognitionException {
<         try {
<             // JavaScript.g:442:2: ( '\\u00a0' )
<             // JavaScript.g:442:4: '\\u00a0'
<             {
<             match('\u00A0'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NBSP"
< 
<     // $ANTLR start "USP"
<     public final void mUSP() throws RecognitionException {
<         try {
<             // JavaScript.g:446:2: ( '\\u1680' | '\\u180E' | '\\u2000' | '\\u2001' | '\\u2002' | '\\u2003' | '\\u2004' | '\\u2005' | '\\u2006' | '\\u2007' | '\\u2008' | '\\u2009' | '\\u200A' | '\\u202F' | '\\u205F' | '\\u3000' )
<             // JavaScript.g:
<             {
<             if ( input.LA(1)=='\u1680'||input.LA(1)=='\u180E'||(input.LA(1)>='\u2000' && input.LA(1)<='\u200A')||input.LA(1)=='\u202F'||input.LA(1)=='\u205F'||input.LA(1)=='\u3000' ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "USP"
< 
<     // $ANTLR start "WhiteSpace"
<     public final void mWhiteSpace() throws RecognitionException {
<         try {
<             int _type = WhiteSpace;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:465:2: ( ( TAB | VT | FF | SP | NBSP | USP )+ )
<             // JavaScript.g:465:4: ( TAB | VT | FF | SP | NBSP | USP )+
<             {
<             // JavaScript.g:465:4: ( TAB | VT | FF | SP | NBSP | USP )+
<             int cnt1=0;
<             loop1:
<             do {
<                 int alt1=2;
<                 int LA1_0 = input.LA(1);
< 
<                 if ( (LA1_0=='\t'||(LA1_0>='\u000B' && LA1_0<='\f')||LA1_0==' '||LA1_0=='\u00A0'||LA1_0=='\u1680'||LA1_0=='\u180E'||(LA1_0>='\u2000' && LA1_0<='\u200A')||LA1_0=='\u202F'||LA1_0=='\u205F'||LA1_0=='\u3000') ) {
<                     alt1=1;
<                 }
< 
< 
<                 switch (alt1) {
<             	case 1 :
<             	    // JavaScript.g:
<             	    {
<             	    if ( input.LA(1)=='\t'||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||input.LA(1)==' '||input.LA(1)=='\u00A0'||input.LA(1)=='\u1680'||input.LA(1)=='\u180E'||(input.LA(1)>='\u2000' && input.LA(1)<='\u200A')||input.LA(1)=='\u202F'||input.LA(1)=='\u205F'||input.LA(1)=='\u3000' ) {
<             	        input.consume();
< 
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        recover(mse);
<             	        throw mse;}
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt1 >= 1 ) break loop1;
<                         EarlyExitException eee =
<                             new EarlyExitException(1, input);
<                         throw eee;
<                 }
<                 cnt1++;
<             } while (true);
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "WhiteSpace"
< 
<     // $ANTLR start "LF"
<     public final void mLF() throws RecognitionException {
<         try {
<             // JavaScript.g:473:2: ( '\\n' )
<             // JavaScript.g:473:4: '\\n'
<             {
<             match('\n'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LF"
< 
<     // $ANTLR start "CR"
<     public final void mCR() throws RecognitionException {
<         try {
<             // JavaScript.g:477:2: ( '\\r' )
<             // JavaScript.g:477:4: '\\r'
<             {
<             match('\r'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CR"
< 
<     // $ANTLR start "LS"
<     public final void mLS() throws RecognitionException {
<         try {
<             // JavaScript.g:481:2: ( '\\u2028' )
<             // JavaScript.g:481:4: '\\u2028'
<             {
<             match('\u2028'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LS"
< 
<     // $ANTLR start "PS"
<     public final void mPS() throws RecognitionException {
<         try {
<             // JavaScript.g:485:2: ( '\\u2029' )
<             // JavaScript.g:485:4: '\\u2029'
<             {
<             match('\u2029'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PS"
< 
<     // $ANTLR start "LineTerminator"
<     public final void mLineTerminator() throws RecognitionException {
<         try {
<             // JavaScript.g:489:2: ( CR | LF | LS | PS )
<             // JavaScript.g:
<             {
<             if ( input.LA(1)=='\n'||input.LA(1)=='\r'||(input.LA(1)>='\u2028' && input.LA(1)<='\u2029') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LineTerminator"
< 
<     // $ANTLR start "EOL"
<     public final void mEOL() throws RecognitionException {
<         try {
<             int _type = EOL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:493:2: ( ( ( CR ( LF )? ) | LF | LS | PS ) )
<             // JavaScript.g:493:4: ( ( CR ( LF )? ) | LF | LS | PS )
<             {
<             // JavaScript.g:493:4: ( ( CR ( LF )? ) | LF | LS | PS )
<             int alt3=4;
<             switch ( input.LA(1) ) {
<             case '\r':
<                 {
<                 alt3=1;
<                 }
<                 break;
<             case '\n':
<                 {
<                 alt3=2;
<                 }
<                 break;
<             case '\u2028':
<                 {
<                 alt3=3;
<                 }
<                 break;
<             case '\u2029':
<                 {
<                 alt3=4;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 3, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt3) {
<                 case 1 :
<                     // JavaScript.g:493:6: ( CR ( LF )? )
<                     {
<                     // JavaScript.g:493:6: ( CR ( LF )? )
<                     // JavaScript.g:493:8: CR ( LF )?
<                     {
<                     mCR(); 
<                     // JavaScript.g:493:11: ( LF )?
<                     int alt2=2;
<                     int LA2_0 = input.LA(1);
< 
<                     if ( (LA2_0=='\n') ) {
<                         alt2=1;
<                     }
<                     switch (alt2) {
<                         case 1 :
<                             // JavaScript.g:493:11: LF
<                             {
<                             mLF(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:493:19: LF
<                     {
<                     mLF(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:493:24: LS
<                     {
<                     mLS(); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:493:29: PS
<                     {
<                     mPS(); 
< 
<                     }
<                     break;
< 
<             }
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EOL"
< 
<     // $ANTLR start "MultiLineComment"
<     public final void mMultiLineComment() throws RecognitionException {
<         try {
<             int _type = MultiLineComment;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:500:2: ( '/*' ( options {greedy=false; } : . )* '*/' )
<             // JavaScript.g:500:4: '/*' ( options {greedy=false; } : . )* '*/'
<             {
<             match("/*"); 
< 
<             // JavaScript.g:500:9: ( options {greedy=false; } : . )*
<             loop4:
<             do {
<                 int alt4=2;
<                 int LA4_0 = input.LA(1);
< 
<                 if ( (LA4_0=='*') ) {
<                     int LA4_1 = input.LA(2);
< 
<                     if ( (LA4_1=='/') ) {
<                         alt4=2;
<                     }
<                     else if ( ((LA4_1>='\u0000' && LA4_1<='.')||(LA4_1>='0' && LA4_1<='\uFFFF')) ) {
<                         alt4=1;
<                     }
< 
< 
<                 }
<                 else if ( ((LA4_0>='\u0000' && LA4_0<=')')||(LA4_0>='+' && LA4_0<='\uFFFF')) ) {
<                     alt4=1;
<                 }
< 
< 
<                 switch (alt4) {
<             	case 1 :
<             	    // JavaScript.g:500:41: .
<             	    {
<             	    matchAny(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop4;
<                 }
<             } while (true);
< 
<             match("*/"); 
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MultiLineComment"
< 
<     // $ANTLR start "SingleLineComment"
<     public final void mSingleLineComment() throws RecognitionException {
<         try {
<             int _type = SingleLineComment;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:504:2: ( '//' (~ ( LineTerminator ) )* )
<             // JavaScript.g:504:4: '//' (~ ( LineTerminator ) )*
<             {
<             match("//"); 
< 
<             // JavaScript.g:504:9: (~ ( LineTerminator ) )*
<             loop5:
<             do {
<                 int alt5=2;
<                 int LA5_0 = input.LA(1);
< 
<                 if ( ((LA5_0>='\u0000' && LA5_0<='\t')||(LA5_0>='\u000B' && LA5_0<='\f')||(LA5_0>='\u000E' && LA5_0<='\u2027')||(LA5_0>='\u202A' && LA5_0<='\uFFFF')) ) {
<                     alt5=1;
<                 }
< 
< 
<                 switch (alt5) {
<             	case 1 :
<             	    // JavaScript.g:504:11: ~ ( LineTerminator )
<             	    {
<             	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<             	        input.consume();
< 
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        recover(mse);
<             	        throw mse;}
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop5;
<                 }
<             } while (true);
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SingleLineComment"
< 
<     // $ANTLR start "IdentifierStartASCII"
<     public final void mIdentifierStartASCII() throws RecognitionException {
<         try {
<             // JavaScript.g:605:2: ( 'a' .. 'z' | 'A' .. 'Z' | '$' | '_' | BSLASH 'u' HexDigit HexDigit HexDigit HexDigit )
<             int alt6=5;
<             switch ( input.LA(1) ) {
<             case 'a':
<             case 'b':
<             case 'c':
<             case 'd':
<             case 'e':
<             case 'f':
<             case 'g':
<             case 'h':
<             case 'i':
<             case 'j':
<             case 'k':
<             case 'l':
<             case 'm':
<             case 'n':
<             case 'o':
<             case 'p':
<             case 'q':
<             case 'r':
<             case 's':
<             case 't':
<             case 'u':
<             case 'v':
<             case 'w':
<             case 'x':
<             case 'y':
<             case 'z':
<                 {
<                 alt6=1;
<                 }
<                 break;
<             case 'A':
<             case 'B':
<             case 'C':
<             case 'D':
<             case 'E':
<             case 'F':
<             case 'G':
<             case 'H':
<             case 'I':
<             case 'J':
<             case 'K':
<             case 'L':
<             case 'M':
<             case 'N':
<             case 'O':
<             case 'P':
<             case 'Q':
<             case 'R':
<             case 'S':
<             case 'T':
<             case 'U':
<             case 'V':
<             case 'W':
<             case 'X':
<             case 'Y':
<             case 'Z':
<                 {
<                 alt6=2;
<                 }
<                 break;
<             case '$':
<                 {
<                 alt6=3;
<                 }
<                 break;
<             case '_':
<                 {
<                 alt6=4;
<                 }
<                 break;
<             case '\\':
<                 {
<                 alt6=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 6, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt6) {
<                 case 1 :
<                     // JavaScript.g:605:4: 'a' .. 'z'
<                     {
<                     matchRange('a','z'); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:605:15: 'A' .. 'Z'
<                     {
<                     matchRange('A','Z'); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:606:4: '$'
<                     {
<                     match('$'); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:607:4: '_'
<                     {
<                     match('_'); 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:608:4: BSLASH 'u' HexDigit HexDigit HexDigit HexDigit
<                     {
<                     mBSLASH(); 
<                     match('u'); 
<                     mHexDigit(); 
<                     mHexDigit(); 
<                     mHexDigit(); 
<                     mHexDigit(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IdentifierStartASCII"
< 
<     // $ANTLR start "IdentifierPart"
<     public final void mIdentifierPart() throws RecognitionException {
<         try {
<             // JavaScript.g:616:2: ( DecimalDigit | IdentifierStartASCII | {...}?)
<             int alt7=3;
<             switch ( input.LA(1) ) {
<             case '0':
<             case '1':
<             case '2':
<             case '3':
<             case '4':
<             case '5':
<             case '6':
<             case '7':
<             case '8':
<             case '9':
<                 {
<                 alt7=1;
<                 }
<                 break;
<             case '$':
<             case 'A':
<             case 'B':
<             case 'C':
<             case 'D':
<             case 'E':
<             case 'F':
<             case 'G':
<             case 'H':
<             case 'I':
<             case 'J':
<             case 'K':
<             case 'L':
<             case 'M':
<             case 'N':
<             case 'O':
<             case 'P':
<             case 'Q':
<             case 'R':
<             case 'S':
<             case 'T':
<             case 'U':
<             case 'V':
<             case 'W':
<             case 'X':
<             case 'Y':
<             case 'Z':
<             case '\\':
<             case '_':
<             case 'a':
<             case 'b':
<             case 'c':
<             case 'd':
<             case 'e':
<             case 'f':
<             case 'g':
<             case 'h':
<             case 'i':
<             case 'j':
<             case 'k':
<             case 'l':
<             case 'm':
<             case 'n':
<             case 'o':
<             case 'p':
<             case 'q':
<             case 'r':
<             case 's':
<             case 't':
<             case 'u':
<             case 'v':
<             case 'w':
<             case 'x':
<             case 'y':
<             case 'z':
<                 {
<                 alt7=2;
<                 }
<                 break;
<             default:
<                 alt7=3;}
< 
<             switch (alt7) {
<                 case 1 :
<                     // JavaScript.g:616:4: DecimalDigit
<                     {
<                     mDecimalDigit(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:617:4: IdentifierStartASCII
<                     {
<                     mIdentifierStartASCII(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:618:4: {...}?
<                     {
<                     if ( !(( isIdentifierPartUnicode(input.LA(1)) )) ) {
<                         throw new FailedPredicateException(input, "IdentifierPart", " isIdentifierPartUnicode(input.LA(1)) ");
<                     }
<                      matchAny(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IdentifierPart"
< 
<     // $ANTLR start "IdentifierNameASCIIStart"
<     public final void mIdentifierNameASCIIStart() throws RecognitionException {
<         try {
<             // JavaScript.g:622:2: ( IdentifierStartASCII ( IdentifierPart )* )
<             // JavaScript.g:622:4: IdentifierStartASCII ( IdentifierPart )*
<             {
<             mIdentifierStartASCII(); 
<             // JavaScript.g:622:25: ( IdentifierPart )*
<             loop8:
<             do {
<                 int alt8=2;
<                 int LA8_0 = input.LA(1);
< 
<                 if ( (LA8_0=='$'||(LA8_0>='0' && LA8_0<='9')||(LA8_0>='A' && LA8_0<='Z')||LA8_0=='\\'||LA8_0=='_'||(LA8_0>='a' && LA8_0<='z')) ) {
<                     alt8=1;
<                 }
<                 else if ( (( isIdentifierPartUnicode(input.LA(1)) )) ) {
<                     alt8=1;
<                 }
< 
< 
<                 switch (alt8) {
<             	case 1 :
<             	    // JavaScript.g:622:25: IdentifierPart
<             	    {
<             	    mIdentifierPart(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop8;
<                 }
<             } while (true);
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IdentifierNameASCIIStart"
< 
<     // $ANTLR start "Identifier"
<     public final void mIdentifier() throws RecognitionException {
<         try {
<             int _type = Identifier;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:634:2: ( IdentifierNameASCIIStart | )
<             int alt9=2;
<             int LA9_0 = input.LA(1);
< 
<             if ( (LA9_0=='$'||(LA9_0>='A' && LA9_0<='Z')||LA9_0=='\\'||LA9_0=='_'||(LA9_0>='a' && LA9_0<='z')) ) {
<                 alt9=1;
<             }
<             else {
<                 alt9=2;}
<             switch (alt9) {
<                 case 1 :
<                     // JavaScript.g:634:4: IdentifierNameASCIIStart
<                     {
<                     mIdentifierNameASCIIStart(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:635:4: 
<                     {
<                      consumeIdentifierUnicodeStart(); 
< 
<                     }
<                     break;
< 
<             }
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "Identifier"
< 
<     // $ANTLR start "DecimalDigit"
<     public final void mDecimalDigit() throws RecognitionException {
<         try {
<             // JavaScript.g:718:2: ( '0' .. '9' )
<             // JavaScript.g:718:4: '0' .. '9'
<             {
<             matchRange('0','9'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DecimalDigit"
< 
<     // $ANTLR start "HexDigit"
<     public final void mHexDigit() throws RecognitionException {
<         try {
<             // JavaScript.g:722:2: ( DecimalDigit | 'a' .. 'f' | 'A' .. 'F' )
<             // JavaScript.g:
<             {
<             if ( (input.LA(1)>='0' && input.LA(1)<='9')||(input.LA(1)>='A' && input.LA(1)<='F')||(input.LA(1)>='a' && input.LA(1)<='f') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "HexDigit"
< 
<     // $ANTLR start "OctalDigit"
<     public final void mOctalDigit() throws RecognitionException {
<         try {
<             // JavaScript.g:726:2: ( '0' .. '7' )
<             // JavaScript.g:726:4: '0' .. '7'
<             {
<             matchRange('0','7'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OctalDigit"
< 
<     // $ANTLR start "ExponentPart"
<     public final void mExponentPart() throws RecognitionException {
<         try {
<             // JavaScript.g:730:2: ( ( 'e' | 'E' ) ( '+' | '-' )? ( DecimalDigit )+ )
<             // JavaScript.g:730:4: ( 'e' | 'E' ) ( '+' | '-' )? ( DecimalDigit )+
<             {
<             if ( input.LA(1)=='E'||input.LA(1)=='e' ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
<             // JavaScript.g:730:18: ( '+' | '-' )?
<             int alt10=2;
<             int LA10_0 = input.LA(1);
< 
<             if ( (LA10_0=='+'||LA10_0=='-') ) {
<                 alt10=1;
<             }
<             switch (alt10) {
<                 case 1 :
<                     // JavaScript.g:
<                     {
<                     if ( input.LA(1)=='+'||input.LA(1)=='-' ) {
<                         input.consume();
< 
<                     }
<                     else {
<                         MismatchedSetException mse = new MismatchedSetException(null,input);
<                         recover(mse);
<                         throw mse;}
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             // JavaScript.g:730:33: ( DecimalDigit )+
<             int cnt11=0;
<             loop11:
<             do {
<                 int alt11=2;
<                 int LA11_0 = input.LA(1);
< 
<                 if ( ((LA11_0>='0' && LA11_0<='9')) ) {
<                     alt11=1;
<                 }
< 
< 
<                 switch (alt11) {
<             	case 1 :
<             	    // JavaScript.g:730:33: DecimalDigit
<             	    {
<             	    mDecimalDigit(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt11 >= 1 ) break loop11;
<                         EarlyExitException eee =
<                             new EarlyExitException(11, input);
<                         throw eee;
<                 }
<                 cnt11++;
<             } while (true);
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ExponentPart"
< 
<     // $ANTLR start "DecimalIntegerLiteral"
<     public final void mDecimalIntegerLiteral() throws RecognitionException {
<         try {
<             // JavaScript.g:734:2: ( '0' | '1' .. '9' ( DecimalDigit )* )
<             int alt13=2;
<             int LA13_0 = input.LA(1);
< 
<             if ( (LA13_0=='0') ) {
<                 alt13=1;
<             }
<             else if ( ((LA13_0>='1' && LA13_0<='9')) ) {
<                 alt13=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 13, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt13) {
<                 case 1 :
<                     // JavaScript.g:734:4: '0'
<                     {
<                     match('0'); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:735:4: '1' .. '9' ( DecimalDigit )*
<                     {
<                     matchRange('1','9'); 
<                     // JavaScript.g:735:13: ( DecimalDigit )*
<                     loop12:
<                     do {
<                         int alt12=2;
<                         int LA12_0 = input.LA(1);
< 
<                         if ( ((LA12_0>='0' && LA12_0<='9')) ) {
<                             alt12=1;
<                         }
< 
< 
<                         switch (alt12) {
<                     	case 1 :
<                     	    // JavaScript.g:735:13: DecimalDigit
<                     	    {
<                     	    mDecimalDigit(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop12;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DecimalIntegerLiteral"
< 
<     // $ANTLR start "DecimalLiteral"
<     public final void mDecimalLiteral() throws RecognitionException {
<         try {
<             int _type = DecimalLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:739:2: ( DecimalIntegerLiteral '.' ( DecimalDigit )* ( ExponentPart )? | '.' ( DecimalDigit )+ ( ExponentPart )? | DecimalIntegerLiteral ( ExponentPart )? )
<             int alt19=3;
<             alt19 = dfa19.predict(input);
<             switch (alt19) {
<                 case 1 :
<                     // JavaScript.g:739:4: DecimalIntegerLiteral '.' ( DecimalDigit )* ( ExponentPart )?
<                     {
<                     mDecimalIntegerLiteral(); 
<                     match('.'); 
<                     // JavaScript.g:739:30: ( DecimalDigit )*
<                     loop14:
<                     do {
<                         int alt14=2;
<                         int LA14_0 = input.LA(1);
< 
<                         if ( ((LA14_0>='0' && LA14_0<='9')) ) {
<                             alt14=1;
<                         }
< 
< 
<                         switch (alt14) {
<                     	case 1 :
<                     	    // JavaScript.g:739:30: DecimalDigit
<                     	    {
<                     	    mDecimalDigit(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop14;
<                         }
<                     } while (true);
< 
<                     // JavaScript.g:739:44: ( ExponentPart )?
<                     int alt15=2;
<                     int LA15_0 = input.LA(1);
< 
<                     if ( (LA15_0=='E'||LA15_0=='e') ) {
<                         alt15=1;
<                     }
<                     switch (alt15) {
<                         case 1 :
<                             // JavaScript.g:739:44: ExponentPart
<                             {
<                             mExponentPart(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:740:4: '.' ( DecimalDigit )+ ( ExponentPart )?
<                     {
<                     match('.'); 
<                     // JavaScript.g:740:8: ( DecimalDigit )+
<                     int cnt16=0;
<                     loop16:
<                     do {
<                         int alt16=2;
<                         int LA16_0 = input.LA(1);
< 
<                         if ( ((LA16_0>='0' && LA16_0<='9')) ) {
<                             alt16=1;
<                         }
< 
< 
<                         switch (alt16) {
<                     	case 1 :
<                     	    // JavaScript.g:740:8: DecimalDigit
<                     	    {
<                     	    mDecimalDigit(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    if ( cnt16 >= 1 ) break loop16;
<                                 EarlyExitException eee =
<                                     new EarlyExitException(16, input);
<                                 throw eee;
<                         }
<                         cnt16++;
<                     } while (true);
< 
<                     // JavaScript.g:740:22: ( ExponentPart )?
<                     int alt17=2;
<                     int LA17_0 = input.LA(1);
< 
<                     if ( (LA17_0=='E'||LA17_0=='e') ) {
<                         alt17=1;
<                     }
<                     switch (alt17) {
<                         case 1 :
<                             // JavaScript.g:740:22: ExponentPart
<                             {
<                             mExponentPart(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:741:4: DecimalIntegerLiteral ( ExponentPart )?
<                     {
<                     mDecimalIntegerLiteral(); 
<                     // JavaScript.g:741:26: ( ExponentPart )?
<                     int alt18=2;
<                     int LA18_0 = input.LA(1);
< 
<                     if ( (LA18_0=='E'||LA18_0=='e') ) {
<                         alt18=1;
<                     }
<                     switch (alt18) {
<                         case 1 :
<                             // JavaScript.g:741:26: ExponentPart
<                             {
<                             mExponentPart(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
< 
<             }
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DecimalLiteral"
< 
<     // $ANTLR start "OctalIntegerLiteral"
<     public final void mOctalIntegerLiteral() throws RecognitionException {
<         try {
<             int _type = OctalIntegerLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:745:2: ( '0' ( OctalDigit )+ )
<             // JavaScript.g:745:4: '0' ( OctalDigit )+
<             {
<             match('0'); 
<             // JavaScript.g:745:8: ( OctalDigit )+
<             int cnt20=0;
<             loop20:
<             do {
<                 int alt20=2;
<                 int LA20_0 = input.LA(1);
< 
<                 if ( ((LA20_0>='0' && LA20_0<='7')) ) {
<                     alt20=1;
<                 }
< 
< 
<                 switch (alt20) {
<             	case 1 :
<             	    // JavaScript.g:745:8: OctalDigit
<             	    {
<             	    mOctalDigit(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt20 >= 1 ) break loop20;
<                         EarlyExitException eee =
<                             new EarlyExitException(20, input);
<                         throw eee;
<                 }
<                 cnt20++;
<             } while (true);
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OctalIntegerLiteral"
< 
<     // $ANTLR start "HexIntegerLiteral"
<     public final void mHexIntegerLiteral() throws RecognitionException {
<         try {
<             int _type = HexIntegerLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:749:2: ( ( '0x' | '0X' ) ( HexDigit )+ )
<             // JavaScript.g:749:4: ( '0x' | '0X' ) ( HexDigit )+
<             {
<             // JavaScript.g:749:4: ( '0x' | '0X' )
<             int alt21=2;
<             int LA21_0 = input.LA(1);
< 
<             if ( (LA21_0=='0') ) {
<                 int LA21_1 = input.LA(2);
< 
<                 if ( (LA21_1=='x') ) {
<                     alt21=1;
<                 }
<                 else if ( (LA21_1=='X') ) {
<                     alt21=2;
<                 }
<                 else {
<                     NoViableAltException nvae =
<                         new NoViableAltException("", 21, 1, input);
< 
<                     throw nvae;
<                 }
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 21, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt21) {
<                 case 1 :
<                     // JavaScript.g:749:6: '0x'
<                     {
<                     match("0x"); 
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:749:13: '0X'
<                     {
<                     match("0X"); 
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             // JavaScript.g:749:20: ( HexDigit )+
<             int cnt22=0;
<             loop22:
<             do {
<                 int alt22=2;
<                 int LA22_0 = input.LA(1);
< 
<                 if ( ((LA22_0>='0' && LA22_0<='9')||(LA22_0>='A' && LA22_0<='F')||(LA22_0>='a' && LA22_0<='f')) ) {
<                     alt22=1;
<                 }
< 
< 
<                 switch (alt22) {
<             	case 1 :
<             	    // JavaScript.g:749:20: HexDigit
<             	    {
<             	    mHexDigit(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt22 >= 1 ) break loop22;
<                         EarlyExitException eee =
<                             new EarlyExitException(22, input);
<                         throw eee;
<                 }
<                 cnt22++;
<             } while (true);
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "HexIntegerLiteral"
< 
<     // $ANTLR start "CharacterEscapeSequence"
<     public final void mCharacterEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:768:2: (~ ( DecimalDigit | 'x' | 'u' | LineTerminator ) )
<             // JavaScript.g:768:4: ~ ( DecimalDigit | 'x' | 'u' | LineTerminator )
<             {
<             if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='/')||(input.LA(1)>=':' && input.LA(1)<='t')||(input.LA(1)>='v' && input.LA(1)<='w')||(input.LA(1)>='y' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CharacterEscapeSequence"
< 
<     // $ANTLR start "ZeroToThree"
<     public final void mZeroToThree() throws RecognitionException {
<         try {
<             // JavaScript.g:772:2: ( '0' .. '3' )
<             // JavaScript.g:772:4: '0' .. '3'
<             {
<             matchRange('0','3'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ZeroToThree"
< 
<     // $ANTLR start "OctalEscapeSequence"
<     public final void mOctalEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:776:2: ( OctalDigit | ZeroToThree OctalDigit | '4' .. '7' OctalDigit | ZeroToThree OctalDigit OctalDigit )
<             int alt23=4;
<             int LA23_0 = input.LA(1);
< 
<             if ( ((LA23_0>='0' && LA23_0<='3')) ) {
<                 int LA23_1 = input.LA(2);
< 
<                 if ( ((LA23_1>='0' && LA23_1<='7')) ) {
<                     int LA23_4 = input.LA(3);
< 
<                     if ( ((LA23_4>='0' && LA23_4<='7')) ) {
<                         alt23=4;
<                     }
<                     else {
<                         alt23=2;}
<                 }
<                 else {
<                     alt23=1;}
<             }
<             else if ( ((LA23_0>='4' && LA23_0<='7')) ) {
<                 int LA23_2 = input.LA(2);
< 
<                 if ( ((LA23_2>='0' && LA23_2<='7')) ) {
<                     alt23=3;
<                 }
<                 else {
<                     alt23=1;}
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 23, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt23) {
<                 case 1 :
<                     // JavaScript.g:776:4: OctalDigit
<                     {
<                     mOctalDigit(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:777:4: ZeroToThree OctalDigit
<                     {
<                     mZeroToThree(); 
<                     mOctalDigit(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:778:4: '4' .. '7' OctalDigit
<                     {
<                     matchRange('4','7'); 
<                     mOctalDigit(); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:779:4: ZeroToThree OctalDigit OctalDigit
<                     {
<                     mZeroToThree(); 
<                     mOctalDigit(); 
<                     mOctalDigit(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OctalEscapeSequence"
< 
<     // $ANTLR start "HexEscapeSequence"
<     public final void mHexEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:783:2: ( 'x' HexDigit HexDigit )
<             // JavaScript.g:783:4: 'x' HexDigit HexDigit
<             {
<             match('x'); 
<             mHexDigit(); 
<             mHexDigit(); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "HexEscapeSequence"
< 
<     // $ANTLR start "UnicodeEscapeSequence"
<     public final void mUnicodeEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:787:2: ( 'u' HexDigit HexDigit HexDigit HexDigit )
<             // JavaScript.g:787:4: 'u' HexDigit HexDigit HexDigit HexDigit
<             {
<             match('u'); 
<             mHexDigit(); 
<             mHexDigit(); 
<             mHexDigit(); 
<             mHexDigit(); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "UnicodeEscapeSequence"
< 
<     // $ANTLR start "EscapeSequence"
<     public final void mEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:791:2: ( BSLASH ( CharacterEscapeSequence | OctalEscapeSequence | HexEscapeSequence | UnicodeEscapeSequence ) )
<             // JavaScript.g:792:2: BSLASH ( CharacterEscapeSequence | OctalEscapeSequence | HexEscapeSequence | UnicodeEscapeSequence )
<             {
<             mBSLASH(); 
<             // JavaScript.g:793:2: ( CharacterEscapeSequence | OctalEscapeSequence | HexEscapeSequence | UnicodeEscapeSequence )
<             int alt24=4;
<             int LA24_0 = input.LA(1);
< 
<             if ( ((LA24_0>='\u0000' && LA24_0<='\t')||(LA24_0>='\u000B' && LA24_0<='\f')||(LA24_0>='\u000E' && LA24_0<='/')||(LA24_0>=':' && LA24_0<='t')||(LA24_0>='v' && LA24_0<='w')||(LA24_0>='y' && LA24_0<='\u2027')||(LA24_0>='\u202A' && LA24_0<='\uFFFF')) ) {
<                 alt24=1;
<             }
<             else if ( ((LA24_0>='0' && LA24_0<='7')) ) {
<                 alt24=2;
<             }
<             else if ( (LA24_0=='x') ) {
<                 alt24=3;
<             }
<             else if ( (LA24_0=='u') ) {
<                 alt24=4;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 24, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt24) {
<                 case 1 :
<                     // JavaScript.g:794:3: CharacterEscapeSequence
<                     {
<                     mCharacterEscapeSequence(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:795:5: OctalEscapeSequence
<                     {
<                     mOctalEscapeSequence(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:796:5: HexEscapeSequence
<                     {
<                     mHexEscapeSequence(); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:797:5: UnicodeEscapeSequence
<                     {
<                     mUnicodeEscapeSequence(); 
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EscapeSequence"
< 
<     // $ANTLR start "StringLiteral"
<     public final void mStringLiteral() throws RecognitionException {
<         try {
<             int _type = StringLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:802:2: ( SQUOTE (~ ( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* SQUOTE | DQUOTE (~ ( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* DQUOTE )
<             int alt27=2;
<             int LA27_0 = input.LA(1);
< 
<             if ( (LA27_0=='\'') ) {
<                 alt27=1;
<             }
<             else if ( (LA27_0=='\"') ) {
<                 alt27=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 27, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt27) {
<                 case 1 :
<                     // JavaScript.g:802:4: SQUOTE (~ ( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* SQUOTE
<                     {
<                     mSQUOTE(); 
<                     // JavaScript.g:802:11: (~ ( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )*
<                     loop25:
<                     do {
<                         int alt25=3;
<                         int LA25_0 = input.LA(1);
< 
<                         if ( ((LA25_0>='\u0000' && LA25_0<='\t')||(LA25_0>='\u000B' && LA25_0<='\f')||(LA25_0>='\u000E' && LA25_0<='&')||(LA25_0>='(' && LA25_0<='[')||(LA25_0>=']' && LA25_0<='\u2027')||(LA25_0>='\u202A' && LA25_0<='\uFFFF')) ) {
<                             alt25=1;
<                         }
<                         else if ( (LA25_0=='\\') ) {
<                             alt25=2;
<                         }
< 
< 
<                         switch (alt25) {
<                     	case 1 :
<                     	    // JavaScript.g:802:13: ~ ( SQUOTE | BSLASH | LineTerminator )
<                     	    {
<                     	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='&')||(input.LA(1)>='(' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                     	        input.consume();
< 
<                     	    }
<                     	    else {
<                     	        MismatchedSetException mse = new MismatchedSetException(null,input);
<                     	        recover(mse);
<                     	        throw mse;}
< 
< 
<                     	    }
<                     	    break;
<                     	case 2 :
<                     	    // JavaScript.g:802:53: EscapeSequence
<                     	    {
<                     	    mEscapeSequence(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop25;
<                         }
<                     } while (true);
< 
<                     mSQUOTE(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:803:4: DQUOTE (~ ( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* DQUOTE
<                     {
<                     mDQUOTE(); 
<                     // JavaScript.g:803:11: (~ ( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )*
<                     loop26:
<                     do {
<                         int alt26=3;
<                         int LA26_0 = input.LA(1);
< 
<                         if ( ((LA26_0>='\u0000' && LA26_0<='\t')||(LA26_0>='\u000B' && LA26_0<='\f')||(LA26_0>='\u000E' && LA26_0<='!')||(LA26_0>='#' && LA26_0<='[')||(LA26_0>=']' && LA26_0<='\u2027')||(LA26_0>='\u202A' && LA26_0<='\uFFFF')) ) {
<                             alt26=1;
<                         }
<                         else if ( (LA26_0=='\\') ) {
<                             alt26=2;
<                         }
< 
< 
<                         switch (alt26) {
<                     	case 1 :
<                     	    // JavaScript.g:803:13: ~ ( DQUOTE | BSLASH | LineTerminator )
<                     	    {
<                     	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='!')||(input.LA(1)>='#' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                     	        input.consume();
< 
<                     	    }
<                     	    else {
<                     	        MismatchedSetException mse = new MismatchedSetException(null,input);
<                     	        recover(mse);
<                     	        throw mse;}
< 
< 
<                     	    }
<                     	    break;
<                     	case 2 :
<                     	    // JavaScript.g:803:53: EscapeSequence
<                     	    {
<                     	    mEscapeSequence(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop26;
<                         }
<                     } while (true);
< 
<                     mDQUOTE(); 
< 
<                     }
<                     break;
< 
<             }
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "StringLiteral"
< 
<     // $ANTLR start "BackslashSequence"
<     public final void mBackslashSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:811:2: ( BSLASH ~ ( LineTerminator ) )
<             // JavaScript.g:811:4: BSLASH ~ ( LineTerminator )
<             {
<             mBSLASH(); 
<             if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BackslashSequence"
< 
<     // $ANTLR start "RegularExpressionFirstChar"
<     public final void mRegularExpressionFirstChar() throws RecognitionException {
<         try {
<             // JavaScript.g:815:2: (~ ( LineTerminator | MUL | BSLASH | DIV ) | BackslashSequence )
<             int alt28=2;
<             int LA28_0 = input.LA(1);
< 
<             if ( ((LA28_0>='\u0000' && LA28_0<='\t')||(LA28_0>='\u000B' && LA28_0<='\f')||(LA28_0>='\u000E' && LA28_0<=')')||(LA28_0>='+' && LA28_0<='.')||(LA28_0>='0' && LA28_0<='[')||(LA28_0>=']' && LA28_0<='\u2027')||(LA28_0>='\u202A' && LA28_0<='\uFFFF')) ) {
<                 alt28=1;
<             }
<             else if ( (LA28_0=='\\') ) {
<                 alt28=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 28, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt28) {
<                 case 1 :
<                     // JavaScript.g:815:4: ~ ( LineTerminator | MUL | BSLASH | DIV )
<                     {
<                     if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<=')')||(input.LA(1)>='+' && input.LA(1)<='.')||(input.LA(1)>='0' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                         input.consume();
< 
<                     }
<                     else {
<                         MismatchedSetException mse = new MismatchedSetException(null,input);
<                         recover(mse);
<                         throw mse;}
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:816:4: BackslashSequence
<                     {
<                     mBackslashSequence(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RegularExpressionFirstChar"
< 
<     // $ANTLR start "RegularExpressionChar"
<     public final void mRegularExpressionChar() throws RecognitionException {
<         try {
<             // JavaScript.g:820:2: (~ ( LineTerminator | BSLASH | DIV ) | BackslashSequence )
<             int alt29=2;
<             int LA29_0 = input.LA(1);
< 
<             if ( ((LA29_0>='\u0000' && LA29_0<='\t')||(LA29_0>='\u000B' && LA29_0<='\f')||(LA29_0>='\u000E' && LA29_0<='.')||(LA29_0>='0' && LA29_0<='[')||(LA29_0>=']' && LA29_0<='\u2027')||(LA29_0>='\u202A' && LA29_0<='\uFFFF')) ) {
<                 alt29=1;
<             }
<             else if ( (LA29_0=='\\') ) {
<                 alt29=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 29, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt29) {
<                 case 1 :
<                     // JavaScript.g:820:4: ~ ( LineTerminator | BSLASH | DIV )
<                     {
<                     if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='.')||(input.LA(1)>='0' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                         input.consume();
< 
<                     }
<                     else {
<                         MismatchedSetException mse = new MismatchedSetException(null,input);
<                         recover(mse);
<                         throw mse;}
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:821:4: BackslashSequence
<                     {
<                     mBackslashSequence(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RegularExpressionChar"
< 
<     // $ANTLR start "RegularExpressionLiteral"
<     public final void mRegularExpressionLiteral() throws RecognitionException {
<         try {
<             int _type = RegularExpressionLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:825:2: ({...}? => DIV RegularExpressionFirstChar ( RegularExpressionChar )* DIV ( IdentifierPart )* )
<             // JavaScript.g:825:4: {...}? => DIV RegularExpressionFirstChar ( RegularExpressionChar )* DIV ( IdentifierPart )*
<             {
<             if ( !(( areRegularExpressionsEnabled() )) ) {
<                 throw new FailedPredicateException(input, "RegularExpressionLiteral", " areRegularExpressionsEnabled() ");
<             }
<             mDIV(); 
<             mRegularExpressionFirstChar(); 
<             // JavaScript.g:825:73: ( RegularExpressionChar )*
<             loop30:
<             do {
<                 int alt30=2;
<                 int LA30_0 = input.LA(1);
< 
<                 if ( ((LA30_0>='\u0000' && LA30_0<='\t')||(LA30_0>='\u000B' && LA30_0<='\f')||(LA30_0>='\u000E' && LA30_0<='.')||(LA30_0>='0' && LA30_0<='\u2027')||(LA30_0>='\u202A' && LA30_0<='\uFFFF')) ) {
<                     alt30=1;
<                 }
< 
< 
<                 switch (alt30) {
<             	case 1 :
<             	    // JavaScript.g:825:73: RegularExpressionChar
<             	    {
<             	    mRegularExpressionChar(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop30;
<                 }
<             } while (true);
< 
<             mDIV(); 
<             // JavaScript.g:825:100: ( IdentifierPart )*
<             loop31:
<             do {
<                 int alt31=2;
<                 int LA31_0 = input.LA(1);
< 
<                 if ( (LA31_0=='$'||(LA31_0>='0' && LA31_0<='9')||(LA31_0>='A' && LA31_0<='Z')||LA31_0=='\\'||LA31_0=='_'||(LA31_0>='a' && LA31_0<='z')) ) {
<                     alt31=1;
<                 }
<                 else if ( (( isIdentifierPartUnicode(input.LA(1)) )) ) {
<                     alt31=1;
<                 }
< 
< 
<                 switch (alt31) {
<             	case 1 :
<             	    // JavaScript.g:825:100: IdentifierPart
<             	    {
<             	    mIdentifierPart(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop31;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RegularExpressionLiteral"
< 
<     public void mTokens() throws RecognitionException {
<         // JavaScript.g:1:8: ( NULL | TRUE | FALSE | BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH | ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE | LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS | WhiteSpace | EOL | MultiLineComment | SingleLineComment | Identifier | DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral | StringLiteral | RegularExpressionLiteral )
<         int alt32=117;
<         alt32 = dfa32.predict(input);
<         switch (alt32) {
<             case 1 :
<                 // JavaScript.g:1:10: NULL
<                 {
<                 mNULL(); 
< 
<                 }
<                 break;
<             case 2 :
<                 // JavaScript.g:1:15: TRUE
<                 {
<                 mTRUE(); 
< 
<                 }
<                 break;
<             case 3 :
<                 // JavaScript.g:1:20: FALSE
<                 {
<                 mFALSE(); 
< 
<                 }
<                 break;
<             case 4 :
<                 // JavaScript.g:1:26: BREAK
<                 {
<                 mBREAK(); 
< 
<                 }
<                 break;
<             case 5 :
<                 // JavaScript.g:1:32: CASE
<                 {
<                 mCASE(); 
< 
<                 }
<                 break;
<             case 6 :
<                 // JavaScript.g:1:37: CATCH
<                 {
<                 mCATCH(); 
< 
<                 }
<                 break;
<             case 7 :
<                 // JavaScript.g:1:43: CONTINUE
<                 {
<                 mCONTINUE(); 
< 
<                 }
<                 break;
<             case 8 :
<                 // JavaScript.g:1:52: DEFAULT
<                 {
<                 mDEFAULT(); 
< 
<                 }
<                 break;
<             case 9 :
<                 // JavaScript.g:1:60: DELETE
<                 {
<                 mDELETE(); 
< 
<                 }
<                 break;
<             case 10 :
<                 // JavaScript.g:1:67: DO
<                 {
<                 mDO(); 
< 
<                 }
<                 break;
<             case 11 :
<                 // JavaScript.g:1:70: ELSE
<                 {
<                 mELSE(); 
< 
<                 }
<                 break;
<             case 12 :
<                 // JavaScript.g:1:75: FINALLY
<                 {
<                 mFINALLY(); 
< 
<                 }
<                 break;
<             case 13 :
<                 // JavaScript.g:1:83: FOR
<                 {
<                 mFOR(); 
< 
<                 }
<                 break;
<             case 14 :
<                 // JavaScript.g:1:87: FUNCTION
<                 {
<                 mFUNCTION(); 
< 
<                 }
<                 break;
<             case 15 :
<                 // JavaScript.g:1:96: IF
<                 {
<                 mIF(); 
< 
<                 }
<                 break;
<             case 16 :
<                 // JavaScript.g:1:99: IN
<                 {
<                 mIN(); 
< 
<                 }
<                 break;
<             case 17 :
<                 // JavaScript.g:1:102: INSTANCEOF
<                 {
<                 mINSTANCEOF(); 
< 
<                 }
<                 break;
<             case 18 :
<                 // JavaScript.g:1:113: NEW
<                 {
<                 mNEW(); 
< 
<                 }
<                 break;
<             case 19 :
<                 // JavaScript.g:1:117: RETURN
<                 {
<                 mRETURN(); 
< 
<                 }
<                 break;
<             case 20 :
<                 // JavaScript.g:1:124: SWITCH
<                 {
<                 mSWITCH(); 
< 
<                 }
<                 break;
<             case 21 :
<                 // JavaScript.g:1:131: THIS
<                 {
<                 mTHIS(); 
< 
<                 }
<                 break;
<             case 22 :
<                 // JavaScript.g:1:136: THROW
<                 {
<                 mTHROW(); 
< 
<                 }
<                 break;
<             case 23 :
<                 // JavaScript.g:1:142: TRY
<                 {
<                 mTRY(); 
< 
<                 }
<                 break;
<             case 24 :
<                 // JavaScript.g:1:146: TYPEOF
<                 {
<                 mTYPEOF(); 
< 
<                 }
<                 break;
<             case 25 :
<                 // JavaScript.g:1:153: VAR
<                 {
<                 mVAR(); 
< 
<                 }
<                 break;
<             case 26 :
<                 // JavaScript.g:1:157: VOID
<                 {
<                 mVOID(); 
< 
<                 }
<                 break;
<             case 27 :
<                 // JavaScript.g:1:162: WHILE
<                 {
<                 mWHILE(); 
< 
<                 }
<                 break;
<             case 28 :
<                 // JavaScript.g:1:168: WITH
<                 {
<                 mWITH(); 
< 
<                 }
<                 break;
<             case 29 :
<                 // JavaScript.g:1:173: ABSTRACT
<                 {
<                 mABSTRACT(); 
< 
<                 }
<                 break;
<             case 30 :
<                 // JavaScript.g:1:182: BOOLEAN
<                 {
<                 mBOOLEAN(); 
< 
<                 }
<                 break;
<             case 31 :
<                 // JavaScript.g:1:190: BYTE
<                 {
<                 mBYTE(); 
< 
<                 }
<                 break;
<             case 32 :
<                 // JavaScript.g:1:195: CHAR
<                 {
<                 mCHAR(); 
< 
<                 }
<                 break;
<             case 33 :
<                 // JavaScript.g:1:200: CLASS
<                 {
<                 mCLASS(); 
< 
<                 }
<                 break;
<             case 34 :
<                 // JavaScript.g:1:206: CONST
<                 {
<                 mCONST(); 
< 
<                 }
<                 break;
<             case 35 :
<                 // JavaScript.g:1:212: DEBUGGER
<                 {
<                 mDEBUGGER(); 
< 
<                 }
<                 break;
<             case 36 :
<                 // JavaScript.g:1:221: DOUBLE
<                 {
<                 mDOUBLE(); 
< 
<                 }
<                 break;
<             case 37 :
<                 // JavaScript.g:1:228: ENUM
<                 {
<                 mENUM(); 
< 
<                 }
<                 break;
<             case 38 :
<                 // JavaScript.g:1:233: EXPORT
<                 {
<                 mEXPORT(); 
< 
<                 }
<                 break;
<             case 39 :
<                 // JavaScript.g:1:240: EXTENDS
<                 {
<                 mEXTENDS(); 
< 
<                 }
<                 break;
<             case 40 :
<                 // JavaScript.g:1:248: FINAL
<                 {
<                 mFINAL(); 
< 
<                 }
<                 break;
<             case 41 :
<                 // JavaScript.g:1:254: FLOAT
<                 {
<                 mFLOAT(); 
< 
<                 }
<                 break;
<             case 42 :
<                 // JavaScript.g:1:260: GOTO
<                 {
<                 mGOTO(); 
< 
<                 }
<                 break;
<             case 43 :
<                 // JavaScript.g:1:265: IMPLEMENTS
<                 {
<                 mIMPLEMENTS(); 
< 
<                 }
<                 break;
<             case 44 :
<                 // JavaScript.g:1:276: IMPORT
<                 {
<                 mIMPORT(); 
< 
<                 }
<                 break;
<             case 45 :
<                 // JavaScript.g:1:283: INT
<                 {
<                 mINT(); 
< 
<                 }
<                 break;
<             case 46 :
<                 // JavaScript.g:1:287: INTERFACE
<                 {
<                 mINTERFACE(); 
< 
<                 }
<                 break;
<             case 47 :
<                 // JavaScript.g:1:297: LONG
<                 {
<                 mLONG(); 
< 
<                 }
<                 break;
<             case 48 :
<                 // JavaScript.g:1:302: NATIVE
<                 {
<                 mNATIVE(); 
< 
<                 }
<                 break;
<             case 49 :
<                 // JavaScript.g:1:309: PACKAGE
<                 {
<                 mPACKAGE(); 
< 
<                 }
<                 break;
<             case 50 :
<                 // JavaScript.g:1:317: PRIVATE
<                 {
<                 mPRIVATE(); 
< 
<                 }
<                 break;
<             case 51 :
<                 // JavaScript.g:1:325: PROTECTED
<                 {
<                 mPROTECTED(); 
< 
<                 }
<                 break;
<             case 52 :
<                 // JavaScript.g:1:335: PUBLIC
<                 {
<                 mPUBLIC(); 
< 
<                 }
<                 break;
<             case 53 :
<                 // JavaScript.g:1:342: SHORT
<                 {
<                 mSHORT(); 
< 
<                 }
<                 break;
<             case 54 :
<                 // JavaScript.g:1:348: STATIC
<                 {
<                 mSTATIC(); 
< 
<                 }
<                 break;
<             case 55 :
<                 // JavaScript.g:1:355: SUPER
<                 {
<                 mSUPER(); 
< 
<                 }
<                 break;
<             case 56 :
<                 // JavaScript.g:1:361: SYNCHRONIZED
<                 {
<                 mSYNCHRONIZED(); 
< 
<                 }
<                 break;
<             case 57 :
<                 // JavaScript.g:1:374: THROWS
<                 {
<                 mTHROWS(); 
< 
<                 }
<                 break;
<             case 58 :
<                 // JavaScript.g:1:381: TRANSIENT
<                 {
<                 mTRANSIENT(); 
< 
<                 }
<                 break;
<             case 59 :
<                 // JavaScript.g:1:391: VOLATILE
<                 {
<                 mVOLATILE(); 
< 
<                 }
<                 break;
<             case 60 :
<                 // JavaScript.g:1:400: LBRACE
<                 {
<                 mLBRACE(); 
< 
<                 }
<                 break;
<             case 61 :
<                 // JavaScript.g:1:407: RBRACE
<                 {
<                 mRBRACE(); 
< 
<                 }
<                 break;
<             case 62 :
<                 // JavaScript.g:1:414: LPAREN
<                 {
<                 mLPAREN(); 
< 
<                 }
<                 break;
<             case 63 :
<                 // JavaScript.g:1:421: RPAREN
<                 {
<                 mRPAREN(); 
< 
<                 }
<                 break;
<             case 64 :
<                 // JavaScript.g:1:428: LBRACK
<                 {
<                 mLBRACK(); 
< 
<                 }
<                 break;
<             case 65 :
<                 // JavaScript.g:1:435: RBRACK
<                 {
<                 mRBRACK(); 
< 
<                 }
<                 break;
<             case 66 :
<                 // JavaScript.g:1:442: DOT
<                 {
<                 mDOT(); 
< 
<                 }
<                 break;
<             case 67 :
<                 // JavaScript.g:1:446: SEMIC
<                 {
<                 mSEMIC(); 
< 
<                 }
<                 break;
<             case 68 :
<                 // JavaScript.g:1:452: COMMA
<                 {
<                 mCOMMA(); 
< 
<                 }
<                 break;
<             case 69 :
<                 // JavaScript.g:1:458: LT
<                 {
<                 mLT(); 
< 
<                 }
<                 break;
<             case 70 :
<                 // JavaScript.g:1:461: GT
<                 {
<                 mGT(); 
< 
<                 }
<                 break;
<             case 71 :
<                 // JavaScript.g:1:464: LTE
<                 {
<                 mLTE(); 
< 
<                 }
<                 break;
<             case 72 :
<                 // JavaScript.g:1:468: GTE
<                 {
<                 mGTE(); 
< 
<                 }
<                 break;
<             case 73 :
<                 // JavaScript.g:1:472: EQ
<                 {
<                 mEQ(); 
< 
<                 }
<                 break;
<             case 74 :
<                 // JavaScript.g:1:475: NEQ
<                 {
<                 mNEQ(); 
< 
<                 }
<                 break;
<             case 75 :
<                 // JavaScript.g:1:479: SAME
<                 {
<                 mSAME(); 
< 
<                 }
<                 break;
<             case 76 :
<                 // JavaScript.g:1:484: NSAME
<                 {
<                 mNSAME(); 
< 
<                 }
<                 break;
<             case 77 :
<                 // JavaScript.g:1:490: ADD
<                 {
<                 mADD(); 
< 
<                 }
<                 break;
<             case 78 :
<                 // JavaScript.g:1:494: SUB
<                 {
<                 mSUB(); 
< 
<                 }
<                 break;
<             case 79 :
<                 // JavaScript.g:1:498: MUL
<                 {
<                 mMUL(); 
< 
<                 }
<                 break;
<             case 80 :
<                 // JavaScript.g:1:502: MOD
<                 {
<                 mMOD(); 
< 
<                 }
<                 break;
<             case 81 :
<                 // JavaScript.g:1:506: INC
<                 {
<                 mINC(); 
< 
<                 }
<                 break;
<             case 82 :
<                 // JavaScript.g:1:510: DEC
<                 {
<                 mDEC(); 
< 
<                 }
<                 break;
<             case 83 :
<                 // JavaScript.g:1:514: SHL
<                 {
<                 mSHL(); 
< 
<                 }
<                 break;
<             case 84 :
<                 // JavaScript.g:1:518: SHR
<                 {
<                 mSHR(); 
< 
<                 }
<                 break;
<             case 85 :
<                 // JavaScript.g:1:522: SHU
<                 {
<                 mSHU(); 
< 
<                 }
<                 break;
<             case 86 :
<                 // JavaScript.g:1:526: AND
<                 {
<                 mAND(); 
< 
<                 }
<                 break;
<             case 87 :
<                 // JavaScript.g:1:530: OR
<                 {
<                 mOR(); 
< 
<                 }
<                 break;
<             case 88 :
<                 // JavaScript.g:1:533: XOR
<                 {
<                 mXOR(); 
< 
<                 }
<                 break;
<             case 89 :
<                 // JavaScript.g:1:537: NOT
<                 {
<                 mNOT(); 
< 
<                 }
<                 break;
<             case 90 :
<                 // JavaScript.g:1:541: INV
<                 {
<                 mINV(); 
< 
<                 }
<                 break;
<             case 91 :
<                 // JavaScript.g:1:545: LAND
<                 {
<                 mLAND(); 
< 
<                 }
<                 break;
<             case 92 :
<                 // JavaScript.g:1:550: LOR
<                 {
<                 mLOR(); 
< 
<                 }
<                 break;
<             case 93 :
<                 // JavaScript.g:1:554: QUE
<                 {
<                 mQUE(); 
< 
<                 }
<                 break;
<             case 94 :
<                 // JavaScript.g:1:558: COLON
<                 {
<                 mCOLON(); 
< 
<                 }
<                 break;
<             case 95 :
<                 // JavaScript.g:1:564: ASSIGN
<                 {
<                 mASSIGN(); 
< 
<                 }
<                 break;
<             case 96 :
<                 // JavaScript.g:1:571: ADDASS
<                 {
<                 mADDASS(); 
< 
<                 }
<                 break;
<             case 97 :
<                 // JavaScript.g:1:578: SUBASS
<                 {
<                 mSUBASS(); 
< 
<                 }
<                 break;
<             case 98 :
<                 // JavaScript.g:1:585: MULASS
<                 {
<                 mMULASS(); 
< 
<                 }
<                 break;
<             case 99 :
<                 // JavaScript.g:1:592: MODASS
<                 {
<                 mMODASS(); 
< 
<                 }
<                 break;
<             case 100 :
<                 // JavaScript.g:1:599: SHLASS
<                 {
<                 mSHLASS(); 
< 
<                 }
<                 break;
<             case 101 :
<                 // JavaScript.g:1:606: SHRASS
<                 {
<                 mSHRASS(); 
< 
<                 }
<                 break;
<             case 102 :
<                 // JavaScript.g:1:613: SHUASS
<                 {
<                 mSHUASS(); 
< 
<                 }
<                 break;
<             case 103 :
<                 // JavaScript.g:1:620: ANDASS
<                 {
<                 mANDASS(); 
< 
<                 }
<                 break;
<             case 104 :
<                 // JavaScript.g:1:627: ORASS
<                 {
<                 mORASS(); 
< 
<                 }
<                 break;
<             case 105 :
<                 // JavaScript.g:1:633: XORASS
<                 {
<                 mXORASS(); 
< 
<                 }
<                 break;
<             case 106 :
<                 // JavaScript.g:1:640: DIV
<                 {
<                 mDIV(); 
< 
<                 }
<                 break;
<             case 107 :
<                 // JavaScript.g:1:644: DIVASS
<                 {
<                 mDIVASS(); 
< 
<                 }
<                 break;
<             case 108 :
<                 // JavaScript.g:1:651: WhiteSpace
<                 {
<                 mWhiteSpace(); 
< 
<                 }
<                 break;
<             case 109 :
<                 // JavaScript.g:1:662: EOL
<                 {
<                 mEOL(); 
< 
<                 }
<                 break;
<             case 110 :
<                 // JavaScript.g:1:666: MultiLineComment
<                 {
<                 mMultiLineComment(); 
< 
<                 }
<                 break;
<             case 111 :
<                 // JavaScript.g:1:683: SingleLineComment
<                 {
<                 mSingleLineComment(); 
< 
<                 }
<                 break;
<             case 112 :
<                 // JavaScript.g:1:701: Identifier
<                 {
<                 mIdentifier(); 
< 
<                 }
<                 break;
<             case 113 :
<                 // JavaScript.g:1:712: DecimalLiteral
<                 {
<                 mDecimalLiteral(); 
< 
<                 }
<                 break;
<             case 114 :
<                 // JavaScript.g:1:727: OctalIntegerLiteral
<                 {
<                 mOctalIntegerLiteral(); 
< 
<                 }
<                 break;
<             case 115 :
<                 // JavaScript.g:1:747: HexIntegerLiteral
<                 {
<                 mHexIntegerLiteral(); 
< 
<                 }
<                 break;
<             case 116 :
<                 // JavaScript.g:1:765: StringLiteral
<                 {
<                 mStringLiteral(); 
< 
<                 }
<                 break;
<             case 117 :
<                 // JavaScript.g:1:779: RegularExpressionLiteral
<                 {
<                 mRegularExpressionLiteral(); 
< 
<                 }
<                 break;
< 
<         }
< 
<     }
< 
< 
<     protected DFA19 dfa19 = new DFA19(this);
<     protected DFA32 dfa32 = new DFA32(this);
<     static final String DFA19_eotS =
<         "\1\uffff\2\4\3\uffff\1\4";
<     static final String DFA19_eofS =
<         "\7\uffff";
<     static final String DFA19_minS =
<         "\3\56\3\uffff\1\56";
<     static final String DFA19_maxS =
<         "\1\71\1\56\1\71\3\uffff\1\71";
<     static final String DFA19_acceptS =
<         "\3\uffff\1\2\1\3\1\1\1\uffff";
<     static final String DFA19_specialS =
<         "\7\uffff}>";
<     static final String[] DFA19_transitionS = {
<             "\1\3\1\uffff\1\1\11\2",
<             "\1\5",
<             "\1\5\1\uffff\12\6",
<             "",
<             "",
<             "",
<             "\1\5\1\uffff\12\6"
<     };
< 
<     static final short[] DFA19_eot = DFA.unpackEncodedString(DFA19_eotS);
<     static final short[] DFA19_eof = DFA.unpackEncodedString(DFA19_eofS);
<     static final char[] DFA19_min = DFA.unpackEncodedStringToUnsignedChars(DFA19_minS);
<     static final char[] DFA19_max = DFA.unpackEncodedStringToUnsignedChars(DFA19_maxS);
<     static final short[] DFA19_accept = DFA.unpackEncodedString(DFA19_acceptS);
<     static final short[] DFA19_special = DFA.unpackEncodedString(DFA19_specialS);
<     static final short[][] DFA19_transition;
< 
<     static {
<         int numStates = DFA19_transitionS.length;
<         DFA19_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA19_transition[i] = DFA.unpackEncodedString(DFA19_transitionS[i]);
<         }
<     }
< 
<     class DFA19 extends DFA {
< 
<         public DFA19(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 19;
<             this.eot = DFA19_eot;
<             this.eof = DFA19_eof;
<             this.min = DFA19_min;
<             this.max = DFA19_max;
<             this.accept = DFA19_accept;
<             this.special = DFA19_special;
<             this.transition = DFA19_transition;
<         }
<         public String getDescription() {
<             return "738:1: DecimalLiteral : ( DecimalIntegerLiteral '.' ( DecimalDigit )* ( ExponentPart )? | '.' ( DecimalDigit )+ ( ExponentPart )? | DecimalIntegerLiteral ( ExponentPart )? );";
<         }
<     }
<     static final String DFA32_eotS =
<         "\21\53\6\uffff\1\131\2\uffff\1\134\1\137\1\141\1\143\1\146\1\151"+
<         "\1\153\1\155\1\160\1\163\1\165\3\uffff\1\171\3\uffff\1\55\2\uffff"+
<         "\23\53\1\u0097\3\53\1\u009c\1\u009f\21\53\2\uffff\1\u00b4\2\uffff"+
<         "\1\u00b7\1\uffff\1\u00b9\1\uffff\1\u00bb\23\uffff\1\u00bc\6\uffff"+
<         "\1\53\1\u00be\2\53\1\u00c1\6\53\1\u00c8\16\53\1\uffff\4\53\1\uffff"+
<         "\1\53\1\u00de\1\uffff\7\53\1\u00e7\13\53\2\uffff\1\u00f4\7\uffff"+
<         "\1\u00f5\1\uffff\1\53\1\u00f7\1\uffff\1\53\1\u00f9\4\53\1\uffff"+
<         "\4\53\1\u0102\1\u0103\3\53\1\u0107\5\53\1\u010d\1\u010e\4\53\1\uffff"+
<         "\10\53\1\uffff\1\u011b\2\53\1\u011e\1\53\1\u0120\1\u0121\4\53\3"+
<         "\uffff\1\53\1\uffff\1\53\1\uffff\1\u0129\1\53\1\u012b\1\u012d\1"+
<         "\53\1\u012f\1\u0130\1\53\2\uffff\1\u0132\1\53\1\u0134\1\uffff\1"+
<         "\u0135\4\53\2\uffff\10\53\1\u0142\1\53\1\u0144\1\53\1\uffff\1\53"+
<         "\1\u0147\1\uffff\1\53\2\uffff\4\53\1\u014d\1\53\1\u014f\1\uffff"+
<         "\1\u0150\1\uffff\1\53\1\uffff\1\53\2\uffff\1\53\1\uffff\1\53\2\uffff"+
<         "\1\53\1\u0156\1\53\1\u0158\1\u0159\4\53\1\u015e\1\u015f\1\u0160"+
<         "\1\uffff\1\u0161\1\uffff\2\53\1\uffff\4\53\1\u0168\1\uffff\1\53"+
<         "\2\uffff\1\u016a\1\53\1\u016c\1\53\1\u016e\1\uffff\1\53\2\uffff"+
<         "\1\u0170\3\53\4\uffff\3\53\1\u0177\1\u0178\1\53\1\uffff\1\53\1\uffff"+
<         "\1\u017b\1\uffff\1\u017c\1\uffff\1\u017d\1\uffff\4\53\1\u0182\1"+
<         "\u0183\2\uffff\1\53\1\u0185\3\uffff\1\53\1\u0187\2\53\2\uffff\1"+
<         "\u018a\1\uffff\1\u018b\1\uffff\1\u018c\1\53\3\uffff\1\53\1\u018f"+
<         "\1\uffff";
<     static final String DFA32_eofS =
<         "\u0190\uffff";
<     static final String DFA32_minS =
<         "\1\11\1\141\1\150\1\141\1\157\1\141\1\145\1\154\1\146\1\145\1\150"+
<         "\1\141\1\150\1\142\2\157\1\141\6\uffff\1\60\2\uffff\1\74\3\75\1"+
<         "\53\1\55\2\75\1\46\2\75\3\uffff\1\0\3\uffff\1\60\2\uffff\1\154\1"+
<         "\167\1\164\1\141\1\151\1\160\1\154\1\156\1\162\1\156\1\157\1\145"+
<         "\1\157\1\164\1\163\1\156\2\141\1\142\1\44\1\163\1\165\1\160\2\44"+
<         "\1\160\1\164\1\151\1\157\1\141\1\160\1\156\1\162\2\151\1\164\1\163"+
<         "\1\164\1\156\1\143\1\151\1\142\2\uffff\1\75\2\uffff\1\75\1\uffff"+
<         "\1\75\1\uffff\1\75\23\uffff\1\0\6\uffff\1\154\1\44\1\151\1\145\1"+
<         "\44\1\156\1\163\1\157\1\145\1\163\1\141\1\44\1\143\2\141\1\154\2"+
<         "\145\1\143\1\163\1\162\1\163\1\141\1\145\1\165\1\142\1\uffff\1\145"+
<         "\1\155\1\157\1\145\1\uffff\1\164\1\44\1\uffff\1\154\1\165\1\164"+
<         "\1\162\1\164\1\145\1\143\1\44\1\144\1\141\1\154\1\150\1\164\1\157"+
<         "\1\147\1\153\1\166\1\164\1\154\2\uffff\1\75\7\uffff\1\44\1\uffff"+
<         "\1\166\1\44\1\uffff\1\163\1\44\1\167\1\157\1\145\1\154\1\uffff\2"+
<         "\164\1\153\1\145\2\44\1\150\1\151\1\164\1\44\1\163\1\165\1\164\1"+
<         "\147\1\154\2\44\1\162\1\156\1\141\1\162\1\uffff\1\145\2\162\1\143"+
<         "\1\164\1\151\1\162\1\150\1\uffff\1\44\1\164\1\145\1\44\1\162\2\44"+
<         "\2\141\1\145\1\151\3\uffff\1\145\1\uffff\1\151\1\uffff\1\44\1\146"+
<         "\2\44\1\151\2\44\1\141\2\uffff\1\44\1\156\1\44\1\uffff\1\44\1\154"+
<         "\1\145\1\147\1\145\2\uffff\1\164\1\144\1\156\1\146\1\155\1\164\1"+
<         "\156\1\150\1\44\1\143\1\44\1\162\1\uffff\1\151\1\44\1\uffff\1\141"+
<         "\2\uffff\1\147\1\164\2\143\1\44\1\145\1\44\1\uffff\1\44\1\uffff"+
<         "\1\171\1\uffff\1\157\2\uffff\1\156\1\uffff\1\165\2\uffff\1\164\1"+
<         "\44\1\145\2\44\1\163\1\143\1\141\1\145\3\44\1\uffff\1\44\1\uffff"+
<         "\1\157\1\154\1\uffff\1\143\2\145\1\164\1\44\1\uffff\1\156\2\uffff"+
<         "\1\44\1\156\1\44\1\145\1\44\1\uffff\1\162\2\uffff\1\44\1\145\1\143"+
<         "\1\156\4\uffff\1\156\1\145\1\164\2\44\1\145\1\uffff\1\164\1\uffff"+
<         "\1\44\1\uffff\1\44\1\uffff\1\44\1\uffff\1\157\1\145\1\164\1\151"+
<         "\2\44\2\uffff\1\144\1\44\3\uffff\1\146\1\44\1\163\1\172\2\uffff"+
<         "\1\44\1\uffff\1\44\1\uffff\1\44\1\145\3\uffff\1\144\1\44\1\uffff";
<     static final String DFA32_maxS =
<         "\1\u3000\1\165\1\171\1\165\1\171\2\157\1\170\1\156\1\145\1\171\1"+
<         "\157\1\151\1\142\2\157\1\165\6\uffff\1\71\2\uffff\1\75\1\76\7\75"+
<         "\1\174\1\75\3\uffff\1\uffff\3\uffff\1\170\2\uffff\1\154\1\167\1"+
<         "\164\1\171\1\162\1\160\1\154\1\156\1\162\1\156\1\157\1\145\1\157"+
<         "\2\164\1\156\2\141\1\154\1\172\1\163\1\165\1\164\2\172\1\160\1\164"+
<         "\1\151\1\157\1\141\1\160\1\156\1\162\1\154\1\151\1\164\1\163\1\164"+
<         "\1\156\1\143\1\157\1\142\2\uffff\1\75\2\uffff\1\76\1\uffff\1\75"+
<         "\1\uffff\1\75\23\uffff\1\uffff\6\uffff\1\154\1\172\1\151\1\145\1"+
<         "\172\1\156\1\163\1\157\1\145\1\163\1\141\1\172\1\143\2\141\1\154"+
<         "\2\145\1\143\1\164\1\162\1\163\1\141\1\145\1\165\1\142\1\uffff\1"+
<         "\145\1\155\1\157\1\145\1\uffff\1\164\1\172\1\uffff\1\157\1\165\1"+
<         "\164\1\162\1\164\1\145\1\143\1\172\1\144\1\141\1\154\1\150\1\164"+
<         "\1\157\1\147\1\153\1\166\1\164\1\154\2\uffff\1\75\7\uffff\1\172"+
<         "\1\uffff\1\166\1\172\1\uffff\1\163\1\172\1\167\1\157\1\145\1\154"+
<         "\1\uffff\2\164\1\153\1\145\2\172\1\150\1\151\1\164\1\172\1\163\1"+
<         "\165\1\164\1\147\1\154\2\172\1\162\1\156\1\141\1\162\1\uffff\1\145"+
<         "\2\162\1\143\1\164\1\151\1\162\1\150\1\uffff\1\172\1\164\1\145\1"+
<         "\172\1\162\2\172\2\141\1\145\1\151\3\uffff\1\145\1\uffff\1\151\1"+
<         "\uffff\1\172\1\146\2\172\1\151\2\172\1\141\2\uffff\1\172\1\156\1"+
<         "\172\1\uffff\1\172\1\154\1\145\1\147\1\145\2\uffff\1\164\1\144\1"+
<         "\156\1\146\1\155\1\164\1\156\1\150\1\172\1\143\1\172\1\162\1\uffff"+
<         "\1\151\1\172\1\uffff\1\141\2\uffff\1\147\1\164\2\143\1\172\1\145"+
<         "\1\172\1\uffff\1\172\1\uffff\1\171\1\uffff\1\157\2\uffff\1\156\1"+
<         "\uffff\1\165\2\uffff\1\164\1\172\1\145\2\172\1\163\1\143\1\141\1"+
<         "\145\3\172\1\uffff\1\172\1\uffff\1\157\1\154\1\uffff\1\143\2\145"+
<         "\1\164\1\172\1\uffff\1\156\2\uffff\1\172\1\156\1\172\1\145\1\172"+
<         "\1\uffff\1\162\2\uffff\1\172\1\145\1\143\1\156\4\uffff\1\156\1\145"+
<         "\1\164\2\172\1\145\1\uffff\1\164\1\uffff\1\172\1\uffff\1\172\1\uffff"+
<         "\1\172\1\uffff\1\157\1\145\1\164\1\151\2\172\2\uffff\1\144\1\172"+
<         "\3\uffff\1\146\1\172\1\163\1\172\2\uffff\1\172\1\uffff\1\172\1\uffff"+
<         "\1\172\1\145\3\uffff\1\144\1\172\1\uffff";
<     static final String DFA32_acceptS =
<         "\21\uffff\1\74\1\75\1\76\1\77\1\100\1\101\1\uffff\1\103\1\104\13"+
<         "\uffff\1\132\1\135\1\136\1\uffff\1\154\1\155\1\160\1\uffff\1\161"+
<         "\1\164\52\uffff\1\102\1\107\1\uffff\1\105\1\110\1\uffff\1\106\1"+
<         "\uffff\1\137\1\uffff\1\131\1\121\1\140\1\115\1\122\1\141\1\116\1"+
<         "\142\1\117\1\143\1\120\1\133\1\147\1\126\1\134\1\150\1\127\1\151"+
<         "\1\130\1\uffff\1\156\1\157\1\152\1\165\1\163\1\162\32\uffff\1\12"+
<         "\4\uffff\1\17\2\uffff\1\20\23\uffff\1\144\1\123\1\uffff\1\145\1"+
<         "\124\1\113\1\111\1\114\1\112\1\153\1\uffff\1\22\2\uffff\1\27\6\uffff"+
<         "\1\15\25\uffff\1\55\10\uffff\1\31\13\uffff\1\146\1\125\1\1\1\uffff"+
<         "\1\2\1\uffff\1\25\10\uffff\1\37\1\5\3\uffff\1\40\5\uffff\1\13\1"+
<         "\45\14\uffff\1\32\2\uffff\1\34\1\uffff\1\52\1\57\7\uffff\1\26\1"+
<         "\uffff\1\3\1\uffff\1\50\1\uffff\1\51\1\4\1\uffff\1\6\1\uffff\1\42"+
<         "\1\41\14\uffff\1\65\1\uffff\1\67\2\uffff\1\33\5\uffff\1\60\1\uffff"+
<         "\1\71\1\30\5\uffff\1\11\1\uffff\1\44\1\46\4\uffff\1\54\1\23\1\24"+
<         "\1\66\6\uffff\1\64\1\uffff\1\14\1\uffff\1\36\1\uffff\1\10\1\uffff"+
<         "\1\47\6\uffff\1\61\1\62\2\uffff\1\16\1\7\1\43\4\uffff\1\73\1\35"+
<         "\1\uffff\1\72\1\uffff\1\56\2\uffff\1\63\1\21\1\53\2\uffff\1\70";
<     static final String DFA32_specialS =
<         "\50\uffff\1\0\115\uffff\1\1\u0119\uffff}>";
<     static final String[] DFA32_transitionS = {
<             "\1\51\1\52\2\51\1\52\22\uffff\1\51\1\35\1\56\2\uffff\1\41\1"+
<             "\42\1\56\1\23\1\24\1\40\1\36\1\31\1\37\1\27\1\50\1\54\11\55"+
<             "\1\47\1\30\1\32\1\34\1\33\1\46\33\uffff\1\25\1\uffff\1\26\1"+
<             "\44\2\uffff\1\15\1\4\1\5\1\6\1\7\1\3\1\16\1\uffff\1\10\2\uffff"+
<             "\1\17\1\uffff\1\1\1\uffff\1\20\1\uffff\1\11\1\12\1\2\1\uffff"+
<             "\1\13\1\14\3\uffff\1\21\1\43\1\22\1\45\41\uffff\1\51\u15df\uffff"+
<             "\1\51\u018d\uffff\1\51\u07f1\uffff\13\51\35\uffff\2\52\5\uffff"+
<             "\1\51\57\uffff\1\51\u0fa0\uffff\1\51",
<             "\1\61\3\uffff\1\60\17\uffff\1\57",
<             "\1\63\11\uffff\1\62\6\uffff\1\64",
<             "\1\65\7\uffff\1\66\2\uffff\1\71\2\uffff\1\67\5\uffff\1\70",
<             "\1\73\2\uffff\1\72\6\uffff\1\74",
<             "\1\75\6\uffff\1\77\3\uffff\1\100\2\uffff\1\76",
<             "\1\101\11\uffff\1\102",
<             "\1\103\1\uffff\1\104\11\uffff\1\105",
<             "\1\106\6\uffff\1\110\1\107",
<             "\1\111",
<             "\1\113\13\uffff\1\114\1\115\1\uffff\1\112\1\uffff\1\116",
<             "\1\117\15\uffff\1\120",
<             "\1\121\1\122",
<             "\1\123",
<             "\1\124",
<             "\1\125",
<             "\1\126\20\uffff\1\127\2\uffff\1\130",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\12\55",
<             "",
<             "",
<             "\1\133\1\132",
<             "\1\135\1\136",
<             "\1\140",
<             "\1\142",
<             "\1\144\21\uffff\1\145",
<             "\1\147\17\uffff\1\150",
<             "\1\152",
<             "\1\154",
<             "\1\156\26\uffff\1\157",
<             "\1\162\76\uffff\1\161",
<             "\1\164",
<             "",
<             "",
<             "",
<             "\12\172\1\uffff\2\172\1\uffff\34\172\1\167\4\172\1\170\15\172"+
<             "\1\166\u1fea\172\2\uffff\udfd6\172",
<             "",
<             "",
<             "",
<             "\10\174\40\uffff\1\173\37\uffff\1\173",
<             "",
<             "",
<             "\1\175",
<             "\1\176",
<             "\1\177",
<             "\1\u0082\23\uffff\1\u0080\3\uffff\1\u0081",
<             "\1\u0083\10\uffff\1\u0084",
<             "\1\u0085",
<             "\1\u0086",
<             "\1\u0087",
<             "\1\u0088",
<             "\1\u0089",
<             "\1\u008a",
<             "\1\u008b",
<             "\1\u008c",
<             "\1\u008d",
<             "\1\u008e\1\u008f",
<             "\1\u0090",
<             "\1\u0091",
<             "\1\u0092",
<             "\1\u0095\3\uffff\1\u0093\5\uffff\1\u0094",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\24\53\1\u0096\5\53",
<             "\1\u0098",
<             "\1\u0099",
<             "\1\u009a\3\uffff\1\u009b",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\22\53\1\u009d\1\u009e\6\53",
<             "\1\u00a0",
<             "\1\u00a1",
<             "\1\u00a2",
<             "\1\u00a3",
<             "\1\u00a4",
<             "\1\u00a5",
<             "\1\u00a6",
<             "\1\u00a7",
<             "\1\u00a8\2\uffff\1\u00a9",
<             "\1\u00aa",
<             "\1\u00ab",
<             "\1\u00ac",
<             "\1\u00ad",
<             "\1\u00ae",
<             "\1\u00af",
<             "\1\u00b0\5\uffff\1\u00b1",
<             "\1\u00b2",
<             "",
<             "",
<             "\1\u00b3",
<             "",
<             "",
<             "\1\u00b6\1\u00b5",
<             "",
<             "\1\u00b8",
<             "",
<             "\1\u00ba",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\12\172\1\uffff\2\172\1\uffff\u201a\172\2\uffff\udfd6\172",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\1\u00bd",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00bf",
<             "\1\u00c0",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00c2",
<             "\1\u00c3",
<             "\1\u00c4",
<             "\1\u00c5",
<             "\1\u00c6",
<             "\1\u00c7",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00c9",
<             "\1\u00ca",
<             "\1\u00cb",
<             "\1\u00cc",
<             "\1\u00cd",
<             "\1\u00ce",
<             "\1\u00cf",
<             "\1\u00d1\1\u00d0",
<             "\1\u00d2",
<             "\1\u00d3",
<             "\1\u00d4",
<             "\1\u00d5",
<             "\1\u00d6",
<             "\1\u00d7",
<             "",
<             "\1\u00d8",
<             "\1\u00d9",
<             "\1\u00da",
<             "\1\u00db",
<             "",
<             "\1\u00dc",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\4\53\1\u00dd\25\53",
<             "",
<             "\1\u00df\2\uffff\1\u00e0",
<             "\1\u00e1",
<             "\1\u00e2",
<             "\1\u00e3",
<             "\1\u00e4",
<             "\1\u00e5",
<             "\1\u00e6",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00e8",
<             "\1\u00e9",
<             "\1\u00ea",
<             "\1\u00eb",
<             "\1\u00ec",
<             "\1\u00ed",
<             "\1\u00ee",
<             "\1\u00ef",
<             "\1\u00f0",
<             "\1\u00f1",
<             "\1\u00f2",
<             "",
<             "",
<             "\1\u00f3",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u00f6",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u00f8",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00fa",
<             "\1\u00fb",
<             "\1\u00fc",
<             "\1\u00fd",
<             "",
<             "\1\u00fe",
<             "\1\u00ff",
<             "\1\u0100",
<             "\1\u0101",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0104",
<             "\1\u0105",
<             "\1\u0106",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0108",
<             "\1\u0109",
<             "\1\u010a",
<             "\1\u010b",
<             "\1\u010c",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u010f",
<             "\1\u0110",
<             "\1\u0111",
<             "\1\u0112",
<             "",
<             "\1\u0113",
<             "\1\u0114",
<             "\1\u0115",
<             "\1\u0116",
<             "\1\u0117",
<             "\1\u0118",
<             "\1\u0119",
<             "\1\u011a",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u011c",
<             "\1\u011d",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u011f",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0122",
<             "\1\u0123",
<             "\1\u0124",
<             "\1\u0125",
<             "",
<             "",
<             "",
<             "\1\u0126",
<             "",
<             "\1\u0127",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\22\53\1\u0128\7\53",
<             "\1\u012a",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\13\53\1\u012c\16\53",
<             "\1\u012e",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0131",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0133",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0136",
<             "\1\u0137",
<             "\1\u0138",
<             "\1\u0139",
<             "",
<             "",
<             "\1\u013a",
<             "\1\u013b",
<             "\1\u013c",
<             "\1\u013d",
<             "\1\u013e",
<             "\1\u013f",
<             "\1\u0140",
<             "\1\u0141",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0143",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0145",
<             "",
<             "\1\u0146",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0148",
<             "",
<             "",
<             "\1\u0149",
<             "\1\u014a",
<             "\1\u014b",
<             "\1\u014c",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u014e",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0151",
<             "",
<             "\1\u0152",
<             "",
<             "",
<             "\1\u0153",
<             "",
<             "\1\u0154",
<             "",
<             "",
<             "\1\u0155",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0157",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u015a",
<             "\1\u015b",
<             "\1\u015c",
<             "\1\u015d",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0162",
<             "\1\u0163",
<             "",
<             "\1\u0164",
<             "\1\u0165",
<             "\1\u0166",
<             "\1\u0167",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0169",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u016b",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u016d",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u016f",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0171",
<             "\1\u0172",
<             "\1\u0173",
<             "",
<             "",
<             "",
<             "",
<             "\1\u0174",
<             "\1\u0175",
<             "\1\u0176",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0179",
<             "",
<             "\1\u017a",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u017e",
<             "\1\u017f",
<             "\1\u0180",
<             "\1\u0181",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "",
<             "\1\u0184",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "",
<             "",
<             "\1\u0186",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0188",
<             "\1\u0189",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u018d",
<             "",
<             "",
<             "",
<             "\1\u018e",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             ""
<     };
< 
<     static final short[] DFA32_eot = DFA.unpackEncodedString(DFA32_eotS);
<     static final short[] DFA32_eof = DFA.unpackEncodedString(DFA32_eofS);
<     static final char[] DFA32_min = DFA.unpackEncodedStringToUnsignedChars(DFA32_minS);
<     static final char[] DFA32_max = DFA.unpackEncodedStringToUnsignedChars(DFA32_maxS);
<     static final short[] DFA32_accept = DFA.unpackEncodedString(DFA32_acceptS);
<     static final short[] DFA32_special = DFA.unpackEncodedString(DFA32_specialS);
<     static final short[][] DFA32_transition;
< 
<     static {
<         int numStates = DFA32_transitionS.length;
<         DFA32_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA32_transition[i] = DFA.unpackEncodedString(DFA32_transitionS[i]);
<         }
<     }
< 
<     class DFA32 extends DFA {
< 
<         public DFA32(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 32;
<             this.eot = DFA32_eot;
<             this.eof = DFA32_eof;
<             this.min = DFA32_min;
<             this.max = DFA32_max;
<             this.accept = DFA32_accept;
<             this.special = DFA32_special;
<             this.transition = DFA32_transition;
<         }
<         public String getDescription() {
<             return "1:1: Tokens : ( NULL | TRUE | FALSE | BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH | ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE | LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS | WhiteSpace | EOL | MultiLineComment | SingleLineComment | Identifier | DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral | StringLiteral | RegularExpressionLiteral );";
<         }
<         public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
<             IntStream input = _input;
<         	int _s = s;
<             switch ( s ) {
<                     case 0 : 
<                         int LA32_40 = input.LA(1);
< 
<                          
<                         int index32_40 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( (LA32_40=='=') ) {s = 118;}
< 
<                         else if ( (LA32_40=='*') ) {s = 119;}
< 
<                         else if ( (LA32_40=='/') ) {s = 120;}
< 
<                         else if ( ((LA32_40>='\u0000' && LA32_40<='\t')||(LA32_40>='\u000B' && LA32_40<='\f')||(LA32_40>='\u000E' && LA32_40<=')')||(LA32_40>='+' && LA32_40<='.')||(LA32_40>='0' && LA32_40<='<')||(LA32_40>='>' && LA32_40<='\u2027')||(LA32_40>='\u202A' && LA32_40<='\uFFFF')) && (( areRegularExpressionsEnabled() ))) {s = 122;}
< 
<                         else s = 121;
< 
<                          
<                         input.seek(index32_40);
<                         if ( s>=0 ) return s;
<                         break;
<                     case 1 : 
<                         int LA32_118 = input.LA(1);
< 
<                          
<                         int index32_118 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( ((LA32_118>='\u0000' && LA32_118<='\t')||(LA32_118>='\u000B' && LA32_118<='\f')||(LA32_118>='\u000E' && LA32_118<='\u2027')||(LA32_118>='\u202A' && LA32_118<='\uFFFF')) && (( areRegularExpressionsEnabled() ))) {s = 122;}
< 
<                         else s = 188;
< 
<                          
<                         input.seek(index32_118);
<                         if ( s>=0 ) return s;
<                         break;
<             }
<             NoViableAltException nvae =
<                 new NoViableAltException(getDescription(), 32, _s, input);
<             error(nvae);
<             throw nvae;
<         }
<     }
<  
< 
< }
\ No newline at end of file
diff -r -N code-worker/tasks/clonedigger/js_antlr/JavaScriptParser.java code-worker/code-worker/tasks/clonedigger/js_antlr/JavaScriptParser.java
1,10124d0
< // $ANTLR 3.1.1 JavaScript.g 2009-03-06 21:11:52
< 
< import org.antlr.runtime.*;
< import java.util.Stack;
< import java.util.List;
< import java.util.ArrayList;
< 
< 
< import org.antlr.runtime.tree.*;
< 
< public class JavaScriptParser extends Parser {
<     public static final String[] tokenNames = new String[] {
<         "<invalid>", "<EOR>", "<DOWN>", "<UP>", "NULL", "TRUE", "FALSE", "BREAK", "CASE", "CATCH", "CONTINUE", "DEFAULT", "DELETE", "DO", "ELSE", "FINALLY", "FOR", "FUNCTION", "IF", "IN", "INSTANCEOF", "NEW", "RETURN", "SWITCH", "THIS", "THROW", "TRY", "TYPEOF", "VAR", "VOID", "WHILE", "WITH", "ABSTRACT", "BOOLEAN", "BYTE", "CHAR", "CLASS", "CONST", "DEBUGGER", "DOUBLE", "ENUM", "EXPORT", "EXTENDS", "FINAL", "FLOAT", "GOTO", "IMPLEMENTS", "IMPORT", "INT", "INTERFACE", "LONG", "NATIVE", "PACKAGE", "PRIVATE", "PROTECTED", "PUBLIC", "SHORT", "STATIC", "SUPER", "SYNCHRONIZED", "THROWS", "TRANSIENT", "VOLATILE", "LBRACE", "RBRACE", "LPAREN", "RPAREN", "LBRACK", "RBRACK", "DOT", "SEMIC", "COMMA", "LT", "GT", "LTE", "GTE", "EQ", "NEQ", "SAME", "NSAME", "ADD", "SUB", "MUL", "MOD", "INC", "DEC", "SHL", "SHR", "SHU", "AND", "OR", "XOR", "NOT", "INV", "LAND", "LOR", "QUE", "COLON", "ASSIGN", "ADDASS", "SUBASS", "MULASS", "MODASS", "SHLASS", "SHRASS", "SHUASS", "ANDASS", "ORASS", "XORASS", "DIV", "DIVASS", "ARGS", "ARRAY", "BLOCK", "BYFIELD", "BYINDEX", "CALL", "CEXPR", "EXPR", "FORITER", "FORSTEP", "ITEM", "LABELLED", "NAMEDVALUE", "NEG", "OBJECT", "PAREXPR", "PDEC", "PINC", "POS", "BSLASH", "DQUOTE", "SQUOTE", "TAB", "VT", "FF", "SP", "NBSP", "USP", "WhiteSpace", "LF", "CR", "LS", "PS", "LineTerminator", "EOL", "MultiLineComment", "SingleLineComment", "Identifier", "StringLiteral", "HexDigit", "IdentifierStartASCII", "DecimalDigit", "IdentifierPart", "IdentifierNameASCIIStart", "RegularExpressionLiteral", "OctalDigit", "ExponentPart", "DecimalIntegerLiteral", "DecimalLiteral", "OctalIntegerLiteral", "HexIntegerLiteral", "CharacterEscapeSequence", "ZeroToThree", "OctalEscapeSequence", "HexEscapeSequence", "UnicodeEscapeSequence", "EscapeSequence", "BackslashSequence", "RegularExpressionFirstChar", "RegularExpressionChar"
<     };
<     public static final int BackslashSequence=168;
<     public static final int CONST=37;
<     public static final int COMMA=71;
<     public static final int RegularExpressionLiteral=155;
<     public static final int ARGS=111;
<     public static final int ARRAY=112;
<     public static final int LF=140;
<     public static final int SYNCHRONIZED=59;
<     public static final int HexDigit=150;
<     public static final int DOUBLE=39;
<     public static final int EXPR=118;
<     public static final int ADDASS=99;
<     public static final int DecimalDigit=152;
<     public static final int FALSE=6;
<     public static final int USP=138;
<     public static final int ABSTRACT=32;
<     public static final int SP=136;
<     public static final int DQUOTE=131;
<     public static final int IMPORT=47;
<     public static final int SEMIC=70;
<     public static final int MODASS=102;
<     public static final int PACKAGE=52;
<     public static final int SQUOTE=132;
<     public static final int SHR=87;
<     public static final int CONTINUE=10;
<     public static final int DOT=69;
<     public static final int PRIVATE=53;
<     public static final int MultiLineComment=146;
<     public static final int HexIntegerLiteral=161;
<     public static final int AND=89;
<     public static final int RegularExpressionFirstChar=169;
<     public static final int DIVASS=110;
<     public static final int FUNCTION=17;
<     public static final int GTE=75;
<     public static final int OctalEscapeSequence=164;
<     public static final int HexEscapeSequence=165;
<     public static final int SingleLineComment=147;
<     public static final int UnicodeEscapeSequence=166;
<     public static final int POS=129;
<     public static final int RPAREN=66;
<     public static final int IdentifierStartASCII=151;
<     public static final int FINALLY=15;
<     public static final int IdentifierNameASCIIStart=154;
<     public static final int EXTENDS=42;
<     public static final int IdentifierPart=153;
<     public static final int SUPER=58;
<     public static final int Identifier=148;
<     public static final int SAME=78;
<     public static final int CHAR=35;
<     public static final int NEW=21;
<     public static final int EQ=76;
<     public static final int LT=72;
<     public static final int FINAL=43;
<     public static final int SUBASS=100;
<     public static final int VT=134;
<     public static final int LAND=94;
<     public static final int LBRACK=67;
<     public static final int CATCH=9;
<     public static final int STATIC=57;
<     public static final int CASE=8;
<     public static final int MUL=82;
<     public static final int INTERFACE=49;
<     public static final int ExponentPart=157;
<     public static final int INV=93;
<     public static final int BOOLEAN=33;
<     public static final int ELSE=14;
<     public static final int CharacterEscapeSequence=162;
<     public static final int BSLASH=130;
<     public static final int SHLASS=103;
<     public static final int DecimalLiteral=159;
<     public static final int BREAK=7;
<     public static final int NULL=4;
<     public static final int XOR=91;
<     public static final int COLON=97;
<     public static final int DIV=109;
<     public static final int ORASS=107;
<     public static final int TRUE=5;
<     public static final int ADD=80;
<     public static final int THROW=25;
<     public static final int SHORT=56;
<     public static final int LABELLED=122;
<     public static final int CR=141;
<     public static final int RegularExpressionChar=170;
<     public static final int PUBLIC=55;
<     public static final int SHL=86;
<     public static final int LONG=50;
<     public static final int LOR=95;
<     public static final int TYPEOF=27;
<     public static final int INC=84;
<     public static final int TRANSIENT=61;
<     public static final int TAB=133;
<     public static final int FLOAT=44;
<     public static final int ZeroToThree=163;
<     public static final int THROWS=60;
<     public static final int FF=135;
<     public static final int FORITER=119;
<     public static final int GOTO=45;
<     public static final int MOD=83;
<     public static final int EXPORT=41;
<     public static final int OR=90;
<     public static final int MULASS=101;
<     public static final int LBRACE=63;
<     public static final int BLOCK=113;
<     public static final int RBRACE=64;
<     public static final int PROTECTED=54;
<     public static final int ANDASS=106;
<     public static final int LineTerminator=144;
<     public static final int SHU=88;
<     public static final int EscapeSequence=167;
<     public static final int PAREXPR=126;
<     public static final int INT=48;
<     public static final int LS=142;
<     public static final int CEXPR=117;
<     public static final int ASSIGN=98;
<     public static final int VOID=29;
<     public static final int INSTANCEOF=20;
<     public static final int LPAREN=65;
<     public static final int WhiteSpace=139;
<     public static final int XORASS=108;
<     public static final int QUE=96;
<     public static final int NEQ=77;
<     public static final int NAMEDVALUE=123;
<     public static final int ENUM=40;
<     public static final int PS=143;
<     public static final int DEBUGGER=38;
<     public static final int DELETE=12;
<     public static final int OBJECT=125;
<     public static final int DO=13;
<     public static final int IMPLEMENTS=46;
<     public static final int OctalIntegerLiteral=160;
<     public static final int WHILE=30;
<     public static final int SWITCH=23;
<     public static final int BYINDEX=115;
<     public static final int FORSTEP=120;
<     public static final int OctalDigit=156;
<     public static final int PINC=128;
<     public static final int GT=73;
<     public static final int StringLiteral=149;
<     public static final int DecimalIntegerLiteral=158;
<     public static final int SHRASS=104;
<     public static final int ITEM=121;
<     public static final int SHUASS=105;
<     public static final int THIS=24;
<     public static final int WITH=31;
<     public static final int IN=19;
<     public static final int VAR=28;
<     public static final int LTE=74;
<     public static final int CLASS=36;
<     public static final int NATIVE=51;
<     public static final int DEC=85;
<     public static final int RETURN=22;
<     public static final int BYTE=34;
<     public static final int VOLATILE=62;
<     public static final int IF=18;
<     public static final int EOF=-1;
<     public static final int EOL=145;
<     public static final int NBSP=137;
<     public static final int CALL=116;
<     public static final int FOR=16;
<     public static final int RBRACK=68;
<     public static final int DEFAULT=11;
<     public static final int NEG=124;
<     public static final int SUB=81;
<     public static final int NOT=92;
<     public static final int TRY=26;
<     public static final int PDEC=127;
<     public static final int BYFIELD=114;
<     public static final int NSAME=79;
< 
<     // delegates
<     // delegators
< 
< 
<         public JavaScriptParser(TokenStream input) {
<             this(input, new RecognizerSharedState());
<         }
<         public JavaScriptParser(TokenStream input, RecognizerSharedState state) {
<             super(input, state);
<              
<         }
<         
<     protected TreeAdaptor adaptor = new CommonTreeAdaptor();
< 
<     public void setTreeAdaptor(TreeAdaptor adaptor) {
<         this.adaptor = adaptor;
<     }
<     public TreeAdaptor getTreeAdaptor() {
<         return adaptor;
<     }
< 
<     public String[] getTokenNames() { return JavaScriptParser.tokenNames; }
<     public String getGrammarFileName() { return "JavaScript.g"; }
< 
< 
<     private final boolean isLeftHandSideAssign(RuleReturnScope lhs, Object[] cached)
<     {
<     	if (cached[0] != null)
<     	{
<     		return ((Boolean)cached[0]).booleanValue();
<     	}
<     	
<     	boolean result;
<     	if (isLeftHandSideExpression(lhs))
<     	{
<     		switch (input.LA(1))
<     		{
<     			case ASSIGN:
<     			case MULASS:
<     			case DIVASS:
<     			case MODASS:
<     			case ADDASS:
<     			case SUBASS:
<     			case SHLASS:
<     			case SHRASS:
<     			case SHUASS:
<     			case ANDASS:
<     			case XORASS:
<     			case ORASS:
<     				result = true;
<     				break;
<     			default:
<     				result = false;
<     				break;
<     		}
<     	}
<     	else
<     	{
<     		result = false;
<     	}
<     	
<     	cached[0] = new Boolean(result);
<     	return result;
<     }
< 
<     private final static boolean isLeftHandSideExpression(RuleReturnScope lhs)
<     {
<     	if (lhs.getTree() == null) // e.g. during backtracking
<     	{
<     		return true;
<     	}
<     	else
<     	{
<     		switch (((Tree)lhs.getTree()).getType())
<     		{
<     		// primaryExpression
<     			case THIS:
<     			case Identifier:
<     			case NULL:
<     			case TRUE:
<     			case FALSE:
<     			case DecimalLiteral:
<     			case OctalIntegerLiteral:
<     			case HexIntegerLiteral:
<     			case StringLiteral:
<     			case RegularExpressionLiteral:
<     			case ARRAY:
<     			case OBJECT:
<     			case PAREXPR:
<     		// functionExpression
<     			case FUNCTION:
<     		// newExpression
<     			case NEW:
<     		// leftHandSideExpression
<     			case CALL:
<     			case BYFIELD:
<     			case BYINDEX:
<     				return true;
<     			
<     			default:
<     				return false;
<     		}
<     	}
<     }
<     	
<     private final boolean isLeftHandSideIn(RuleReturnScope lhs, Object[] cached)
<     {
<     	if (cached[0] != null)
<     	{
<     		return ((Boolean)cached[0]).booleanValue();
<     	}
<     	
<     	boolean result = isLeftHandSideExpression(lhs) && (input.LA(1) == IN);
<     	cached[0] = new Boolean(result);
<     	return result;
<     }
< 
<     private final void promoteEOL(ParserRuleReturnScope rule)
<     {
<     	// Get current token and its type (the possibly offending token).
<     	Token lt = input.LT(1);
<     	int la = lt.getType();
<     	
<     	// We only need to promote an EOL when the current token is offending (not a SEMIC, EOF, RBRACE, EOL or MultiLineComment).
<     	// EOL and MultiLineComment are not offending as they're already promoted in a previous call to this method.
<     	// Promoting an EOL means switching it from off channel to on channel.
<     	// A MultiLineComment gets promoted when it contains an EOL.
<     	if (!(la == SEMIC || la == EOF || la == RBRACE || la == EOL || la == MultiLineComment))
<     	{
<     		// Start on the possition before the current token and scan backwards off channel tokens until the previous on channel token.
<     		for (int ix = lt.getTokenIndex() - 1; ix > 0; ix--)
<     		{
<     			lt = input.get(ix);
<     			if (lt.getChannel() == Token.DEFAULT_CHANNEL)
<     			{
<     				// On channel token found: stop scanning.
<     				break;
<     			}
<     			else if (lt.getType() == EOL || (lt.getType() == MultiLineComment && lt.getText().matches("/.*\r\n|\r|\n")))
<     			{
<     				// We found our EOL: promote the token to on channel, position the input on it and reset the rule start.
<     				lt.setChannel(Token.DEFAULT_CHANNEL);
<     				input.seek(lt.getTokenIndex());
<     				if (rule != null)
<     				{
<     					rule.start = lt;
<     				}
<     				break;
<     			}
<     		}
<     	}
<     }	
< 
< 
<     public static class token_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "token"
<     // JavaScript.g:511:1: token : ( reservedWord | Identifier | punctuator | numericLiteral | StringLiteral );
<     public final JavaScriptParser.token_return token() throws RecognitionException {
<         JavaScriptParser.token_return retval = new JavaScriptParser.token_return();
<         retval.start = input.LT(1);
<         int token_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier2=null;
<         Token StringLiteral5=null;
<         JavaScriptParser.reservedWord_return reservedWord1 = null;
< 
<         JavaScriptParser.punctuator_return punctuator3 = null;
< 
<         JavaScriptParser.numericLiteral_return numericLiteral4 = null;
< 
< 
<         MyAstNode Identifier2_tree=null;
<         MyAstNode StringLiteral5_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 1) ) { return retval; }
<             // JavaScript.g:512:2: ( reservedWord | Identifier | punctuator | numericLiteral | StringLiteral )
<             int alt1=5;
<             switch ( input.LA(1) ) {
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case BREAK:
<             case CASE:
<             case CATCH:
<             case CONTINUE:
<             case DEFAULT:
<             case DELETE:
<             case DO:
<             case ELSE:
<             case FINALLY:
<             case FOR:
<             case FUNCTION:
<             case IF:
<             case IN:
<             case INSTANCEOF:
<             case NEW:
<             case RETURN:
<             case SWITCH:
<             case THIS:
<             case THROW:
<             case TRY:
<             case TYPEOF:
<             case VAR:
<             case VOID:
<             case WHILE:
<             case WITH:
<             case ABSTRACT:
<             case BOOLEAN:
<             case BYTE:
<             case CHAR:
<             case CLASS:
<             case CONST:
<             case DEBUGGER:
<             case DOUBLE:
<             case ENUM:
<             case EXPORT:
<             case EXTENDS:
<             case FINAL:
<             case FLOAT:
<             case GOTO:
<             case IMPLEMENTS:
<             case IMPORT:
<             case INT:
<             case INTERFACE:
<             case LONG:
<             case NATIVE:
<             case PACKAGE:
<             case PRIVATE:
<             case PROTECTED:
<             case PUBLIC:
<             case SHORT:
<             case STATIC:
<             case SUPER:
<             case SYNCHRONIZED:
<             case THROWS:
<             case TRANSIENT:
<             case VOLATILE:
<                 {
<                 alt1=1;
<                 }
<                 break;
<             case Identifier:
<                 {
<                 alt1=2;
<                 }
<                 break;
<             case LBRACE:
<             case RBRACE:
<             case LPAREN:
<             case RPAREN:
<             case LBRACK:
<             case RBRACK:
<             case DOT:
<             case SEMIC:
<             case COMMA:
<             case LT:
<             case GT:
<             case LTE:
<             case GTE:
<             case EQ:
<             case NEQ:
<             case SAME:
<             case NSAME:
<             case ADD:
<             case SUB:
<             case MUL:
<             case MOD:
<             case INC:
<             case DEC:
<             case SHL:
<             case SHR:
<             case SHU:
<             case AND:
<             case OR:
<             case XOR:
<             case NOT:
<             case INV:
<             case LAND:
<             case LOR:
<             case QUE:
<             case COLON:
<             case ASSIGN:
<             case ADDASS:
<             case SUBASS:
<             case MULASS:
<             case MODASS:
<             case SHLASS:
<             case SHRASS:
<             case SHUASS:
<             case ANDASS:
<             case ORASS:
<             case XORASS:
<             case DIV:
<             case DIVASS:
<                 {
<                 alt1=3;
<                 }
<                 break;
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt1=4;
<                 }
<                 break;
<             case StringLiteral:
<                 {
<                 alt1=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 1, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt1) {
<                 case 1 :
<                     // JavaScript.g:512:4: reservedWord
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_reservedWord_in_token1756);
<                     reservedWord1=reservedWord();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, reservedWord1.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:513:4: Identifier
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     Identifier2=(Token)match(input,Identifier,FOLLOW_Identifier_in_token1761); 
<                     Identifier2_tree = (MyAstNode)adaptor.create(Identifier2);
<                     adaptor.addChild(root_0, Identifier2_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:514:4: punctuator
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_punctuator_in_token1766);
<                     punctuator3=punctuator();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, punctuator3.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:515:4: numericLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_numericLiteral_in_token1771);
<                     numericLiteral4=numericLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, numericLiteral4.getTree());
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:516:4: StringLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     StringLiteral5=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_token1776); 
<                     StringLiteral5_tree = (MyAstNode)adaptor.create(StringLiteral5);
<                     adaptor.addChild(root_0, StringLiteral5_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "token"
< 
<     public static class reservedWord_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "reservedWord"
<     // JavaScript.g:521:1: reservedWord : ( keyword | futureReservedWord | NULL | booleanLiteral );
<     public final JavaScriptParser.reservedWord_return reservedWord() throws RecognitionException {
<         JavaScriptParser.reservedWord_return retval = new JavaScriptParser.reservedWord_return();
<         retval.start = input.LT(1);
<         int reservedWord_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token NULL8=null;
<         JavaScriptParser.keyword_return keyword6 = null;
< 
<         JavaScriptParser.futureReservedWord_return futureReservedWord7 = null;
< 
<         JavaScriptParser.booleanLiteral_return booleanLiteral9 = null;
< 
< 
<         MyAstNode NULL8_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 2) ) { return retval; }
<             // JavaScript.g:522:2: ( keyword | futureReservedWord | NULL | booleanLiteral )
<             int alt2=4;
<             switch ( input.LA(1) ) {
<             case BREAK:
<             case CASE:
<             case CATCH:
<             case CONTINUE:
<             case DEFAULT:
<             case DELETE:
<             case DO:
<             case ELSE:
<             case FINALLY:
<             case FOR:
<             case FUNCTION:
<             case IF:
<             case IN:
<             case INSTANCEOF:
<             case NEW:
<             case RETURN:
<             case SWITCH:
<             case THIS:
<             case THROW:
<             case TRY:
<             case TYPEOF:
<             case VAR:
<             case VOID:
<             case WHILE:
<             case WITH:
<                 {
<                 alt2=1;
<                 }
<                 break;
<             case ABSTRACT:
<             case BOOLEAN:
<             case BYTE:
<             case CHAR:
<             case CLASS:
<             case CONST:
<             case DEBUGGER:
<             case DOUBLE:
<             case ENUM:
<             case EXPORT:
<             case EXTENDS:
<             case FINAL:
<             case FLOAT:
<             case GOTO:
<             case IMPLEMENTS:
<             case IMPORT:
<             case INT:
<             case INTERFACE:
<             case LONG:
<             case NATIVE:
<             case PACKAGE:
<             case PRIVATE:
<             case PROTECTED:
<             case PUBLIC:
<             case SHORT:
<             case STATIC:
<             case SUPER:
<             case SYNCHRONIZED:
<             case THROWS:
<             case TRANSIENT:
<             case VOLATILE:
<                 {
<                 alt2=2;
<                 }
<                 break;
<             case NULL:
<                 {
<                 alt2=3;
<                 }
<                 break;
<             case TRUE:
<             case FALSE:
<                 {
<                 alt2=4;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 2, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt2) {
<                 case 1 :
<                     // JavaScript.g:522:4: keyword
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_keyword_in_reservedWord1789);
<                     keyword6=keyword();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, keyword6.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:523:4: futureReservedWord
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_futureReservedWord_in_reservedWord1794);
<                     futureReservedWord7=futureReservedWord();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, futureReservedWord7.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:524:4: NULL
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NULL8=(Token)match(input,NULL,FOLLOW_NULL_in_reservedWord1799); 
<                     NULL8_tree = (MyAstNode)adaptor.create(NULL8);
<                     adaptor.addChild(root_0, NULL8_tree);
< 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:525:4: booleanLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_booleanLiteral_in_reservedWord1804);
<                     booleanLiteral9=booleanLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, booleanLiteral9.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "reservedWord"
< 
<     public static class keyword_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "keyword"
<     // JavaScript.g:532:1: keyword : ( BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH );
<     public final JavaScriptParser.keyword_return keyword() throws RecognitionException {
<         JavaScriptParser.keyword_return retval = new JavaScriptParser.keyword_return();
<         retval.start = input.LT(1);
<         int keyword_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set10=null;
< 
<         MyAstNode set10_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 3) ) { return retval; }
<             // JavaScript.g:533:2: ( BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set10=(Token)input.LT(1);
<             if ( (input.LA(1)>=BREAK && input.LA(1)<=WITH) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set10));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "keyword"
< 
<     public static class futureReservedWord_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "futureReservedWord"
<     // JavaScript.g:564:1: futureReservedWord : ( ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE );
<     public final JavaScriptParser.futureReservedWord_return futureReservedWord() throws RecognitionException {
<         JavaScriptParser.futureReservedWord_return retval = new JavaScriptParser.futureReservedWord_return();
<         retval.start = input.LT(1);
<         int futureReservedWord_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set11=null;
< 
<         MyAstNode set11_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 4) ) { return retval; }
<             // JavaScript.g:565:2: ( ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set11=(Token)input.LT(1);
<             if ( (input.LA(1)>=ABSTRACT && input.LA(1)<=VOLATILE) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set11));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "futureReservedWord"
< 
<     public static class punctuator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "punctuator"
<     // JavaScript.g:642:1: punctuator : ( LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS );
<     public final JavaScriptParser.punctuator_return punctuator() throws RecognitionException {
<         JavaScriptParser.punctuator_return retval = new JavaScriptParser.punctuator_return();
<         retval.start = input.LT(1);
<         int punctuator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set12=null;
< 
<         MyAstNode set12_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 5) ) { return retval; }
<             // JavaScript.g:643:2: ( LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set12=(Token)input.LT(1);
<             if ( (input.LA(1)>=LBRACE && input.LA(1)<=DIVASS) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set12));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "punctuator"
< 
<     public static class literal_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "literal"
<     // JavaScript.g:697:1: literal : ( NULL | booleanLiteral | numericLiteral | StringLiteral | RegularExpressionLiteral );
<     public final JavaScriptParser.literal_return literal() throws RecognitionException {
<         JavaScriptParser.literal_return retval = new JavaScriptParser.literal_return();
<         retval.start = input.LT(1);
<         int literal_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token NULL13=null;
<         Token StringLiteral16=null;
<         Token RegularExpressionLiteral17=null;
<         JavaScriptParser.booleanLiteral_return booleanLiteral14 = null;
< 
<         JavaScriptParser.numericLiteral_return numericLiteral15 = null;
< 
< 
<         MyAstNode NULL13_tree=null;
<         MyAstNode StringLiteral16_tree=null;
<         MyAstNode RegularExpressionLiteral17_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 6) ) { return retval; }
<             // JavaScript.g:698:2: ( NULL | booleanLiteral | numericLiteral | StringLiteral | RegularExpressionLiteral )
<             int alt3=5;
<             switch ( input.LA(1) ) {
<             case NULL:
<                 {
<                 alt3=1;
<                 }
<                 break;
<             case TRUE:
<             case FALSE:
<                 {
<                 alt3=2;
<                 }
<                 break;
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt3=3;
<                 }
<                 break;
<             case StringLiteral:
<                 {
<                 alt3=4;
<                 }
<                 break;
<             case RegularExpressionLiteral:
<                 {
<                 alt3=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 3, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt3) {
<                 case 1 :
<                     // JavaScript.g:698:4: NULL
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NULL13=(Token)match(input,NULL,FOLLOW_NULL_in_literal2485); 
<                     NULL13_tree = (MyAstNode)adaptor.create(NULL13);
<                     adaptor.addChild(root_0, NULL13_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:699:4: booleanLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_booleanLiteral_in_literal2490);
<                     booleanLiteral14=booleanLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, booleanLiteral14.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:700:4: numericLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_numericLiteral_in_literal2495);
<                     numericLiteral15=numericLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, numericLiteral15.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:701:4: StringLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     StringLiteral16=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_literal2500); 
<                     StringLiteral16_tree = (MyAstNode)adaptor.create(StringLiteral16);
<                     adaptor.addChild(root_0, StringLiteral16_tree);
< 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:702:4: RegularExpressionLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     RegularExpressionLiteral17=(Token)match(input,RegularExpressionLiteral,FOLLOW_RegularExpressionLiteral_in_literal2505); 
<                     RegularExpressionLiteral17_tree = (MyAstNode)adaptor.create(RegularExpressionLiteral17);
<                     adaptor.addChild(root_0, RegularExpressionLiteral17_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "literal"
< 
<     public static class booleanLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "booleanLiteral"
<     // JavaScript.g:705:1: booleanLiteral : ( TRUE | FALSE );
<     public final JavaScriptParser.booleanLiteral_return booleanLiteral() throws RecognitionException {
<         JavaScriptParser.booleanLiteral_return retval = new JavaScriptParser.booleanLiteral_return();
<         retval.start = input.LT(1);
<         int booleanLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set18=null;
< 
<         MyAstNode set18_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 7) ) { return retval; }
<             // JavaScript.g:706:2: ( TRUE | FALSE )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set18=(Token)input.LT(1);
<             if ( (input.LA(1)>=TRUE && input.LA(1)<=FALSE) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set18));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "booleanLiteral"
< 
<     public static class numericLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "numericLiteral"
<     // JavaScript.g:752:1: numericLiteral : ( DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral );
<     public final JavaScriptParser.numericLiteral_return numericLiteral() throws RecognitionException {
<         JavaScriptParser.numericLiteral_return retval = new JavaScriptParser.numericLiteral_return();
<         retval.start = input.LT(1);
<         int numericLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set19=null;
< 
<         MyAstNode set19_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 8) ) { return retval; }
<             // JavaScript.g:753:2: ( DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set19=(Token)input.LT(1);
<             if ( (input.LA(1)>=DecimalLiteral && input.LA(1)<=HexIntegerLiteral) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set19));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "numericLiteral"
< 
<     public static class primaryExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "primaryExpression"
<     // JavaScript.g:840:1: primaryExpression : ( THIS | Identifier | literal | arrayLiteral | objectLiteral | lpar= LPAREN expression RPAREN -> ^( PAREXPR[$lpar, \"PAREXPR\"] expression ) );
<     public final JavaScriptParser.primaryExpression_return primaryExpression() throws RecognitionException {
<         JavaScriptParser.primaryExpression_return retval = new JavaScriptParser.primaryExpression_return();
<         retval.start = input.LT(1);
<         int primaryExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lpar=null;
<         Token THIS20=null;
<         Token Identifier21=null;
<         Token RPAREN26=null;
<         JavaScriptParser.literal_return literal22 = null;
< 
<         JavaScriptParser.arrayLiteral_return arrayLiteral23 = null;
< 
<         JavaScriptParser.objectLiteral_return objectLiteral24 = null;
< 
<         JavaScriptParser.expression_return expression25 = null;
< 
< 
<         MyAstNode lpar_tree=null;
<         MyAstNode THIS20_tree=null;
<         MyAstNode Identifier21_tree=null;
<         MyAstNode RPAREN26_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 9) ) { return retval; }
<             // JavaScript.g:841:2: ( THIS | Identifier | literal | arrayLiteral | objectLiteral | lpar= LPAREN expression RPAREN -> ^( PAREXPR[$lpar, \"PAREXPR\"] expression ) )
<             int alt4=6;
<             switch ( input.LA(1) ) {
<             case THIS:
<                 {
<                 alt4=1;
<                 }
<                 break;
<             case Identifier:
<                 {
<                 alt4=2;
<                 }
<                 break;
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case StringLiteral:
<             case RegularExpressionLiteral:
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt4=3;
<                 }
<                 break;
<             case LBRACK:
<                 {
<                 alt4=4;
<                 }
<                 break;
<             case LBRACE:
<                 {
<                 alt4=5;
<                 }
<                 break;
<             case LPAREN:
<                 {
<                 alt4=6;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 4, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt4) {
<                 case 1 :
<                     // JavaScript.g:841:4: THIS
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     THIS20=(Token)match(input,THIS,FOLLOW_THIS_in_primaryExpression3118); 
<                     THIS20_tree = (MyAstNode)adaptor.create(THIS20);
<                     adaptor.addChild(root_0, THIS20_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:842:4: Identifier
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     Identifier21=(Token)match(input,Identifier,FOLLOW_Identifier_in_primaryExpression3123); 
<                     Identifier21_tree = (MyAstNode)adaptor.create(Identifier21);
<                     adaptor.addChild(root_0, Identifier21_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:843:4: literal
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_literal_in_primaryExpression3128);
<                     literal22=literal();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, literal22.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:844:4: arrayLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_arrayLiteral_in_primaryExpression3133);
<                     arrayLiteral23=arrayLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, arrayLiteral23.getTree());
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:845:4: objectLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_objectLiteral_in_primaryExpression3138);
<                     objectLiteral24=objectLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, objectLiteral24.getTree());
< 
<                     }
<                     break;
<                 case 6 :
<                     // JavaScript.g:846:4: lpar= LPAREN expression RPAREN
<                     {
<                     lpar=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primaryExpression3145);  
<                     stream_LPAREN.add(lpar);
< 
<                     pushFollow(FOLLOW_expression_in_primaryExpression3147);
<                     expression25=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(expression25.getTree());
<                     RPAREN26=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primaryExpression3149);  
<                     stream_RPAREN.add(RPAREN26);
< 
< 
< 
<                     // AST REWRITE
<                     // elements: expression
<                     // token labels: 
<                     // rule labels: retval
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 846:34: -> ^( PAREXPR[$lpar, \"PAREXPR\"] expression )
<                     {
<                         // JavaScript.g:846:37: ^( PAREXPR[$lpar, \"PAREXPR\"] expression )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(PAREXPR, lpar, "PAREXPR"), root_1);
< 
<                         adaptor.addChild(root_1, stream_expression.nextTree());
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "primaryExpression"
< 
<     public static class arrayLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "arrayLiteral"
<     // JavaScript.g:849:1: arrayLiteral : lb= LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK -> ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* ) ;
<     public final JavaScriptParser.arrayLiteral_return arrayLiteral() throws RecognitionException {
<         JavaScriptParser.arrayLiteral_return retval = new JavaScriptParser.arrayLiteral_return();
<         retval.start = input.LT(1);
<         int arrayLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token COMMA28=null;
<         Token RBRACK30=null;
<         JavaScriptParser.arrayItem_return arrayItem27 = null;
< 
<         JavaScriptParser.arrayItem_return arrayItem29 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode COMMA28_tree=null;
<         MyAstNode RBRACK30_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RBRACK=new RewriteRuleTokenStream(adaptor,"token RBRACK");
<         RewriteRuleTokenStream stream_LBRACK=new RewriteRuleTokenStream(adaptor,"token LBRACK");
<         RewriteRuleSubtreeStream stream_arrayItem=new RewriteRuleSubtreeStream(adaptor,"rule arrayItem");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 10) ) { return retval; }
<             // JavaScript.g:850:2: (lb= LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK -> ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* ) )
<             // JavaScript.g:850:4: lb= LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK
<             {
<             lb=(Token)match(input,LBRACK,FOLLOW_LBRACK_in_arrayLiteral3173);  
<             stream_LBRACK.add(lb);
< 
<             // JavaScript.g:850:14: ( arrayItem ( COMMA arrayItem )* )?
<             int alt6=2;
<             int LA6_0 = input.LA(1);
< 
<             if ( ((LA6_0>=NULL && LA6_0<=FALSE)||LA6_0==DELETE||LA6_0==FUNCTION||LA6_0==NEW||LA6_0==THIS||LA6_0==TYPEOF||LA6_0==VOID||LA6_0==LBRACE||LA6_0==LPAREN||LA6_0==LBRACK||LA6_0==COMMA||(LA6_0>=ADD && LA6_0<=SUB)||(LA6_0>=INC && LA6_0<=DEC)||(LA6_0>=NOT && LA6_0<=INV)||(LA6_0>=Identifier && LA6_0<=StringLiteral)||LA6_0==RegularExpressionLiteral||(LA6_0>=DecimalLiteral && LA6_0<=HexIntegerLiteral)) ) {
<                 alt6=1;
<             }
<             else if ( (LA6_0==RBRACK) ) {
<                 int LA6_2 = input.LA(2);
< 
<                 if ( (( input.LA(1) == COMMA )) ) {
<                     alt6=1;
<                 }
<             }
<             switch (alt6) {
<                 case 1 :
<                     // JavaScript.g:850:16: arrayItem ( COMMA arrayItem )*
<                     {
<                     pushFollow(FOLLOW_arrayItem_in_arrayLiteral3177);
<                     arrayItem27=arrayItem();
< 
<                     state._fsp--;
< 
<                     stream_arrayItem.add(arrayItem27.getTree());
<                     // JavaScript.g:850:26: ( COMMA arrayItem )*
<                     loop5:
<                     do {
<                         int alt5=2;
<                         int LA5_0 = input.LA(1);
< 
<                         if ( (LA5_0==COMMA) ) {
<                             alt5=1;
<                         }
< 
< 
<                         switch (alt5) {
<                     	case 1 :
<                     	    // JavaScript.g:850:28: COMMA arrayItem
<                     	    {
<                     	    COMMA28=(Token)match(input,COMMA,FOLLOW_COMMA_in_arrayLiteral3181);  
<                     	    stream_COMMA.add(COMMA28);
< 
<                     	    pushFollow(FOLLOW_arrayItem_in_arrayLiteral3183);
<                     	    arrayItem29=arrayItem();
< 
<                     	    state._fsp--;
< 
<                     	    stream_arrayItem.add(arrayItem29.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop5;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RBRACK30=(Token)match(input,RBRACK,FOLLOW_RBRACK_in_arrayLiteral3191);  
<             stream_RBRACK.add(RBRACK30);
< 
< 
< 
<             // AST REWRITE
<             // elements: arrayItem
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 851:2: -> ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* )
<             {
<                 // JavaScript.g:851:5: ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ARRAY, lb, "ARRAY"), root_1);
< 
<                 // JavaScript.g:851:28: ( arrayItem )*
<                 while ( stream_arrayItem.hasNext() ) {
<                     adaptor.addChild(root_1, stream_arrayItem.nextTree());
< 
<                 }
<                 stream_arrayItem.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "arrayLiteral"
< 
<     public static class arrayItem_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "arrayItem"
<     // JavaScript.g:854:1: arrayItem : (expr= assignmentExpression | {...}?) -> ^( ITEM ( $expr)? ) ;
<     public final JavaScriptParser.arrayItem_return arrayItem() throws RecognitionException {
<         JavaScriptParser.arrayItem_return retval = new JavaScriptParser.arrayItem_return();
<         retval.start = input.LT(1);
<         int arrayItem_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.assignmentExpression_return expr = null;
< 
< 
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 11) ) { return retval; }
<             // JavaScript.g:855:2: ( (expr= assignmentExpression | {...}?) -> ^( ITEM ( $expr)? ) )
<             // JavaScript.g:855:4: (expr= assignmentExpression | {...}?)
<             {
<             // JavaScript.g:855:4: (expr= assignmentExpression | {...}?)
<             int alt7=2;
<             int LA7_0 = input.LA(1);
< 
<             if ( ((LA7_0>=NULL && LA7_0<=FALSE)||LA7_0==DELETE||LA7_0==FUNCTION||LA7_0==NEW||LA7_0==THIS||LA7_0==TYPEOF||LA7_0==VOID||LA7_0==LBRACE||LA7_0==LPAREN||LA7_0==LBRACK||(LA7_0>=ADD && LA7_0<=SUB)||(LA7_0>=INC && LA7_0<=DEC)||(LA7_0>=NOT && LA7_0<=INV)||(LA7_0>=Identifier && LA7_0<=StringLiteral)||LA7_0==RegularExpressionLiteral||(LA7_0>=DecimalLiteral && LA7_0<=HexIntegerLiteral)) ) {
<                 alt7=1;
<             }
<             else if ( (LA7_0==RBRACK||LA7_0==COMMA) ) {
<                 alt7=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 7, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt7) {
<                 case 1 :
<                     // JavaScript.g:855:6: expr= assignmentExpression
<                     {
<                     pushFollow(FOLLOW_assignmentExpression_in_arrayItem3219);
<                     expr=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     stream_assignmentExpression.add(expr.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:855:34: {...}?
<                     {
<                     if ( !(( input.LA(1) == COMMA )) ) {
<                         throw new FailedPredicateException(input, "arrayItem", " input.LA(1) == COMMA ");
<                     }
< 
<                     }
<                     break;
< 
<             }
< 
< 
< 
<             // AST REWRITE
<             // elements: expr
<             // token labels: 
<             // rule labels: expr, retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_expr=new RewriteRuleSubtreeStream(adaptor,"token expr",expr!=null?expr.tree:null);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 856:2: -> ^( ITEM ( $expr)? )
<             {
<                 // JavaScript.g:856:5: ^( ITEM ( $expr)? )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ITEM, "ITEM"), root_1);
< 
<                 // JavaScript.g:856:13: ( $expr)?
<                 if ( stream_expr.hasNext() ) {
<                     adaptor.addChild(root_1, stream_expr.nextTree());
< 
<                 }
<                 stream_expr.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "arrayItem"
< 
<     public static class objectLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "objectLiteral"
<     // JavaScript.g:859:1: objectLiteral : lb= LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE -> ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* ) ;
<     public final JavaScriptParser.objectLiteral_return objectLiteral() throws RecognitionException {
<         JavaScriptParser.objectLiteral_return retval = new JavaScriptParser.objectLiteral_return();
<         retval.start = input.LT(1);
<         int objectLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token COMMA32=null;
<         Token RBRACE34=null;
<         JavaScriptParser.nameValuePair_return nameValuePair31 = null;
< 
<         JavaScriptParser.nameValuePair_return nameValuePair33 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode COMMA32_tree=null;
<         MyAstNode RBRACE34_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_nameValuePair=new RewriteRuleSubtreeStream(adaptor,"rule nameValuePair");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 12) ) { return retval; }
<             // JavaScript.g:860:2: (lb= LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE -> ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* ) )
<             // JavaScript.g:860:4: lb= LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE
<             {
<             lb=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_objectLiteral3251);  
<             stream_LBRACE.add(lb);
< 
<             // JavaScript.g:860:14: ( nameValuePair ( COMMA nameValuePair )* )?
<             int alt9=2;
<             int LA9_0 = input.LA(1);
< 
<             if ( ((LA9_0>=Identifier && LA9_0<=StringLiteral)||(LA9_0>=DecimalLiteral && LA9_0<=HexIntegerLiteral)) ) {
<                 alt9=1;
<             }
<             switch (alt9) {
<                 case 1 :
<                     // JavaScript.g:860:16: nameValuePair ( COMMA nameValuePair )*
<                     {
<                     pushFollow(FOLLOW_nameValuePair_in_objectLiteral3255);
<                     nameValuePair31=nameValuePair();
< 
<                     state._fsp--;
< 
<                     stream_nameValuePair.add(nameValuePair31.getTree());
<                     // JavaScript.g:860:30: ( COMMA nameValuePair )*
<                     loop8:
<                     do {
<                         int alt8=2;
<                         int LA8_0 = input.LA(1);
< 
<                         if ( (LA8_0==COMMA) ) {
<                             alt8=1;
<                         }
< 
< 
<                         switch (alt8) {
<                     	case 1 :
<                     	    // JavaScript.g:860:32: COMMA nameValuePair
<                     	    {
<                     	    COMMA32=(Token)match(input,COMMA,FOLLOW_COMMA_in_objectLiteral3259);  
<                     	    stream_COMMA.add(COMMA32);
< 
<                     	    pushFollow(FOLLOW_nameValuePair_in_objectLiteral3261);
<                     	    nameValuePair33=nameValuePair();
< 
<                     	    state._fsp--;
< 
<                     	    stream_nameValuePair.add(nameValuePair33.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop8;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RBRACE34=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_objectLiteral3269);  
<             stream_RBRACE.add(RBRACE34);
< 
< 
< 
<             // AST REWRITE
<             // elements: nameValuePair
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 861:2: -> ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* )
<             {
<                 // JavaScript.g:861:5: ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(OBJECT, lb, "OBJECT"), root_1);
< 
<                 // JavaScript.g:861:30: ( nameValuePair )*
<                 while ( stream_nameValuePair.hasNext() ) {
<                     adaptor.addChild(root_1, stream_nameValuePair.nextTree());
< 
<                 }
<                 stream_nameValuePair.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "objectLiteral"
< 
<     public static class nameValuePair_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "nameValuePair"
<     // JavaScript.g:864:1: nameValuePair : propertyName COLON assignmentExpression -> ^( NAMEDVALUE propertyName assignmentExpression ) ;
<     public final JavaScriptParser.nameValuePair_return nameValuePair() throws RecognitionException {
<         JavaScriptParser.nameValuePair_return retval = new JavaScriptParser.nameValuePair_return();
<         retval.start = input.LT(1);
<         int nameValuePair_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token COLON36=null;
<         JavaScriptParser.propertyName_return propertyName35 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression37 = null;
< 
< 
<         MyAstNode COLON36_tree=null;
<         RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
<         RewriteRuleSubtreeStream stream_propertyName=new RewriteRuleSubtreeStream(adaptor,"rule propertyName");
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 13) ) { return retval; }
<             // JavaScript.g:865:2: ( propertyName COLON assignmentExpression -> ^( NAMEDVALUE propertyName assignmentExpression ) )
<             // JavaScript.g:865:4: propertyName COLON assignmentExpression
<             {
<             pushFollow(FOLLOW_propertyName_in_nameValuePair3294);
<             propertyName35=propertyName();
< 
<             state._fsp--;
< 
<             stream_propertyName.add(propertyName35.getTree());
<             COLON36=(Token)match(input,COLON,FOLLOW_COLON_in_nameValuePair3296);  
<             stream_COLON.add(COLON36);
< 
<             pushFollow(FOLLOW_assignmentExpression_in_nameValuePair3298);
<             assignmentExpression37=assignmentExpression();
< 
<             state._fsp--;
< 
<             stream_assignmentExpression.add(assignmentExpression37.getTree());
< 
< 
<             // AST REWRITE
<             // elements: assignmentExpression, propertyName
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 866:2: -> ^( NAMEDVALUE propertyName assignmentExpression )
<             {
<                 // JavaScript.g:866:5: ^( NAMEDVALUE propertyName assignmentExpression )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(NAMEDVALUE, "NAMEDVALUE"), root_1);
< 
<                 adaptor.addChild(root_1, stream_propertyName.nextTree());
<                 adaptor.addChild(root_1, stream_assignmentExpression.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "nameValuePair"
< 
<     public static class propertyName_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "propertyName"
<     // JavaScript.g:869:1: propertyName : ( Identifier | StringLiteral | numericLiteral );
<     public final JavaScriptParser.propertyName_return propertyName() throws RecognitionException {
<         JavaScriptParser.propertyName_return retval = new JavaScriptParser.propertyName_return();
<         retval.start = input.LT(1);
<         int propertyName_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier38=null;
<         Token StringLiteral39=null;
<         JavaScriptParser.numericLiteral_return numericLiteral40 = null;
< 
< 
<         MyAstNode Identifier38_tree=null;
<         MyAstNode StringLiteral39_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 14) ) { return retval; }
<             // JavaScript.g:870:2: ( Identifier | StringLiteral | numericLiteral )
<             int alt10=3;
<             switch ( input.LA(1) ) {
<             case Identifier:
<                 {
<                 alt10=1;
<                 }
<                 break;
<             case StringLiteral:
<                 {
<                 alt10=2;
<                 }
<                 break;
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt10=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 10, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt10) {
<                 case 1 :
<                     // JavaScript.g:870:4: Identifier
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     Identifier38=(Token)match(input,Identifier,FOLLOW_Identifier_in_propertyName3322); 
<                     Identifier38_tree = (MyAstNode)adaptor.create(Identifier38);
<                     adaptor.addChild(root_0, Identifier38_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:871:4: StringLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     StringLiteral39=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_propertyName3327); 
<                     StringLiteral39_tree = (MyAstNode)adaptor.create(StringLiteral39);
<                     adaptor.addChild(root_0, StringLiteral39_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:872:4: numericLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_numericLiteral_in_propertyName3332);
<                     numericLiteral40=numericLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, numericLiteral40.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "propertyName"
< 
<     public static class memberExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "memberExpression"
<     // JavaScript.g:884:1: memberExpression : ( primaryExpression | functionExpression | newExpression );
<     public final JavaScriptParser.memberExpression_return memberExpression() throws RecognitionException {
<         JavaScriptParser.memberExpression_return retval = new JavaScriptParser.memberExpression_return();
<         retval.start = input.LT(1);
<         int memberExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.primaryExpression_return primaryExpression41 = null;
< 
<         JavaScriptParser.functionExpression_return functionExpression42 = null;
< 
<         JavaScriptParser.newExpression_return newExpression43 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 15) ) { return retval; }
<             // JavaScript.g:885:2: ( primaryExpression | functionExpression | newExpression )
<             int alt11=3;
<             switch ( input.LA(1) ) {
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case THIS:
<             case LBRACE:
<             case LPAREN:
<             case LBRACK:
<             case Identifier:
<             case StringLiteral:
<             case RegularExpressionLiteral:
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt11=1;
<                 }
<                 break;
<             case FUNCTION:
<                 {
<                 alt11=2;
<                 }
<                 break;
<             case NEW:
<                 {
<                 alt11=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 11, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt11) {
<                 case 1 :
<                     // JavaScript.g:885:4: primaryExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_primaryExpression_in_memberExpression3350);
<                     primaryExpression41=primaryExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, primaryExpression41.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:886:4: functionExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_functionExpression_in_memberExpression3355);
<                     functionExpression42=functionExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, functionExpression42.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:887:4: newExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_newExpression_in_memberExpression3360);
<                     newExpression43=newExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, newExpression43.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "memberExpression"
< 
<     public static class newExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "newExpression"
<     // JavaScript.g:890:1: newExpression : ( NEW primaryExpression | NEW functionExpression );
<     public final JavaScriptParser.newExpression_return newExpression() throws RecognitionException {
<         JavaScriptParser.newExpression_return retval = new JavaScriptParser.newExpression_return();
<         retval.start = input.LT(1);
<         int newExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token NEW44=null;
<         Token NEW46=null;
<         JavaScriptParser.primaryExpression_return primaryExpression45 = null;
< 
<         JavaScriptParser.functionExpression_return functionExpression47 = null;
< 
< 
<         MyAstNode NEW44_tree=null;
<         MyAstNode NEW46_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 16) ) { return retval; }
<             // JavaScript.g:891:2: ( NEW primaryExpression | NEW functionExpression )
<             int alt12=2;
<             int LA12_0 = input.LA(1);
< 
<             if ( (LA12_0==NEW) ) {
<                 int LA12_1 = input.LA(2);
< 
<                 if ( (LA12_1==FUNCTION) ) {
<                     alt12=2;
<                 }
<                 else if ( ((LA12_1>=NULL && LA12_1<=FALSE)||LA12_1==THIS||LA12_1==LBRACE||LA12_1==LPAREN||LA12_1==LBRACK||(LA12_1>=Identifier && LA12_1<=StringLiteral)||LA12_1==RegularExpressionLiteral||(LA12_1>=DecimalLiteral && LA12_1<=HexIntegerLiteral)) ) {
<                     alt12=1;
<                 }
<                 else {
<                     NoViableAltException nvae =
<                         new NoViableAltException("", 12, 1, input);
< 
<                     throw nvae;
<                 }
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 12, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt12) {
<                 case 1 :
<                     // JavaScript.g:891:4: NEW primaryExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NEW44=(Token)match(input,NEW,FOLLOW_NEW_in_newExpression3371); 
<                     NEW44_tree = (MyAstNode)adaptor.create(NEW44);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(NEW44_tree, root_0);
< 
<                     pushFollow(FOLLOW_primaryExpression_in_newExpression3374);
<                     primaryExpression45=primaryExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, primaryExpression45.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:892:7: NEW functionExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NEW46=(Token)match(input,NEW,FOLLOW_NEW_in_newExpression3382); 
<                     NEW46_tree = (MyAstNode)adaptor.create(NEW46);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(NEW46_tree, root_0);
< 
<                     pushFollow(FOLLOW_functionExpression_in_newExpression3385);
<                     functionExpression47=functionExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, functionExpression47.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "newExpression"
< 
<     public static class arguments_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "arguments"
<     // JavaScript.g:896:1: arguments : LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN -> ^( ARGS ( assignmentExpression )* ) ;
<     public final JavaScriptParser.arguments_return arguments() throws RecognitionException {
<         JavaScriptParser.arguments_return retval = new JavaScriptParser.arguments_return();
<         retval.start = input.LT(1);
<         int arguments_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LPAREN48=null;
<         Token COMMA50=null;
<         Token RPAREN52=null;
<         JavaScriptParser.assignmentExpression_return assignmentExpression49 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression51 = null;
< 
< 
<         MyAstNode LPAREN48_tree=null;
<         MyAstNode COMMA50_tree=null;
<         MyAstNode RPAREN52_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 17) ) { return retval; }
<             // JavaScript.g:897:2: ( LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN -> ^( ARGS ( assignmentExpression )* ) )
<             // JavaScript.g:897:4: LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN
<             {
<             LPAREN48=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_arguments3398);  
<             stream_LPAREN.add(LPAREN48);
< 
<             // JavaScript.g:897:11: ( assignmentExpression ( COMMA assignmentExpression )* )?
<             int alt14=2;
<             int LA14_0 = input.LA(1);
< 
<             if ( ((LA14_0>=NULL && LA14_0<=FALSE)||LA14_0==DELETE||LA14_0==FUNCTION||LA14_0==NEW||LA14_0==THIS||LA14_0==TYPEOF||LA14_0==VOID||LA14_0==LBRACE||LA14_0==LPAREN||LA14_0==LBRACK||(LA14_0>=ADD && LA14_0<=SUB)||(LA14_0>=INC && LA14_0<=DEC)||(LA14_0>=NOT && LA14_0<=INV)||(LA14_0>=Identifier && LA14_0<=StringLiteral)||LA14_0==RegularExpressionLiteral||(LA14_0>=DecimalLiteral && LA14_0<=HexIntegerLiteral)) ) {
<                 alt14=1;
<             }
<             switch (alt14) {
<                 case 1 :
<                     // JavaScript.g:897:13: assignmentExpression ( COMMA assignmentExpression )*
<                     {
<                     pushFollow(FOLLOW_assignmentExpression_in_arguments3402);
<                     assignmentExpression49=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     stream_assignmentExpression.add(assignmentExpression49.getTree());
<                     // JavaScript.g:897:34: ( COMMA assignmentExpression )*
<                     loop13:
<                     do {
<                         int alt13=2;
<                         int LA13_0 = input.LA(1);
< 
<                         if ( (LA13_0==COMMA) ) {
<                             alt13=1;
<                         }
< 
< 
<                         switch (alt13) {
<                     	case 1 :
<                     	    // JavaScript.g:897:36: COMMA assignmentExpression
<                     	    {
<                     	    COMMA50=(Token)match(input,COMMA,FOLLOW_COMMA_in_arguments3406);  
<                     	    stream_COMMA.add(COMMA50);
< 
<                     	    pushFollow(FOLLOW_assignmentExpression_in_arguments3408);
<                     	    assignmentExpression51=assignmentExpression();
< 
<                     	    state._fsp--;
< 
<                     	    stream_assignmentExpression.add(assignmentExpression51.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop13;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RPAREN52=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_arguments3416);  
<             stream_RPAREN.add(RPAREN52);
< 
< 
< 
<             // AST REWRITE
<             // elements: assignmentExpression
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 898:2: -> ^( ARGS ( assignmentExpression )* )
<             {
<                 // JavaScript.g:898:5: ^( ARGS ( assignmentExpression )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ARGS, "ARGS"), root_1);
< 
<                 // JavaScript.g:898:13: ( assignmentExpression )*
<                 while ( stream_assignmentExpression.hasNext() ) {
<                     adaptor.addChild(root_1, stream_assignmentExpression.nextTree());
< 
<                 }
<                 stream_assignmentExpression.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "arguments"
< 
<     public static class leftHandSideExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "leftHandSideExpression"
<     // JavaScript.g:901:1: leftHandSideExpression : ( memberExpression -> memberExpression ) ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )* ;
<     public final JavaScriptParser.leftHandSideExpression_return leftHandSideExpression() throws RecognitionException {
<         JavaScriptParser.leftHandSideExpression_return retval = new JavaScriptParser.leftHandSideExpression_return();
<         retval.start = input.LT(1);
<         int leftHandSideExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LBRACK55=null;
<         Token RBRACK57=null;
<         Token DOT58=null;
<         Token Identifier59=null;
<         JavaScriptParser.memberExpression_return memberExpression53 = null;
< 
<         JavaScriptParser.arguments_return arguments54 = null;
< 
<         JavaScriptParser.expression_return expression56 = null;
< 
< 
<         MyAstNode LBRACK55_tree=null;
<         MyAstNode RBRACK57_tree=null;
<         MyAstNode DOT58_tree=null;
<         MyAstNode Identifier59_tree=null;
<         RewriteRuleTokenStream stream_RBRACK=new RewriteRuleTokenStream(adaptor,"token RBRACK");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleTokenStream stream_LBRACK=new RewriteRuleTokenStream(adaptor,"token LBRACK");
<         RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
<         RewriteRuleSubtreeStream stream_arguments=new RewriteRuleSubtreeStream(adaptor,"rule arguments");
<         RewriteRuleSubtreeStream stream_memberExpression=new RewriteRuleSubtreeStream(adaptor,"rule memberExpression");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 18) ) { return retval; }
<             // JavaScript.g:902:2: ( ( memberExpression -> memberExpression ) ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )* )
<             // JavaScript.g:903:2: ( memberExpression -> memberExpression ) ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )*
<             {
<             // JavaScript.g:903:2: ( memberExpression -> memberExpression )
<             // JavaScript.g:904:3: memberExpression
<             {
<             pushFollow(FOLLOW_memberExpression_in_leftHandSideExpression3445);
<             memberExpression53=memberExpression();
< 
<             state._fsp--;
< 
<             stream_memberExpression.add(memberExpression53.getTree());
< 
< 
<             // AST REWRITE
<             // elements: memberExpression
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 904:22: -> memberExpression
<             {
<                 adaptor.addChild(root_0, stream_memberExpression.nextTree());
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             // JavaScript.g:906:2: ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )*
<             loop15:
<             do {
<                 int alt15=4;
<                 switch ( input.LA(1) ) {
<                 case LPAREN:
<                     {
<                     alt15=1;
<                     }
<                     break;
<                 case LBRACK:
<                     {
<                     alt15=2;
<                     }
<                     break;
<                 case DOT:
<                     {
<                     alt15=3;
<                     }
<                     break;
< 
<                 }
< 
<                 switch (alt15) {
<             	case 1 :
<             	    // JavaScript.g:907:3: arguments
<             	    {
<             	    pushFollow(FOLLOW_arguments_in_leftHandSideExpression3461);
<             	    arguments54=arguments();
< 
<             	    state._fsp--;
< 
<             	    stream_arguments.add(arguments54.getTree());
< 
< 
<             	    // AST REWRITE
<             	    // elements: arguments, leftHandSideExpression
<             	    // token labels: 
<             	    // rule labels: retval
<             	    // token list labels: 
<             	    // rule list labels: 
<             	    retval.tree = root_0;
<             	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             	    root_0 = (MyAstNode)adaptor.nil();
<             	    // 907:15: -> ^( CALL $leftHandSideExpression arguments )
<             	    {
<             	        // JavaScript.g:907:18: ^( CALL $leftHandSideExpression arguments )
<             	        {
<             	        MyAstNode root_1 = (MyAstNode)adaptor.nil();
<             	        root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(CALL, "CALL"), root_1);
< 
<             	        adaptor.addChild(root_1, stream_retval.nextTree());
<             	        adaptor.addChild(root_1, stream_arguments.nextTree());
< 
<             	        adaptor.addChild(root_0, root_1);
<             	        }
< 
<             	    }
< 
<             	    retval.tree = root_0;
<             	    }
<             	    break;
<             	case 2 :
<             	    // JavaScript.g:908:5: LBRACK expression RBRACK
<             	    {
<             	    LBRACK55=(Token)match(input,LBRACK,FOLLOW_LBRACK_in_leftHandSideExpression3482);  
<             	    stream_LBRACK.add(LBRACK55);
< 
<             	    pushFollow(FOLLOW_expression_in_leftHandSideExpression3484);
<             	    expression56=expression();
< 
<             	    state._fsp--;
< 
<             	    stream_expression.add(expression56.getTree());
<             	    RBRACK57=(Token)match(input,RBRACK,FOLLOW_RBRACK_in_leftHandSideExpression3486);  
<             	    stream_RBRACK.add(RBRACK57);
< 
< 
< 
<             	    // AST REWRITE
<             	    // elements: expression, leftHandSideExpression
<             	    // token labels: 
<             	    // rule labels: retval
<             	    // token list labels: 
<             	    // rule list labels: 
<             	    retval.tree = root_0;
<             	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             	    root_0 = (MyAstNode)adaptor.nil();
<             	    // 908:30: -> ^( BYINDEX $leftHandSideExpression expression )
<             	    {
<             	        // JavaScript.g:908:33: ^( BYINDEX $leftHandSideExpression expression )
<             	        {
<             	        MyAstNode root_1 = (MyAstNode)adaptor.nil();
<             	        root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BYINDEX, "BYINDEX"), root_1);
< 
<             	        adaptor.addChild(root_1, stream_retval.nextTree());
<             	        adaptor.addChild(root_1, stream_expression.nextTree());
< 
<             	        adaptor.addChild(root_0, root_1);
<             	        }
< 
<             	    }
< 
<             	    retval.tree = root_0;
<             	    }
<             	    break;
<             	case 3 :
<             	    // JavaScript.g:909:5: DOT Identifier
<             	    {
<             	    DOT58=(Token)match(input,DOT,FOLLOW_DOT_in_leftHandSideExpression3505);  
<             	    stream_DOT.add(DOT58);
< 
<             	    Identifier59=(Token)match(input,Identifier,FOLLOW_Identifier_in_leftHandSideExpression3507);  
<             	    stream_Identifier.add(Identifier59);
< 
< 
< 
<             	    // AST REWRITE
<             	    // elements: Identifier, leftHandSideExpression
<             	    // token labels: 
<             	    // rule labels: retval
<             	    // token list labels: 
<             	    // rule list labels: 
<             	    retval.tree = root_0;
<             	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             	    root_0 = (MyAstNode)adaptor.nil();
<             	    // 909:21: -> ^( BYFIELD $leftHandSideExpression Identifier )
<             	    {
<             	        // JavaScript.g:909:24: ^( BYFIELD $leftHandSideExpression Identifier )
<             	        {
<             	        MyAstNode root_1 = (MyAstNode)adaptor.nil();
<             	        root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BYFIELD, "BYFIELD"), root_1);
< 
<             	        adaptor.addChild(root_1, stream_retval.nextTree());
<             	        adaptor.addChild(root_1, stream_Identifier.nextNode());
< 
<             	        adaptor.addChild(root_0, root_1);
<             	        }
< 
<             	    }
< 
<             	    retval.tree = root_0;
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop15;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "leftHandSideExpression"
< 
<     public static class postfixExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "postfixExpression"
<     // JavaScript.g:923:1: postfixExpression : leftHandSideExpression ( postfixOperator )? ;
<     public final JavaScriptParser.postfixExpression_return postfixExpression() throws RecognitionException {
<         JavaScriptParser.postfixExpression_return retval = new JavaScriptParser.postfixExpression_return();
<         retval.start = input.LT(1);
<         int postfixExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.leftHandSideExpression_return leftHandSideExpression60 = null;
< 
<         JavaScriptParser.postfixOperator_return postfixOperator61 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 19) ) { return retval; }
<             // JavaScript.g:924:2: ( leftHandSideExpression ( postfixOperator )? )
<             // JavaScript.g:924:4: leftHandSideExpression ( postfixOperator )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_leftHandSideExpression_in_postfixExpression3542);
<             leftHandSideExpression60=leftHandSideExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, leftHandSideExpression60.getTree());
<              if (input.LA(1) == INC || input.LA(1) == DEC) promoteEOL(null); 
<             // JavaScript.g:924:95: ( postfixOperator )?
<             int alt16=2;
<             int LA16_0 = input.LA(1);
< 
<             if ( ((LA16_0>=INC && LA16_0<=DEC)) ) {
<                 alt16=1;
<             }
<             switch (alt16) {
<                 case 1 :
<                     // JavaScript.g:924:97: postfixOperator
<                     {
<                     pushFollow(FOLLOW_postfixOperator_in_postfixExpression3548);
<                     postfixOperator61=postfixOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(postfixOperator61.getTree(), root_0);
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "postfixExpression"
< 
<     public static class postfixOperator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "postfixOperator"
<     // JavaScript.g:927:1: postfixOperator : (op= INC | op= DEC );
<     public final JavaScriptParser.postfixOperator_return postfixOperator() throws RecognitionException {
<         JavaScriptParser.postfixOperator_return retval = new JavaScriptParser.postfixOperator_return();
<         retval.start = input.LT(1);
<         int postfixOperator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token op=null;
< 
<         MyAstNode op_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 20) ) { return retval; }
<             // JavaScript.g:928:2: (op= INC | op= DEC )
<             int alt17=2;
<             int LA17_0 = input.LA(1);
< 
<             if ( (LA17_0==INC) ) {
<                 alt17=1;
<             }
<             else if ( (LA17_0==DEC) ) {
<                 alt17=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 17, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt17) {
<                 case 1 :
<                     // JavaScript.g:928:4: op= INC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,INC,FOLLOW_INC_in_postfixOperator3566); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(PINC); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:929:4: op= DEC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,DEC,FOLLOW_DEC_in_postfixOperator3575); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(PDEC); 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "postfixOperator"
< 
<     public static class unaryExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "unaryExpression"
<     // JavaScript.g:936:1: unaryExpression : ( postfixExpression | unaryOperator unaryExpression );
<     public final JavaScriptParser.unaryExpression_return unaryExpression() throws RecognitionException {
<         JavaScriptParser.unaryExpression_return retval = new JavaScriptParser.unaryExpression_return();
<         retval.start = input.LT(1);
<         int unaryExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.postfixExpression_return postfixExpression62 = null;
< 
<         JavaScriptParser.unaryOperator_return unaryOperator63 = null;
< 
<         JavaScriptParser.unaryExpression_return unaryExpression64 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 21) ) { return retval; }
<             // JavaScript.g:937:2: ( postfixExpression | unaryOperator unaryExpression )
<             int alt18=2;
<             int LA18_0 = input.LA(1);
< 
<             if ( ((LA18_0>=NULL && LA18_0<=FALSE)||LA18_0==FUNCTION||LA18_0==NEW||LA18_0==THIS||LA18_0==LBRACE||LA18_0==LPAREN||LA18_0==LBRACK||(LA18_0>=Identifier && LA18_0<=StringLiteral)||LA18_0==RegularExpressionLiteral||(LA18_0>=DecimalLiteral && LA18_0<=HexIntegerLiteral)) ) {
<                 alt18=1;
<             }
<             else if ( (LA18_0==DELETE||LA18_0==TYPEOF||LA18_0==VOID||(LA18_0>=ADD && LA18_0<=SUB)||(LA18_0>=INC && LA18_0<=DEC)||(LA18_0>=NOT && LA18_0<=INV)) ) {
<                 alt18=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 18, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt18) {
<                 case 1 :
<                     // JavaScript.g:937:4: postfixExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_postfixExpression_in_unaryExpression3592);
<                     postfixExpression62=postfixExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, postfixExpression62.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:938:4: unaryOperator unaryExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_unaryOperator_in_unaryExpression3597);
<                     unaryOperator63=unaryOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(unaryOperator63.getTree(), root_0);
<                     pushFollow(FOLLOW_unaryExpression_in_unaryExpression3600);
<                     unaryExpression64=unaryExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, unaryExpression64.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "unaryExpression"
< 
<     public static class unaryOperator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "unaryOperator"
<     // JavaScript.g:941:1: unaryOperator : ( DELETE | VOID | TYPEOF | INC | DEC | op= ADD | op= SUB | INV | NOT );
<     public final JavaScriptParser.unaryOperator_return unaryOperator() throws RecognitionException {
<         JavaScriptParser.unaryOperator_return retval = new JavaScriptParser.unaryOperator_return();
<         retval.start = input.LT(1);
<         int unaryOperator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token op=null;
<         Token DELETE65=null;
<         Token VOID66=null;
<         Token TYPEOF67=null;
<         Token INC68=null;
<         Token DEC69=null;
<         Token INV70=null;
<         Token NOT71=null;
< 
<         MyAstNode op_tree=null;
<         MyAstNode DELETE65_tree=null;
<         MyAstNode VOID66_tree=null;
<         MyAstNode TYPEOF67_tree=null;
<         MyAstNode INC68_tree=null;
<         MyAstNode DEC69_tree=null;
<         MyAstNode INV70_tree=null;
<         MyAstNode NOT71_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 22) ) { return retval; }
<             // JavaScript.g:942:2: ( DELETE | VOID | TYPEOF | INC | DEC | op= ADD | op= SUB | INV | NOT )
<             int alt19=9;
<             switch ( input.LA(1) ) {
<             case DELETE:
<                 {
<                 alt19=1;
<                 }
<                 break;
<             case VOID:
<                 {
<                 alt19=2;
<                 }
<                 break;
<             case TYPEOF:
<                 {
<                 alt19=3;
<                 }
<                 break;
<             case INC:
<                 {
<                 alt19=4;
<                 }
<                 break;
<             case DEC:
<                 {
<                 alt19=5;
<                 }
<                 break;
<             case ADD:
<                 {
<                 alt19=6;
<                 }
<                 break;
<             case SUB:
<                 {
<                 alt19=7;
<                 }
<                 break;
<             case INV:
<                 {
<                 alt19=8;
<                 }
<                 break;
<             case NOT:
<                 {
<                 alt19=9;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 19, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt19) {
<                 case 1 :
<                     // JavaScript.g:942:4: DELETE
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     DELETE65=(Token)match(input,DELETE,FOLLOW_DELETE_in_unaryOperator3612); 
<                     DELETE65_tree = (MyAstNode)adaptor.create(DELETE65);
<                     adaptor.addChild(root_0, DELETE65_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:943:4: VOID
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     VOID66=(Token)match(input,VOID,FOLLOW_VOID_in_unaryOperator3617); 
<                     VOID66_tree = (MyAstNode)adaptor.create(VOID66);
<                     adaptor.addChild(root_0, VOID66_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:944:4: TYPEOF
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     TYPEOF67=(Token)match(input,TYPEOF,FOLLOW_TYPEOF_in_unaryOperator3622); 
<                     TYPEOF67_tree = (MyAstNode)adaptor.create(TYPEOF67);
<                     adaptor.addChild(root_0, TYPEOF67_tree);
< 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:945:4: INC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     INC68=(Token)match(input,INC,FOLLOW_INC_in_unaryOperator3627); 
<                     INC68_tree = (MyAstNode)adaptor.create(INC68);
<                     adaptor.addChild(root_0, INC68_tree);
< 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:946:4: DEC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     DEC69=(Token)match(input,DEC,FOLLOW_DEC_in_unaryOperator3632); 
<                     DEC69_tree = (MyAstNode)adaptor.create(DEC69);
<                     adaptor.addChild(root_0, DEC69_tree);
< 
< 
<                     }
<                     break;
<                 case 6 :
<                     // JavaScript.g:947:4: op= ADD
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,ADD,FOLLOW_ADD_in_unaryOperator3639); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(POS); 
< 
<                     }
<                     break;
<                 case 7 :
<                     // JavaScript.g:948:4: op= SUB
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,SUB,FOLLOW_SUB_in_unaryOperator3648); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(NEG); 
< 
<                     }
<                     break;
<                 case 8 :
<                     // JavaScript.g:949:4: INV
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     INV70=(Token)match(input,INV,FOLLOW_INV_in_unaryOperator3655); 
<                     INV70_tree = (MyAstNode)adaptor.create(INV70);
<                     adaptor.addChild(root_0, INV70_tree);
< 
< 
<                     }
<                     break;
<                 case 9 :
<                     // JavaScript.g:950:4: NOT
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NOT71=(Token)match(input,NOT,FOLLOW_NOT_in_unaryOperator3660); 
<                     NOT71_tree = (MyAstNode)adaptor.create(NOT71);
<                     adaptor.addChild(root_0, NOT71_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "unaryOperator"
< 
<     public static class multiplicativeExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "multiplicativeExpression"
<     // JavaScript.g:957:1: multiplicativeExpression : unaryExpression ( ( MUL | DIV | MOD ) unaryExpression )* ;
<     public final JavaScriptParser.multiplicativeExpression_return multiplicativeExpression() throws RecognitionException {
<         JavaScriptParser.multiplicativeExpression_return retval = new JavaScriptParser.multiplicativeExpression_return();
<         retval.start = input.LT(1);
<         int multiplicativeExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set73=null;
<         JavaScriptParser.unaryExpression_return unaryExpression72 = null;
< 
<         JavaScriptParser.unaryExpression_return unaryExpression74 = null;
< 
< 
<         MyAstNode set73_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 23) ) { return retval; }
<             // JavaScript.g:958:2: ( unaryExpression ( ( MUL | DIV | MOD ) unaryExpression )* )
<             // JavaScript.g:958:4: unaryExpression ( ( MUL | DIV | MOD ) unaryExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_unaryExpression_in_multiplicativeExpression3675);
<             unaryExpression72=unaryExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, unaryExpression72.getTree());
<             // JavaScript.g:958:20: ( ( MUL | DIV | MOD ) unaryExpression )*
<             loop20:
<             do {
<                 int alt20=2;
<                 int LA20_0 = input.LA(1);
< 
<                 if ( ((LA20_0>=MUL && LA20_0<=MOD)||LA20_0==DIV) ) {
<                     alt20=1;
<                 }
< 
< 
<                 switch (alt20) {
<             	case 1 :
<             	    // JavaScript.g:958:22: ( MUL | DIV | MOD ) unaryExpression
<             	    {
<             	    set73=(Token)input.LT(1);
<             	    set73=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=MUL && input.LA(1)<=MOD)||input.LA(1)==DIV ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set73), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_unaryExpression_in_multiplicativeExpression3694);
<             	    unaryExpression74=unaryExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, unaryExpression74.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop20;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "multiplicativeExpression"
< 
<     public static class additiveExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "additiveExpression"
<     // JavaScript.g:965:1: additiveExpression : multiplicativeExpression ( ( ADD | SUB ) multiplicativeExpression )* ;
<     public final JavaScriptParser.additiveExpression_return additiveExpression() throws RecognitionException {
<         JavaScriptParser.additiveExpression_return retval = new JavaScriptParser.additiveExpression_return();
<         retval.start = input.LT(1);
<         int additiveExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set76=null;
<         JavaScriptParser.multiplicativeExpression_return multiplicativeExpression75 = null;
< 
<         JavaScriptParser.multiplicativeExpression_return multiplicativeExpression77 = null;
< 
< 
<         MyAstNode set76_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 24) ) { return retval; }
<             // JavaScript.g:966:2: ( multiplicativeExpression ( ( ADD | SUB ) multiplicativeExpression )* )
<             // JavaScript.g:966:4: multiplicativeExpression ( ( ADD | SUB ) multiplicativeExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_multiplicativeExpression_in_additiveExpression3712);
<             multiplicativeExpression75=multiplicativeExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, multiplicativeExpression75.getTree());
<             // JavaScript.g:966:29: ( ( ADD | SUB ) multiplicativeExpression )*
<             loop21:
<             do {
<                 int alt21=2;
<                 int LA21_0 = input.LA(1);
< 
<                 if ( ((LA21_0>=ADD && LA21_0<=SUB)) ) {
<                     alt21=1;
<                 }
< 
< 
<                 switch (alt21) {
<             	case 1 :
<             	    // JavaScript.g:966:31: ( ADD | SUB ) multiplicativeExpression
<             	    {
<             	    set76=(Token)input.LT(1);
<             	    set76=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=ADD && input.LA(1)<=SUB) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set76), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_multiplicativeExpression_in_additiveExpression3727);
<             	    multiplicativeExpression77=multiplicativeExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, multiplicativeExpression77.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop21;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "additiveExpression"
< 
<     public static class shiftExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "shiftExpression"
<     // JavaScript.g:973:1: shiftExpression : additiveExpression ( ( SHL | SHR | SHU ) additiveExpression )* ;
<     public final JavaScriptParser.shiftExpression_return shiftExpression() throws RecognitionException {
<         JavaScriptParser.shiftExpression_return retval = new JavaScriptParser.shiftExpression_return();
<         retval.start = input.LT(1);
<         int shiftExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set79=null;
<         JavaScriptParser.additiveExpression_return additiveExpression78 = null;
< 
<         JavaScriptParser.additiveExpression_return additiveExpression80 = null;
< 
< 
<         MyAstNode set79_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 25) ) { return retval; }
<             // JavaScript.g:974:2: ( additiveExpression ( ( SHL | SHR | SHU ) additiveExpression )* )
<             // JavaScript.g:974:4: additiveExpression ( ( SHL | SHR | SHU ) additiveExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_additiveExpression_in_shiftExpression3746);
<             additiveExpression78=additiveExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, additiveExpression78.getTree());
<             // JavaScript.g:974:23: ( ( SHL | SHR | SHU ) additiveExpression )*
<             loop22:
<             do {
<                 int alt22=2;
<                 int LA22_0 = input.LA(1);
< 
<                 if ( ((LA22_0>=SHL && LA22_0<=SHU)) ) {
<                     alt22=1;
<                 }
< 
< 
<                 switch (alt22) {
<             	case 1 :
<             	    // JavaScript.g:974:25: ( SHL | SHR | SHU ) additiveExpression
<             	    {
<             	    set79=(Token)input.LT(1);
<             	    set79=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=SHL && input.LA(1)<=SHU) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set79), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_additiveExpression_in_shiftExpression3765);
<             	    additiveExpression80=additiveExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, additiveExpression80.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop22;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "shiftExpression"
< 
<     public static class relationalExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "relationalExpression"
<     // JavaScript.g:981:1: relationalExpression : shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )* ;
<     public final JavaScriptParser.relationalExpression_return relationalExpression() throws RecognitionException {
<         JavaScriptParser.relationalExpression_return retval = new JavaScriptParser.relationalExpression_return();
<         retval.start = input.LT(1);
<         int relationalExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set82=null;
<         JavaScriptParser.shiftExpression_return shiftExpression81 = null;
< 
<         JavaScriptParser.shiftExpression_return shiftExpression83 = null;
< 
< 
<         MyAstNode set82_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 26) ) { return retval; }
<             // JavaScript.g:982:2: ( shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )* )
<             // JavaScript.g:982:4: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_shiftExpression_in_relationalExpression3784);
<             shiftExpression81=shiftExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, shiftExpression81.getTree());
<             // JavaScript.g:982:20: ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )*
<             loop23:
<             do {
<                 int alt23=2;
<                 int LA23_0 = input.LA(1);
< 
<                 if ( ((LA23_0>=IN && LA23_0<=INSTANCEOF)||(LA23_0>=LT && LA23_0<=GTE)) ) {
<                     alt23=1;
<                 }
< 
< 
<                 switch (alt23) {
<             	case 1 :
<             	    // JavaScript.g:982:22: ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression
<             	    {
<             	    set82=(Token)input.LT(1);
<             	    set82=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=IN && input.LA(1)<=INSTANCEOF)||(input.LA(1)>=LT && input.LA(1)<=GTE) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set82), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_shiftExpression_in_relationalExpression3815);
<             	    shiftExpression83=shiftExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, shiftExpression83.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop23;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "relationalExpression"
< 
<     public static class relationalExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "relationalExpressionNoIn"
<     // JavaScript.g:985:1: relationalExpressionNoIn : shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )* ;
<     public final JavaScriptParser.relationalExpressionNoIn_return relationalExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.relationalExpressionNoIn_return retval = new JavaScriptParser.relationalExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int relationalExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set85=null;
<         JavaScriptParser.shiftExpression_return shiftExpression84 = null;
< 
<         JavaScriptParser.shiftExpression_return shiftExpression86 = null;
< 
< 
<         MyAstNode set85_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 27) ) { return retval; }
<             // JavaScript.g:986:2: ( shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )* )
<             // JavaScript.g:986:4: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_shiftExpression_in_relationalExpressionNoIn3829);
<             shiftExpression84=shiftExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, shiftExpression84.getTree());
<             // JavaScript.g:986:20: ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )*
<             loop24:
<             do {
<                 int alt24=2;
<                 int LA24_0 = input.LA(1);
< 
<                 if ( (LA24_0==INSTANCEOF||(LA24_0>=LT && LA24_0<=GTE)) ) {
<                     alt24=1;
<                 }
< 
< 
<                 switch (alt24) {
<             	case 1 :
<             	    // JavaScript.g:986:22: ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression
<             	    {
<             	    set85=(Token)input.LT(1);
<             	    set85=(Token)input.LT(1);
<             	    if ( input.LA(1)==INSTANCEOF||(input.LA(1)>=LT && input.LA(1)<=GTE) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set85), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_shiftExpression_in_relationalExpressionNoIn3856);
<             	    shiftExpression86=shiftExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, shiftExpression86.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop24;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "relationalExpressionNoIn"
< 
<     public static class equalityExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "equalityExpression"
<     // JavaScript.g:993:1: equalityExpression : relationalExpression ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )* ;
<     public final JavaScriptParser.equalityExpression_return equalityExpression() throws RecognitionException {
<         JavaScriptParser.equalityExpression_return retval = new JavaScriptParser.equalityExpression_return();
<         retval.start = input.LT(1);
<         int equalityExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set88=null;
<         JavaScriptParser.relationalExpression_return relationalExpression87 = null;
< 
<         JavaScriptParser.relationalExpression_return relationalExpression89 = null;
< 
< 
<         MyAstNode set88_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 28) ) { return retval; }
<             // JavaScript.g:994:2: ( relationalExpression ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )* )
<             // JavaScript.g:994:4: relationalExpression ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_relationalExpression_in_equalityExpression3875);
<             relationalExpression87=relationalExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, relationalExpression87.getTree());
<             // JavaScript.g:994:25: ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )*
<             loop25:
<             do {
<                 int alt25=2;
<                 int LA25_0 = input.LA(1);
< 
<                 if ( ((LA25_0>=EQ && LA25_0<=NSAME)) ) {
<                     alt25=1;
<                 }
< 
< 
<                 switch (alt25) {
<             	case 1 :
<             	    // JavaScript.g:994:27: ( EQ | NEQ | SAME | NSAME ) relationalExpression
<             	    {
<             	    set88=(Token)input.LT(1);
<             	    set88=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=EQ && input.LA(1)<=NSAME) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set88), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_relationalExpression_in_equalityExpression3898);
<             	    relationalExpression89=relationalExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, relationalExpression89.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop25;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "equalityExpression"
< 
<     public static class equalityExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "equalityExpressionNoIn"
<     // JavaScript.g:997:1: equalityExpressionNoIn : relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )* ;
<     public final JavaScriptParser.equalityExpressionNoIn_return equalityExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.equalityExpressionNoIn_return retval = new JavaScriptParser.equalityExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int equalityExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set91=null;
<         JavaScriptParser.relationalExpressionNoIn_return relationalExpressionNoIn90 = null;
< 
<         JavaScriptParser.relationalExpressionNoIn_return relationalExpressionNoIn92 = null;
< 
< 
<         MyAstNode set91_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 29) ) { return retval; }
<             // JavaScript.g:998:2: ( relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )* )
<             // JavaScript.g:998:4: relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3912);
<             relationalExpressionNoIn90=relationalExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, relationalExpressionNoIn90.getTree());
<             // JavaScript.g:998:29: ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )*
<             loop26:
<             do {
<                 int alt26=2;
<                 int LA26_0 = input.LA(1);
< 
<                 if ( ((LA26_0>=EQ && LA26_0<=NSAME)) ) {
<                     alt26=1;
<                 }
< 
< 
<                 switch (alt26) {
<             	case 1 :
<             	    // JavaScript.g:998:31: ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn
<             	    {
<             	    set91=(Token)input.LT(1);
<             	    set91=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=EQ && input.LA(1)<=NSAME) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set91), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3935);
<             	    relationalExpressionNoIn92=relationalExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, relationalExpressionNoIn92.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop26;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "equalityExpressionNoIn"
< 
<     public static class bitwiseANDExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseANDExpression"
<     // JavaScript.g:1005:1: bitwiseANDExpression : equalityExpression ( AND equalityExpression )* ;
<     public final JavaScriptParser.bitwiseANDExpression_return bitwiseANDExpression() throws RecognitionException {
<         JavaScriptParser.bitwiseANDExpression_return retval = new JavaScriptParser.bitwiseANDExpression_return();
<         retval.start = input.LT(1);
<         int bitwiseANDExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token AND94=null;
<         JavaScriptParser.equalityExpression_return equalityExpression93 = null;
< 
<         JavaScriptParser.equalityExpression_return equalityExpression95 = null;
< 
< 
<         MyAstNode AND94_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 30) ) { return retval; }
<             // JavaScript.g:1006:2: ( equalityExpression ( AND equalityExpression )* )
<             // JavaScript.g:1006:4: equalityExpression ( AND equalityExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_equalityExpression_in_bitwiseANDExpression3955);
<             equalityExpression93=equalityExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, equalityExpression93.getTree());
<             // JavaScript.g:1006:23: ( AND equalityExpression )*
<             loop27:
<             do {
<                 int alt27=2;
<                 int LA27_0 = input.LA(1);
< 
<                 if ( (LA27_0==AND) ) {
<                     alt27=1;
<                 }
< 
< 
<                 switch (alt27) {
<             	case 1 :
<             	    // JavaScript.g:1006:25: AND equalityExpression
<             	    {
<             	    AND94=(Token)match(input,AND,FOLLOW_AND_in_bitwiseANDExpression3959); 
<             	    AND94_tree = (MyAstNode)adaptor.create(AND94);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(AND94_tree, root_0);
< 
<             	    pushFollow(FOLLOW_equalityExpression_in_bitwiseANDExpression3962);
<             	    equalityExpression95=equalityExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, equalityExpression95.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop27;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseANDExpression"
< 
<     public static class bitwiseANDExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseANDExpressionNoIn"
<     // JavaScript.g:1009:1: bitwiseANDExpressionNoIn : equalityExpressionNoIn ( AND equalityExpressionNoIn )* ;
<     public final JavaScriptParser.bitwiseANDExpressionNoIn_return bitwiseANDExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.bitwiseANDExpressionNoIn_return retval = new JavaScriptParser.bitwiseANDExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int bitwiseANDExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token AND97=null;
<         JavaScriptParser.equalityExpressionNoIn_return equalityExpressionNoIn96 = null;
< 
<         JavaScriptParser.equalityExpressionNoIn_return equalityExpressionNoIn98 = null;
< 
< 
<         MyAstNode AND97_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 31) ) { return retval; }
<             // JavaScript.g:1010:2: ( equalityExpressionNoIn ( AND equalityExpressionNoIn )* )
<             // JavaScript.g:1010:4: equalityExpressionNoIn ( AND equalityExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3976);
<             equalityExpressionNoIn96=equalityExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, equalityExpressionNoIn96.getTree());
<             // JavaScript.g:1010:27: ( AND equalityExpressionNoIn )*
<             loop28:
<             do {
<                 int alt28=2;
<                 int LA28_0 = input.LA(1);
< 
<                 if ( (LA28_0==AND) ) {
<                     alt28=1;
<                 }
< 
< 
<                 switch (alt28) {
<             	case 1 :
<             	    // JavaScript.g:1010:29: AND equalityExpressionNoIn
<             	    {
<             	    AND97=(Token)match(input,AND,FOLLOW_AND_in_bitwiseANDExpressionNoIn3980); 
<             	    AND97_tree = (MyAstNode)adaptor.create(AND97);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(AND97_tree, root_0);
< 
<             	    pushFollow(FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3983);
<             	    equalityExpressionNoIn98=equalityExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, equalityExpressionNoIn98.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop28;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseANDExpressionNoIn"
< 
<     public static class bitwiseXORExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseXORExpression"
<     // JavaScript.g:1013:1: bitwiseXORExpression : bitwiseANDExpression ( XOR bitwiseANDExpression )* ;
<     public final JavaScriptParser.bitwiseXORExpression_return bitwiseXORExpression() throws RecognitionException {
<         JavaScriptParser.bitwiseXORExpression_return retval = new JavaScriptParser.bitwiseXORExpression_return();
<         retval.start = input.LT(1);
<         int bitwiseXORExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token XOR100=null;
<         JavaScriptParser.bitwiseANDExpression_return bitwiseANDExpression99 = null;
< 
<         JavaScriptParser.bitwiseANDExpression_return bitwiseANDExpression101 = null;
< 
< 
<         MyAstNode XOR100_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 32) ) { return retval; }
<             // JavaScript.g:1014:2: ( bitwiseANDExpression ( XOR bitwiseANDExpression )* )
<             // JavaScript.g:1014:4: bitwiseANDExpression ( XOR bitwiseANDExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression3999);
<             bitwiseANDExpression99=bitwiseANDExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseANDExpression99.getTree());
<             // JavaScript.g:1014:25: ( XOR bitwiseANDExpression )*
<             loop29:
<             do {
<                 int alt29=2;
<                 int LA29_0 = input.LA(1);
< 
<                 if ( (LA29_0==XOR) ) {
<                     alt29=1;
<                 }
< 
< 
<                 switch (alt29) {
<             	case 1 :
<             	    // JavaScript.g:1014:27: XOR bitwiseANDExpression
<             	    {
<             	    XOR100=(Token)match(input,XOR,FOLLOW_XOR_in_bitwiseXORExpression4003); 
<             	    XOR100_tree = (MyAstNode)adaptor.create(XOR100);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(XOR100_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression4006);
<             	    bitwiseANDExpression101=bitwiseANDExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseANDExpression101.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop29;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseXORExpression"
< 
<     public static class bitwiseXORExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseXORExpressionNoIn"
<     // JavaScript.g:1017:1: bitwiseXORExpressionNoIn : bitwiseANDExpressionNoIn ( XOR bitwiseANDExpressionNoIn )* ;
<     public final JavaScriptParser.bitwiseXORExpressionNoIn_return bitwiseXORExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.bitwiseXORExpressionNoIn_return retval = new JavaScriptParser.bitwiseXORExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int bitwiseXORExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token XOR103=null;
<         JavaScriptParser.bitwiseANDExpressionNoIn_return bitwiseANDExpressionNoIn102 = null;
< 
<         JavaScriptParser.bitwiseANDExpressionNoIn_return bitwiseANDExpressionNoIn104 = null;
< 
< 
<         MyAstNode XOR103_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 33) ) { return retval; }
<             // JavaScript.g:1018:2: ( bitwiseANDExpressionNoIn ( XOR bitwiseANDExpressionNoIn )* )
<             // JavaScript.g:1018:4: bitwiseANDExpressionNoIn ( XOR bitwiseANDExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4022);
<             bitwiseANDExpressionNoIn102=bitwiseANDExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseANDExpressionNoIn102.getTree());
<             // JavaScript.g:1018:29: ( XOR bitwiseANDExpressionNoIn )*
<             loop30:
<             do {
<                 int alt30=2;
<                 int LA30_0 = input.LA(1);
< 
<                 if ( (LA30_0==XOR) ) {
<                     alt30=1;
<                 }
< 
< 
<                 switch (alt30) {
<             	case 1 :
<             	    // JavaScript.g:1018:31: XOR bitwiseANDExpressionNoIn
<             	    {
<             	    XOR103=(Token)match(input,XOR,FOLLOW_XOR_in_bitwiseXORExpressionNoIn4026); 
<             	    XOR103_tree = (MyAstNode)adaptor.create(XOR103);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(XOR103_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4029);
<             	    bitwiseANDExpressionNoIn104=bitwiseANDExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseANDExpressionNoIn104.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop30;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseXORExpressionNoIn"
< 
<     public static class bitwiseORExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseORExpression"
<     // JavaScript.g:1021:1: bitwiseORExpression : bitwiseXORExpression ( OR bitwiseXORExpression )* ;
<     public final JavaScriptParser.bitwiseORExpression_return bitwiseORExpression() throws RecognitionException {
<         JavaScriptParser.bitwiseORExpression_return retval = new JavaScriptParser.bitwiseORExpression_return();
<         retval.start = input.LT(1);
<         int bitwiseORExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token OR106=null;
<         JavaScriptParser.bitwiseXORExpression_return bitwiseXORExpression105 = null;
< 
<         JavaScriptParser.bitwiseXORExpression_return bitwiseXORExpression107 = null;
< 
< 
<         MyAstNode OR106_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 34) ) { return retval; }
<             // JavaScript.g:1022:2: ( bitwiseXORExpression ( OR bitwiseXORExpression )* )
<             // JavaScript.g:1022:4: bitwiseXORExpression ( OR bitwiseXORExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4044);
<             bitwiseXORExpression105=bitwiseXORExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseXORExpression105.getTree());
<             // JavaScript.g:1022:25: ( OR bitwiseXORExpression )*
<             loop31:
<             do {
<                 int alt31=2;
<                 int LA31_0 = input.LA(1);
< 
<                 if ( (LA31_0==OR) ) {
<                     alt31=1;
<                 }
< 
< 
<                 switch (alt31) {
<             	case 1 :
<             	    // JavaScript.g:1022:27: OR bitwiseXORExpression
<             	    {
<             	    OR106=(Token)match(input,OR,FOLLOW_OR_in_bitwiseORExpression4048); 
<             	    OR106_tree = (MyAstNode)adaptor.create(OR106);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(OR106_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4051);
<             	    bitwiseXORExpression107=bitwiseXORExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseXORExpression107.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop31;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseORExpression"
< 
<     public static class bitwiseORExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseORExpressionNoIn"
<     // JavaScript.g:1025:1: bitwiseORExpressionNoIn : bitwiseXORExpressionNoIn ( OR bitwiseXORExpressionNoIn )* ;
<     public final JavaScriptParser.bitwiseORExpressionNoIn_return bitwiseORExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.bitwiseORExpressionNoIn_return retval = new JavaScriptParser.bitwiseORExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int bitwiseORExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token OR109=null;
<         JavaScriptParser.bitwiseXORExpressionNoIn_return bitwiseXORExpressionNoIn108 = null;
< 
<         JavaScriptParser.bitwiseXORExpressionNoIn_return bitwiseXORExpressionNoIn110 = null;
< 
< 
<         MyAstNode OR109_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 35) ) { return retval; }
<             // JavaScript.g:1026:2: ( bitwiseXORExpressionNoIn ( OR bitwiseXORExpressionNoIn )* )
<             // JavaScript.g:1026:4: bitwiseXORExpressionNoIn ( OR bitwiseXORExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4066);
<             bitwiseXORExpressionNoIn108=bitwiseXORExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseXORExpressionNoIn108.getTree());
<             // JavaScript.g:1026:29: ( OR bitwiseXORExpressionNoIn )*
<             loop32:
<             do {
<                 int alt32=2;
<                 int LA32_0 = input.LA(1);
< 
<                 if ( (LA32_0==OR) ) {
<                     alt32=1;
<                 }
< 
< 
<                 switch (alt32) {
<             	case 1 :
<             	    // JavaScript.g:1026:31: OR bitwiseXORExpressionNoIn
<             	    {
<             	    OR109=(Token)match(input,OR,FOLLOW_OR_in_bitwiseORExpressionNoIn4070); 
<             	    OR109_tree = (MyAstNode)adaptor.create(OR109);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(OR109_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4073);
<             	    bitwiseXORExpressionNoIn110=bitwiseXORExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseXORExpressionNoIn110.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop32;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseORExpressionNoIn"
< 
<     public static class logicalANDExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalANDExpression"
<     // JavaScript.g:1033:1: logicalANDExpression : bitwiseORExpression ( LAND bitwiseORExpression )* ;
<     public final JavaScriptParser.logicalANDExpression_return logicalANDExpression() throws RecognitionException {
<         JavaScriptParser.logicalANDExpression_return retval = new JavaScriptParser.logicalANDExpression_return();
<         retval.start = input.LT(1);
<         int logicalANDExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LAND112=null;
<         JavaScriptParser.bitwiseORExpression_return bitwiseORExpression111 = null;
< 
<         JavaScriptParser.bitwiseORExpression_return bitwiseORExpression113 = null;
< 
< 
<         MyAstNode LAND112_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 36) ) { return retval; }
<             // JavaScript.g:1034:2: ( bitwiseORExpression ( LAND bitwiseORExpression )* )
<             // JavaScript.g:1034:4: bitwiseORExpression ( LAND bitwiseORExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseORExpression_in_logicalANDExpression4092);
<             bitwiseORExpression111=bitwiseORExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseORExpression111.getTree());
<             // JavaScript.g:1034:24: ( LAND bitwiseORExpression )*
<             loop33:
<             do {
<                 int alt33=2;
<                 int LA33_0 = input.LA(1);
< 
<                 if ( (LA33_0==LAND) ) {
<                     alt33=1;
<                 }
< 
< 
<                 switch (alt33) {
<             	case 1 :
<             	    // JavaScript.g:1034:26: LAND bitwiseORExpression
<             	    {
<             	    LAND112=(Token)match(input,LAND,FOLLOW_LAND_in_logicalANDExpression4096); 
<             	    LAND112_tree = (MyAstNode)adaptor.create(LAND112);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LAND112_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseORExpression_in_logicalANDExpression4099);
<             	    bitwiseORExpression113=bitwiseORExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseORExpression113.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop33;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalANDExpression"
< 
<     public static class logicalANDExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalANDExpressionNoIn"
<     // JavaScript.g:1037:1: logicalANDExpressionNoIn : bitwiseORExpressionNoIn ( LAND bitwiseORExpressionNoIn )* ;
<     public final JavaScriptParser.logicalANDExpressionNoIn_return logicalANDExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.logicalANDExpressionNoIn_return retval = new JavaScriptParser.logicalANDExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int logicalANDExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LAND115=null;
<         JavaScriptParser.bitwiseORExpressionNoIn_return bitwiseORExpressionNoIn114 = null;
< 
<         JavaScriptParser.bitwiseORExpressionNoIn_return bitwiseORExpressionNoIn116 = null;
< 
< 
<         MyAstNode LAND115_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 37) ) { return retval; }
<             // JavaScript.g:1038:2: ( bitwiseORExpressionNoIn ( LAND bitwiseORExpressionNoIn )* )
<             // JavaScript.g:1038:4: bitwiseORExpressionNoIn ( LAND bitwiseORExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4113);
<             bitwiseORExpressionNoIn114=bitwiseORExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseORExpressionNoIn114.getTree());
<             // JavaScript.g:1038:28: ( LAND bitwiseORExpressionNoIn )*
<             loop34:
<             do {
<                 int alt34=2;
<                 int LA34_0 = input.LA(1);
< 
<                 if ( (LA34_0==LAND) ) {
<                     alt34=1;
<                 }
< 
< 
<                 switch (alt34) {
<             	case 1 :
<             	    // JavaScript.g:1038:30: LAND bitwiseORExpressionNoIn
<             	    {
<             	    LAND115=(Token)match(input,LAND,FOLLOW_LAND_in_logicalANDExpressionNoIn4117); 
<             	    LAND115_tree = (MyAstNode)adaptor.create(LAND115);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LAND115_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4120);
<             	    bitwiseORExpressionNoIn116=bitwiseORExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseORExpressionNoIn116.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop34;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalANDExpressionNoIn"
< 
<     public static class logicalORExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalORExpression"
<     // JavaScript.g:1041:1: logicalORExpression : logicalANDExpression ( LOR logicalANDExpression )* ;
<     public final JavaScriptParser.logicalORExpression_return logicalORExpression() throws RecognitionException {
<         JavaScriptParser.logicalORExpression_return retval = new JavaScriptParser.logicalORExpression_return();
<         retval.start = input.LT(1);
<         int logicalORExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LOR118=null;
<         JavaScriptParser.logicalANDExpression_return logicalANDExpression117 = null;
< 
<         JavaScriptParser.logicalANDExpression_return logicalANDExpression119 = null;
< 
< 
<         MyAstNode LOR118_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 38) ) { return retval; }
<             // JavaScript.g:1042:2: ( logicalANDExpression ( LOR logicalANDExpression )* )
<             // JavaScript.g:1042:4: logicalANDExpression ( LOR logicalANDExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalANDExpression_in_logicalORExpression4135);
<             logicalANDExpression117=logicalANDExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalANDExpression117.getTree());
<             // JavaScript.g:1042:25: ( LOR logicalANDExpression )*
<             loop35:
<             do {
<                 int alt35=2;
<                 int LA35_0 = input.LA(1);
< 
<                 if ( (LA35_0==LOR) ) {
<                     alt35=1;
<                 }
< 
< 
<                 switch (alt35) {
<             	case 1 :
<             	    // JavaScript.g:1042:27: LOR logicalANDExpression
<             	    {
<             	    LOR118=(Token)match(input,LOR,FOLLOW_LOR_in_logicalORExpression4139); 
<             	    LOR118_tree = (MyAstNode)adaptor.create(LOR118);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LOR118_tree, root_0);
< 
<             	    pushFollow(FOLLOW_logicalANDExpression_in_logicalORExpression4142);
<             	    logicalANDExpression119=logicalANDExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, logicalANDExpression119.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop35;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalORExpression"
< 
<     public static class logicalORExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalORExpressionNoIn"
<     // JavaScript.g:1045:1: logicalORExpressionNoIn : logicalANDExpressionNoIn ( LOR logicalANDExpressionNoIn )* ;
<     public final JavaScriptParser.logicalORExpressionNoIn_return logicalORExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.logicalORExpressionNoIn_return retval = new JavaScriptParser.logicalORExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int logicalORExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LOR121=null;
<         JavaScriptParser.logicalANDExpressionNoIn_return logicalANDExpressionNoIn120 = null;
< 
<         JavaScriptParser.logicalANDExpressionNoIn_return logicalANDExpressionNoIn122 = null;
< 
< 
<         MyAstNode LOR121_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 39) ) { return retval; }
<             // JavaScript.g:1046:2: ( logicalANDExpressionNoIn ( LOR logicalANDExpressionNoIn )* )
<             // JavaScript.g:1046:4: logicalANDExpressionNoIn ( LOR logicalANDExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4157);
<             logicalANDExpressionNoIn120=logicalANDExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalANDExpressionNoIn120.getTree());
<             // JavaScript.g:1046:29: ( LOR logicalANDExpressionNoIn )*
<             loop36:
<             do {
<                 int alt36=2;
<                 int LA36_0 = input.LA(1);
< 
<                 if ( (LA36_0==LOR) ) {
<                     alt36=1;
<                 }
< 
< 
<                 switch (alt36) {
<             	case 1 :
<             	    // JavaScript.g:1046:31: LOR logicalANDExpressionNoIn
<             	    {
<             	    LOR121=(Token)match(input,LOR,FOLLOW_LOR_in_logicalORExpressionNoIn4161); 
<             	    LOR121_tree = (MyAstNode)adaptor.create(LOR121);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LOR121_tree, root_0);
< 
<             	    pushFollow(FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4164);
<             	    logicalANDExpressionNoIn122=logicalANDExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, logicalANDExpressionNoIn122.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop36;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalORExpressionNoIn"
< 
<     public static class conditionalExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "conditionalExpression"
<     // JavaScript.g:1053:1: conditionalExpression : logicalORExpression ( QUE assignmentExpression COLON assignmentExpression )? ;
<     public final JavaScriptParser.conditionalExpression_return conditionalExpression() throws RecognitionException {
<         JavaScriptParser.conditionalExpression_return retval = new JavaScriptParser.conditionalExpression_return();
<         retval.start = input.LT(1);
<         int conditionalExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token QUE124=null;
<         Token COLON126=null;
<         JavaScriptParser.logicalORExpression_return logicalORExpression123 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression125 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression127 = null;
< 
< 
<         MyAstNode QUE124_tree=null;
<         MyAstNode COLON126_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 40) ) { return retval; }
<             // JavaScript.g:1054:2: ( logicalORExpression ( QUE assignmentExpression COLON assignmentExpression )? )
<             // JavaScript.g:1054:4: logicalORExpression ( QUE assignmentExpression COLON assignmentExpression )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalORExpression_in_conditionalExpression4183);
<             logicalORExpression123=logicalORExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalORExpression123.getTree());
<             // JavaScript.g:1054:24: ( QUE assignmentExpression COLON assignmentExpression )?
<             int alt37=2;
<             int LA37_0 = input.LA(1);
< 
<             if ( (LA37_0==QUE) ) {
<                 alt37=1;
<             }
<             switch (alt37) {
<                 case 1 :
<                     // JavaScript.g:1054:26: QUE assignmentExpression COLON assignmentExpression
<                     {
<                     QUE124=(Token)match(input,QUE,FOLLOW_QUE_in_conditionalExpression4187); 
<                     QUE124_tree = (MyAstNode)adaptor.create(QUE124);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(QUE124_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpression_in_conditionalExpression4190);
<                     assignmentExpression125=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression125.getTree());
<                     COLON126=(Token)match(input,COLON,FOLLOW_COLON_in_conditionalExpression4192); 
<                     pushFollow(FOLLOW_assignmentExpression_in_conditionalExpression4195);
<                     assignmentExpression127=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression127.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "conditionalExpression"
< 
<     public static class conditionalExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "conditionalExpressionNoIn"
<     // JavaScript.g:1057:1: conditionalExpressionNoIn : logicalORExpressionNoIn ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )? ;
<     public final JavaScriptParser.conditionalExpressionNoIn_return conditionalExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.conditionalExpressionNoIn_return retval = new JavaScriptParser.conditionalExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int conditionalExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token QUE129=null;
<         Token COLON131=null;
<         JavaScriptParser.logicalORExpressionNoIn_return logicalORExpressionNoIn128 = null;
< 
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn130 = null;
< 
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn132 = null;
< 
< 
<         MyAstNode QUE129_tree=null;
<         MyAstNode COLON131_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 41) ) { return retval; }
<             // JavaScript.g:1058:2: ( logicalORExpressionNoIn ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )? )
<             // JavaScript.g:1058:4: logicalORExpressionNoIn ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalORExpressionNoIn_in_conditionalExpressionNoIn4209);
<             logicalORExpressionNoIn128=logicalORExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalORExpressionNoIn128.getTree());
<             // JavaScript.g:1058:28: ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )?
<             int alt38=2;
<             int LA38_0 = input.LA(1);
< 
<             if ( (LA38_0==QUE) ) {
<                 alt38=1;
<             }
<             switch (alt38) {
<                 case 1 :
<                     // JavaScript.g:1058:30: QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn
<                     {
<                     QUE129=(Token)match(input,QUE,FOLLOW_QUE_in_conditionalExpressionNoIn4213); 
<                     QUE129_tree = (MyAstNode)adaptor.create(QUE129);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(QUE129_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4216);
<                     assignmentExpressionNoIn130=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn130.getTree());
<                     COLON131=(Token)match(input,COLON,FOLLOW_COLON_in_conditionalExpressionNoIn4218); 
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4221);
<                     assignmentExpressionNoIn132=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn132.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "conditionalExpressionNoIn"
< 
<     public static class assignmentExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "assignmentExpression"
<     // JavaScript.g:1087:1: assignmentExpression : lhs= conditionalExpression ({...}? assignmentOperator assignmentExpression )? ;
<     public final JavaScriptParser.assignmentExpression_return assignmentExpression() throws RecognitionException {
<         JavaScriptParser.assignmentExpression_return retval = new JavaScriptParser.assignmentExpression_return();
<         retval.start = input.LT(1);
<         int assignmentExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.conditionalExpression_return lhs = null;
< 
<         JavaScriptParser.assignmentOperator_return assignmentOperator133 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression134 = null;
< 
< 
< 
< 
<         	Object[] isLhs = new Object[1];
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 42) ) { return retval; }
<             // JavaScript.g:1092:2: (lhs= conditionalExpression ({...}? assignmentOperator assignmentExpression )? )
<             // JavaScript.g:1092:4: lhs= conditionalExpression ({...}? assignmentOperator assignmentExpression )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_conditionalExpression_in_assignmentExpression4249);
<             lhs=conditionalExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, lhs.getTree());
<             // JavaScript.g:1093:2: ({...}? assignmentOperator assignmentExpression )?
<             int alt39=2;
<             int LA39_0 = input.LA(1);
< 
<             if ( ((LA39_0>=ASSIGN && LA39_0<=XORASS)||LA39_0==DIVASS) ) {
<                 int LA39_1 = input.LA(2);
< 
<                 if ( (( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                     alt39=1;
<                 }
<             }
<             switch (alt39) {
<                 case 1 :
<                     // JavaScript.g:1093:4: {...}? assignmentOperator assignmentExpression
<                     {
<                     if ( !(( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                         throw new FailedPredicateException(input, "assignmentExpression", " isLeftHandSideAssign(lhs, isLhs) ");
<                     }
<                     pushFollow(FOLLOW_assignmentOperator_in_assignmentExpression4256);
<                     assignmentOperator133=assignmentOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(assignmentOperator133.getTree(), root_0);
<                     pushFollow(FOLLOW_assignmentExpression_in_assignmentExpression4259);
<                     assignmentExpression134=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression134.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "assignmentExpression"
< 
<     public static class assignmentOperator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "assignmentOperator"
<     // JavaScript.g:1096:1: assignmentOperator : ( ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS );
<     public final JavaScriptParser.assignmentOperator_return assignmentOperator() throws RecognitionException {
<         JavaScriptParser.assignmentOperator_return retval = new JavaScriptParser.assignmentOperator_return();
<         retval.start = input.LT(1);
<         int assignmentOperator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set135=null;
< 
<         MyAstNode set135_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 43) ) { return retval; }
<             // JavaScript.g:1097:2: ( ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set135=(Token)input.LT(1);
<             if ( (input.LA(1)>=ASSIGN && input.LA(1)<=XORASS)||input.LA(1)==DIVASS ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set135));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "assignmentOperator"
< 
<     public static class assignmentExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "assignmentExpressionNoIn"
<     // JavaScript.g:1100:1: assignmentExpressionNoIn : lhs= conditionalExpressionNoIn ({...}? assignmentOperator assignmentExpressionNoIn )? ;
<     public final JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.assignmentExpressionNoIn_return retval = new JavaScriptParser.assignmentExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int assignmentExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.conditionalExpressionNoIn_return lhs = null;
< 
<         JavaScriptParser.assignmentOperator_return assignmentOperator136 = null;
< 
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn137 = null;
< 
< 
< 
< 
<         	Object[] isLhs = new Object[1];
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 44) ) { return retval; }
<             // JavaScript.g:1105:2: (lhs= conditionalExpressionNoIn ({...}? assignmentOperator assignmentExpressionNoIn )? )
<             // JavaScript.g:1105:4: lhs= conditionalExpressionNoIn ({...}? assignmentOperator assignmentExpressionNoIn )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_conditionalExpressionNoIn_in_assignmentExpressionNoIn4336);
<             lhs=conditionalExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, lhs.getTree());
<             // JavaScript.g:1106:2: ({...}? assignmentOperator assignmentExpressionNoIn )?
<             int alt40=2;
<             int LA40_0 = input.LA(1);
< 
<             if ( ((LA40_0>=ASSIGN && LA40_0<=XORASS)||LA40_0==DIVASS) ) {
<                 int LA40_1 = input.LA(2);
< 
<                 if ( (( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                     alt40=1;
<                 }
<             }
<             switch (alt40) {
<                 case 1 :
<                     // JavaScript.g:1106:4: {...}? assignmentOperator assignmentExpressionNoIn
<                     {
<                     if ( !(( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                         throw new FailedPredicateException(input, "assignmentExpressionNoIn", " isLeftHandSideAssign(lhs, isLhs) ");
<                     }
<                     pushFollow(FOLLOW_assignmentOperator_in_assignmentExpressionNoIn4343);
<                     assignmentOperator136=assignmentOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(assignmentOperator136.getTree(), root_0);
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_assignmentExpressionNoIn4346);
<                     assignmentExpressionNoIn137=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn137.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "assignmentExpressionNoIn"
< 
<     public static class expression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "expression"
<     // JavaScript.g:1113:1: expression : exprs+= assignmentExpression ( COMMA exprs+= assignmentExpression )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs;
<     public final JavaScriptParser.expression_return expression() throws RecognitionException {
<         JavaScriptParser.expression_return retval = new JavaScriptParser.expression_return();
<         retval.start = input.LT(1);
<         int expression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token COMMA138=null;
<         List list_exprs=null;
<         RuleReturnScope exprs = null;
<         MyAstNode COMMA138_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 45) ) { return retval; }
<             // JavaScript.g:1114:2: (exprs+= assignmentExpression ( COMMA exprs+= assignmentExpression )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs)
<             // JavaScript.g:1114:4: exprs+= assignmentExpression ( COMMA exprs+= assignmentExpression )*
<             {
<             pushFollow(FOLLOW_assignmentExpression_in_expression4368);
<             exprs=assignmentExpression();
< 
<             state._fsp--;
< 
<             stream_assignmentExpression.add(exprs.getTree());
<             if (list_exprs==null) list_exprs=new ArrayList();
<             list_exprs.add(exprs.getTree());
< 
<             // JavaScript.g:1114:32: ( COMMA exprs+= assignmentExpression )*
<             loop41:
<             do {
<                 int alt41=2;
<                 int LA41_0 = input.LA(1);
< 
<                 if ( (LA41_0==COMMA) ) {
<                     alt41=1;
<                 }
< 
< 
<                 switch (alt41) {
<             	case 1 :
<             	    // JavaScript.g:1114:34: COMMA exprs+= assignmentExpression
<             	    {
<             	    COMMA138=(Token)match(input,COMMA,FOLLOW_COMMA_in_expression4372);  
<             	    stream_COMMA.add(COMMA138);
< 
<             	    pushFollow(FOLLOW_assignmentExpression_in_expression4376);
<             	    exprs=assignmentExpression();
< 
<             	    state._fsp--;
< 
<             	    stream_assignmentExpression.add(exprs.getTree());
<             	    if (list_exprs==null) list_exprs=new ArrayList();
<             	    list_exprs.add(exprs.getTree());
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop41;
<                 }
<             } while (true);
< 
< 
< 
<             // AST REWRITE
<             // elements: exprs, exprs
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: exprs
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<             RewriteRuleSubtreeStream stream_exprs=new RewriteRuleSubtreeStream(adaptor,"token exprs",list_exprs);
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1115:2: -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ )
<             if ( list_exprs.size() > 1 ) {
<                 // JavaScript.g:1115:28: ^( CEXPR ( $exprs)+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(CEXPR, "CEXPR"), root_1);
< 
<                 if ( !(stream_exprs.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_exprs.hasNext() ) {
<                     adaptor.addChild(root_1, stream_exprs.nextTree());
< 
<                 }
<                 stream_exprs.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
<             else // 1116:2: -> $exprs
<             {
<                 adaptor.addChild(root_0, stream_exprs.nextTree());
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "expression"
< 
<     public static class expressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "expressionNoIn"
<     // JavaScript.g:1119:1: expressionNoIn : exprs+= assignmentExpressionNoIn ( COMMA exprs+= assignmentExpressionNoIn )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs;
<     public final JavaScriptParser.expressionNoIn_return expressionNoIn() throws RecognitionException {
<         JavaScriptParser.expressionNoIn_return retval = new JavaScriptParser.expressionNoIn_return();
<         retval.start = input.LT(1);
<         int expressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token COMMA139=null;
<         List list_exprs=null;
<         RuleReturnScope exprs = null;
<         MyAstNode COMMA139_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleSubtreeStream stream_assignmentExpressionNoIn=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpressionNoIn");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 46) ) { return retval; }
<             // JavaScript.g:1120:2: (exprs+= assignmentExpressionNoIn ( COMMA exprs+= assignmentExpressionNoIn )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs)
<             // JavaScript.g:1120:4: exprs+= assignmentExpressionNoIn ( COMMA exprs+= assignmentExpressionNoIn )*
<             {
<             pushFollow(FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4413);
<             exprs=assignmentExpressionNoIn();
< 
<             state._fsp--;
< 
<             stream_assignmentExpressionNoIn.add(exprs.getTree());
<             if (list_exprs==null) list_exprs=new ArrayList();
<             list_exprs.add(exprs.getTree());
< 
<             // JavaScript.g:1120:36: ( COMMA exprs+= assignmentExpressionNoIn )*
<             loop42:
<             do {
<                 int alt42=2;
<                 int LA42_0 = input.LA(1);
< 
<                 if ( (LA42_0==COMMA) ) {
<                     alt42=1;
<                 }
< 
< 
<                 switch (alt42) {
<             	case 1 :
<             	    // JavaScript.g:1120:38: COMMA exprs+= assignmentExpressionNoIn
<             	    {
<             	    COMMA139=(Token)match(input,COMMA,FOLLOW_COMMA_in_expressionNoIn4417);  
<             	    stream_COMMA.add(COMMA139);
< 
<             	    pushFollow(FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4421);
<             	    exprs=assignmentExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    stream_assignmentExpressionNoIn.add(exprs.getTree());
<             	    if (list_exprs==null) list_exprs=new ArrayList();
<             	    list_exprs.add(exprs.getTree());
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop42;
<                 }
<             } while (true);
< 
< 
< 
<             // AST REWRITE
<             // elements: exprs, exprs
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: exprs
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<             RewriteRuleSubtreeStream stream_exprs=new RewriteRuleSubtreeStream(adaptor,"token exprs",list_exprs);
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1121:2: -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ )
<             if ( list_exprs.size() > 1 ) {
<                 // JavaScript.g:1121:28: ^( CEXPR ( $exprs)+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(CEXPR, "CEXPR"), root_1);
< 
<                 if ( !(stream_exprs.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_exprs.hasNext() ) {
<                     adaptor.addChild(root_1, stream_exprs.nextTree());
< 
<                 }
<                 stream_exprs.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
<             else // 1122:2: -> $exprs
<             {
<                 adaptor.addChild(root_0, stream_exprs.nextTree());
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "expressionNoIn"
< 
<     public static class semic_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "semic"
<     // JavaScript.g:1147:1: semic : ( SEMIC | EOF | RBRACE | EOL | MultiLineComment );
<     public final JavaScriptParser.semic_return semic() throws RecognitionException {
<         JavaScriptParser.semic_return retval = new JavaScriptParser.semic_return();
<         retval.start = input.LT(1);
<         int semic_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SEMIC140=null;
<         Token EOF141=null;
<         Token RBRACE142=null;
<         Token EOL143=null;
<         Token MultiLineComment144=null;
< 
<         MyAstNode SEMIC140_tree=null;
<         MyAstNode EOF141_tree=null;
<         MyAstNode RBRACE142_tree=null;
<         MyAstNode EOL143_tree=null;
<         MyAstNode MultiLineComment144_tree=null;
< 
< 
<         	// Mark current position so we can unconsume a RBRACE.
<         	int marker = input.mark();
<         	// Promote EOL if appropriate	
<         	promoteEOL(retval);
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 47) ) { return retval; }
<             // JavaScript.g:1155:2: ( SEMIC | EOF | RBRACE | EOL | MultiLineComment )
<             int alt43=5;
<             switch ( input.LA(1) ) {
<             case SEMIC:
<                 {
<                 alt43=1;
<                 }
<                 break;
<             case EOF:
<                 {
<                 alt43=2;
<                 }
<                 break;
<             case RBRACE:
<                 {
<                 alt43=3;
<                 }
<                 break;
<             case EOL:
<                 {
<                 alt43=4;
<                 }
<                 break;
<             case MultiLineComment:
<                 {
<                 alt43=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 43, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt43) {
<                 case 1 :
<                     // JavaScript.g:1155:4: SEMIC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     SEMIC140=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_semic4472); 
<                     SEMIC140_tree = (MyAstNode)adaptor.create(SEMIC140);
<                     adaptor.addChild(root_0, SEMIC140_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1156:4: EOF
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     EOF141=(Token)match(input,EOF,FOLLOW_EOF_in_semic4477); 
<                     EOF141_tree = (MyAstNode)adaptor.create(EOF141);
<                     adaptor.addChild(root_0, EOF141_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1157:4: RBRACE
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     RBRACE142=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_semic4482); 
<                     RBRACE142_tree = (MyAstNode)adaptor.create(RBRACE142);
<                     adaptor.addChild(root_0, RBRACE142_tree);
< 
<                      input.rewind(marker); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:1158:4: EOL
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     EOL143=(Token)match(input,EOL,FOLLOW_EOL_in_semic4489); 
<                     EOL143_tree = (MyAstNode)adaptor.create(EOL143);
<                     adaptor.addChild(root_0, EOL143_tree);
< 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:1158:10: MultiLineComment
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     MultiLineComment144=(Token)match(input,MultiLineComment,FOLLOW_MultiLineComment_in_semic4493); 
<                     MultiLineComment144_tree = (MyAstNode)adaptor.create(MultiLineComment144);
<                     adaptor.addChild(root_0, MultiLineComment144_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "semic"
< 
<     public static class statement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "statement"
<     // JavaScript.g:1166:1: statement options {k=1; } : ({...}? block | statementTail );
<     public final JavaScriptParser.statement_return statement() throws RecognitionException {
<         JavaScriptParser.statement_return retval = new JavaScriptParser.statement_return();
<         retval.start = input.LT(1);
<         int statement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.block_return block145 = null;
< 
<         JavaScriptParser.statementTail_return statementTail146 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 48) ) { return retval; }
<             // JavaScript.g:1175:2: ({...}? block | statementTail )
<             int alt44=2;
<             alt44 = dfa44.predict(input);
<             switch (alt44) {
<                 case 1 :
<                     // JavaScript.g:1175:4: {...}? block
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     if ( !(( input.LA(1) == LBRACE )) ) {
<                         throw new FailedPredicateException(input, "statement", " input.LA(1) == LBRACE ");
<                     }
<                     pushFollow(FOLLOW_block_in_statement4527);
<                     block145=block();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, block145.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1176:4: statementTail
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_statementTail_in_statement4532);
<                     statementTail146=statementTail();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, statementTail146.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
< 
<                     if(retval.tree != null)
<                         retval.tree.is_statement = true;
<                 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "statement"
< 
<     public static class statementTail_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "statementTail"
<     // JavaScript.g:1179:1: statementTail : ( variableStatement | emptyStatement | expressionStatement | ifStatement | iterationStatement | continueStatement | breakStatement | returnStatement | withStatement | labelledStatement | switchStatement | throwStatement | tryStatement );
<     public final JavaScriptParser.statementTail_return statementTail() throws RecognitionException {
<         JavaScriptParser.statementTail_return retval = new JavaScriptParser.statementTail_return();
<         retval.start = input.LT(1);
<         int statementTail_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.variableStatement_return variableStatement147 = null;
< 
<         JavaScriptParser.emptyStatement_return emptyStatement148 = null;
< 
<         JavaScriptParser.expressionStatement_return expressionStatement149 = null;
< 
<         JavaScriptParser.ifStatement_return ifStatement150 = null;
< 
<         JavaScriptParser.iterationStatement_return iterationStatement151 = null;
< 
<         JavaScriptParser.continueStatement_return continueStatement152 = null;
< 
<         JavaScriptParser.breakStatement_return breakStatement153 = null;
< 
<         JavaScriptParser.returnStatement_return returnStatement154 = null;
< 
<         JavaScriptParser.withStatement_return withStatement155 = null;
< 
<         JavaScriptParser.labelledStatement_return labelledStatement156 = null;
< 
<         JavaScriptParser.switchStatement_return switchStatement157 = null;
< 
<         JavaScriptParser.throwStatement_return throwStatement158 = null;
< 
<         JavaScriptParser.tryStatement_return tryStatement159 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 49) ) { return retval; }
<             // JavaScript.g:1180:2: ( variableStatement | emptyStatement | expressionStatement | ifStatement | iterationStatement | continueStatement | breakStatement | returnStatement | withStatement | labelledStatement | switchStatement | throwStatement | tryStatement )
<             int alt45=13;
<             alt45 = dfa45.predict(input);
<             switch (alt45) {
<                 case 1 :
<                     // JavaScript.g:1180:4: variableStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_variableStatement_in_statementTail4544);
<                     variableStatement147=variableStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, variableStatement147.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1181:4: emptyStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_emptyStatement_in_statementTail4549);
<                     emptyStatement148=emptyStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, emptyStatement148.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1182:4: expressionStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_expressionStatement_in_statementTail4554);
<                     expressionStatement149=expressionStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, expressionStatement149.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:1183:4: ifStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_ifStatement_in_statementTail4559);
<                     ifStatement150=ifStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, ifStatement150.getTree());
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:1184:4: iterationStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_iterationStatement_in_statementTail4564);
<                     iterationStatement151=iterationStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, iterationStatement151.getTree());
< 
<                     }
<                     break;
<                 case 6 :
<                     // JavaScript.g:1185:4: continueStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_continueStatement_in_statementTail4569);
<                     continueStatement152=continueStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, continueStatement152.getTree());
< 
<                     }
<                     break;
<                 case 7 :
<                     // JavaScript.g:1186:4: breakStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_breakStatement_in_statementTail4574);
<                     breakStatement153=breakStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, breakStatement153.getTree());
< 
<                     }
<                     break;
<                 case 8 :
<                     // JavaScript.g:1187:4: returnStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_returnStatement_in_statementTail4579);
<                     returnStatement154=returnStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, returnStatement154.getTree());
< 
<                     }
<                     break;
<                 case 9 :
<                     // JavaScript.g:1188:4: withStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_withStatement_in_statementTail4584);
<                     withStatement155=withStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, withStatement155.getTree());
< 
<                     }
<                     break;
<                 case 10 :
<                     // JavaScript.g:1189:4: labelledStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_labelledStatement_in_statementTail4589);
<                     labelledStatement156=labelledStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, labelledStatement156.getTree());
< 
<                     }
<                     break;
<                 case 11 :
<                     // JavaScript.g:1190:4: switchStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_switchStatement_in_statementTail4594);
<                     switchStatement157=switchStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, switchStatement157.getTree());
< 
<                     }
<                     break;
<                 case 12 :
<                     // JavaScript.g:1191:4: throwStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_throwStatement_in_statementTail4599);
<                     throwStatement158=throwStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, throwStatement158.getTree());
< 
<                     }
<                     break;
<                 case 13 :
<                     // JavaScript.g:1192:4: tryStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_tryStatement_in_statementTail4604);
<                     tryStatement159=tryStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, tryStatement159.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "statementTail"
< 
<     public static class block_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "block"
<     // JavaScript.g:1197:1: block : lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) ;
<     public final JavaScriptParser.block_return block() throws RecognitionException {
<         JavaScriptParser.block_return retval = new JavaScriptParser.block_return();
<         retval.start = input.LT(1);
<         int block_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token RBRACE161=null;
<         JavaScriptParser.sourceElement_return sourceElement160 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode RBRACE161_tree=null;
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_sourceElement=new RewriteRuleSubtreeStream(adaptor,"rule sourceElement");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 50) ) { return retval; }
<             // JavaScript.g:1198:2: (lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) )
<             // JavaScript.g:1198:4: lb= LBRACE ( sourceElement )* RBRACE
<             {
<             lb=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_block4619);  
<             stream_LBRACE.add(lb);
< 
<             // JavaScript.g:1198:14: ( sourceElement )*
<             loop46:
<             do {
<                 int alt46=2;
<                 int LA46_0 = input.LA(1);
< 
<                 if ( ((LA46_0>=NULL && LA46_0<=BREAK)||LA46_0==CONTINUE||(LA46_0>=DELETE && LA46_0<=DO)||(LA46_0>=FOR && LA46_0<=IF)||(LA46_0>=NEW && LA46_0<=WITH)||LA46_0==LBRACE||LA46_0==LPAREN||LA46_0==LBRACK||LA46_0==SEMIC||(LA46_0>=ADD && LA46_0<=SUB)||(LA46_0>=INC && LA46_0<=DEC)||(LA46_0>=NOT && LA46_0<=INV)||(LA46_0>=Identifier && LA46_0<=StringLiteral)||LA46_0==RegularExpressionLiteral||(LA46_0>=DecimalLiteral && LA46_0<=HexIntegerLiteral)) ) {
<                     alt46=1;
<                 }
< 
< 
<                 switch (alt46) {
<             	case 1 :
<             	    // JavaScript.g:1198:14: sourceElement
<             	    {
<             	    pushFollow(FOLLOW_sourceElement_in_block4621);
<             	    sourceElement160=sourceElement();
< 
<             	    state._fsp--;
< 
<             	    stream_sourceElement.add(sourceElement160.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop46;
<                 }
<             } while (true);
< 
<             RBRACE161=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_block4624);  
<             stream_RBRACE.add(RBRACE161);
< 
< 
< 
<             // AST REWRITE
<             // elements: sourceElement
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1199:2: -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<             {
<                 // JavaScript.g:1199:5: ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BLOCK, lb, "BLOCK"), root_1);
< 
<                 // JavaScript.g:1199:28: ( sourceElement )*
<                 while ( stream_sourceElement.hasNext() ) {
<                     adaptor.addChild(root_1, stream_sourceElement.nextTree());
< 
<                 }
<                 stream_sourceElement.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "block"
< 
<     public static class variableStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "variableStatement"
<     // JavaScript.g:1206:1: variableStatement : VAR variableDeclaration ( COMMA variableDeclaration )* semic -> ^( VAR ( variableDeclaration )+ ) ;
<     public final JavaScriptParser.variableStatement_return variableStatement() throws RecognitionException {
<         JavaScriptParser.variableStatement_return retval = new JavaScriptParser.variableStatement_return();
<         retval.start = input.LT(1);
<         int variableStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token VAR162=null;
<         Token COMMA164=null;
<         JavaScriptParser.variableDeclaration_return variableDeclaration163 = null;
< 
<         JavaScriptParser.variableDeclaration_return variableDeclaration165 = null;
< 
<         JavaScriptParser.semic_return semic166 = null;
< 
< 
<         MyAstNode VAR162_tree=null;
<         MyAstNode COMMA164_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_VAR=new RewriteRuleTokenStream(adaptor,"token VAR");
<         RewriteRuleSubtreeStream stream_variableDeclaration=new RewriteRuleSubtreeStream(adaptor,"rule variableDeclaration");
<         RewriteRuleSubtreeStream stream_semic=new RewriteRuleSubtreeStream(adaptor,"rule semic");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 51) ) { return retval; }
<             // JavaScript.g:1207:2: ( VAR variableDeclaration ( COMMA variableDeclaration )* semic -> ^( VAR ( variableDeclaration )+ ) )
<             // JavaScript.g:1207:4: VAR variableDeclaration ( COMMA variableDeclaration )* semic
<             {
<             VAR162=(Token)match(input,VAR,FOLLOW_VAR_in_variableStatement4653);  
<             stream_VAR.add(VAR162);
< 
<             pushFollow(FOLLOW_variableDeclaration_in_variableStatement4655);
<             variableDeclaration163=variableDeclaration();
< 
<             state._fsp--;
< 
<             stream_variableDeclaration.add(variableDeclaration163.getTree());
<             // JavaScript.g:1207:28: ( COMMA variableDeclaration )*
<             loop47:
<             do {
<                 int alt47=2;
<                 int LA47_0 = input.LA(1);
< 
<                 if ( (LA47_0==COMMA) ) {
<                     alt47=1;
<                 }
< 
< 
<                 switch (alt47) {
<             	case 1 :
<             	    // JavaScript.g:1207:30: COMMA variableDeclaration
<             	    {
<             	    COMMA164=(Token)match(input,COMMA,FOLLOW_COMMA_in_variableStatement4659);  
<             	    stream_COMMA.add(COMMA164);
< 
<             	    pushFollow(FOLLOW_variableDeclaration_in_variableStatement4661);
<             	    variableDeclaration165=variableDeclaration();
< 
<             	    state._fsp--;
< 
<             	    stream_variableDeclaration.add(variableDeclaration165.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop47;
<                 }
<             } while (true);
< 
<             pushFollow(FOLLOW_semic_in_variableStatement4666);
<             semic166=semic();
< 
<             state._fsp--;
< 
<             stream_semic.add(semic166.getTree());
< 
< 
<             // AST REWRITE
<             // elements: variableDeclaration, VAR
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1208:2: -> ^( VAR ( variableDeclaration )+ )
<             {
<                 // JavaScript.g:1208:5: ^( VAR ( variableDeclaration )+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_VAR.nextNode(), root_1);
< 
<                 if ( !(stream_variableDeclaration.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_variableDeclaration.hasNext() ) {
<                     adaptor.addChild(root_1, stream_variableDeclaration.nextTree());
< 
<                 }
<                 stream_variableDeclaration.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "variableStatement"
< 
<     public static class variableDeclaration_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "variableDeclaration"
<     // JavaScript.g:1211:1: variableDeclaration : Identifier ( ASSIGN assignmentExpression )? ;
<     public final JavaScriptParser.variableDeclaration_return variableDeclaration() throws RecognitionException {
<         JavaScriptParser.variableDeclaration_return retval = new JavaScriptParser.variableDeclaration_return();
<         retval.start = input.LT(1);
<         int variableDeclaration_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier167=null;
<         Token ASSIGN168=null;
<         JavaScriptParser.assignmentExpression_return assignmentExpression169 = null;
< 
< 
<         MyAstNode Identifier167_tree=null;
<         MyAstNode ASSIGN168_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 52) ) { return retval; }
<             // JavaScript.g:1212:2: ( Identifier ( ASSIGN assignmentExpression )? )
<             // JavaScript.g:1212:4: Identifier ( ASSIGN assignmentExpression )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             Identifier167=(Token)match(input,Identifier,FOLLOW_Identifier_in_variableDeclaration4689); 
<             Identifier167_tree = (MyAstNode)adaptor.create(Identifier167);
<             adaptor.addChild(root_0, Identifier167_tree);
< 
<             // JavaScript.g:1212:15: ( ASSIGN assignmentExpression )?
<             int alt48=2;
<             int LA48_0 = input.LA(1);
< 
<             if ( (LA48_0==ASSIGN) ) {
<                 alt48=1;
<             }
<             switch (alt48) {
<                 case 1 :
<                     // JavaScript.g:1212:17: ASSIGN assignmentExpression
<                     {
<                     ASSIGN168=(Token)match(input,ASSIGN,FOLLOW_ASSIGN_in_variableDeclaration4693); 
<                     ASSIGN168_tree = (MyAstNode)adaptor.create(ASSIGN168);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(ASSIGN168_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpression_in_variableDeclaration4696);
<                     assignmentExpression169=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression169.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "variableDeclaration"
< 
<     public static class variableDeclarationNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "variableDeclarationNoIn"
<     // JavaScript.g:1215:1: variableDeclarationNoIn : Identifier ( ASSIGN assignmentExpressionNoIn )? ;
<     public final JavaScriptParser.variableDeclarationNoIn_return variableDeclarationNoIn() throws RecognitionException {
<         JavaScriptParser.variableDeclarationNoIn_return retval = new JavaScriptParser.variableDeclarationNoIn_return();
<         retval.start = input.LT(1);
<         int variableDeclarationNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier170=null;
<         Token ASSIGN171=null;
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn172 = null;
< 
< 
<         MyAstNode Identifier170_tree=null;
<         MyAstNode ASSIGN171_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 53) ) { return retval; }
<             // JavaScript.g:1216:2: ( Identifier ( ASSIGN assignmentExpressionNoIn )? )
<             // JavaScript.g:1216:4: Identifier ( ASSIGN assignmentExpressionNoIn )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             Identifier170=(Token)match(input,Identifier,FOLLOW_Identifier_in_variableDeclarationNoIn4711); 
<             Identifier170_tree = (MyAstNode)adaptor.create(Identifier170);
<             adaptor.addChild(root_0, Identifier170_tree);
< 
<             // JavaScript.g:1216:15: ( ASSIGN assignmentExpressionNoIn )?
<             int alt49=2;
<             int LA49_0 = input.LA(1);
< 
<             if ( (LA49_0==ASSIGN) ) {
<                 alt49=1;
<             }
<             switch (alt49) {
<                 case 1 :
<                     // JavaScript.g:1216:17: ASSIGN assignmentExpressionNoIn
<                     {
<                     ASSIGN171=(Token)match(input,ASSIGN,FOLLOW_ASSIGN_in_variableDeclarationNoIn4715); 
<                     ASSIGN171_tree = (MyAstNode)adaptor.create(ASSIGN171);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(ASSIGN171_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_variableDeclarationNoIn4718);
<                     assignmentExpressionNoIn172=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn172.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "variableDeclarationNoIn"
< 
<     public static class emptyStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "emptyStatement"
<     // JavaScript.g:1223:1: emptyStatement : SEMIC ;
<     public final JavaScriptParser.emptyStatement_return emptyStatement() throws RecognitionException {
<         JavaScriptParser.emptyStatement_return retval = new JavaScriptParser.emptyStatement_return();
<         retval.start = input.LT(1);
<         int emptyStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SEMIC173=null;
< 
<         MyAstNode SEMIC173_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 54) ) { return retval; }
<             // JavaScript.g:1224:2: ( SEMIC )
<             // JavaScript.g:1224:4: SEMIC
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             SEMIC173=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_emptyStatement4737); 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "emptyStatement"
< 
<     public static class expressionStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "expressionStatement"
<     // JavaScript.g:1237:1: expressionStatement : expression semic ;
<     public final JavaScriptParser.expressionStatement_return expressionStatement() throws RecognitionException {
<         JavaScriptParser.expressionStatement_return retval = new JavaScriptParser.expressionStatement_return();
<         retval.start = input.LT(1);
<         int expressionStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.expression_return expression174 = null;
< 
<         JavaScriptParser.semic_return semic175 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 55) ) { return retval; }
<             // JavaScript.g:1238:2: ( expression semic )
<             // JavaScript.g:1238:4: expression semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_expression_in_expressionStatement4756);
<             expression174=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression174.getTree());
<             pushFollow(FOLLOW_semic_in_expressionStatement4758);
<             semic175=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "expressionStatement"
< 
<     public static class ifStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "ifStatement"
<     // JavaScript.g:1245:1: ifStatement : IF LPAREN expression RPAREN statement ({...}? ELSE statement )? -> ^( IF expression ( statement )+ ) ;
<     public final JavaScriptParser.ifStatement_return ifStatement() throws RecognitionException {
<         JavaScriptParser.ifStatement_return retval = new JavaScriptParser.ifStatement_return();
<         retval.start = input.LT(1);
<         int ifStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token IF176=null;
<         Token LPAREN177=null;
<         Token RPAREN179=null;
<         Token ELSE181=null;
<         JavaScriptParser.expression_return expression178 = null;
< 
<         JavaScriptParser.statement_return statement180 = null;
< 
<         JavaScriptParser.statement_return statement182 = null;
< 
< 
<         MyAstNode IF176_tree=null;
<         MyAstNode LPAREN177_tree=null;
<         MyAstNode RPAREN179_tree=null;
<         MyAstNode ELSE181_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_ELSE=new RewriteRuleTokenStream(adaptor,"token ELSE");
<         RewriteRuleTokenStream stream_IF=new RewriteRuleTokenStream(adaptor,"token IF");
<         RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 56) ) { return retval; }
<             // JavaScript.g:1247:2: ( IF LPAREN expression RPAREN statement ({...}? ELSE statement )? -> ^( IF expression ( statement )+ ) )
<             // JavaScript.g:1247:4: IF LPAREN expression RPAREN statement ({...}? ELSE statement )?
<             {
<             IF176=(Token)match(input,IF,FOLLOW_IF_in_ifStatement4776);  
<             stream_IF.add(IF176);
< 
<             LPAREN177=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_ifStatement4778);  
<             stream_LPAREN.add(LPAREN177);
< 
<             pushFollow(FOLLOW_expression_in_ifStatement4780);
<             expression178=expression();
< 
<             state._fsp--;
< 
<             stream_expression.add(expression178.getTree());
<             RPAREN179=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_ifStatement4782);  
<             stream_RPAREN.add(RPAREN179);
< 
<             pushFollow(FOLLOW_statement_in_ifStatement4784);
<             statement180=statement();
< 
<             state._fsp--;
< 
<             stream_statement.add(statement180.getTree());
<             // JavaScript.g:1247:42: ({...}? ELSE statement )?
<             int alt50=2;
<             int LA50_0 = input.LA(1);
< 
<             if ( (LA50_0==ELSE) ) {
<                 int LA50_1 = input.LA(2);
< 
<                 if ( (( input.LA(1) == ELSE )) ) {
<                     alt50=1;
<                 }
<             }
<             switch (alt50) {
<                 case 1 :
<                     // JavaScript.g:1247:44: {...}? ELSE statement
<                     {
<                     if ( !(( input.LA(1) == ELSE )) ) {
<                         throw new FailedPredicateException(input, "ifStatement", " input.LA(1) == ELSE ");
<                     }
<                     ELSE181=(Token)match(input,ELSE,FOLLOW_ELSE_in_ifStatement4790);  
<                     stream_ELSE.add(ELSE181);
< 
<                     pushFollow(FOLLOW_statement_in_ifStatement4792);
<                     statement182=statement();
< 
<                     state._fsp--;
< 
<                     stream_statement.add(statement182.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
< 
<             // AST REWRITE
<             // elements: IF, statement, expression
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1248:2: -> ^( IF expression ( statement )+ )
<             {
<                 // JavaScript.g:1248:5: ^( IF expression ( statement )+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_IF.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_expression.nextTree());
<                 if ( !(stream_statement.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_statement.hasNext() ) {
<                     adaptor.addChild(root_1, stream_statement.nextTree());
< 
<                 }
<                 stream_statement.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "ifStatement"
< 
<     public static class iterationStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "iterationStatement"
<     // JavaScript.g:1255:1: iterationStatement : ( doStatement | whileStatement | forStatement );
<     public final JavaScriptParser.iterationStatement_return iterationStatement() throws RecognitionException {
<         JavaScriptParser.iterationStatement_return retval = new JavaScriptParser.iterationStatement_return();
<         retval.start = input.LT(1);
<         int iterationStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.doStatement_return doStatement183 = null;
< 
<         JavaScriptParser.whileStatement_return whileStatement184 = null;
< 
<         JavaScriptParser.forStatement_return forStatement185 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 57) ) { return retval; }
<             // JavaScript.g:1256:2: ( doStatement | whileStatement | forStatement )
<             int alt51=3;
<             switch ( input.LA(1) ) {
<             case DO:
<                 {
<                 alt51=1;
<                 }
<                 break;
<             case WHILE:
<                 {
<                 alt51=2;
<                 }
<                 break;
<             case FOR:
<                 {
<                 alt51=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 51, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt51) {
<                 case 1 :
<                     // JavaScript.g:1256:4: doStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_doStatement_in_iterationStatement4825);
<                     doStatement183=doStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, doStatement183.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1257:4: whileStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_whileStatement_in_iterationStatement4830);
<                     whileStatement184=whileStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, whileStatement184.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1258:4: forStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forStatement_in_iterationStatement4835);
<                     forStatement185=forStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forStatement185.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "iterationStatement"
< 
<     public static class doStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "doStatement"
<     // JavaScript.g:1261:1: doStatement : DO statement WHILE LPAREN expression RPAREN semic -> ^( DO statement expression ) ;
<     public final JavaScriptParser.doStatement_return doStatement() throws RecognitionException {
<         JavaScriptParser.doStatement_return retval = new JavaScriptParser.doStatement_return();
<         retval.start = input.LT(1);
<         int doStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token DO186=null;
<         Token WHILE188=null;
<         Token LPAREN189=null;
<         Token RPAREN191=null;
<         JavaScriptParser.statement_return statement187 = null;
< 
<         JavaScriptParser.expression_return expression190 = null;
< 
<         JavaScriptParser.semic_return semic192 = null;
< 
< 
<         MyAstNode DO186_tree=null;
<         MyAstNode WHILE188_tree=null;
<         MyAstNode LPAREN189_tree=null;
<         MyAstNode RPAREN191_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_DO=new RewriteRuleTokenStream(adaptor,"token DO");
<         RewriteRuleTokenStream stream_WHILE=new RewriteRuleTokenStream(adaptor,"token WHILE");
<         RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");
<         RewriteRuleSubtreeStream stream_semic=new RewriteRuleSubtreeStream(adaptor,"rule semic");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 58) ) { return retval; }
<             // JavaScript.g:1262:2: ( DO statement WHILE LPAREN expression RPAREN semic -> ^( DO statement expression ) )
<             // JavaScript.g:1262:4: DO statement WHILE LPAREN expression RPAREN semic
<             {
<             DO186=(Token)match(input,DO,FOLLOW_DO_in_doStatement4847);  
<             stream_DO.add(DO186);
< 
<             pushFollow(FOLLOW_statement_in_doStatement4849);
<             statement187=statement();
< 
<             state._fsp--;
< 
<             stream_statement.add(statement187.getTree());
<             WHILE188=(Token)match(input,WHILE,FOLLOW_WHILE_in_doStatement4851);  
<             stream_WHILE.add(WHILE188);
< 
<             LPAREN189=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_doStatement4853);  
<             stream_LPAREN.add(LPAREN189);
< 
<             pushFollow(FOLLOW_expression_in_doStatement4855);
<             expression190=expression();
< 
<             state._fsp--;
< 
<             stream_expression.add(expression190.getTree());
<             RPAREN191=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_doStatement4857);  
<             stream_RPAREN.add(RPAREN191);
< 
<             pushFollow(FOLLOW_semic_in_doStatement4859);
<             semic192=semic();
< 
<             state._fsp--;
< 
<             stream_semic.add(semic192.getTree());
< 
< 
<             // AST REWRITE
<             // elements: statement, expression, DO
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1263:2: -> ^( DO statement expression )
<             {
<                 // JavaScript.g:1263:5: ^( DO statement expression )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_DO.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_statement.nextTree());
<                 adaptor.addChild(root_1, stream_expression.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "doStatement"
< 
<     public static class whileStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "whileStatement"
<     // JavaScript.g:1266:1: whileStatement : WHILE LPAREN expression RPAREN statement ;
<     public final JavaScriptParser.whileStatement_return whileStatement() throws RecognitionException {
<         JavaScriptParser.whileStatement_return retval = new JavaScriptParser.whileStatement_return();
<         retval.start = input.LT(1);
<         int whileStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token WHILE193=null;
<         Token LPAREN194=null;
<         Token RPAREN196=null;
<         JavaScriptParser.expression_return expression195 = null;
< 
<         JavaScriptParser.statement_return statement197 = null;
< 
< 
<         MyAstNode WHILE193_tree=null;
<         MyAstNode LPAREN194_tree=null;
<         MyAstNode RPAREN196_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 59) ) { return retval; }
<             // JavaScript.g:1267:2: ( WHILE LPAREN expression RPAREN statement )
<             // JavaScript.g:1267:4: WHILE LPAREN expression RPAREN statement
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             WHILE193=(Token)match(input,WHILE,FOLLOW_WHILE_in_whileStatement4884); 
<             WHILE193_tree = (MyAstNode)adaptor.create(WHILE193);
<             root_0 = (MyAstNode)adaptor.becomeRoot(WHILE193_tree, root_0);
< 
<             LPAREN194=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_whileStatement4887); 
<             pushFollow(FOLLOW_expression_in_whileStatement4890);
<             expression195=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression195.getTree());
<             RPAREN196=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_whileStatement4892); 
<             pushFollow(FOLLOW_statement_in_whileStatement4895);
<             statement197=statement();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, statement197.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "whileStatement"
< 
<     public static class forStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forStatement"
<     // JavaScript.g:1311:1: forStatement : FOR LPAREN forControl RPAREN statement ;
<     public final JavaScriptParser.forStatement_return forStatement() throws RecognitionException {
<         JavaScriptParser.forStatement_return retval = new JavaScriptParser.forStatement_return();
<         retval.start = input.LT(1);
<         int forStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token FOR198=null;
<         Token LPAREN199=null;
<         Token RPAREN201=null;
<         JavaScriptParser.forControl_return forControl200 = null;
< 
<         JavaScriptParser.statement_return statement202 = null;
< 
< 
<         MyAstNode FOR198_tree=null;
<         MyAstNode LPAREN199_tree=null;
<         MyAstNode RPAREN201_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 60) ) { return retval; }
<             // JavaScript.g:1312:2: ( FOR LPAREN forControl RPAREN statement )
<             // JavaScript.g:1312:4: FOR LPAREN forControl RPAREN statement
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             FOR198=(Token)match(input,FOR,FOLLOW_FOR_in_forStatement4908); 
<             FOR198_tree = (MyAstNode)adaptor.create(FOR198);
<             root_0 = (MyAstNode)adaptor.becomeRoot(FOR198_tree, root_0);
< 
<             LPAREN199=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_forStatement4911); 
<             pushFollow(FOLLOW_forControl_in_forStatement4914);
<             forControl200=forControl();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, forControl200.getTree());
<             RPAREN201=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_forStatement4916); 
<             pushFollow(FOLLOW_statement_in_forStatement4919);
<             statement202=statement();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, statement202.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forStatement"
< 
<     public static class forControl_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControl"
<     // JavaScript.g:1315:1: forControl : ( forControlVar | forControlExpression | forControlSemic );
<     public final JavaScriptParser.forControl_return forControl() throws RecognitionException {
<         JavaScriptParser.forControl_return retval = new JavaScriptParser.forControl_return();
<         retval.start = input.LT(1);
<         int forControl_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.forControlVar_return forControlVar203 = null;
< 
<         JavaScriptParser.forControlExpression_return forControlExpression204 = null;
< 
<         JavaScriptParser.forControlSemic_return forControlSemic205 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 61) ) { return retval; }
<             // JavaScript.g:1316:2: ( forControlVar | forControlExpression | forControlSemic )
<             int alt52=3;
<             switch ( input.LA(1) ) {
<             case VAR:
<                 {
<                 alt52=1;
<                 }
<                 break;
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case DELETE:
<             case FUNCTION:
<             case NEW:
<             case THIS:
<             case TYPEOF:
<             case VOID:
<             case LBRACE:
<             case LPAREN:
<             case LBRACK:
<             case ADD:
<             case SUB:
<             case INC:
<             case DEC:
<             case NOT:
<             case INV:
<             case Identifier:
<             case StringLiteral:
<             case RegularExpressionLiteral:
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt52=2;
<                 }
<                 break;
<             case SEMIC:
<                 {
<                 alt52=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 52, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt52) {
<                 case 1 :
<                     // JavaScript.g:1316:4: forControlVar
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forControlVar_in_forControl4930);
<                     forControlVar203=forControlVar();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forControlVar203.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1317:4: forControlExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forControlExpression_in_forControl4935);
<                     forControlExpression204=forControlExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forControlExpression204.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1318:4: forControlSemic
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forControlSemic_in_forControl4940);
<                     forControlSemic205=forControlSemic();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forControlSemic205.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControl"
< 
<     public static class forControlVar_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControlVar"
<     // JavaScript.g:1321:1: forControlVar : VAR variableDeclarationNoIn ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) ) ;
<     public final JavaScriptParser.forControlVar_return forControlVar() throws RecognitionException {
<         JavaScriptParser.forControlVar_return retval = new JavaScriptParser.forControlVar_return();
<         retval.start = input.LT(1);
<         int forControlVar_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token VAR206=null;
<         Token IN208=null;
<         Token COMMA210=null;
<         Token SEMIC212=null;
<         Token SEMIC213=null;
<         JavaScriptParser.expression_return ex1 = null;
< 
<         JavaScriptParser.expression_return ex2 = null;
< 
<         JavaScriptParser.variableDeclarationNoIn_return variableDeclarationNoIn207 = null;
< 
<         JavaScriptParser.expression_return expression209 = null;
< 
<         JavaScriptParser.variableDeclarationNoIn_return variableDeclarationNoIn211 = null;
< 
< 
<         MyAstNode VAR206_tree=null;
<         MyAstNode IN208_tree=null;
<         MyAstNode COMMA210_tree=null;
<         MyAstNode SEMIC212_tree=null;
<         MyAstNode SEMIC213_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_VAR=new RewriteRuleTokenStream(adaptor,"token VAR");
<         RewriteRuleTokenStream stream_SEMIC=new RewriteRuleTokenStream(adaptor,"token SEMIC");
<         RewriteRuleTokenStream stream_IN=new RewriteRuleTokenStream(adaptor,"token IN");
<         RewriteRuleSubtreeStream stream_variableDeclarationNoIn=new RewriteRuleSubtreeStream(adaptor,"rule variableDeclarationNoIn");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 62) ) { return retval; }
<             // JavaScript.g:1322:2: ( VAR variableDeclarationNoIn ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) ) )
<             // JavaScript.g:1322:4: VAR variableDeclarationNoIn ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) )
<             {
<             VAR206=(Token)match(input,VAR,FOLLOW_VAR_in_forControlVar4951);  
<             stream_VAR.add(VAR206);
< 
<             pushFollow(FOLLOW_variableDeclarationNoIn_in_forControlVar4953);
<             variableDeclarationNoIn207=variableDeclarationNoIn();
< 
<             state._fsp--;
< 
<             stream_variableDeclarationNoIn.add(variableDeclarationNoIn207.getTree());
<             // JavaScript.g:1323:2: ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) )
<             int alt56=2;
<             int LA56_0 = input.LA(1);
< 
<             if ( (LA56_0==IN) ) {
<                 alt56=1;
<             }
<             else if ( ((LA56_0>=SEMIC && LA56_0<=COMMA)) ) {
<                 alt56=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 56, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt56) {
<                 case 1 :
<                     // JavaScript.g:1324:3: ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) )
<                     {
<                     // JavaScript.g:1324:3: ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) )
<                     // JavaScript.g:1325:4: IN expression
<                     {
<                     IN208=(Token)match(input,IN,FOLLOW_IN_in_forControlVar4965);  
<                     stream_IN.add(IN208);
< 
<                     pushFollow(FOLLOW_expression_in_forControlVar4967);
<                     expression209=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(expression209.getTree());
< 
< 
<                     // AST REWRITE
<                     // elements: expression, VAR, variableDeclarationNoIn
<                     // token labels: 
<                     // rule labels: retval
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1326:4: -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) )
<                     {
<                         // JavaScript.g:1326:7: ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORITER, "FORITER"), root_1);
< 
<                         // JavaScript.g:1326:18: ^( VAR variableDeclarationNoIn )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot(stream_VAR.nextNode(), root_2);
< 
<                         adaptor.addChild(root_2, stream_variableDeclarationNoIn.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1326:51: ^( EXPR expression )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_expression.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1329:3: ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) )
<                     {
<                     // JavaScript.g:1329:3: ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) )
<                     // JavaScript.g:1330:4: ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )?
<                     {
<                     // JavaScript.g:1330:4: ( COMMA variableDeclarationNoIn )*
<                     loop53:
<                     do {
<                         int alt53=2;
<                         int LA53_0 = input.LA(1);
< 
<                         if ( (LA53_0==COMMA) ) {
<                             alt53=1;
<                         }
< 
< 
<                         switch (alt53) {
<                     	case 1 :
<                     	    // JavaScript.g:1330:6: COMMA variableDeclarationNoIn
<                     	    {
<                     	    COMMA210=(Token)match(input,COMMA,FOLLOW_COMMA_in_forControlVar5013);  
<                     	    stream_COMMA.add(COMMA210);
< 
<                     	    pushFollow(FOLLOW_variableDeclarationNoIn_in_forControlVar5015);
<                     	    variableDeclarationNoIn211=variableDeclarationNoIn();
< 
<                     	    state._fsp--;
< 
<                     	    stream_variableDeclarationNoIn.add(variableDeclarationNoIn211.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop53;
<                         }
<                     } while (true);
< 
<                     SEMIC212=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlVar5020);  
<                     stream_SEMIC.add(SEMIC212);
< 
<                     // JavaScript.g:1330:48: (ex1= expression )?
<                     int alt54=2;
<                     int LA54_0 = input.LA(1);
< 
<                     if ( ((LA54_0>=NULL && LA54_0<=FALSE)||LA54_0==DELETE||LA54_0==FUNCTION||LA54_0==NEW||LA54_0==THIS||LA54_0==TYPEOF||LA54_0==VOID||LA54_0==LBRACE||LA54_0==LPAREN||LA54_0==LBRACK||(LA54_0>=ADD && LA54_0<=SUB)||(LA54_0>=INC && LA54_0<=DEC)||(LA54_0>=NOT && LA54_0<=INV)||(LA54_0>=Identifier && LA54_0<=StringLiteral)||LA54_0==RegularExpressionLiteral||(LA54_0>=DecimalLiteral && LA54_0<=HexIntegerLiteral)) ) {
<                         alt54=1;
<                     }
<                     switch (alt54) {
<                         case 1 :
<                             // JavaScript.g:1330:48: ex1= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlVar5024);
<                             ex1=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex1.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
<                     SEMIC213=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlVar5027);  
<                     stream_SEMIC.add(SEMIC213);
< 
<                     // JavaScript.g:1330:70: (ex2= expression )?
<                     int alt55=2;
<                     int LA55_0 = input.LA(1);
< 
<                     if ( ((LA55_0>=NULL && LA55_0<=FALSE)||LA55_0==DELETE||LA55_0==FUNCTION||LA55_0==NEW||LA55_0==THIS||LA55_0==TYPEOF||LA55_0==VOID||LA55_0==LBRACE||LA55_0==LPAREN||LA55_0==LBRACK||(LA55_0>=ADD && LA55_0<=SUB)||(LA55_0>=INC && LA55_0<=DEC)||(LA55_0>=NOT && LA55_0<=INV)||(LA55_0>=Identifier && LA55_0<=StringLiteral)||LA55_0==RegularExpressionLiteral||(LA55_0>=DecimalLiteral && LA55_0<=HexIntegerLiteral)) ) {
<                         alt55=1;
<                     }
<                     switch (alt55) {
<                         case 1 :
<                             // JavaScript.g:1330:70: ex2= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlVar5031);
<                             ex2=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex2.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
< 
< 
<                     // AST REWRITE
<                     // elements: ex1, variableDeclarationNoIn, ex2, VAR
<                     // token labels: 
<                     // rule labels: ex2, retval, ex1
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<                     RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1331:4: -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<                     {
<                         // JavaScript.g:1331:7: ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORSTEP, "FORSTEP"), root_1);
< 
<                         // JavaScript.g:1331:18: ^( VAR ( variableDeclarationNoIn )+ )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot(stream_VAR.nextNode(), root_2);
< 
<                         if ( !(stream_variableDeclarationNoIn.hasNext()) ) {
<                             throw new RewriteEarlyExitException();
<                         }
<                         while ( stream_variableDeclarationNoIn.hasNext() ) {
<                             adaptor.addChild(root_2, stream_variableDeclarationNoIn.nextTree());
< 
<                         }
<                         stream_variableDeclarationNoIn.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1331:52: ^( EXPR ( $ex1)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1331:60: ( $ex1)?
<                         if ( stream_ex1.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                         }
<                         stream_ex1.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1331:68: ^( EXPR ( $ex2)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1331:76: ( $ex2)?
<                         if ( stream_ex2.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                         }
<                         stream_ex2.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControlVar"
< 
<     public static class forControlExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControlExpression"
<     // JavaScript.g:1336:1: forControlExpression : ex1= expressionNoIn ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) ) ;
<     public final JavaScriptParser.forControlExpression_return forControlExpression() throws RecognitionException {
<         JavaScriptParser.forControlExpression_return retval = new JavaScriptParser.forControlExpression_return();
<         retval.start = input.LT(1);
<         int forControlExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token IN214=null;
<         Token SEMIC215=null;
<         Token SEMIC216=null;
<         JavaScriptParser.expressionNoIn_return ex1 = null;
< 
<         JavaScriptParser.expression_return ex2 = null;
< 
<         JavaScriptParser.expression_return ex3 = null;
< 
< 
<         MyAstNode IN214_tree=null;
<         MyAstNode SEMIC215_tree=null;
<         MyAstNode SEMIC216_tree=null;
<         RewriteRuleTokenStream stream_SEMIC=new RewriteRuleTokenStream(adaptor,"token SEMIC");
<         RewriteRuleTokenStream stream_IN=new RewriteRuleTokenStream(adaptor,"token IN");
<         RewriteRuleSubtreeStream stream_expressionNoIn=new RewriteRuleSubtreeStream(adaptor,"rule expressionNoIn");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
< 
<         	Object[] isLhs = new Object[1];
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 63) ) { return retval; }
<             // JavaScript.g:1341:2: (ex1= expressionNoIn ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) ) )
<             // JavaScript.g:1341:4: ex1= expressionNoIn ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) )
<             {
<             pushFollow(FOLLOW_expressionNoIn_in_forControlExpression5097);
<             ex1=expressionNoIn();
< 
<             state._fsp--;
< 
<             stream_expressionNoIn.add(ex1.getTree());
<             // JavaScript.g:1342:2: ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) )
<             int alt59=2;
<             int LA59_0 = input.LA(1);
< 
<             if ( (LA59_0==IN) ) {
<                 alt59=1;
<             }
<             else if ( (LA59_0==SEMIC) ) {
<                 alt59=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 59, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt59) {
<                 case 1 :
<                     // JavaScript.g:1343:3: {...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) )
<                     {
<                     if ( !(( isLeftHandSideIn(ex1, isLhs) )) ) {
<                         throw new FailedPredicateException(input, "forControlExpression", " isLeftHandSideIn(ex1, isLhs) ");
<                     }
<                     // JavaScript.g:1343:37: ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) )
<                     // JavaScript.g:1344:4: IN ex2= expression
<                     {
<                     IN214=(Token)match(input,IN,FOLLOW_IN_in_forControlExpression5112);  
<                     stream_IN.add(IN214);
< 
<                     pushFollow(FOLLOW_expression_in_forControlExpression5116);
<                     ex2=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(ex2.getTree());
< 
< 
<                     // AST REWRITE
<                     // elements: ex2, ex1
<                     // token labels: 
<                     // rule labels: ex2, retval, ex1
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<                     RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1345:4: -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) )
<                     {
<                         // JavaScript.g:1345:7: ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORITER, "FORITER"), root_1);
< 
<                         // JavaScript.g:1345:18: ^( EXPR $ex1)
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1345:33: ^( EXPR $ex2)
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1348:3: ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) )
<                     {
<                     // JavaScript.g:1348:3: ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) )
<                     // JavaScript.g:1349:4: SEMIC (ex2= expression )? SEMIC (ex3= expression )?
<                     {
<                     SEMIC215=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlExpression5162);  
<                     stream_SEMIC.add(SEMIC215);
< 
<                     // JavaScript.g:1349:13: (ex2= expression )?
<                     int alt57=2;
<                     int LA57_0 = input.LA(1);
< 
<                     if ( ((LA57_0>=NULL && LA57_0<=FALSE)||LA57_0==DELETE||LA57_0==FUNCTION||LA57_0==NEW||LA57_0==THIS||LA57_0==TYPEOF||LA57_0==VOID||LA57_0==LBRACE||LA57_0==LPAREN||LA57_0==LBRACK||(LA57_0>=ADD && LA57_0<=SUB)||(LA57_0>=INC && LA57_0<=DEC)||(LA57_0>=NOT && LA57_0<=INV)||(LA57_0>=Identifier && LA57_0<=StringLiteral)||LA57_0==RegularExpressionLiteral||(LA57_0>=DecimalLiteral && LA57_0<=HexIntegerLiteral)) ) {
<                         alt57=1;
<                     }
<                     switch (alt57) {
<                         case 1 :
<                             // JavaScript.g:1349:13: ex2= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlExpression5166);
<                             ex2=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex2.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
<                     SEMIC216=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlExpression5169);  
<                     stream_SEMIC.add(SEMIC216);
< 
<                     // JavaScript.g:1349:35: (ex3= expression )?
<                     int alt58=2;
<                     int LA58_0 = input.LA(1);
< 
<                     if ( ((LA58_0>=NULL && LA58_0<=FALSE)||LA58_0==DELETE||LA58_0==FUNCTION||LA58_0==NEW||LA58_0==THIS||LA58_0==TYPEOF||LA58_0==VOID||LA58_0==LBRACE||LA58_0==LPAREN||LA58_0==LBRACK||(LA58_0>=ADD && LA58_0<=SUB)||(LA58_0>=INC && LA58_0<=DEC)||(LA58_0>=NOT && LA58_0<=INV)||(LA58_0>=Identifier && LA58_0<=StringLiteral)||LA58_0==RegularExpressionLiteral||(LA58_0>=DecimalLiteral && LA58_0<=HexIntegerLiteral)) ) {
<                         alt58=1;
<                     }
<                     switch (alt58) {
<                         case 1 :
<                             // JavaScript.g:1349:35: ex3= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlExpression5173);
<                             ex3=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex3.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
< 
< 
<                     // AST REWRITE
<                     // elements: ex1, ex2, ex3
<                     // token labels: 
<                     // rule labels: ex2, retval, ex1, ex3
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<                     RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
<                     RewriteRuleSubtreeStream stream_ex3=new RewriteRuleSubtreeStream(adaptor,"token ex3",ex3!=null?ex3.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1350:4: -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) )
<                     {
<                         // JavaScript.g:1350:7: ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORSTEP, "FORSTEP"), root_1);
< 
<                         // JavaScript.g:1350:18: ^( EXPR $ex1)
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1350:33: ^( EXPR ( $ex2)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1350:41: ( $ex2)?
<                         if ( stream_ex2.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                         }
<                         stream_ex2.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1350:49: ^( EXPR ( $ex3)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1350:57: ( $ex3)?
<                         if ( stream_ex3.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex3.nextTree());
< 
<                         }
<                         stream_ex3.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControlExpression"
< 
<     public static class forControlSemic_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControlSemic"
<     // JavaScript.g:1355:1: forControlSemic : SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ;
<     public final JavaScriptParser.forControlSemic_return forControlSemic() throws RecognitionException {
<         JavaScriptParser.forControlSemic_return retval = new JavaScriptParser.forControlSemic_return();
<         retval.start = input.LT(1);
<         int forControlSemic_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SEMIC217=null;
<         Token SEMIC218=null;
<         JavaScriptParser.expression_return ex1 = null;
< 
<         JavaScriptParser.expression_return ex2 = null;
< 
< 
<         MyAstNode SEMIC217_tree=null;
<         MyAstNode SEMIC218_tree=null;
<         RewriteRuleTokenStream stream_SEMIC=new RewriteRuleTokenStream(adaptor,"token SEMIC");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 64) ) { return retval; }
<             // JavaScript.g:1356:2: ( SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) )
<             // JavaScript.g:1356:4: SEMIC (ex1= expression )? SEMIC (ex2= expression )?
<             {
<             SEMIC217=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlSemic5232);  
<             stream_SEMIC.add(SEMIC217);
< 
<             // JavaScript.g:1356:13: (ex1= expression )?
<             int alt60=2;
<             int LA60_0 = input.LA(1);
< 
<             if ( ((LA60_0>=NULL && LA60_0<=FALSE)||LA60_0==DELETE||LA60_0==FUNCTION||LA60_0==NEW||LA60_0==THIS||LA60_0==TYPEOF||LA60_0==VOID||LA60_0==LBRACE||LA60_0==LPAREN||LA60_0==LBRACK||(LA60_0>=ADD && LA60_0<=SUB)||(LA60_0>=INC && LA60_0<=DEC)||(LA60_0>=NOT && LA60_0<=INV)||(LA60_0>=Identifier && LA60_0<=StringLiteral)||LA60_0==RegularExpressionLiteral||(LA60_0>=DecimalLiteral && LA60_0<=HexIntegerLiteral)) ) {
<                 alt60=1;
<             }
<             switch (alt60) {
<                 case 1 :
<                     // JavaScript.g:1356:13: ex1= expression
<                     {
<                     pushFollow(FOLLOW_expression_in_forControlSemic5236);
<                     ex1=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(ex1.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
<             SEMIC218=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlSemic5239);  
<             stream_SEMIC.add(SEMIC218);
< 
<             // JavaScript.g:1356:35: (ex2= expression )?
<             int alt61=2;
<             int LA61_0 = input.LA(1);
< 
<             if ( ((LA61_0>=NULL && LA61_0<=FALSE)||LA61_0==DELETE||LA61_0==FUNCTION||LA61_0==NEW||LA61_0==THIS||LA61_0==TYPEOF||LA61_0==VOID||LA61_0==LBRACE||LA61_0==LPAREN||LA61_0==LBRACK||(LA61_0>=ADD && LA61_0<=SUB)||(LA61_0>=INC && LA61_0<=DEC)||(LA61_0>=NOT && LA61_0<=INV)||(LA61_0>=Identifier && LA61_0<=StringLiteral)||LA61_0==RegularExpressionLiteral||(LA61_0>=DecimalLiteral && LA61_0<=HexIntegerLiteral)) ) {
<                 alt61=1;
<             }
<             switch (alt61) {
<                 case 1 :
<                     // JavaScript.g:1356:35: ex2= expression
<                     {
<                     pushFollow(FOLLOW_expression_in_forControlSemic5243);
<                     ex2=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(ex2.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
< 
<             // AST REWRITE
<             // elements: ex2, ex1
<             // token labels: 
<             // rule labels: ex2, retval, ex1
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<             RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1357:2: -> ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<             {
<                 // JavaScript.g:1357:5: ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORSTEP, "FORSTEP"), root_1);
< 
<                 // JavaScript.g:1357:16: ^( EXPR )
<                 {
<                 MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                 root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                 adaptor.addChild(root_1, root_2);
<                 }
<                 // JavaScript.g:1357:26: ^( EXPR ( $ex1)? )
<                 {
<                 MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                 root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                 // JavaScript.g:1357:34: ( $ex1)?
<                 if ( stream_ex1.hasNext() ) {
<                     adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                 }
<                 stream_ex1.reset();
< 
<                 adaptor.addChild(root_1, root_2);
<                 }
<                 // JavaScript.g:1357:42: ^( EXPR ( $ex2)? )
<                 {
<                 MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                 root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                 // JavaScript.g:1357:50: ( $ex2)?
<                 if ( stream_ex2.hasNext() ) {
<                     adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                 }
<                 stream_ex2.reset();
< 
<                 adaptor.addChild(root_1, root_2);
<                 }
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControlSemic"
< 
<     public static class continueStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "continueStatement"
<     // JavaScript.g:1369:1: continueStatement : CONTINUE ( Identifier )? semic ;
<     public final JavaScriptParser.continueStatement_return continueStatement() throws RecognitionException {
<         JavaScriptParser.continueStatement_return retval = new JavaScriptParser.continueStatement_return();
<         retval.start = input.LT(1);
<         int continueStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token CONTINUE219=null;
<         Token Identifier220=null;
<         JavaScriptParser.semic_return semic221 = null;
< 
< 
<         MyAstNode CONTINUE219_tree=null;
<         MyAstNode Identifier220_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 65) ) { return retval; }
<             // JavaScript.g:1370:2: ( CONTINUE ( Identifier )? semic )
<             // JavaScript.g:1370:4: CONTINUE ( Identifier )? semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             CONTINUE219=(Token)match(input,CONTINUE,FOLLOW_CONTINUE_in_continueStatement5297); 
<             CONTINUE219_tree = (MyAstNode)adaptor.create(CONTINUE219);
<             root_0 = (MyAstNode)adaptor.becomeRoot(CONTINUE219_tree, root_0);
< 
<              if (input.LA(1) == Identifier) promoteEOL(null); 
<             // JavaScript.g:1370:67: ( Identifier )?
<             int alt62=2;
<             int LA62_0 = input.LA(1);
< 
<             if ( (LA62_0==Identifier) ) {
<                 alt62=1;
<             }
<             switch (alt62) {
<                 case 1 :
<                     // JavaScript.g:1370:67: Identifier
<                     {
<                     Identifier220=(Token)match(input,Identifier,FOLLOW_Identifier_in_continueStatement5302); 
<                     Identifier220_tree = (MyAstNode)adaptor.create(Identifier220);
<                     adaptor.addChild(root_0, Identifier220_tree);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_semic_in_continueStatement5305);
<             semic221=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "continueStatement"
< 
<     public static class breakStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "breakStatement"
<     // JavaScript.g:1382:1: breakStatement : BREAK ( Identifier )? semic ;
<     public final JavaScriptParser.breakStatement_return breakStatement() throws RecognitionException {
<         JavaScriptParser.breakStatement_return retval = new JavaScriptParser.breakStatement_return();
<         retval.start = input.LT(1);
<         int breakStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token BREAK222=null;
<         Token Identifier223=null;
<         JavaScriptParser.semic_return semic224 = null;
< 
< 
<         MyAstNode BREAK222_tree=null;
<         MyAstNode Identifier223_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 66) ) { return retval; }
<             // JavaScript.g:1383:2: ( BREAK ( Identifier )? semic )
<             // JavaScript.g:1383:4: BREAK ( Identifier )? semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             BREAK222=(Token)match(input,BREAK,FOLLOW_BREAK_in_breakStatement5324); 
<             BREAK222_tree = (MyAstNode)adaptor.create(BREAK222);
<             root_0 = (MyAstNode)adaptor.becomeRoot(BREAK222_tree, root_0);
< 
<              if (input.LA(1) == Identifier) promoteEOL(null); 
<             // JavaScript.g:1383:64: ( Identifier )?
<             int alt63=2;
<             int LA63_0 = input.LA(1);
< 
<             if ( (LA63_0==Identifier) ) {
<                 alt63=1;
<             }
<             switch (alt63) {
<                 case 1 :
<                     // JavaScript.g:1383:64: Identifier
<                     {
<                     Identifier223=(Token)match(input,Identifier,FOLLOW_Identifier_in_breakStatement5329); 
<                     Identifier223_tree = (MyAstNode)adaptor.create(Identifier223);
<                     adaptor.addChild(root_0, Identifier223_tree);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_semic_in_breakStatement5332);
<             semic224=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "breakStatement"
< 
<     public static class returnStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "returnStatement"
<     // JavaScript.g:1403:1: returnStatement : RETURN ( expression )? semic ;
<     public final JavaScriptParser.returnStatement_return returnStatement() throws RecognitionException {
<         JavaScriptParser.returnStatement_return retval = new JavaScriptParser.returnStatement_return();
<         retval.start = input.LT(1);
<         int returnStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token RETURN225=null;
<         JavaScriptParser.expression_return expression226 = null;
< 
<         JavaScriptParser.semic_return semic227 = null;
< 
< 
<         MyAstNode RETURN225_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 67) ) { return retval; }
<             // JavaScript.g:1404:2: ( RETURN ( expression )? semic )
<             // JavaScript.g:1404:4: RETURN ( expression )? semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             RETURN225=(Token)match(input,RETURN,FOLLOW_RETURN_in_returnStatement5351); 
<             RETURN225_tree = (MyAstNode)adaptor.create(RETURN225);
<             root_0 = (MyAstNode)adaptor.becomeRoot(RETURN225_tree, root_0);
< 
<              promoteEOL(null); 
<             // JavaScript.g:1404:34: ( expression )?
<             int alt64=2;
<             int LA64_0 = input.LA(1);
< 
<             if ( ((LA64_0>=NULL && LA64_0<=FALSE)||LA64_0==DELETE||LA64_0==FUNCTION||LA64_0==NEW||LA64_0==THIS||LA64_0==TYPEOF||LA64_0==VOID||LA64_0==LBRACE||LA64_0==LPAREN||LA64_0==LBRACK||(LA64_0>=ADD && LA64_0<=SUB)||(LA64_0>=INC && LA64_0<=DEC)||(LA64_0>=NOT && LA64_0<=INV)||(LA64_0>=Identifier && LA64_0<=StringLiteral)||LA64_0==RegularExpressionLiteral||(LA64_0>=DecimalLiteral && LA64_0<=HexIntegerLiteral)) ) {
<                 alt64=1;
<             }
<             switch (alt64) {
<                 case 1 :
<                     // JavaScript.g:1404:34: expression
<                     {
<                     pushFollow(FOLLOW_expression_in_returnStatement5356);
<                     expression226=expression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, expression226.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_semic_in_returnStatement5359);
<             semic227=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "returnStatement"
< 
<     public static class withStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "withStatement"
<     // JavaScript.g:1411:1: withStatement : WITH LPAREN expression RPAREN statement ;
<     public final JavaScriptParser.withStatement_return withStatement() throws RecognitionException {
<         JavaScriptParser.withStatement_return retval = new JavaScriptParser.withStatement_return();
<         retval.start = input.LT(1);
<         int withStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token WITH228=null;
<         Token LPAREN229=null;
<         Token RPAREN231=null;
<         JavaScriptParser.expression_return expression230 = null;
< 
<         JavaScriptParser.statement_return statement232 = null;
< 
< 
<         MyAstNode WITH228_tree=null;
<         MyAstNode LPAREN229_tree=null;
<         MyAstNode RPAREN231_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 68) ) { return retval; }
<             // JavaScript.g:1412:2: ( WITH LPAREN expression RPAREN statement )
<             // JavaScript.g:1412:4: WITH LPAREN expression RPAREN statement
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             WITH228=(Token)match(input,WITH,FOLLOW_WITH_in_withStatement5376); 
<             WITH228_tree = (MyAstNode)adaptor.create(WITH228);
<             root_0 = (MyAstNode)adaptor.becomeRoot(WITH228_tree, root_0);
< 
<             LPAREN229=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_withStatement5379); 
<             pushFollow(FOLLOW_expression_in_withStatement5382);
<             expression230=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression230.getTree());
<             RPAREN231=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_withStatement5384); 
<             pushFollow(FOLLOW_statement_in_withStatement5387);
<             statement232=statement();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, statement232.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "withStatement"
< 
<     public static class switchStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "switchStatement"
<     // JavaScript.g:1419:1: switchStatement : SWITCH LPAREN expression RPAREN LBRACE ({...}? => defaultClause | caseClause )* RBRACE -> ^( SWITCH expression ( defaultClause )? ( caseClause )* ) ;
<     public final JavaScriptParser.switchStatement_return switchStatement() throws RecognitionException {
<         JavaScriptParser.switchStatement_return retval = new JavaScriptParser.switchStatement_return();
<         retval.start = input.LT(1);
<         int switchStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SWITCH233=null;
<         Token LPAREN234=null;
<         Token RPAREN236=null;
<         Token LBRACE237=null;
<         Token RBRACE240=null;
<         JavaScriptParser.expression_return expression235 = null;
< 
<         JavaScriptParser.defaultClause_return defaultClause238 = null;
< 
<         JavaScriptParser.caseClause_return caseClause239 = null;
< 
< 
<         MyAstNode SWITCH233_tree=null;
<         MyAstNode LPAREN234_tree=null;
<         MyAstNode RPAREN236_tree=null;
<         MyAstNode LBRACE237_tree=null;
<         MyAstNode RBRACE240_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_SWITCH=new RewriteRuleTokenStream(adaptor,"token SWITCH");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_caseClause=new RewriteRuleSubtreeStream(adaptor,"rule caseClause");
<         RewriteRuleSubtreeStream stream_defaultClause=new RewriteRuleSubtreeStream(adaptor,"rule defaultClause");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
< 
<         	int defaultClauseCount = 0;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 69) ) { return retval; }
<             // JavaScript.g:1424:2: ( SWITCH LPAREN expression RPAREN LBRACE ({...}? => defaultClause | caseClause )* RBRACE -> ^( SWITCH expression ( defaultClause )? ( caseClause )* ) )
<             // JavaScript.g:1424:4: SWITCH LPAREN expression RPAREN LBRACE ({...}? => defaultClause | caseClause )* RBRACE
<             {
<             SWITCH233=(Token)match(input,SWITCH,FOLLOW_SWITCH_in_switchStatement5408);  
<             stream_SWITCH.add(SWITCH233);
< 
<             LPAREN234=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_switchStatement5410);  
<             stream_LPAREN.add(LPAREN234);
< 
<             pushFollow(FOLLOW_expression_in_switchStatement5412);
<             expression235=expression();
< 
<             state._fsp--;
< 
<             stream_expression.add(expression235.getTree());
<             RPAREN236=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_switchStatement5414);  
<             stream_RPAREN.add(RPAREN236);
< 
<             LBRACE237=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_switchStatement5416);  
<             stream_LBRACE.add(LBRACE237);
< 
<             // JavaScript.g:1424:43: ({...}? => defaultClause | caseClause )*
<             loop65:
<             do {
<                 int alt65=3;
<                 int LA65_0 = input.LA(1);
< 
<                 if ( (LA65_0==DEFAULT) && (( defaultClauseCount == 0 ))) {
<                     alt65=1;
<                 }
<                 else if ( (LA65_0==CASE) ) {
<                     alt65=2;
<                 }
< 
< 
<                 switch (alt65) {
<             	case 1 :
<             	    // JavaScript.g:1424:45: {...}? => defaultClause
<             	    {
<             	    if ( !(( defaultClauseCount == 0 )) ) {
<             	        throw new FailedPredicateException(input, "switchStatement", " defaultClauseCount == 0 ");
<             	    }
<             	    pushFollow(FOLLOW_defaultClause_in_switchStatement5423);
<             	    defaultClause238=defaultClause();
< 
<             	    state._fsp--;
< 
<             	    stream_defaultClause.add(defaultClause238.getTree());
<             	     defaultClauseCount++; 
< 
<             	    }
<             	    break;
<             	case 2 :
<             	    // JavaScript.g:1424:118: caseClause
<             	    {
<             	    pushFollow(FOLLOW_caseClause_in_switchStatement5429);
<             	    caseClause239=caseClause();
< 
<             	    state._fsp--;
< 
<             	    stream_caseClause.add(caseClause239.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop65;
<                 }
<             } while (true);
< 
<             RBRACE240=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_switchStatement5434);  
<             stream_RBRACE.add(RBRACE240);
< 
< 
< 
<             // AST REWRITE
<             // elements: defaultClause, SWITCH, expression, caseClause
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1425:2: -> ^( SWITCH expression ( defaultClause )? ( caseClause )* )
<             {
<                 // JavaScript.g:1425:5: ^( SWITCH expression ( defaultClause )? ( caseClause )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_SWITCH.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_expression.nextTree());
<                 // JavaScript.g:1425:26: ( defaultClause )?
<                 if ( stream_defaultClause.hasNext() ) {
<                     adaptor.addChild(root_1, stream_defaultClause.nextTree());
< 
<                 }
<                 stream_defaultClause.reset();
<                 // JavaScript.g:1425:41: ( caseClause )*
<                 while ( stream_caseClause.hasNext() ) {
<                     adaptor.addChild(root_1, stream_caseClause.nextTree());
< 
<                 }
<                 stream_caseClause.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "switchStatement"
< 
<     public static class caseClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "caseClause"
<     // JavaScript.g:1428:1: caseClause : CASE expression COLON ( statement )* ;
<     public final JavaScriptParser.caseClause_return caseClause() throws RecognitionException {
<         JavaScriptParser.caseClause_return retval = new JavaScriptParser.caseClause_return();
<         retval.start = input.LT(1);
<         int caseClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token CASE241=null;
<         Token COLON243=null;
<         JavaScriptParser.expression_return expression242 = null;
< 
<         JavaScriptParser.statement_return statement244 = null;
< 
< 
<         MyAstNode CASE241_tree=null;
<         MyAstNode COLON243_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 70) ) { return retval; }
<             // JavaScript.g:1429:2: ( CASE expression COLON ( statement )* )
<             // JavaScript.g:1429:4: CASE expression COLON ( statement )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             CASE241=(Token)match(input,CASE,FOLLOW_CASE_in_caseClause5462); 
<             CASE241_tree = (MyAstNode)adaptor.create(CASE241);
<             root_0 = (MyAstNode)adaptor.becomeRoot(CASE241_tree, root_0);
< 
<             pushFollow(FOLLOW_expression_in_caseClause5465);
<             expression242=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression242.getTree());
<             COLON243=(Token)match(input,COLON,FOLLOW_COLON_in_caseClause5467); 
<             // JavaScript.g:1429:28: ( statement )*
<             loop66:
<             do {
<                 int alt66=2;
<                 int LA66_0 = input.LA(1);
< 
<                 if ( ((LA66_0>=NULL && LA66_0<=BREAK)||LA66_0==CONTINUE||(LA66_0>=DELETE && LA66_0<=DO)||(LA66_0>=FOR && LA66_0<=IF)||(LA66_0>=NEW && LA66_0<=WITH)||LA66_0==LBRACE||LA66_0==LPAREN||LA66_0==LBRACK||LA66_0==SEMIC||(LA66_0>=ADD && LA66_0<=SUB)||(LA66_0>=INC && LA66_0<=DEC)||(LA66_0>=NOT && LA66_0<=INV)||(LA66_0>=Identifier && LA66_0<=StringLiteral)||LA66_0==RegularExpressionLiteral||(LA66_0>=DecimalLiteral && LA66_0<=HexIntegerLiteral)) ) {
<                     alt66=1;
<                 }
< 
< 
<                 switch (alt66) {
<             	case 1 :
<             	    // JavaScript.g:1429:28: statement
<             	    {
<             	    pushFollow(FOLLOW_statement_in_caseClause5470);
<             	    statement244=statement();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, statement244.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop66;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "caseClause"
< 
<     public static class defaultClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "defaultClause"
<     // JavaScript.g:1432:1: defaultClause : DEFAULT COLON ( statement )* ;
<     public final JavaScriptParser.defaultClause_return defaultClause() throws RecognitionException {
<         JavaScriptParser.defaultClause_return retval = new JavaScriptParser.defaultClause_return();
<         retval.start = input.LT(1);
<         int defaultClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token DEFAULT245=null;
<         Token COLON246=null;
<         JavaScriptParser.statement_return statement247 = null;
< 
< 
<         MyAstNode DEFAULT245_tree=null;
<         MyAstNode COLON246_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 71) ) { return retval; }
<             // JavaScript.g:1433:2: ( DEFAULT COLON ( statement )* )
<             // JavaScript.g:1433:4: DEFAULT COLON ( statement )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             DEFAULT245=(Token)match(input,DEFAULT,FOLLOW_DEFAULT_in_defaultClause5483); 
<             DEFAULT245_tree = (MyAstNode)adaptor.create(DEFAULT245);
<             root_0 = (MyAstNode)adaptor.becomeRoot(DEFAULT245_tree, root_0);
< 
<             COLON246=(Token)match(input,COLON,FOLLOW_COLON_in_defaultClause5486); 
<             // JavaScript.g:1433:20: ( statement )*
<             loop67:
<             do {
<                 int alt67=2;
<                 int LA67_0 = input.LA(1);
< 
<                 if ( ((LA67_0>=NULL && LA67_0<=BREAK)||LA67_0==CONTINUE||(LA67_0>=DELETE && LA67_0<=DO)||(LA67_0>=FOR && LA67_0<=IF)||(LA67_0>=NEW && LA67_0<=WITH)||LA67_0==LBRACE||LA67_0==LPAREN||LA67_0==LBRACK||LA67_0==SEMIC||(LA67_0>=ADD && LA67_0<=SUB)||(LA67_0>=INC && LA67_0<=DEC)||(LA67_0>=NOT && LA67_0<=INV)||(LA67_0>=Identifier && LA67_0<=StringLiteral)||LA67_0==RegularExpressionLiteral||(LA67_0>=DecimalLiteral && LA67_0<=HexIntegerLiteral)) ) {
<                     alt67=1;
<                 }
< 
< 
<                 switch (alt67) {
<             	case 1 :
<             	    // JavaScript.g:1433:20: statement
<             	    {
<             	    pushFollow(FOLLOW_statement_in_defaultClause5489);
<             	    statement247=statement();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, statement247.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop67;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "defaultClause"
< 
<     public static class labelledStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "labelledStatement"
<     // JavaScript.g:1440:1: labelledStatement : Identifier COLON statement -> ^( LABELLED Identifier statement ) ;
<     public final JavaScriptParser.labelledStatement_return labelledStatement() throws RecognitionException {
<         JavaScriptParser.labelledStatement_return retval = new JavaScriptParser.labelledStatement_return();
<         retval.start = input.LT(1);
<         int labelledStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier248=null;
<         Token COLON249=null;
<         JavaScriptParser.statement_return statement250 = null;
< 
< 
<         MyAstNode Identifier248_tree=null;
<         MyAstNode COLON249_tree=null;
<         RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 72) ) { return retval; }
<             // JavaScript.g:1441:2: ( Identifier COLON statement -> ^( LABELLED Identifier statement ) )
<             // JavaScript.g:1441:4: Identifier COLON statement
<             {
<             Identifier248=(Token)match(input,Identifier,FOLLOW_Identifier_in_labelledStatement5506);  
<             stream_Identifier.add(Identifier248);
< 
<             COLON249=(Token)match(input,COLON,FOLLOW_COLON_in_labelledStatement5508);  
<             stream_COLON.add(COLON249);
< 
<             pushFollow(FOLLOW_statement_in_labelledStatement5510);
<             statement250=statement();
< 
<             state._fsp--;
< 
<             stream_statement.add(statement250.getTree());
< 
< 
<             // AST REWRITE
<             // elements: statement, Identifier
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1442:2: -> ^( LABELLED Identifier statement )
<             {
<                 // JavaScript.g:1442:5: ^( LABELLED Identifier statement )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(LABELLED, "LABELLED"), root_1);
< 
<                 adaptor.addChild(root_1, stream_Identifier.nextNode());
<                 adaptor.addChild(root_1, stream_statement.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "labelledStatement"
< 
<     public static class throwStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "throwStatement"
<     // JavaScript.g:1464:1: throwStatement : THROW expression semic ;
<     public final JavaScriptParser.throwStatement_return throwStatement() throws RecognitionException {
<         JavaScriptParser.throwStatement_return retval = new JavaScriptParser.throwStatement_return();
<         retval.start = input.LT(1);
<         int throwStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token THROW251=null;
<         JavaScriptParser.expression_return expression252 = null;
< 
<         JavaScriptParser.semic_return semic253 = null;
< 
< 
<         MyAstNode THROW251_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 73) ) { return retval; }
<             // JavaScript.g:1465:2: ( THROW expression semic )
<             // JavaScript.g:1465:4: THROW expression semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             THROW251=(Token)match(input,THROW,FOLLOW_THROW_in_throwStatement5541); 
<             THROW251_tree = (MyAstNode)adaptor.create(THROW251);
<             root_0 = (MyAstNode)adaptor.becomeRoot(THROW251_tree, root_0);
< 
<              promoteEOL(null); 
<             pushFollow(FOLLOW_expression_in_throwStatement5546);
<             expression252=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression252.getTree());
<             pushFollow(FOLLOW_semic_in_throwStatement5548);
<             semic253=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "throwStatement"
< 
<     public static class tryStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "tryStatement"
<     // JavaScript.g:1472:1: tryStatement : TRY block ( catchClause ( finallyClause )? | finallyClause ) ;
<     public final JavaScriptParser.tryStatement_return tryStatement() throws RecognitionException {
<         JavaScriptParser.tryStatement_return retval = new JavaScriptParser.tryStatement_return();
<         retval.start = input.LT(1);
<         int tryStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token TRY254=null;
<         JavaScriptParser.block_return block255 = null;
< 
<         JavaScriptParser.catchClause_return catchClause256 = null;
< 
<         JavaScriptParser.finallyClause_return finallyClause257 = null;
< 
<         JavaScriptParser.finallyClause_return finallyClause258 = null;
< 
< 
<         MyAstNode TRY254_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 74) ) { return retval; }
<             // JavaScript.g:1473:2: ( TRY block ( catchClause ( finallyClause )? | finallyClause ) )
<             // JavaScript.g:1473:4: TRY block ( catchClause ( finallyClause )? | finallyClause )
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             TRY254=(Token)match(input,TRY,FOLLOW_TRY_in_tryStatement5565); 
<             TRY254_tree = (MyAstNode)adaptor.create(TRY254);
<             root_0 = (MyAstNode)adaptor.becomeRoot(TRY254_tree, root_0);
< 
<             pushFollow(FOLLOW_block_in_tryStatement5568);
<             block255=block();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, block255.getTree());
<             // JavaScript.g:1473:15: ( catchClause ( finallyClause )? | finallyClause )
<             int alt69=2;
<             int LA69_0 = input.LA(1);
< 
<             if ( (LA69_0==CATCH) ) {
<                 alt69=1;
<             }
<             else if ( (LA69_0==FINALLY) ) {
<                 alt69=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 69, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt69) {
<                 case 1 :
<                     // JavaScript.g:1473:17: catchClause ( finallyClause )?
<                     {
<                     pushFollow(FOLLOW_catchClause_in_tryStatement5572);
<                     catchClause256=catchClause();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, catchClause256.getTree());
<                     // JavaScript.g:1473:29: ( finallyClause )?
<                     int alt68=2;
<                     int LA68_0 = input.LA(1);
< 
<                     if ( (LA68_0==FINALLY) ) {
<                         alt68=1;
<                     }
<                     switch (alt68) {
<                         case 1 :
<                             // JavaScript.g:1473:29: finallyClause
<                             {
<                             pushFollow(FOLLOW_finallyClause_in_tryStatement5574);
<                             finallyClause257=finallyClause();
< 
<                             state._fsp--;
< 
<                             adaptor.addChild(root_0, finallyClause257.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1473:46: finallyClause
<                     {
<                     pushFollow(FOLLOW_finallyClause_in_tryStatement5579);
<                     finallyClause258=finallyClause();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, finallyClause258.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "tryStatement"
< 
<     public static class catchClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "catchClause"
<     // JavaScript.g:1476:1: catchClause : CATCH LPAREN Identifier RPAREN block ;
<     public final JavaScriptParser.catchClause_return catchClause() throws RecognitionException {
<         JavaScriptParser.catchClause_return retval = new JavaScriptParser.catchClause_return();
<         retval.start = input.LT(1);
<         int catchClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token CATCH259=null;
<         Token LPAREN260=null;
<         Token Identifier261=null;
<         Token RPAREN262=null;
<         JavaScriptParser.block_return block263 = null;
< 
< 
<         MyAstNode CATCH259_tree=null;
<         MyAstNode LPAREN260_tree=null;
<         MyAstNode Identifier261_tree=null;
<         MyAstNode RPAREN262_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 75) ) { return retval; }
<             // JavaScript.g:1477:2: ( CATCH LPAREN Identifier RPAREN block )
<             // JavaScript.g:1477:4: CATCH LPAREN Identifier RPAREN block
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             CATCH259=(Token)match(input,CATCH,FOLLOW_CATCH_in_catchClause5593); 
<             CATCH259_tree = (MyAstNode)adaptor.create(CATCH259);
<             root_0 = (MyAstNode)adaptor.becomeRoot(CATCH259_tree, root_0);
< 
<             LPAREN260=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_catchClause5596); 
<             Identifier261=(Token)match(input,Identifier,FOLLOW_Identifier_in_catchClause5599); 
<             Identifier261_tree = (MyAstNode)adaptor.create(Identifier261);
<             adaptor.addChild(root_0, Identifier261_tree);
< 
<             RPAREN262=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_catchClause5601); 
<             pushFollow(FOLLOW_block_in_catchClause5604);
<             block263=block();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, block263.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "catchClause"
< 
<     public static class finallyClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "finallyClause"
<     // JavaScript.g:1480:1: finallyClause : FINALLY block ;
<     public final JavaScriptParser.finallyClause_return finallyClause() throws RecognitionException {
<         JavaScriptParser.finallyClause_return retval = new JavaScriptParser.finallyClause_return();
<         retval.start = input.LT(1);
<         int finallyClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token FINALLY264=null;
<         JavaScriptParser.block_return block265 = null;
< 
< 
<         MyAstNode FINALLY264_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 76) ) { return retval; }
<             // JavaScript.g:1481:2: ( FINALLY block )
<             // JavaScript.g:1481:4: FINALLY block
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             FINALLY264=(Token)match(input,FINALLY,FOLLOW_FINALLY_in_finallyClause5616); 
<             FINALLY264_tree = (MyAstNode)adaptor.create(FINALLY264);
<             root_0 = (MyAstNode)adaptor.becomeRoot(FINALLY264_tree, root_0);
< 
<             pushFollow(FOLLOW_block_in_finallyClause5619);
<             block265=block();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, block265.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "finallyClause"
< 
<     public static class functionDeclaration_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "functionDeclaration"
<     // JavaScript.g:1494:1: functionDeclaration : FUNCTION name= Identifier formalParameterList functionBody -> ^( FUNCTION $name formalParameterList functionBody ) ;
<     public final JavaScriptParser.functionDeclaration_return functionDeclaration() throws RecognitionException {
<         JavaScriptParser.functionDeclaration_return retval = new JavaScriptParser.functionDeclaration_return();
<         retval.start = input.LT(1);
<         int functionDeclaration_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token name=null;
<         Token FUNCTION266=null;
<         JavaScriptParser.formalParameterList_return formalParameterList267 = null;
< 
<         JavaScriptParser.functionBody_return functionBody268 = null;
< 
< 
<         MyAstNode name_tree=null;
<         MyAstNode FUNCTION266_tree=null;
<         RewriteRuleTokenStream stream_FUNCTION=new RewriteRuleTokenStream(adaptor,"token FUNCTION");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleSubtreeStream stream_formalParameterList=new RewriteRuleSubtreeStream(adaptor,"rule formalParameterList");
<         RewriteRuleSubtreeStream stream_functionBody=new RewriteRuleSubtreeStream(adaptor,"rule functionBody");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 77) ) { return retval; }
<             // JavaScript.g:1495:2: ( FUNCTION name= Identifier formalParameterList functionBody -> ^( FUNCTION $name formalParameterList functionBody ) )
<             // JavaScript.g:1495:4: FUNCTION name= Identifier formalParameterList functionBody
<             {
<             FUNCTION266=(Token)match(input,FUNCTION,FOLLOW_FUNCTION_in_functionDeclaration5640);  
<             stream_FUNCTION.add(FUNCTION266);
< 
<             name=(Token)match(input,Identifier,FOLLOW_Identifier_in_functionDeclaration5644);  
<             stream_Identifier.add(name);
< 
<             pushFollow(FOLLOW_formalParameterList_in_functionDeclaration5646);
<             formalParameterList267=formalParameterList();
< 
<             state._fsp--;
< 
<             stream_formalParameterList.add(formalParameterList267.getTree());
<             pushFollow(FOLLOW_functionBody_in_functionDeclaration5648);
<             functionBody268=functionBody();
< 
<             state._fsp--;
< 
<             stream_functionBody.add(functionBody268.getTree());
< 
< 
<             // AST REWRITE
<             // elements: name, FUNCTION, functionBody, formalParameterList
<             // token labels: name
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1496:2: -> ^( FUNCTION $name formalParameterList functionBody )
<             {
<                 // JavaScript.g:1496:5: ^( FUNCTION $name formalParameterList functionBody )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_FUNCTION.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_name.nextNode());
<                 adaptor.addChild(root_1, stream_formalParameterList.nextTree());
<                 adaptor.addChild(root_1, stream_functionBody.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "functionDeclaration"
< 
<     public static class functionExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "functionExpression"
<     // JavaScript.g:1499:1: functionExpression : FUNCTION (name= Identifier )? formalParameterList functionBody -> ^( FUNCTION ( $name)? formalParameterList functionBody ) ;
<     public final JavaScriptParser.functionExpression_return functionExpression() throws RecognitionException {
<         JavaScriptParser.functionExpression_return retval = new JavaScriptParser.functionExpression_return();
<         retval.start = input.LT(1);
<         int functionExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token name=null;
<         Token FUNCTION269=null;
<         JavaScriptParser.formalParameterList_return formalParameterList270 = null;
< 
<         JavaScriptParser.functionBody_return functionBody271 = null;
< 
< 
<         MyAstNode name_tree=null;
<         MyAstNode FUNCTION269_tree=null;
<         RewriteRuleTokenStream stream_FUNCTION=new RewriteRuleTokenStream(adaptor,"token FUNCTION");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleSubtreeStream stream_formalParameterList=new RewriteRuleSubtreeStream(adaptor,"rule formalParameterList");
<         RewriteRuleSubtreeStream stream_functionBody=new RewriteRuleSubtreeStream(adaptor,"rule functionBody");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 78) ) { return retval; }
<             // JavaScript.g:1500:2: ( FUNCTION (name= Identifier )? formalParameterList functionBody -> ^( FUNCTION ( $name)? formalParameterList functionBody ) )
<             // JavaScript.g:1500:4: FUNCTION (name= Identifier )? formalParameterList functionBody
<             {
<             FUNCTION269=(Token)match(input,FUNCTION,FOLLOW_FUNCTION_in_functionExpression5675);  
<             stream_FUNCTION.add(FUNCTION269);
< 
<             // JavaScript.g:1500:17: (name= Identifier )?
<             int alt70=2;
<             int LA70_0 = input.LA(1);
< 
<             if ( (LA70_0==Identifier) ) {
<                 alt70=1;
<             }
<             switch (alt70) {
<                 case 1 :
<                     // JavaScript.g:1500:17: name= Identifier
<                     {
<                     name=(Token)match(input,Identifier,FOLLOW_Identifier_in_functionExpression5679);  
<                     stream_Identifier.add(name);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_formalParameterList_in_functionExpression5682);
<             formalParameterList270=formalParameterList();
< 
<             state._fsp--;
< 
<             stream_formalParameterList.add(formalParameterList270.getTree());
<             pushFollow(FOLLOW_functionBody_in_functionExpression5684);
<             functionBody271=functionBody();
< 
<             state._fsp--;
< 
<             stream_functionBody.add(functionBody271.getTree());
< 
< 
<             // AST REWRITE
<             // elements: functionBody, formalParameterList, FUNCTION, name
<             // token labels: name
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1501:2: -> ^( FUNCTION ( $name)? formalParameterList functionBody )
<             {
<                 // JavaScript.g:1501:5: ^( FUNCTION ( $name)? formalParameterList functionBody )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_FUNCTION.nextNode(), root_1);
< 
<                 // JavaScript.g:1501:17: ( $name)?
<                 if ( stream_name.hasNext() ) {
<                     adaptor.addChild(root_1, stream_name.nextNode());
< 
<                 }
<                 stream_name.reset();
<                 adaptor.addChild(root_1, stream_formalParameterList.nextTree());
<                 adaptor.addChild(root_1, stream_functionBody.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "functionExpression"
< 
<     public static class formalParameterList_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "formalParameterList"
<     // JavaScript.g:1504:1: formalParameterList : LPAREN (args+= Identifier ( COMMA args+= Identifier )* )? RPAREN -> ^( ARGS ( $args)* ) ;
<     public final JavaScriptParser.formalParameterList_return formalParameterList() throws RecognitionException {
<         JavaScriptParser.formalParameterList_return retval = new JavaScriptParser.formalParameterList_return();
<         retval.start = input.LT(1);
<         int formalParameterList_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LPAREN272=null;
<         Token COMMA273=null;
<         Token RPAREN274=null;
<         Token args=null;
<         List list_args=null;
< 
<         MyAstNode LPAREN272_tree=null;
<         MyAstNode COMMA273_tree=null;
<         MyAstNode RPAREN274_tree=null;
<         MyAstNode args_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 79) ) { return retval; }
<             // JavaScript.g:1505:2: ( LPAREN (args+= Identifier ( COMMA args+= Identifier )* )? RPAREN -> ^( ARGS ( $args)* ) )
<             // JavaScript.g:1505:4: LPAREN (args+= Identifier ( COMMA args+= Identifier )* )? RPAREN
<             {
<             LPAREN272=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_formalParameterList5712);  
<             stream_LPAREN.add(LPAREN272);
< 
<             // JavaScript.g:1505:11: (args+= Identifier ( COMMA args+= Identifier )* )?
<             int alt72=2;
<             int LA72_0 = input.LA(1);
< 
<             if ( (LA72_0==Identifier) ) {
<                 alt72=1;
<             }
<             switch (alt72) {
<                 case 1 :
<                     // JavaScript.g:1505:13: args+= Identifier ( COMMA args+= Identifier )*
<                     {
<                     args=(Token)match(input,Identifier,FOLLOW_Identifier_in_formalParameterList5718);  
<                     stream_Identifier.add(args);
< 
<                     if (list_args==null) list_args=new ArrayList();
<                     list_args.add(args);
< 
<                     // JavaScript.g:1505:30: ( COMMA args+= Identifier )*
<                     loop71:
<                     do {
<                         int alt71=2;
<                         int LA71_0 = input.LA(1);
< 
<                         if ( (LA71_0==COMMA) ) {
<                             alt71=1;
<                         }
< 
< 
<                         switch (alt71) {
<                     	case 1 :
<                     	    // JavaScript.g:1505:32: COMMA args+= Identifier
<                     	    {
<                     	    COMMA273=(Token)match(input,COMMA,FOLLOW_COMMA_in_formalParameterList5722);  
<                     	    stream_COMMA.add(COMMA273);
< 
<                     	    args=(Token)match(input,Identifier,FOLLOW_Identifier_in_formalParameterList5726);  
<                     	    stream_Identifier.add(args);
< 
<                     	    if (list_args==null) list_args=new ArrayList();
<                     	    list_args.add(args);
< 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop71;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RPAREN274=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_formalParameterList5734);  
<             stream_RPAREN.add(RPAREN274);
< 
< 
< 
<             // AST REWRITE
<             // elements: args
<             // token labels: 
<             // rule labels: retval
<             // token list labels: args
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleTokenStream stream_args=new RewriteRuleTokenStream(adaptor,"token args", list_args);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1506:2: -> ^( ARGS ( $args)* )
<             {
<                 // JavaScript.g:1506:5: ^( ARGS ( $args)* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ARGS, "ARGS"), root_1);
< 
<                 // JavaScript.g:1506:13: ( $args)*
<                 while ( stream_args.hasNext() ) {
<                     adaptor.addChild(root_1, stream_args.nextNode());
< 
<                 }
<                 stream_args.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "formalParameterList"
< 
<     public static class functionBody_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "functionBody"
<     // JavaScript.g:1509:1: functionBody : lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) ;
<     public final JavaScriptParser.functionBody_return functionBody() throws RecognitionException {
<         JavaScriptParser.functionBody_return retval = new JavaScriptParser.functionBody_return();
<         retval.start = input.LT(1);
<         int functionBody_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token RBRACE276=null;
<         JavaScriptParser.sourceElement_return sourceElement275 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode RBRACE276_tree=null;
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_sourceElement=new RewriteRuleSubtreeStream(adaptor,"rule sourceElement");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 80) ) { return retval; }
<             // JavaScript.g:1510:2: (lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) )
<             // JavaScript.g:1510:4: lb= LBRACE ( sourceElement )* RBRACE
<             {
<             lb=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_functionBody5760);  
<             stream_LBRACE.add(lb);
< 
<             // JavaScript.g:1510:14: ( sourceElement )*
<             loop73:
<             do {
<                 int alt73=2;
<                 int LA73_0 = input.LA(1);
< 
<                 if ( ((LA73_0>=NULL && LA73_0<=BREAK)||LA73_0==CONTINUE||(LA73_0>=DELETE && LA73_0<=DO)||(LA73_0>=FOR && LA73_0<=IF)||(LA73_0>=NEW && LA73_0<=WITH)||LA73_0==LBRACE||LA73_0==LPAREN||LA73_0==LBRACK||LA73_0==SEMIC||(LA73_0>=ADD && LA73_0<=SUB)||(LA73_0>=INC && LA73_0<=DEC)||(LA73_0>=NOT && LA73_0<=INV)||(LA73_0>=Identifier && LA73_0<=StringLiteral)||LA73_0==RegularExpressionLiteral||(LA73_0>=DecimalLiteral && LA73_0<=HexIntegerLiteral)) ) {
<                     alt73=1;
<                 }
< 
< 
<                 switch (alt73) {
<             	case 1 :
<             	    // JavaScript.g:1510:14: sourceElement
<             	    {
<             	    pushFollow(FOLLOW_sourceElement_in_functionBody5762);
<             	    sourceElement275=sourceElement();
< 
<             	    state._fsp--;
< 
<             	    stream_sourceElement.add(sourceElement275.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop73;
<                 }
<             } while (true);
< 
<             RBRACE276=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_functionBody5765);  
<             stream_RBRACE.add(RBRACE276);
< 
< 
< 
<             // AST REWRITE
<             // elements: sourceElement
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1511:2: -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<             {
<                 // JavaScript.g:1511:5: ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BLOCK, lb, "BLOCK"), root_1);
< 
<                 // JavaScript.g:1511:28: ( sourceElement )*
<                 while ( stream_sourceElement.hasNext() ) {
<                     adaptor.addChild(root_1, stream_sourceElement.nextTree());
< 
<                 }
<                 stream_sourceElement.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "functionBody"
< 
<     public static class program_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "program"
<     // JavaScript.g:1518:1: program : ( sourceElement )* ;
<     public final JavaScriptParser.program_return program() throws RecognitionException {
<         JavaScriptParser.program_return retval = new JavaScriptParser.program_return();
<         retval.start = input.LT(1);
<         int program_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.sourceElement_return sourceElement277 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 81) ) { return retval; }
<             // JavaScript.g:1519:2: ( ( sourceElement )* )
<             // JavaScript.g:1519:4: ( sourceElement )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             // JavaScript.g:1519:4: ( sourceElement )*
<             loop74:
<             do {
<                 int alt74=2;
<                 int LA74_0 = input.LA(1);
< 
<                 if ( ((LA74_0>=NULL && LA74_0<=BREAK)||LA74_0==CONTINUE||(LA74_0>=DELETE && LA74_0<=DO)||(LA74_0>=FOR && LA74_0<=IF)||(LA74_0>=NEW && LA74_0<=WITH)||LA74_0==LBRACE||LA74_0==LPAREN||LA74_0==LBRACK||LA74_0==SEMIC||(LA74_0>=ADD && LA74_0<=SUB)||(LA74_0>=INC && LA74_0<=DEC)||(LA74_0>=NOT && LA74_0<=INV)||(LA74_0>=Identifier && LA74_0<=StringLiteral)||LA74_0==RegularExpressionLiteral||(LA74_0>=DecimalLiteral && LA74_0<=HexIntegerLiteral)) ) {
<                     alt74=1;
<                 }
< 
< 
<                 switch (alt74) {
<             	case 1 :
<             	    // JavaScript.g:1519:4: sourceElement
<             	    {
<             	    pushFollow(FOLLOW_sourceElement_in_program5794);
<             	    sourceElement277=sourceElement();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, sourceElement277.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop74;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "program"
< 
<     public static class sourceElement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "sourceElement"
<     // JavaScript.g:1527:1: sourceElement options {k=1; } : ({...}? functionDeclaration | statement );
<     public final JavaScriptParser.sourceElement_return sourceElement() throws RecognitionException {
<         JavaScriptParser.sourceElement_return retval = new JavaScriptParser.sourceElement_return();
<         retval.start = input.LT(1);
<         int sourceElement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.functionDeclaration_return functionDeclaration278 = null;
< 
<         JavaScriptParser.statement_return statement279 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 82) ) { return retval; }
<             // JavaScript.g:1532:2: ({...}? functionDeclaration | statement )
<             int alt75=2;
<             alt75 = dfa75.predict(input);
<             switch (alt75) {
<                 case 1 :
<                     // JavaScript.g:1532:4: {...}? functionDeclaration
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     if ( !(( input.LA(1) == FUNCTION )) ) {
<                         throw new FailedPredicateException(input, "sourceElement", " input.LA(1) == FUNCTION ");
<                     }
<                     pushFollow(FOLLOW_functionDeclaration_in_sourceElement5823);
<                     functionDeclaration278=functionDeclaration();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, functionDeclaration278.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1533:4: statement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_statement_in_sourceElement5828);
<                     statement279=statement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, statement279.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "sourceElement"
< 
<     // Delegated rules
< 
< 
<     protected DFA44 dfa44 = new DFA44(this);
<     protected DFA45 dfa45 = new DFA45(this);
<     protected DFA75 dfa75 = new DFA75(this);
<     static final String DFA44_eotS =
<         "\44\uffff";
<     static final String DFA44_eofS =
<         "\44\uffff";
<     static final String DFA44_minS =
<         "\1\4\1\0\42\uffff";
<     static final String DFA44_maxS =
<         "\1\u00a1\1\0\42\uffff";
<     static final String DFA44_acceptS =
<         "\2\uffff\1\2\40\uffff\1\1";
<     static final String DFA44_specialS =
<         "\1\uffff\1\0\42\uffff}>";
<     static final String[] DFA44_transitionS = {
<             "\4\2\2\uffff\1\2\1\uffff\2\2\2\uffff\3\2\2\uffff\13\2\37\uffff"+
<             "\1\1\1\uffff\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff\2\2\2\uffff"+
<             "\2\2\6\uffff\2\2\66\uffff\2\2\5\uffff\1\2\3\uffff\3\2",
<             "\1\uffff",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             ""
<     };
< 
<     static final short[] DFA44_eot = DFA.unpackEncodedString(DFA44_eotS);
<     static final short[] DFA44_eof = DFA.unpackEncodedString(DFA44_eofS);
<     static final char[] DFA44_min = DFA.unpackEncodedStringToUnsignedChars(DFA44_minS);
<     static final char[] DFA44_max = DFA.unpackEncodedStringToUnsignedChars(DFA44_maxS);
<     static final short[] DFA44_accept = DFA.unpackEncodedString(DFA44_acceptS);
<     static final short[] DFA44_special = DFA.unpackEncodedString(DFA44_specialS);
<     static final short[][] DFA44_transition;
< 
<     static {
<         int numStates = DFA44_transitionS.length;
<         DFA44_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA44_transition[i] = DFA.unpackEncodedString(DFA44_transitionS[i]);
<         }
<     }
< 
<     class DFA44 extends DFA {
< 
<         public DFA44(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 44;
<             this.eot = DFA44_eot;
<             this.eof = DFA44_eof;
<             this.min = DFA44_min;
<             this.max = DFA44_max;
<             this.accept = DFA44_accept;
<             this.special = DFA44_special;
<             this.transition = DFA44_transition;
<         }
<         public String getDescription() {
<             return "1166:1: statement options {k=1; } : ({...}? block | statementTail );";
<         }
<         public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
<             TokenStream input = (TokenStream)_input;
<         	int _s = s;
<             switch ( s ) {
<                     case 0 : 
<                         int LA44_1 = input.LA(1);
< 
<                          
<                         int index44_1 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( (( input.LA(1) == LBRACE )) ) {s = 35;}
< 
<                         else if ( (true) ) {s = 2;}
< 
<                          
<                         input.seek(index44_1);
<                         if ( s>=0 ) return s;
<                         break;
<             }
<             NoViableAltException nvae =
<                 new NoViableAltException(getDescription(), 44, _s, input);
<             error(nvae);
<             throw nvae;
<         }
<     }
<     static final String DFA45_eotS =
<         "\17\uffff";
<     static final String DFA45_eofS =
<         "\4\uffff\1\3\12\uffff";
<     static final String DFA45_minS =
<         "\1\4\3\uffff\1\23\12\uffff";
<     static final String DFA45_maxS =
<         "\1\u00a1\3\uffff\1\u0092\12\uffff";
<     static final String DFA45_acceptS =
<         "\1\uffff\1\1\1\2\1\3\1\uffff\1\4\1\5\1\6\1\7\1\10\1\11\1\13\1\14"+
<         "\1\15\1\12";
<     static final String DFA45_specialS =
<         "\17\uffff}>";
<     static final String[] DFA45_transitionS = {
<             "\3\3\1\10\2\uffff\1\7\1\uffff\1\3\1\6\2\uffff\1\6\1\3\1\5\2"+
<             "\uffff\1\3\1\11\1\13\1\3\1\14\1\15\1\3\1\1\1\3\1\6\1\12\37\uffff"+
<             "\1\3\1\uffff\1\3\1\uffff\1\3\2\uffff\1\2\11\uffff\2\3\2\uffff"+
<             "\2\3\6\uffff\2\3\66\uffff\1\4\1\3\5\uffff\1\3\3\uffff\3\3",
<             "",
<             "",
<             "",
<             "\2\3\53\uffff\2\3\1\uffff\1\3\1\uffff\27\3\2\uffff\3\3\1\16"+
<             "\15\3\42\uffff\2\3",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             ""
<     };
< 
<     static final short[] DFA45_eot = DFA.unpackEncodedString(DFA45_eotS);
<     static final short[] DFA45_eof = DFA.unpackEncodedString(DFA45_eofS);
<     static final char[] DFA45_min = DFA.unpackEncodedStringToUnsignedChars(DFA45_minS);
<     static final char[] DFA45_max = DFA.unpackEncodedStringToUnsignedChars(DFA45_maxS);
<     static final short[] DFA45_accept = DFA.unpackEncodedString(DFA45_acceptS);
<     static final short[] DFA45_special = DFA.unpackEncodedString(DFA45_specialS);
<     static final short[][] DFA45_transition;
< 
<     static {
<         int numStates = DFA45_transitionS.length;
<         DFA45_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA45_transition[i] = DFA.unpackEncodedString(DFA45_transitionS[i]);
<         }
<     }
< 
<     class DFA45 extends DFA {
< 
<         public DFA45(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 45;
<             this.eot = DFA45_eot;
<             this.eof = DFA45_eof;
<             this.min = DFA45_min;
<             this.max = DFA45_max;
<             this.accept = DFA45_accept;
<             this.special = DFA45_special;
<             this.transition = DFA45_transition;
<         }
<         public String getDescription() {
<             return "1179:1: statementTail : ( variableStatement | emptyStatement | expressionStatement | ifStatement | iterationStatement | continueStatement | breakStatement | returnStatement | withStatement | labelledStatement | switchStatement | throwStatement | tryStatement );";
<         }
<     }
<     static final String DFA75_eotS =
<         "\44\uffff";
<     static final String DFA75_eofS =
<         "\44\uffff";
<     static final String DFA75_minS =
<         "\1\4\1\0\42\uffff";
<     static final String DFA75_maxS =
<         "\1\u00a1\1\0\42\uffff";
<     static final String DFA75_acceptS =
<         "\2\uffff\1\2\40\uffff\1\1";
<     static final String DFA75_specialS =
<         "\1\uffff\1\0\42\uffff}>";
<     static final String[] DFA75_transitionS = {
<             "\4\2\2\uffff\1\2\1\uffff\2\2\2\uffff\1\2\1\1\1\2\2\uffff\13"+
<             "\2\37\uffff\1\2\1\uffff\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff"+
<             "\2\2\2\uffff\2\2\6\uffff\2\2\66\uffff\2\2\5\uffff\1\2\3\uffff"+
<             "\3\2",
<             "\1\uffff",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             ""
<     };
< 
<     static final short[] DFA75_eot = DFA.unpackEncodedString(DFA75_eotS);
<     static final short[] DFA75_eof = DFA.unpackEncodedString(DFA75_eofS);
<     static final char[] DFA75_min = DFA.unpackEncodedStringToUnsignedChars(DFA75_minS);
<     static final char[] DFA75_max = DFA.unpackEncodedStringToUnsignedChars(DFA75_maxS);
<     static final short[] DFA75_accept = DFA.unpackEncodedString(DFA75_acceptS);
<     static final short[] DFA75_special = DFA.unpackEncodedString(DFA75_specialS);
<     static final short[][] DFA75_transition;
< 
<     static {
<         int numStates = DFA75_transitionS.length;
<         DFA75_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA75_transition[i] = DFA.unpackEncodedString(DFA75_transitionS[i]);
<         }
<     }
< 
<     class DFA75 extends DFA {
< 
<         public DFA75(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 75;
<             this.eot = DFA75_eot;
<             this.eof = DFA75_eof;
<             this.min = DFA75_min;
<             this.max = DFA75_max;
<             this.accept = DFA75_accept;
<             this.special = DFA75_special;
<             this.transition = DFA75_transition;
<         }
<         public String getDescription() {
<             return "1527:1: sourceElement options {k=1; } : ({...}? functionDeclaration | statement );";
<         }
<         public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
<             TokenStream input = (TokenStream)_input;
<         	int _s = s;
<             switch ( s ) {
<                     case 0 : 
<                         int LA75_1 = input.LA(1);
< 
<                          
<                         int index75_1 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( (( input.LA(1) == FUNCTION )) ) {s = 35;}
< 
<                         else if ( (true) ) {s = 2;}
< 
<                          
<                         input.seek(index75_1);
<                         if ( s>=0 ) return s;
<                         break;
<             }
<             NoViableAltException nvae =
<                 new NoViableAltException(getDescription(), 75, _s, input);
<             error(nvae);
<             throw nvae;
<         }
<     }
<  
< 
<     public static final BitSet FOLLOW_reservedWord_in_token1756 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_token1761 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_punctuator_in_token1766 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_numericLiteral_in_token1771 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_StringLiteral_in_token1776 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_keyword_in_reservedWord1789 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_futureReservedWord_in_reservedWord1794 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NULL_in_reservedWord1799 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_booleanLiteral_in_reservedWord1804 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_keyword0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_futureReservedWord0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_punctuator0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NULL_in_literal2485 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_booleanLiteral_in_literal2490 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_numericLiteral_in_literal2495 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_StringLiteral_in_literal2500 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_RegularExpressionLiteral_in_literal2505 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_booleanLiteral0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_numericLiteral0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_THIS_in_primaryExpression3118 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_primaryExpression3123 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_literal_in_primaryExpression3128 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_arrayLiteral_in_primaryExpression3133 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_objectLiteral_in_primaryExpression3138 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_primaryExpression3145 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_primaryExpression3147 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_primaryExpression3149 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACK_in_arrayLiteral3173 = new BitSet(new long[]{0x8000000029221070L,0x000000003033009AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_arrayItem_in_arrayLiteral3177 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000090L});
<     public static final BitSet FOLLOW_COMMA_in_arrayLiteral3181 = new BitSet(new long[]{0x8000000029221070L,0x000000003033009AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_arrayItem_in_arrayLiteral3183 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000090L});
<     public static final BitSet FOLLOW_RBRACK_in_arrayLiteral3191 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_assignmentExpression_in_arrayItem3219 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACE_in_objectLiteral3251 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000001L,0x0000000380300000L});
<     public static final BitSet FOLLOW_nameValuePair_in_objectLiteral3255 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000081L});
<     public static final BitSet FOLLOW_COMMA_in_objectLiteral3259 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000380300000L});
<     public static final BitSet FOLLOW_nameValuePair_in_objectLiteral3261 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000081L});
<     public static final BitSet FOLLOW_RBRACE_in_objectLiteral3269 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_propertyName_in_nameValuePair3294 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_nameValuePair3296 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_nameValuePair3298 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_propertyName3322 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_StringLiteral_in_propertyName3327 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_numericLiteral_in_propertyName3332 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_primaryExpression_in_memberExpression3350 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_functionExpression_in_memberExpression3355 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_newExpression_in_memberExpression3360 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NEW_in_newExpression3371 = new BitSet(new long[]{0x8000000001000070L,0x000000000000000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_primaryExpression_in_newExpression3374 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NEW_in_newExpression3382 = new BitSet(new long[]{0x0000000000020000L});
<     public static final BitSet FOLLOW_functionExpression_in_newExpression3385 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_arguments3398 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000EL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_arguments3402 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_COMMA_in_arguments3406 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_arguments3408 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_RPAREN_in_arguments3416 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_memberExpression_in_leftHandSideExpression3445 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_arguments_in_leftHandSideExpression3461 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_LBRACK_in_leftHandSideExpression3482 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_leftHandSideExpression3484 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
<     public static final BitSet FOLLOW_RBRACK_in_leftHandSideExpression3486 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_DOT_in_leftHandSideExpression3505 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_leftHandSideExpression3507 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_leftHandSideExpression_in_postfixExpression3542 = new BitSet(new long[]{0x0000000000000002L,0x0000000000300000L});
<     public static final BitSet FOLLOW_postfixOperator_in_postfixExpression3548 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_INC_in_postfixOperator3566 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DEC_in_postfixOperator3575 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_postfixExpression_in_unaryExpression3592 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_unaryOperator_in_unaryExpression3597 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_unaryExpression_in_unaryExpression3600 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DELETE_in_unaryOperator3612 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_VOID_in_unaryOperator3617 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_TYPEOF_in_unaryOperator3622 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_INC_in_unaryOperator3627 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DEC_in_unaryOperator3632 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_ADD_in_unaryOperator3639 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SUB_in_unaryOperator3648 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_INV_in_unaryOperator3655 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NOT_in_unaryOperator3660 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_unaryExpression_in_multiplicativeExpression3675 = new BitSet(new long[]{0x0000000000000002L,0x00002000000C0000L});
<     public static final BitSet FOLLOW_set_in_multiplicativeExpression3679 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_unaryExpression_in_multiplicativeExpression3694 = new BitSet(new long[]{0x0000000000000002L,0x00002000000C0000L});
<     public static final BitSet FOLLOW_multiplicativeExpression_in_additiveExpression3712 = new BitSet(new long[]{0x0000000000000002L,0x0000000000030000L});
<     public static final BitSet FOLLOW_set_in_additiveExpression3716 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_multiplicativeExpression_in_additiveExpression3727 = new BitSet(new long[]{0x0000000000000002L,0x0000000000030000L});
<     public static final BitSet FOLLOW_additiveExpression_in_shiftExpression3746 = new BitSet(new long[]{0x0000000000000002L,0x0000000001C00000L});
<     public static final BitSet FOLLOW_set_in_shiftExpression3750 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_additiveExpression_in_shiftExpression3765 = new BitSet(new long[]{0x0000000000000002L,0x0000000001C00000L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpression3784 = new BitSet(new long[]{0x0000000000180002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_set_in_relationalExpression3788 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpression3815 = new BitSet(new long[]{0x0000000000180002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpressionNoIn3829 = new BitSet(new long[]{0x0000000000100002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_set_in_relationalExpressionNoIn3833 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpressionNoIn3856 = new BitSet(new long[]{0x0000000000100002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_relationalExpression_in_equalityExpression3875 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_set_in_equalityExpression3879 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_relationalExpression_in_equalityExpression3898 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3912 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_set_in_equalityExpressionNoIn3916 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3935 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_equalityExpression_in_bitwiseANDExpression3955 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_AND_in_bitwiseANDExpression3959 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_equalityExpression_in_bitwiseANDExpression3962 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3976 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_AND_in_bitwiseANDExpressionNoIn3980 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3983 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression3999 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_XOR_in_bitwiseXORExpression4003 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression4006 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4022 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_XOR_in_bitwiseXORExpressionNoIn4026 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4029 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4044 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_OR_in_bitwiseORExpression4048 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4051 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4066 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_OR_in_bitwiseORExpressionNoIn4070 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4073 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_bitwiseORExpression_in_logicalANDExpression4092 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_LAND_in_logicalANDExpression4096 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseORExpression_in_logicalANDExpression4099 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4113 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_LAND_in_logicalANDExpressionNoIn4117 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4120 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_logicalANDExpression_in_logicalORExpression4135 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_LOR_in_logicalORExpression4139 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_logicalANDExpression_in_logicalORExpression4142 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4157 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_LOR_in_logicalORExpressionNoIn4161 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4164 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_logicalORExpression_in_conditionalExpression4183 = new BitSet(new long[]{0x0000000000000002L,0x0000000100000000L});
<     public static final BitSet FOLLOW_QUE_in_conditionalExpression4187 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_conditionalExpression4190 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_conditionalExpression4192 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_conditionalExpression4195 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_logicalORExpressionNoIn_in_conditionalExpressionNoIn4209 = new BitSet(new long[]{0x0000000000000002L,0x0000000100000000L});
<     public static final BitSet FOLLOW_QUE_in_conditionalExpressionNoIn4213 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4216 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_conditionalExpressionNoIn4218 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4221 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_conditionalExpression_in_assignmentExpression4249 = new BitSet(new long[]{0x0000000000000002L,0x00005FFC00000000L});
<     public static final BitSet FOLLOW_assignmentOperator_in_assignmentExpression4256 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_assignmentExpression4259 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_assignmentOperator0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_conditionalExpressionNoIn_in_assignmentExpressionNoIn4336 = new BitSet(new long[]{0x0000000000000002L,0x00005FFC00000000L});
<     public static final BitSet FOLLOW_assignmentOperator_in_assignmentExpressionNoIn4343 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_assignmentExpressionNoIn4346 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_assignmentExpression_in_expression4368 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_COMMA_in_expression4372 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_expression4376 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4413 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_COMMA_in_expressionNoIn4417 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4421 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_SEMIC_in_semic4472 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_EOF_in_semic4477 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_RBRACE_in_semic4482 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_EOL_in_semic4489 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_MultiLineComment_in_semic4493 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_block_in_statement4527 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_statementTail_in_statement4532 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_variableStatement_in_statementTail4544 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_emptyStatement_in_statementTail4549 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_expressionStatement_in_statementTail4554 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_ifStatement_in_statementTail4559 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_iterationStatement_in_statementTail4564 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_continueStatement_in_statementTail4569 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_breakStatement_in_statementTail4574 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_returnStatement_in_statementTail4579 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_withStatement_in_statementTail4584 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_labelledStatement_in_statementTail4589 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_switchStatement_in_statementTail4594 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_throwStatement_in_statementTail4599 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_tryStatement_in_statementTail4604 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACE_in_block4619 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_sourceElement_in_block4621 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_RBRACE_in_block4624 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_VAR_in_variableStatement4653 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclaration_in_variableStatement4655 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_COMMA_in_variableStatement4659 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclaration_in_variableStatement4661 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_variableStatement4666 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_variableDeclaration4689 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L});
<     public static final BitSet FOLLOW_ASSIGN_in_variableDeclaration4693 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_variableDeclaration4696 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_variableDeclarationNoIn4711 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L});
<     public static final BitSet FOLLOW_ASSIGN_in_variableDeclarationNoIn4715 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_variableDeclarationNoIn4718 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SEMIC_in_emptyStatement4737 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_expression_in_expressionStatement4756 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_expressionStatement4758 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_IF_in_ifStatement4776 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_ifStatement4778 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_ifStatement4780 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_ifStatement4782 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_ifStatement4784 = new BitSet(new long[]{0x0000000000004002L});
<     public static final BitSet FOLLOW_ELSE_in_ifStatement4790 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_ifStatement4792 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_doStatement_in_iterationStatement4825 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_whileStatement_in_iterationStatement4830 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forStatement_in_iterationStatement4835 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DO_in_doStatement4847 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_doStatement4849 = new BitSet(new long[]{0x0000000040000000L});
<     public static final BitSet FOLLOW_WHILE_in_doStatement4851 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_doStatement4853 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_doStatement4855 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_doStatement4857 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_doStatement4859 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_WHILE_in_whileStatement4884 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_whileStatement4887 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_whileStatement4890 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_whileStatement4892 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_whileStatement4895 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FOR_in_forStatement4908 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_forStatement4911 = new BitSet(new long[]{0x8000000039221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_forControl_in_forStatement4914 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_forStatement4916 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_forStatement4919 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forControlVar_in_forControl4930 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forControlExpression_in_forControl4935 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forControlSemic_in_forControl4940 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_VAR_in_forControlVar4951 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclarationNoIn_in_forControlVar4953 = new BitSet(new long[]{0x0000000000080000L,0x00000000000000C0L});
<     public static final BitSet FOLLOW_IN_in_forControlVar4965 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlVar4967 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_COMMA_in_forControlVar5013 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclarationNoIn_in_forControlVar5015 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C0L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlVar5020 = new BitSet(new long[]{0x8000000029221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlVar5024 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlVar5027 = new BitSet(new long[]{0x8000000029221072L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlVar5031 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_expressionNoIn_in_forControlExpression5097 = new BitSet(new long[]{0x0000000000080000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_IN_in_forControlExpression5112 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlExpression5116 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlExpression5162 = new BitSet(new long[]{0x8000000029221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlExpression5166 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlExpression5169 = new BitSet(new long[]{0x8000000029221072L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlExpression5173 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlSemic5232 = new BitSet(new long[]{0x8000000029221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlSemic5236 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlSemic5239 = new BitSet(new long[]{0x8000000029221072L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlSemic5243 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_CONTINUE_in_continueStatement5297 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000160000L});
<     public static final BitSet FOLLOW_Identifier_in_continueStatement5302 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_continueStatement5305 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_BREAK_in_breakStatement5324 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000160000L});
<     public static final BitSet FOLLOW_Identifier_in_breakStatement5329 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_breakStatement5332 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_RETURN_in_returnStatement5351 = new BitSet(new long[]{0x8000000029221070L,0x00000000303300CBL,0x0000000388360000L});
<     public static final BitSet FOLLOW_expression_in_returnStatement5356 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_returnStatement5359 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_WITH_in_withStatement5376 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_withStatement5379 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_withStatement5382 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_withStatement5384 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_withStatement5387 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SWITCH_in_switchStatement5408 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_switchStatement5410 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_switchStatement5412 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_switchStatement5414 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_LBRACE_in_switchStatement5416 = new BitSet(new long[]{0x0000000000000900L,0x0000000000000001L});
<     public static final BitSet FOLLOW_defaultClause_in_switchStatement5423 = new BitSet(new long[]{0x0000000000000900L,0x0000000000000001L});
<     public static final BitSet FOLLOW_caseClause_in_switchStatement5429 = new BitSet(new long[]{0x0000000000000900L,0x0000000000000001L});
<     public static final BitSet FOLLOW_RBRACE_in_switchStatement5434 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_CASE_in_caseClause5462 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_caseClause5465 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_caseClause5467 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_caseClause5470 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_DEFAULT_in_defaultClause5483 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_defaultClause5486 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_defaultClause5489 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_Identifier_in_labelledStatement5506 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_labelledStatement5508 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_labelledStatement5510 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_THROW_in_throwStatement5541 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_throwStatement5546 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_throwStatement5548 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_TRY_in_tryStatement5565 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_block_in_tryStatement5568 = new BitSet(new long[]{0x0000000000008200L});
<     public static final BitSet FOLLOW_catchClause_in_tryStatement5572 = new BitSet(new long[]{0x0000000000008202L});
<     public static final BitSet FOLLOW_finallyClause_in_tryStatement5574 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_finallyClause_in_tryStatement5579 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_CATCH_in_catchClause5593 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_catchClause5596 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_catchClause5599 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_catchClause5601 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_block_in_catchClause5604 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FINALLY_in_finallyClause5616 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_block_in_finallyClause5619 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FUNCTION_in_functionDeclaration5640 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_functionDeclaration5644 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_formalParameterList_in_functionDeclaration5646 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_functionBody_in_functionDeclaration5648 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FUNCTION_in_functionExpression5675 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_functionExpression5679 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_formalParameterList_in_functionExpression5682 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_functionBody_in_functionExpression5684 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_formalParameterList5712 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_formalParameterList5718 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_COMMA_in_formalParameterList5722 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_formalParameterList5726 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_RPAREN_in_formalParameterList5734 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACE_in_functionBody5760 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_sourceElement_in_functionBody5762 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_RBRACE_in_functionBody5765 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_sourceElement_in_program5794 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_functionDeclaration_in_sourceElement5823 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_statement_in_sourceElement5828 = new BitSet(new long[]{0x0000000000000002L});
< 
< }
\ No newline at end of file
diff -r -N code-worker/tasks/clonedigger/js_antlr/JavaScript.tokens code-worker/code-worker/tasks/clonedigger/js_antlr/JavaScript.tokens
1,274d0
< BackslashSequence=168
< CONST=37
< COMMA=71
< RegularExpressionLiteral=155
< ARGS=111
< ARRAY=112
< LF=140
< SYNCHRONIZED=59
< HexDigit=150
< DOUBLE=39
< EXPR=118
< ADDASS=99
< DecimalDigit=152
< FALSE=6
< USP=138
< ABSTRACT=32
< SP=136
< DQUOTE=131
< IMPORT=47
< SEMIC=70
< MODASS=102
< PACKAGE=52
< SQUOTE=132
< SHR=87
< CONTINUE=10
< DOT=69
< PRIVATE=53
< MultiLineComment=146
< HexIntegerLiteral=161
< AND=89
< RegularExpressionFirstChar=169
< DIVASS=110
< FUNCTION=17
< GTE=75
< OctalEscapeSequence=164
< HexEscapeSequence=165
< SingleLineComment=147
< UnicodeEscapeSequence=166
< POS=129
< RPAREN=66
< IdentifierStartASCII=151
< FINALLY=15
< IdentifierNameASCIIStart=154
< EXTENDS=42
< IdentifierPart=153
< SUPER=58
< Identifier=148
< SAME=78
< CHAR=35
< NEW=21
< EQ=76
< LT=72
< FINAL=43
< SUBASS=100
< VT=134
< LAND=94
< LBRACK=67
< CATCH=9
< STATIC=57
< CASE=8
< MUL=82
< INTERFACE=49
< ExponentPart=157
< INV=93
< BOOLEAN=33
< ELSE=14
< CharacterEscapeSequence=162
< BSLASH=130
< SHLASS=103
< DecimalLiteral=159
< BREAK=7
< NULL=4
< XOR=91
< COLON=97
< DIV=109
< ORASS=107
< TRUE=5
< ADD=80
< THROW=25
< SHORT=56
< LABELLED=122
< CR=141
< RegularExpressionChar=170
< PUBLIC=55
< SHL=86
< LONG=50
< LOR=95
< TYPEOF=27
< INC=84
< TRANSIENT=61
< TAB=133
< FLOAT=44
< ZeroToThree=163
< THROWS=60
< FF=135
< FORITER=119
< GOTO=45
< MOD=83
< EXPORT=41
< OR=90
< MULASS=101
< LBRACE=63
< BLOCK=113
< RBRACE=64
< PROTECTED=54
< ANDASS=106
< LineTerminator=144
< SHU=88
< EscapeSequence=167
< PAREXPR=126
< INT=48
< LS=142
< CEXPR=117
< ASSIGN=98
< VOID=29
< INSTANCEOF=20
< LPAREN=65
< WhiteSpace=139
< XORASS=108
< QUE=96
< NEQ=77
< NAMEDVALUE=123
< ENUM=40
< PS=143
< DEBUGGER=38
< DELETE=12
< OBJECT=125
< DO=13
< IMPLEMENTS=46
< OctalIntegerLiteral=160
< WHILE=30
< SWITCH=23
< BYINDEX=115
< FORSTEP=120
< OctalDigit=156
< PINC=128
< GT=73
< StringLiteral=149
< DecimalIntegerLiteral=158
< SHRASS=104
< ITEM=121
< SHUASS=105
< THIS=24
< WITH=31
< IN=19
< VAR=28
< LTE=74
< CLASS=36
< NATIVE=51
< DEC=85
< RETURN=22
< BYTE=34
< VOLATILE=62
< IF=18
< EOL=145
< NBSP=137
< CALL=116
< FOR=16
< RBRACK=68
< DEFAULT=11
< NEG=124
< SUB=81
< NOT=92
< TRY=26
< PDEC=127
< BYFIELD=114
< NSAME=79
< '<'=72
< 'goto'=45
< '>'=73
< 'try'=26
< 'function'=17
< 'with'=31
< '-'=81
< '>>>='=105
< '?'=96
< '!='=77
< '>='=75
< 'do'=13
< '<<'=86
< 'double'=39
< '<='=74
< '='=98
< 'native'=51
< 'void'=29
< 'catch'=9
< ':'=97
< '*'=82
< '>>>'=88
< '<<='=103
< 'synchronized'=59
< 'true'=5
< 'false'=6
< ','=71
< '&&'=94
< 'this'=24
< 'continue'=10
< 'const'=37
< 'debugger'=38
< 'enum'=40
< 'return'=22
< ')'=66
< '=='=76
< 'static'=57
< 'implements'=46
< 'import'=47
< 'typeof'=27
< 'char'=35
< '!'=92
< '+='=99
< 'switch'=23
< 'delete'=12
< 'extends'=42
< '^='=108
< 'class'=36
< 'null'=4
< '+'=80
< 'interface'=49
< '-='=100
< 'case'=8
< 'boolean'=33
< 'else'=14
< '/='=110
< 'package'=52
< '%='=102
< 'var'=28
< '||'=95
< '*='=101
< 'volatile'=62
< 'instanceof'=20
< 'super'=58
< '|='=107
< '++'=84
< '{'=63
< 'throws'=60
< 'float'=44
< 'new'=21
< 'for'=16
< '.'=69
< 'short'=56
< '}'=64
< '~'=93
< 'finally'=15
< 'break'=7
< '%'=83
< 'final'=43
< ';'=70
< 'default'=11
< ']'=68
< '&'=89
< 'int'=48
< '!=='=79
< '&='=106
< 'while'=30
< '['=67
< '/'=109
< 'long'=50
< '^'=91
< 'private'=53
< '|'=90
< '>>='=104
< 'throw'=25
< 'protected'=54
< 'if'=18
< '('=65
< 'byte'=34
< 'transient'=61
< '==='=78
< '>>'=87
< '--'=85
< 'export'=41
< 'in'=19
< 'abstract'=32
< 'public'=55
diff -r -N code-worker/tasks/clonedigger/js_antlr/license.txt code-worker/code-worker/tasks/clonedigger/js_antlr/license.txt
1,30d0
< Software License Agreement (BSD License)
< 
< Copyright (c) 2008, Xebic Research B.V.
< All rights reserved.
< 
< Redistribution and use of this software in source and binary forms, with or without modification, are
< permitted provided that the following conditions are met:
< 
< * Redistributions of source code must retain the above
<   copyright notice, this list of conditions and the
<   following disclaimer.
< 
< * Redistributions in binary form must reproduce the above
<   copyright notice, this list of conditions and the
<   following disclaimer in the documentation and/or other
<   materials provided with the distribution.
< 
< * Neither the name of Xebic Research B.V. nor the names of its
<   contributors may be used to endorse or promote products
<   derived from this software without specific prior
<   written permission of Xebic Research B.V.
< 
< THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED
< WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
< PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
< ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
< LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
< INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
< TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
< ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
\ No newline at end of file
diff -r -N code-worker/tasks/clonedigger/js_antlr/MyAstNodeAdaptor.java code-worker/code-worker/tasks/clonedigger/js_antlr/MyAstNodeAdaptor.java
1,8d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< class MyAstNodeAdaptor extends CommonTreeAdaptor {
<     public Object create(Token t) {
< 	return new MyAstNode(t);
<     }
< };
diff -r -N code-worker/tasks/clonedigger/js_antlr/MyAstNode.java code-worker/code-worker/tasks/clonedigger/js_antlr/MyAstNode.java
1,11d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< import java.io.*;
< 
< public class MyAstNode extends CommonTree {
<     boolean is_statement = false;
<     public MyAstNode(Token t) {
< 	super(t);
<     }
< }
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/all-wcprops
1,65d0
< K 25
< svn:wc:ra_dav:version-url
< V 60
< /svnroot/clonedigger/!svn/ver/203/trunk/clonedigger/js_antlr
< END
< license.txt
< K 25
< svn:wc:ra_dav:version-url
< V 72
< /svnroot/clonedigger/!svn/ver/203/trunk/clonedigger/js_antlr/license.txt
< END
< JavaScriptParser.java
< K 25
< svn:wc:ra_dav:version-url
< V 82
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/JavaScriptParser.java
< END
< MyAstNode.java
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/MyAstNode.java
< END
< TreeProducer.java
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/TreeProducer.java
< END
< build_jar.sh
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/build_jar.sh
< END
< JavaScriptLexer.java
< K 25
< svn:wc:ra_dav:version-url
< V 81
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/JavaScriptLexer.java
< END
< JavaScript.tokens
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/JavaScript.tokens
< END
< JavaScript.g
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/JavaScript.g
< END
< MyAstNodeAdaptor.java
< K 25
< svn:wc:ra_dav:version-url
< V 82
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/MyAstNodeAdaptor.java
< END
< TreeProducer.jar
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/202/trunk/clonedigger/js_antlr/TreeProducer.jar
< END
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/entries code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/entries
1,368d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/js_antlr
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2009-03-06T18:45:22.385766Z
< 203
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< license.txt
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< ee3a9d13084f2209935ace67dd559d0c
< 2009-03-06T18:45:22.385766Z
< 203
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 1581
< 
< JavaScriptParser.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 519732acf5f51240256bfd6d7dbd6dcd
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 402379
< 
< MyAstNode.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 27e85f308359d91397fb04627a0cdcd9
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 214
< 
< TreeProducer.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 7c8a91a3d15f63fd0b3003c1f59093f0
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3691
< 
< build_jar.sh
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 82dc8390e8e5c20d9e2ff0b21e7b4c3b
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 90
< 
< JavaScriptLexer.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 387e4ee62e7a27a21142cffb31669974
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 163438
< 
< JavaScript.tokens
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 33a36e3d0fecd980e180a0386b4c9261
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2917
< 
< JavaScript.g
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 53af44113c8eed53c1485dcc092224ec
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 34209
< 
< MyAstNodeAdaptor.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< fd6fe69efe042f7870d0bd8d1dab83d8
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 188
< 
< TreeProducer.jar
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 0829eef1c8442e34e7e9af15f9170c33
< 2009-03-06T18:34:40.244486Z
< 202
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 119015
< 
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/prop-base/build_jar.sh.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/prop-base/build_jar.sh.svn-base
1,5d0
< K 14
< svn:executable
< V 1
< *
< END
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/prop-base/TreeProducer.jar.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/prop-base/TreeProducer.jar.svn-base
1,5d0
< K 13
< svn:mime-type
< V 24
< application/octet-stream
< END
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/build_jar.sh.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/build_jar.sh.svn-base
1,4d0
< java org.antlr.Tool JavaScript.g
< javac *.java
< jar -cf TreeProducer.jar *.class
< rm *.class
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScript.g.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScript.g.svn-base
1,1538d0
< /*
< 
< Updated by Haoyu Bai:
<     Add Clone Digger specific things and change define of 'block' from 'statement' to 'sourceElement' since functionDeclartion can inline of code.
< 
< Copyrights 2008 Xebic Reasearch BV. All rights reserved (see license.txt).
< Owner : Patrick Hulsmeijer.
< 
< This ANTLR 3 LL(*) grammar is based on Ecma-262 3rd edition (JavaScript 1.5, JScript 5.5). 
< The annotations refer to the "A Grammar Summary" section (e.g. A.1 Lexical Grammar) and the numbers in parenthesis to the paragraph numbers (e.g. (7.8) ).
< This document is best viewed with ANTLRWorks (www.antlr.org).
< 
< 
< The major challenges faced in defining this grammar were:
< 
< -1- Ambiguity surrounding the DIV sign in relation to the multiplicative expression and the regular expression literal.
< This is solved with some lexer driven magic: a gated semantical predicate turns the recognition of regular expressions on or off, based on the
< value of the RegularExpressionsEnabled property. When regular expressions are enabled they take precedence over division expressions. The decision whether
< regular expressions are enabled is based on the heuristics that the previous token can be considered as last token of a left-hand-side operand of a division.
< 
< -2- Automatic semicolon insertion.
< This is solved within the parser. The semicolons are not physically inserted but the situations in which they should are recognized and treated as if they were.
< The physical insertion of semicolons would be undesirable because of several reasons:
< - performance degration because of how ANTLR handles tokens in token streams
< - the alteration of the input, which we need to have unchanged
< - it is superfluous being of no interest to AST construction
< 
< -3- Unicode identifiers
< Because ANTLR couldn't handle the unicode tables defined in the specification well and for performance reasons unicode identifiers are implemented as an action 
< driven alternative to ASCII identifiers. First the ASCII version is tried that is defined in detail in this grammar and then the unicode alternative is tried action driven.
< Because of the fact that the ASCII version is defined in detail the mTokens switch generation in the lexer can predict identifiers appropriately.
< For details see the identifier rules.
< 
< 
< The minor challenges were related to converting the grammar to an ANTLR LL(*) grammar:
< - Resolving the ambiguity between functionDeclaration vs functionExpression and block vs objectLiteral stemming from the expressionStatement production.
< - Left recursive nature of the left hand side expressions.
< - The assignmentExpression production.
< - The forStatement production.
< The grammar was kept as close as possible to the grammar in the "A Grammar Summary" section of Ecma-262.
< 
< */
< 
< grammar JavaScript ;
< 
< options
< {
< 	output = AST ;
<     memoize = true ;
< 	language = Java ;
<     ASTLabelType=MyAstNode;
< }
< 
< tokens
< {
< // Reserved words
< 	NULL		= 'null' ;
< 	TRUE		= 'true' ;
< 	FALSE		= 'false' ;
< 
< // Keywords
< 	BREAK		= 'break' ;
< 	CASE		= 'case' ;
< 	CATCH 		= 'catch' ;
< 	CONTINUE 	= 'continue' ;
< 	DEFAULT		= 'default' ;
< 	DELETE		= 'delete' ;
< 	DO 		= 'do' ;
< 	ELSE 		= 'else' ;
< 	FINALLY 	= 'finally' ;
< 	FOR 		= 'for' ;
< 	FUNCTION 	= 'function' ;
< 	IF 		= 'if' ;
< 	IN 		= 'in' ;
< 	INSTANCEOF 	= 'instanceof' ;
< 	NEW 		= 'new' ;
< 	RETURN 		= 'return' ;
< 	SWITCH 		= 'switch' ;
< 	THIS 		= 'this' ;
< 	THROW 		= 'throw' ;
< 	TRY 		= 'try' ;
< 	TYPEOF 		= 'typeof' ;
< 	VAR 		= 'var' ;
< 	VOID 		= 'void' ;
< 	WHILE 		= 'while' ;
< 	WITH 		= 'with' ;
< 
< // Future reserved words
< 	ABSTRACT	= 'abstract' ;
< 	BOOLEAN 	= 'boolean' ;
< 	BYTE 		= 'byte' ;
< 	CHAR 		= 'char' ;
< 	CLASS 		= 'class' ;
< 	CONST 		= 'const' ;
< 	DEBUGGER 	= 'debugger' ;
< 	DOUBLE		= 'double' ;
< 	ENUM 		= 'enum' ;
< 	EXPORT 		= 'export' ;
< 	EXTENDS		= 'extends' ;
< 	FINAL 		= 'final' ;
< 	FLOAT 		= 'float' ;
< 	GOTO 		= 'goto' ;
< 	IMPLEMENTS 	= 'implements' ;
< 	IMPORT		= 'import' ;
< 	INT 		= 'int' ;
< 	INTERFACE 	= 'interface' ;
< 	LONG 		= 'long' ;
< 	NATIVE 		= 'native' ;
< 	PACKAGE 	= 'package' ;
< 	PRIVATE 	= 'private' ;
< 	PROTECTED 	= 'protected' ;
< 	PUBLIC		= 'public' ;
< 	SHORT 		= 'short' ;
< 	STATIC 		= 'static' ;
< 	SUPER 		= 'super' ;
< 	SYNCHRONIZED 	= 'synchronized' ;
< 	THROWS 		= 'throws' ;
< 	TRANSIENT 	= 'transient' ;
< 	VOLATILE 	= 'volatile' ;
< 
< // Punctuators
< 	LBRACE		= '{' ;
< 	RBRACE		= '}' ;
< 	LPAREN		= '(' ;
< 	RPAREN		= ')' ;
< 	LBRACK		= '[' ;
< 	RBRACK		= ']' ;
< 	DOT		= '.' ;
< 	SEMIC		= ';' ;
< 	COMMA		= ',' ;
< 	LT		= '<' ;
< 	GT		= '>' ;
< 	LTE		= '<=' ;
< 	GTE		= '>=' ;
< 	EQ		= '==' ;
< 	NEQ		= '!=' ;
< 	SAME		= '===' ;
< 	NSAME		= '!==' ;
< 	ADD		= '+' ;
< 	SUB		= '-' ;
< 	MUL		= '*' ;
< 	MOD		= '%' ;
< 	INC		= '++' ;
< 	DEC		= '--' ;
< 	SHL		= '<<' ;
< 	SHR		= '>>' ;
< 	SHU		= '>>>' ;
< 	AND		= '&' ;
< 	OR		= '|' ;
< 	XOR		= '^' ;
< 	NOT		= '!' ;
< 	INV		= '~' ;
< 	LAND		= '&&' ;
< 	LOR		= '||' ;
< 	QUE		= '?' ;
< 	COLON		= ':' ;
< 	ASSIGN		= '=' ;
< 	ADDASS		= '+=' ;
< 	SUBASS		= '-=' ;
< 	MULASS		= '*=' ;
< 	MODASS		= '%=' ;
< 	SHLASS		= '<<=' ;
< 	SHRASS		= '>>=' ;
< 	SHUASS		= '>>>=' ;
< 	ANDASS		= '&=' ;
< 	ORASS		= '|=' ;
< 	XORASS		= '^=' ;
< 	DIV		= '/' ;
< 	DIVASS		= '/=' ;
< 	
< // Imaginary
< 	ARGS ;
< 	ARRAY ;
< 	BLOCK ;
< 	BYFIELD ;
< 	BYINDEX ;
< 	CALL ;
< 	CEXPR ;
< 	EXPR ;
< 	FORITER ;
< 	FORSTEP ;
< 	ITEM ;
< 	LABELLED ;
< 	NAMEDVALUE ;
< 	NEG ;
< 	OBJECT ;
< 	PAREXPR ;
< 	PDEC ;
< 	PINC ;
< 	POS ;
< }
< 
< @lexer::members
< {
< private Token last;
< 
< private final boolean areRegularExpressionsEnabled()
< {
< 	if (last == null)
< 	{
< 		return true;
< 	}
< 	switch (last.getType())
< 	{
< 	// identifier
< 		case Identifier:
< 	// literals
< 		case NULL:
< 		case TRUE:
< 		case FALSE:
< 		case THIS:
< 		case OctalIntegerLiteral:
< 		case DecimalLiteral:
< 		case HexIntegerLiteral:
< 		case StringLiteral:
< 	// member access ending 
< 		case RBRACK:
< 	// function call or nested expression ending
< 		case RPAREN:
< 			return false;
< 	// otherwise OK
< 		default:
< 			return true;
< 	}
< }
< 	
< private final void consumeIdentifierUnicodeStart() throws RecognitionException, NoViableAltException
< {
< 	int ch = input.LA(1);
< 	if (isIdentifierStartUnicode(ch))
< 	{
< 		matchAny();
< 		do
< 		{
< 			ch = input.LA(1);
< 			if (ch == '$' || (ch >= '0' && ch <= '9') || (ch >= 'A' && ch <= 'Z') || ch == '\\' || ch == '_' || (ch >= 'a' && ch <= 'z') || isIdentifierPartUnicode(ch))
< 			{
< 				mIdentifierPart();
< 			}
< 			else
< 			{
< 				return;
< 			}
< 		}
< 		while (true);
< 	}
< 	else
< 	{
< 		throw new NoViableAltException();
< 	}
< }
< 	
< private final boolean isIdentifierPartUnicode(int ch)
< {
< 	return Character.isJavaIdentifierPart(ch);
< }
< 	
< private final boolean isIdentifierStartUnicode(int ch)
< {
< 	return Character.isJavaIdentifierStart(ch);
< }
< 
< public Token nextToken()
< {
< 	Token result = super.nextToken();
< 	if (result.getChannel() == Token.DEFAULT_CHANNEL)
< 	{
< 		last = result;
< 	}
< 	return result;		
< }
< }
< 
< @parser::members
< {
< private final boolean isLeftHandSideAssign(RuleReturnScope lhs, Object[] cached)
< {
< 	if (cached[0] != null)
< 	{
< 		return ((Boolean)cached[0]).booleanValue();
< 	}
< 	
< 	boolean result;
< 	if (isLeftHandSideExpression(lhs))
< 	{
< 		switch (input.LA(1))
< 		{
< 			case ASSIGN:
< 			case MULASS:
< 			case DIVASS:
< 			case MODASS:
< 			case ADDASS:
< 			case SUBASS:
< 			case SHLASS:
< 			case SHRASS:
< 			case SHUASS:
< 			case ANDASS:
< 			case XORASS:
< 			case ORASS:
< 				result = true;
< 				break;
< 			default:
< 				result = false;
< 				break;
< 		}
< 	}
< 	else
< 	{
< 		result = false;
< 	}
< 	
< 	cached[0] = new Boolean(result);
< 	return result;
< }
< 
< private final static boolean isLeftHandSideExpression(RuleReturnScope lhs)
< {
< 	if (lhs.getTree() == null) // e.g. during backtracking
< 	{
< 		return true;
< 	}
< 	else
< 	{
< 		switch (((Tree)lhs.getTree()).getType())
< 		{
< 		// primaryExpression
< 			case THIS:
< 			case Identifier:
< 			case NULL:
< 			case TRUE:
< 			case FALSE:
< 			case DecimalLiteral:
< 			case OctalIntegerLiteral:
< 			case HexIntegerLiteral:
< 			case StringLiteral:
< 			case RegularExpressionLiteral:
< 			case ARRAY:
< 			case OBJECT:
< 			case PAREXPR:
< 		// functionExpression
< 			case FUNCTION:
< 		// newExpression
< 			case NEW:
< 		// leftHandSideExpression
< 			case CALL:
< 			case BYFIELD:
< 			case BYINDEX:
< 				return true;
< 			
< 			default:
< 				return false;
< 		}
< 	}
< }
< 	
< private final boolean isLeftHandSideIn(RuleReturnScope lhs, Object[] cached)
< {
< 	if (cached[0] != null)
< 	{
< 		return ((Boolean)cached[0]).booleanValue();
< 	}
< 	
< 	boolean result = isLeftHandSideExpression(lhs) && (input.LA(1) == IN);
< 	cached[0] = new Boolean(result);
< 	return result;
< }
< 
< private final void promoteEOL(ParserRuleReturnScope rule)
< {
< 	// Get current token and its type (the possibly offending token).
< 	Token lt = input.LT(1);
< 	int la = lt.getType();
< 	
< 	// We only need to promote an EOL when the current token is offending (not a SEMIC, EOF, RBRACE, EOL or MultiLineComment).
< 	// EOL and MultiLineComment are not offending as they're already promoted in a previous call to this method.
< 	// Promoting an EOL means switching it from off channel to on channel.
< 	// A MultiLineComment gets promoted when it contains an EOL.
< 	if (!(la == SEMIC || la == EOF || la == RBRACE || la == EOL || la == MultiLineComment))
< 	{
< 		// Start on the possition before the current token and scan backwards off channel tokens until the previous on channel token.
< 		for (int ix = lt.getTokenIndex() - 1; ix > 0; ix--)
< 		{
< 			lt = input.get(ix);
< 			if (lt.getChannel() == Token.DEFAULT_CHANNEL)
< 			{
< 				// On channel token found: stop scanning.
< 				break;
< 			}
< 			else if (lt.getType() == EOL || (lt.getType() == MultiLineComment && lt.getText().matches("/.*\r\n|\r|\n")))
< 			{
< 				// We found our EOL: promote the token to on channel, position the input on it and reset the rule start.
< 				lt.setChannel(Token.DEFAULT_CHANNEL);
< 				input.seek(lt.getTokenIndex());
< 				if (rule != null)
< 				{
< 					rule.start = lt;
< 				}
< 				break;
< 			}
< 		}
< 	}
< }	
< }
< 
< //
< // $<	A.1 Lexical Grammar (7)
< //
< 
< // Added for lexing purposes
< 
< fragment BSLASH
< 	: '\\'
< 	;
< 	
< fragment DQUOTE
< 	: '"'
< 	;
< 	
< fragment SQUOTE
< 	: '\''
< 	;
< 
< // $<	Whitespace (7.2)
< 
< fragment TAB
< 	: '\u0009'
< 	;
< 
< fragment VT // Vertical TAB
< 	: '\u000b'
< 	;
< 
< fragment FF // Form Feed
< 	: '\u000c'
< 	;
< 
< fragment SP // Space
< 	: '\u0020'
< 	;
< 
< fragment NBSP // Non-Breaking Space
< 	: '\u00a0'
< 	;
< 
< fragment USP // Unicode Space Separator (rest of Unicode category Zs)
< 	: '\u1680'  // OGHAM SPACE MARK
< 	| '\u180E'  // MONGOLIAN VOWEL SEPARATOR
< 	| '\u2000'  // EN QUAD
< 	| '\u2001'  // EM QUAD
< 	| '\u2002'  // EN SPACE
< 	| '\u2003'  // EM SPACE
< 	| '\u2004'  // THREE-PER-EM SPACE
< 	| '\u2005'  // FOUR-PER-EM SPACE
< 	| '\u2006'  // SIX-PER-EM SPACE
< 	| '\u2007'  // FIGURE SPACE
< 	| '\u2008'  // PUNCTUATION SPACE
< 	| '\u2009'  // THIN SPACE
< 	| '\u200A'  // HAIR SPACE
< 	| '\u202F'  // NARROW NO-BREAK SPACE
< 	| '\u205F'  // MEDIUM MATHEMATICAL SPACE
< 	| '\u3000'  // IDEOGRAPHIC SPACE
< 	;
< 
< WhiteSpace
< 	: ( TAB | VT | FF | SP | NBSP | USP )+ { $channel = HIDDEN; }
< 	;
< 
< // $>
< 
< // $<	Line terminators (7.3)
< 
< fragment LF // Line Feed
< 	: '\n'
< 	;
< 
< fragment CR // Carriage Return
< 	: '\r'
< 	;
< 
< fragment LS // Line Separator
< 	: '\u2028'
< 	;
< 
< fragment PS // Paragraph Separator
< 	: '\u2029'
< 	;
< 
< fragment LineTerminator
< 	: CR | LF | LS | PS
< 	;
< 		
< EOL
< 	: ( ( CR LF? ) | LF | LS | PS ) { $channel = HIDDEN; }
< 	;
< // $>
< 
< // $<	Comments (7.4)
< 
< MultiLineComment
< 	: '/*' ( options { greedy = false; } : . )* '*/' { $channel = HIDDEN; }
< 	;
< 
< SingleLineComment
< 	: '//' ( ~( LineTerminator ) )* { $channel = HIDDEN; }
< 	;
< 
< // $>
< 
< // $<	Tokens (7.5)
< 
< token
< 	: reservedWord
< 	| Identifier
< 	| punctuator
< 	| numericLiteral
< 	| StringLiteral
< 	;
< 
< // $<	Reserved words (7.5.1)
< 
< reservedWord
< 	: keyword
< 	| futureReservedWord
< 	| NULL
< 	| booleanLiteral
< 	;
< 
< // $>
< 	
< // $<	Keywords (7.5.2)
< 
< keyword
< 	: BREAK
< 	| CASE
< 	| CATCH
< 	| CONTINUE
< 	| DEFAULT
< 	| DELETE
< 	| DO
< 	| ELSE
< 	| FINALLY
< 	| FOR
< 	| FUNCTION
< 	| IF
< 	| IN
< 	| INSTANCEOF
< 	| NEW
< 	| RETURN
< 	| SWITCH
< 	| THIS
< 	| THROW
< 	| TRY
< 	| TYPEOF
< 	| VAR
< 	| VOID
< 	| WHILE
< 	| WITH
< 	;
< 
< // $>
< 
< // $<	Future reserved words (7.5.3)
< 
< futureReservedWord
< 	: ABSTRACT
< 	| BOOLEAN
< 	| BYTE
< 	| CHAR
< 	| CLASS
< 	| CONST
< 	| DEBUGGER
< 	| DOUBLE
< 	| ENUM
< 	| EXPORT
< 	| EXTENDS
< 	| FINAL
< 	| FLOAT
< 	| GOTO
< 	| IMPLEMENTS
< 	| IMPORT
< 	| INT
< 	| INTERFACE
< 	| LONG
< 	| NATIVE
< 	| PACKAGE
< 	| PRIVATE
< 	| PROTECTED
< 	| PUBLIC
< 	| SHORT
< 	| STATIC
< 	| SUPER
< 	| SYNCHRONIZED
< 	| THROWS
< 	| TRANSIENT
< 	| VOLATILE
< 	;
< 
< // $>
< 
< // $>
< 	
< // $<	Identifiers (7.6)
< 
< fragment IdentifierStartASCII
< 	: 'a'..'z' | 'A'..'Z'
< 	| '$'
< 	| '_'
< 	| BSLASH 'u' HexDigit HexDigit HexDigit HexDigit // UnicodeEscapeSequence
< 	;
< 
< /*
< The first two alternatives define how ANTLR can match ASCII characters which can be considered as part of an identifier.
< The last alternative matches other characters in the unicode range that can be sonsidered as part of an identifier.
< */
< fragment IdentifierPart
< 	: DecimalDigit
< 	| IdentifierStartASCII
< 	| { isIdentifierPartUnicode(input.LA(1)) }? { matchAny(); }
< 	;
< 
< fragment IdentifierNameASCIIStart
< 	: IdentifierStartASCII IdentifierPart*
< 	;
< 
< /*
< The second alternative acts as an action driven fallback to evaluate other characters in the unicode range than the ones in the ASCII subset.
< Due to the first alternative this grammar defines enough so that ANTLR can generate a lexer that correctly predicts identifiers with characters in the ASCII range.
< In that way keywords, other reserved words and ASCII identifiers are recognized with standard ANTLR driven logic. When the first character for an identifier fails to 
< match this ASCII definition, the lexer calls consumeIdentifierUnicodeStart because of the action in the alternative. This method checks whether the character matches 
< as first character in ranges other than ASCII and consumes further characters belonging to the identifier with help of mIdentifierPart generated out of the 
< IdentifierPart rule above.
< */
< Identifier
< 	: IdentifierNameASCIIStart
< 	| { consumeIdentifierUnicodeStart(); }
< 	;
< 
< // $>
< 
< // $<	Punctuators (7.7)
< 
< punctuator
< 	: LBRACE
< 	| RBRACE
< 	| LPAREN
< 	| RPAREN
< 	| LBRACK
< 	| RBRACK
< 	| DOT
< 	| SEMIC
< 	| COMMA
< 	| LT
< 	| GT
< 	| LTE
< 	| GTE
< 	| EQ
< 	| NEQ
< 	| SAME
< 	| NSAME
< 	| ADD
< 	| SUB
< 	| MUL
< 	| MOD
< 	| INC
< 	| DEC
< 	| SHL
< 	| SHR
< 	| SHU
< 	| AND
< 	| OR
< 	| XOR
< 	| NOT
< 	| INV
< 	| LAND
< 	| LOR
< 	| QUE
< 	| COLON
< 	| ASSIGN
< 	| ADDASS
< 	| SUBASS
< 	| MULASS
< 	| MODASS
< 	| SHLASS
< 	| SHRASS
< 	| SHUASS
< 	| ANDASS
< 	| ORASS
< 	| XORASS
< 	| DIV
< 	| DIVASS
< 	;
< 
< // $>
< 
< // $<	Literals (7.8)
< 
< literal
< 	: NULL
< 	| booleanLiteral
< 	| numericLiteral
< 	| StringLiteral
< 	| RegularExpressionLiteral
< 	;
< 
< booleanLiteral
< 	: TRUE
< 	| FALSE
< 	;
< 
< // $<	Numeric literals (7.8.3)
< 
< /*
< Note: octal literals are described in the B Compatibility section.
< These are removed from the standards but are here for backwards compatibility with earlier ECMAScript definitions.
< */
< 
< fragment DecimalDigit
< 	: '0'..'9'
< 	;
< 
< fragment HexDigit
< 	: DecimalDigit | 'a'..'f' | 'A'..'F'
< 	;
< 
< fragment OctalDigit
< 	: '0'..'7'
< 	;
< 
< fragment ExponentPart
< 	: ( 'e' | 'E' ) ( '+' | '-' )? DecimalDigit+
< 	;
< 
< fragment DecimalIntegerLiteral
< 	: '0'
< 	| '1'..'9' DecimalDigit*
< 	;
< 
< DecimalLiteral
< 	: DecimalIntegerLiteral '.' DecimalDigit* ExponentPart?
< 	| '.' DecimalDigit+ ExponentPart?
< 	| DecimalIntegerLiteral ExponentPart?
< 	;
< 
< OctalIntegerLiteral
< 	: '0' OctalDigit+
< 	;
< 
< HexIntegerLiteral
< 	: ( '0x' | '0X' ) HexDigit+
< 	;
< 
< numericLiteral
< 	: DecimalLiteral
< 	| OctalIntegerLiteral
< 	| HexIntegerLiteral
< 	;
< 
< // $>
< 
< // $<	String literals (7.8.4)
< 
< /*
< Note: octal escape sequences are described in the B Compatibility section.
< These are removed from the standards but are here for backwards compatibility with earlier ECMAScript definitions.
< */
< 	
< fragment CharacterEscapeSequence
< 	: ~( DecimalDigit | 'x' | 'u' | LineTerminator ) // Concatenation of SingleEscapeCharacter and NonEscapeCharacter
< 	;
< 
< fragment ZeroToThree
< 	: '0'..'3'
< 	;
< 	
< fragment OctalEscapeSequence
< 	: OctalDigit
< 	| ZeroToThree OctalDigit
< 	| '4'..'7' OctalDigit
< 	| ZeroToThree OctalDigit OctalDigit
< 	;
< 	
< fragment HexEscapeSequence
< 	: 'x' HexDigit HexDigit
< 	;
< 	
< fragment UnicodeEscapeSequence
< 	: 'u' HexDigit HexDigit HexDigit HexDigit
< 	;
< 
< fragment EscapeSequence
< 	:
< 	BSLASH 
< 	(
< 		CharacterEscapeSequence 
< 		| OctalEscapeSequence
< 		| HexEscapeSequence
< 		| UnicodeEscapeSequence
< 	)
< 	;
< 
< StringLiteral
< 	: SQUOTE ( ~( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* SQUOTE
< 	| DQUOTE ( ~( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* DQUOTE
< 	;
< 
< // $>
< 
< // $<	Regular expression literals (7.8.5)
< 
< fragment BackslashSequence
< 	: BSLASH ~( LineTerminator )
< 	;
< 
< fragment RegularExpressionFirstChar
< 	: ~ ( LineTerminator | MUL | BSLASH | DIV )
< 	| BackslashSequence
< 	;
< 
< fragment RegularExpressionChar
< 	: ~ ( LineTerminator | BSLASH | DIV )
< 	| BackslashSequence
< 	;
< 
< RegularExpressionLiteral
< 	: { areRegularExpressionsEnabled() }?=> DIV RegularExpressionFirstChar RegularExpressionChar* DIV IdentifierPart*
< 	;
< 
< // $>
< 
< // $>
< 
< // $>
< 
< //
< // $<	A.3 Expressions (11)
< //
< 
< // $<Primary expressions (11.1)
< 
< primaryExpression
< 	: THIS
< 	| Identifier
< 	| literal
< 	| arrayLiteral
< 	| objectLiteral
< 	| lpar=LPAREN expression RPAREN -> ^( PAREXPR[$lpar, "PAREXPR"] expression )
< 	;
< 
< arrayLiteral
< 	: lb=LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK
< 	-> ^( ARRAY[$lb, "ARRAY"] arrayItem* )
< 	;
< 
< arrayItem
< 	: ( expr=assignmentExpression | { input.LA(1) == COMMA }? )
< 	-> ^( ITEM $expr? )
< 	;
< 
< objectLiteral
< 	: lb=LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE
< 	-> ^( OBJECT[$lb, "OBJECT"] nameValuePair* )
< 	;
< 	
< nameValuePair
< 	: propertyName COLON assignmentExpression
< 	-> ^( NAMEDVALUE propertyName assignmentExpression )
< 	;
< 
< propertyName
< 	: Identifier
< 	| StringLiteral
< 	| numericLiteral
< 	;
< 
< // $>
< 
< // $<Left-hand-side expressions (11.2)
< 
< /*
< Refactored some rules to make them LL(*) compliant:
< all the expressions surrounding member selection and calls have been moved to leftHandSideExpression to make them right recursive
< */
< 
< memberExpression
< 	: primaryExpression
< 	| functionExpression
< 	| newExpression
< 	;
< 
< newExpression
< 	: NEW^ primaryExpression
<     | NEW^ functionExpression
< 	;
< 
< 	
< arguments
< 	: LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN
< 	-> ^( ARGS assignmentExpression* )
< 	;
< 	
< leftHandSideExpression
< 	:
< 	(
< 		memberExpression 		-> memberExpression
< 	)
< 	(
< 		arguments			-> ^( CALL $leftHandSideExpression arguments )
< 		| LBRACK expression RBRACK	-> ^( BYINDEX $leftHandSideExpression expression )
< 		| DOT Identifier		-> ^( BYFIELD $leftHandSideExpression Identifier )
< 	)*
< 	;
< 
< // $>
< 
< // $<Postfix expressions (11.3)
< 
< /*
< The specification states that there are no line terminators allowed before the postfix operators.
< This is enforced by the call to promoteEOL in the action before ( INC | DEC ).
< We only must promote EOLs when the la is INC or DEC because this production is chained as all expression rules.
< In other words: only promote EOL when we are really in a postfix expression. A check on the la will ensure this.
< */
< postfixExpression
< 	: leftHandSideExpression { if (input.LA(1) == INC || input.LA(1) == DEC) promoteEOL(null); } ( postfixOperator^ )?
< 	;
< 	
< postfixOperator
< 	: op=INC { $op.setType(PINC); }
< 	| op=DEC { $op.setType(PDEC); }
< 	;
< 
< // $>
< 
< // $<Unary operators (11.4)
< 
< unaryExpression
< 	: postfixExpression
< 	| unaryOperator^ unaryExpression
< 	;
< 	
< unaryOperator
< 	: DELETE
< 	| VOID
< 	| TYPEOF
< 	| INC
< 	| DEC
< 	| op=ADD { $op.setType(POS); }
< 	| op=SUB { $op.setType(NEG); }
< 	| INV
< 	| NOT
< 	;
< 
< // $>
< 
< // $<Multiplicative operators (11.5)
< 
< multiplicativeExpression
< 	: unaryExpression ( ( MUL | DIV | MOD )^ unaryExpression )*
< 	;
< 
< // $>
< 
< // $<Additive operators (11.6)
< 
< additiveExpression
< 	: multiplicativeExpression ( ( ADD | SUB )^ multiplicativeExpression )*
< 	;
< 
< // $>
< 	
< // $<Bitwise shift operators (11.7)
< 
< shiftExpression
< 	: additiveExpression ( ( SHL | SHR | SHU )^ additiveExpression )*
< 	;
< 
< // $>
< 	
< // $<Relational operators (11.8)
< 
< relationalExpression
< 	: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN )^ shiftExpression )*
< 	;
< 
< relationalExpressionNoIn
< 	: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF )^ shiftExpression )*
< 	;
< 
< // $>
< 	
< // $<Equality operators (11.9)
< 
< equalityExpression
< 	: relationalExpression ( ( EQ | NEQ | SAME | NSAME )^ relationalExpression )*
< 	;
< 
< equalityExpressionNoIn
< 	: relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME )^ relationalExpressionNoIn )*
< 	;
< 
< // $>
< 		
< // $<Binary bitwise operators (11.10)
< 
< bitwiseANDExpression
< 	: equalityExpression ( AND^ equalityExpression )*
< 	;
< 
< bitwiseANDExpressionNoIn
< 	: equalityExpressionNoIn ( AND^ equalityExpressionNoIn )*
< 	;
< 		
< bitwiseXORExpression
< 	: bitwiseANDExpression ( XOR^ bitwiseANDExpression )*
< 	;
< 		
< bitwiseXORExpressionNoIn
< 	: bitwiseANDExpressionNoIn ( XOR^ bitwiseANDExpressionNoIn )*
< 	;
< 	
< bitwiseORExpression
< 	: bitwiseXORExpression ( OR^ bitwiseXORExpression )*
< 	;
< 	
< bitwiseORExpressionNoIn
< 	: bitwiseXORExpressionNoIn ( OR^ bitwiseXORExpressionNoIn )*
< 	;
< 
< // $>
< 	
< // $<Binary logical operators (11.11)
< 
< logicalANDExpression
< 	: bitwiseORExpression ( LAND^ bitwiseORExpression )*
< 	;
< 
< logicalANDExpressionNoIn
< 	: bitwiseORExpressionNoIn ( LAND^ bitwiseORExpressionNoIn )*
< 	;
< 	
< logicalORExpression
< 	: logicalANDExpression ( LOR^ logicalANDExpression )*
< 	;
< 	
< logicalORExpressionNoIn
< 	: logicalANDExpressionNoIn ( LOR^ logicalANDExpressionNoIn )*
< 	;
< 
< // $>
< 	
< // $<Conditional operator (11.12)
< 
< conditionalExpression
< 	: logicalORExpression ( QUE^ assignmentExpression COLON! assignmentExpression )?
< 	;
< 
< conditionalExpressionNoIn
< 	: logicalORExpressionNoIn ( QUE^ assignmentExpressionNoIn COLON! assignmentExpressionNoIn )?
< 	;
< 	
< // $>
< 
< // $<Assignment operators (11.13)
< 
< /*
< The specification defines the AssignmentExpression rule as follows:
< AssignmentExpression :
< 	ConditionalExpression 
< 	LeftHandSideExpression AssignmentOperator AssignmentExpression
< This rule has a LL(*) conflict. Resolving this with a syntactical predicate will yield something like this:
< 
< assignmentExpression
< 	: ( leftHandSideExpression assignmentOperator )=> leftHandSideExpression assignmentOperator^ assignmentExpression
< 	| conditionalExpression
< 	;
< assignmentOperator
< 	: ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS
< 	;
< 	
< But that didn't seem to work. Terence Par writes in his book that LL(*) conflicts in general can best be solved with auto backtracking. But that would be 
< a performance killer for such a heavy used rule.
< The solution I came up with is to always invoke the conditionalExpression first and than decide what to do based on the result of that rule.
< When the rule results in a Tree that can't be coming from a left hand side expression, then we're done.
< When it results in a Tree that is coming from a left hand side expression and the LA(1) is an assignment operator then parse the assignment operator
< followed by the right recursive call.
< */
< assignmentExpression
< @init
< {
< 	Object[] isLhs = new Object[1];
< }
< 	: lhs=conditionalExpression
< 	( { isLeftHandSideAssign(lhs, isLhs) }? assignmentOperator^ assignmentExpression )?	
< 	;
< 
< assignmentOperator
< 	: ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS
< 	;
< 
< assignmentExpressionNoIn
< @init
< {
< 	Object[] isLhs = new Object[1];
< }
< 	: lhs=conditionalExpressionNoIn
< 	( { isLeftHandSideAssign(lhs, isLhs) }? assignmentOperator^ assignmentExpressionNoIn )?
< 	;
< 	
< // $>
< 	
< // $<Comma operator (11.14)
< 
< expression
< 	: exprs+=assignmentExpression ( COMMA exprs+=assignmentExpression )*
< 	-> { $exprs.size() > 1 }? ^( CEXPR $exprs+ )
< 	-> $exprs
< 	;
< 
< expressionNoIn
< 	: exprs+=assignmentExpressionNoIn ( COMMA exprs+=assignmentExpressionNoIn )*
< 	-> { $exprs.size() > 1 }? ^( CEXPR $exprs+ )
< 	-> $exprs
< 	;
< 
< // $>
< 
< // $>
< 	
< //
< // $<	A.4 Statements (12)
< //
< 
< /*
< This rule handles semicolons reported by the lexer and situations where the ECMA 3 specification states there should be semicolons automaticly inserted.
< The auto semicolons are not actually inserted but this rule behaves as if they were.
< 
< In the following situations an ECMA 3 parser should auto insert absent but grammaticly required semicolons:
< - the current token is a right brace
< - the current token is the end of file (EOF) token
< - there is at least one end of line (EOL) token between the current token and the previous token.
< 
< The RBRACE is handled by matching it but not consuming it.
< The EOF needs no further handling because it is not consumed by default.
< The EOL situation is handled by promoting the EOL or MultiLineComment with an EOL present from off channel to on channel
< and thus making it parseable instead of handling it as white space. This promoting is done in the action promoteEOL.
< */
< semic
< @init
< {
< 	// Mark current position so we can unconsume a RBRACE.
< 	int marker = input.mark();
< 	// Promote EOL if appropriate	
< 	promoteEOL(retval);
< }
< 	: SEMIC
< 	| EOF
< 	| RBRACE { input.rewind(marker); }
< 	| EOL | MultiLineComment // (with EOL in it)
< 	;
< 
< /*
< To solve the ambiguity between block and objectLiteral via expressionStatement all but the block alternatives have been moved to statementTail.
< Now when k = 1 and a semantical predicate is defined ANTLR generates code that always will prefer block when the LA(1) is a LBRACE.
< This will result in the same behaviour that is described in the specification under 12.4 on the expressionStatement rule.
< */
< statement
< options
< {
< 	k = 1 ;
< }
< @after {
<         if(retval.tree != null)
<             retval.tree.is_statement = true;
<     }
< 	: { input.LA(1) == LBRACE }? block
< 	| statementTail
< 	;
< 	
< statementTail
< 	: variableStatement
< 	| emptyStatement
< 	| expressionStatement
< 	| ifStatement
< 	| iterationStatement
< 	| continueStatement
< 	| breakStatement
< 	| returnStatement
< 	| withStatement
< 	| labelledStatement
< 	| switchStatement
< 	| throwStatement
< 	| tryStatement
< 	;
< 
< // $<Block (12.1)
< 
< block
< 	: lb=LBRACE sourceElement* RBRACE
< 	-> ^( BLOCK[$lb, "BLOCK"] sourceElement* )
< 	;
< 
< // $>
< 	
< // $<Variable statement 12.2)
< 
< variableStatement
< 	: VAR variableDeclaration ( COMMA variableDeclaration )* semic
< 	-> ^( VAR variableDeclaration+ )
< 	;
< 
< variableDeclaration
< 	: Identifier ( ASSIGN^ assignmentExpression )?
< 	;
< 	
< variableDeclarationNoIn
< 	: Identifier ( ASSIGN^ assignmentExpressionNoIn )?
< 	;
< 
< // $>
< 	
< // $<Empty statement (12.3)
< 
< emptyStatement
< 	: SEMIC!
< 	;
< 
< // $>
< 	
< // $<Expression statement (12.4)
< 
< /*
< The look ahead check on LBRACE and FUNCTION the specification mentions has been left out and its function, resolving the ambiguity between:
< - functionExpression and functionDeclaration
< - block and objectLiteral
< are moved to the statement and sourceElement rules.
< */
< expressionStatement
< 	: expression semic!
< 	;
< 
< // $>
< 	
< // $<The if statement (12.5)
< 
< ifStatement
< // The predicate is there just to get rid of the warning. ANTLR will handle the dangling else just fine.
< 	: IF LPAREN expression RPAREN statement ( { input.LA(1) == ELSE }? ELSE statement )?
< 	-> ^( IF expression statement+ )
< 	;
< 
< // $>
< 	
< // $<Iteration statements (12.6)
< 
< iterationStatement
< 	: doStatement
< 	| whileStatement
< 	| forStatement
< 	;
< 	
< doStatement
< 	: DO statement WHILE LPAREN expression RPAREN semic
< 	-> ^( DO statement expression )
< 	;
< 	
< whileStatement
< 	: WHILE^ LPAREN! expression RPAREN! statement
< 	;
< 
< /*
< The forStatement production is refactored considerably as the specification contains a very none LL(*) compliant definition.
< The initial version was like this:	
< 
< forStatement
< 	: FOR^ LPAREN! forControl RPAREN! statement
< 	;
< forControl
< options
< {
< 	backtrack = true ;
< 	//k = 3 ;
< }
< 	: stepClause
< 	| iterationClause
< 	;
< stepClause
< options
< {
< 	memoize = true ;
< }
< 	: ( ex1=expressionNoIn | var=VAR variableDeclarationNoIn ( COMMA variableDeclarationNoIn )* )? SEMIC ex2=expression? SEMIC ex3=expression?
< 	-> { $var != null }? ^( FORSTEP ^( VAR[$var] variableDeclarationNoIn+ ) ^( EXPR $ex2? ) ^( EXPR $ex3? ) )
< 	-> ^( FORSTEP ^( EXPR $ex1? ) ^( EXPR $ex2? ) ^( EXPR $ex3? ) )
< 	;
< iterationClause
< options
< {
< 	memoize = true ;
< }
< 	: ( leftHandSideExpression | var=VAR variableDeclarationNoIn ) IN expression
< 	-> { $var != null }? ^( FORITER ^( VAR[$var] variableDeclarationNoIn ) ^( EXPR expression ) )
< 	-> ^( FORITER ^( EXPR leftHandSideExpression ) ^( EXPR expression ) )
< 	;
< 	
< But this completely relies on the backtrack feature and capabilities of ANTLR. 
< Furthermore backtracking seemed to have 3 major drawbacks:
< - the performance cost of backtracking is considerably
< - didn't seem to work well with ANTLRWorks
< - when introducing a k value to optimize the backtracking away, ANTLR runs out of heap space
< */
< forStatement
< 	: FOR^ LPAREN! forControl RPAREN! statement
< 	;
< 
< forControl
< 	: forControlVar
< 	| forControlExpression
< 	| forControlSemic
< 	;
< 
< forControlVar
< 	: VAR variableDeclarationNoIn
< 	(
< 		(
< 			IN expression
< 			-> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) )
< 		)
< 		|
< 		(
< 			( COMMA variableDeclarationNoIn )* SEMIC ex1=expression? SEMIC ex2=expression?
< 			-> ^( FORSTEP ^( VAR variableDeclarationNoIn+ ) ^( EXPR $ex1? ) ^( EXPR $ex2? ) )
< 		)
< 	)
< 	;
< 
< forControlExpression
< @init
< {
< 	Object[] isLhs = new Object[1];
< }
< 	: ex1=expressionNoIn
< 	( 
< 		{ isLeftHandSideIn(ex1, isLhs) }? (
< 			IN ex2=expression
< 			-> ^( FORITER ^( EXPR $ex1 ) ^( EXPR $ex2 ) )
< 		)
< 		|
< 		(
< 			SEMIC ex2=expression? SEMIC ex3=expression?
< 			-> ^( FORSTEP ^( EXPR $ex1 ) ^( EXPR $ex2? ) ^( EXPR $ex3? ) )
< 		)
< 	)
< 	;
< 
< forControlSemic
< 	: SEMIC ex1=expression? SEMIC ex2=expression?
< 	-> ^( FORSTEP ^( EXPR ) ^( EXPR $ex1? ) ^( EXPR $ex2? ) )
< 	;
< 
< // $>
< 	
< // $<The continue statement (12.7)
< 
< /*
< The action with the call to promoteEOL after CONTINUE is to enforce the semicolon insertion rule of the specification that there are
< no line terminators allowed beween CONTINUE and the optional identifier.
< As an optimization we check the la first to decide whether there is an identier following.
< */
< continueStatement
< 	: CONTINUE^ { if (input.LA(1) == Identifier) promoteEOL(null); } Identifier? semic!
< 	;
< 
< // $>
< 	
< // $<The break statement (12.8)
< 
< /*
< The action with the call to promoteEOL after BREAK is to enforce the semicolon insertion rule of the specification that there are
< no line terminators allowed beween BREAK and the optional identifier.
< As an optimization we check the la first to decide whether there is an identier following.
< */
< breakStatement
< 	: BREAK^ { if (input.LA(1) == Identifier) promoteEOL(null); } Identifier? semic!
< 	;
< 
< // $>
< 	
< // $<The return statement (12.9)
< 
< /*
< The action calling promoteEOL after RETURN ensures that there are no line terminators between RETURN and the optional expression as the specification states.
< When there are these get promoted to on channel and thus virtual semicolon wannabees.
< So the folowing code:
< 
< return
< 1
< 
< will be parsed as:
< 
< return;
< 1;
< */
< returnStatement
< 	: RETURN^ { promoteEOL(null); } expression? semic!
< 	;
< 
< // $>
< 	
< // $<The with statement (12.10)
< 
< withStatement
< 	: WITH^ LPAREN! expression RPAREN! statement
< 	;
< 
< // $>
< 	
< // $<The switch statement (12.11)
< 
< switchStatement
< @init
< {
< 	int defaultClauseCount = 0;
< }
< 	: SWITCH LPAREN expression RPAREN LBRACE ( { defaultClauseCount == 0 }?=> defaultClause { defaultClauseCount++; } | caseClause )* RBRACE
< 	-> ^( SWITCH expression defaultClause? caseClause* )
< 	;
< 
< caseClause
< 	: CASE^ expression COLON! statement*
< 	;
< 	
< defaultClause
< 	: DEFAULT^ COLON! statement*
< 	;
< 
< // $>
< 	
< // $<Labelled statements (12.12)
< 
< labelledStatement
< 	: Identifier COLON statement
< 	-> ^( LABELLED Identifier statement )
< 	;
< 
< // $>
< 	
< // $<The throw statement (12.13)
< 
< /*
< The action calling promoteEOL after THROW ensures that there are no line terminators between THROW and the expression as the specification states.
< When there are line terminators these get promoted to on channel and thus to virtual semicolon wannabees.
< So the folowing code:
< 
< throw
< new Error()
< 
< will be parsed as:
< 
< throw;
< new Error();
< 
< which will yield a recognition exception!
< */
< throwStatement
< 	: THROW^ { promoteEOL(null); } expression semic!
< 	;
< 
< // $>
< 	
< // $<The try statement (12.14)
< 
< tryStatement
< 	: TRY^ block ( catchClause finallyClause? | finallyClause )
< 	;
< 	
< catchClause
< 	: CATCH^ LPAREN! Identifier RPAREN! block
< 	;
< 	
< finallyClause
< 	: FINALLY^ block
< 	;
< 
< // $>
< 
< // $>
< 
< //
< // $<	A.5 Functions and Programs (13, 14)
< //
< 
< // $<	Function Definition (13)
< 
< functionDeclaration
< 	: FUNCTION name=Identifier formalParameterList functionBody
< 	-> ^( FUNCTION $name formalParameterList functionBody )
< 	;
< 
< functionExpression
< 	: FUNCTION name=Identifier? formalParameterList functionBody
< 	-> ^( FUNCTION $name? formalParameterList functionBody )
< 	;
< 
< formalParameterList
< 	: LPAREN ( args+=Identifier ( COMMA args+=Identifier )* )? RPAREN
< 	-> ^( ARGS $args* )
< 	;
< 
< functionBody
< 	: lb=LBRACE sourceElement* RBRACE
< 	-> ^( BLOCK[$lb, "BLOCK"] sourceElement* )
< 	;
< 
< // $>
< 	
< // $<	Program (14)
< 
< program
< 	: sourceElement*
< 	;
< 
< /*
< By setting k  to 1 for this rule and adding the semantical predicate ANTRL will generate code that will always prefer functionDeclararion over functionExpression
< here and therefor remove the ambiguity between these to production.
< This will result in the same behaviour that is described in the specification under 12.4 on the expressionStatement rule.
< */
< sourceElement
< options
< {
< 	k = 1 ;
< }
< 	: { input.LA(1) == FUNCTION }? functionDeclaration
< 	| statement
< 	;
< 
< // $>
< 
< // $>
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScriptLexer.java.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScriptLexer.java.svn-base
1,5955d0
< // $ANTLR 3.1.1 JavaScript.g 2009-03-06 21:11:54
< 
< import org.antlr.runtime.*;
< import java.util.Stack;
< import java.util.List;
< import java.util.ArrayList;
< 
< public class JavaScriptLexer extends Lexer {
<     public static final int COMMA=71;
<     public static final int CONST=37;
<     public static final int BackslashSequence=168;
<     public static final int RegularExpressionLiteral=155;
<     public static final int ARGS=111;
<     public static final int ARRAY=112;
<     public static final int LF=140;
<     public static final int SYNCHRONIZED=59;
<     public static final int HexDigit=150;
<     public static final int DOUBLE=39;
<     public static final int EXPR=118;
<     public static final int ADDASS=99;
<     public static final int DecimalDigit=152;
<     public static final int FALSE=6;
<     public static final int USP=138;
<     public static final int ABSTRACT=32;
<     public static final int SP=136;
<     public static final int SEMIC=70;
<     public static final int IMPORT=47;
<     public static final int DQUOTE=131;
<     public static final int PACKAGE=52;
<     public static final int MODASS=102;
<     public static final int SHR=87;
<     public static final int SQUOTE=132;
<     public static final int CONTINUE=10;
<     public static final int DOT=69;
<     public static final int PRIVATE=53;
<     public static final int MultiLineComment=146;
<     public static final int AND=89;
<     public static final int HexIntegerLiteral=161;
<     public static final int FUNCTION=17;
<     public static final int DIVASS=110;
<     public static final int RegularExpressionFirstChar=169;
<     public static final int GTE=75;
<     public static final int OctalEscapeSequence=164;
<     public static final int HexEscapeSequence=165;
<     public static final int SingleLineComment=147;
<     public static final int RPAREN=66;
<     public static final int POS=129;
<     public static final int UnicodeEscapeSequence=166;
<     public static final int IdentifierStartASCII=151;
<     public static final int FINALLY=15;
<     public static final int IdentifierNameASCIIStart=154;
<     public static final int EXTENDS=42;
<     public static final int IdentifierPart=153;
<     public static final int SUPER=58;
<     public static final int Identifier=148;
<     public static final int SAME=78;
<     public static final int CHAR=35;
<     public static final int NEW=21;
<     public static final int EQ=76;
<     public static final int LT=72;
<     public static final int FINAL=43;
<     public static final int SUBASS=100;
<     public static final int VT=134;
<     public static final int LAND=94;
<     public static final int LBRACK=67;
<     public static final int CATCH=9;
<     public static final int STATIC=57;
<     public static final int CASE=8;
<     public static final int MUL=82;
<     public static final int INTERFACE=49;
<     public static final int ExponentPart=157;
<     public static final int INV=93;
<     public static final int BOOLEAN=33;
<     public static final int ELSE=14;
<     public static final int CharacterEscapeSequence=162;
<     public static final int BSLASH=130;
<     public static final int SHLASS=103;
<     public static final int DecimalLiteral=159;
<     public static final int BREAK=7;
<     public static final int NULL=4;
<     public static final int XOR=91;
<     public static final int COLON=97;
<     public static final int DIV=109;
<     public static final int ORASS=107;
<     public static final int TRUE=5;
<     public static final int ADD=80;
<     public static final int THROW=25;
<     public static final int SHORT=56;
<     public static final int LABELLED=122;
<     public static final int CR=141;
<     public static final int RegularExpressionChar=170;
<     public static final int PUBLIC=55;
<     public static final int SHL=86;
<     public static final int LONG=50;
<     public static final int LOR=95;
<     public static final int TYPEOF=27;
<     public static final int INC=84;
<     public static final int TRANSIENT=61;
<     public static final int FLOAT=44;
<     public static final int TAB=133;
<     public static final int THROWS=60;
<     public static final int ZeroToThree=163;
<     public static final int FF=135;
<     public static final int FORITER=119;
<     public static final int MOD=83;
<     public static final int GOTO=45;
<     public static final int EXPORT=41;
<     public static final int OR=90;
<     public static final int MULASS=101;
<     public static final int LBRACE=63;
<     public static final int RBRACE=64;
<     public static final int BLOCK=113;
<     public static final int PROTECTED=54;
<     public static final int ANDASS=106;
<     public static final int SHU=88;
<     public static final int LineTerminator=144;
<     public static final int PAREXPR=126;
<     public static final int EscapeSequence=167;
<     public static final int INT=48;
<     public static final int LS=142;
<     public static final int ASSIGN=98;
<     public static final int CEXPR=117;
<     public static final int INSTANCEOF=20;
<     public static final int VOID=29;
<     public static final int LPAREN=65;
<     public static final int WhiteSpace=139;
<     public static final int XORASS=108;
<     public static final int NEQ=77;
<     public static final int QUE=96;
<     public static final int NAMEDVALUE=123;
<     public static final int ENUM=40;
<     public static final int DEBUGGER=38;
<     public static final int PS=143;
<     public static final int DELETE=12;
<     public static final int OBJECT=125;
<     public static final int DO=13;
<     public static final int IMPLEMENTS=46;
<     public static final int SWITCH=23;
<     public static final int WHILE=30;
<     public static final int OctalIntegerLiteral=160;
<     public static final int BYINDEX=115;
<     public static final int FORSTEP=120;
<     public static final int PINC=128;
<     public static final int OctalDigit=156;
<     public static final int GT=73;
<     public static final int StringLiteral=149;
<     public static final int DecimalIntegerLiteral=158;
<     public static final int SHRASS=104;
<     public static final int ITEM=121;
<     public static final int THIS=24;
<     public static final int SHUASS=105;
<     public static final int WITH=31;
<     public static final int IN=19;
<     public static final int LTE=74;
<     public static final int VAR=28;
<     public static final int CLASS=36;
<     public static final int NATIVE=51;
<     public static final int DEC=85;
<     public static final int RETURN=22;
<     public static final int BYTE=34;
<     public static final int VOLATILE=62;
<     public static final int IF=18;
<     public static final int EOF=-1;
<     public static final int EOL=145;
<     public static final int CALL=116;
<     public static final int NBSP=137;
<     public static final int FOR=16;
<     public static final int RBRACK=68;
<     public static final int DEFAULT=11;
<     public static final int NEG=124;
<     public static final int SUB=81;
<     public static final int TRY=26;
<     public static final int NOT=92;
<     public static final int BYFIELD=114;
<     public static final int PDEC=127;
<     public static final int NSAME=79;
< 
<     private Token last;
< 
<     private final boolean areRegularExpressionsEnabled()
<     {
<     	if (last == null)
<     	{
<     		return true;
<     	}
<     	switch (last.getType())
<     	{
<     	// identifier
<     		case Identifier:
<     	// literals
<     		case NULL:
<     		case TRUE:
<     		case FALSE:
<     		case THIS:
<     		case OctalIntegerLiteral:
<     		case DecimalLiteral:
<     		case HexIntegerLiteral:
<     		case StringLiteral:
<     	// member access ending 
<     		case RBRACK:
<     	// function call or nested expression ending
<     		case RPAREN:
<     			return false;
<     	// otherwise OK
<     		default:
<     			return true;
<     	}
<     }
<     	
<     private final void consumeIdentifierUnicodeStart() throws RecognitionException, NoViableAltException
<     {
<     	int ch = input.LA(1);
<     	if (isIdentifierStartUnicode(ch))
<     	{
<     		matchAny();
<     		do
<     		{
<     			ch = input.LA(1);
<     			if (ch == '$' || (ch >= '0' && ch <= '9') || (ch >= 'A' && ch <= 'Z') || ch == '\\' || ch == '_' || (ch >= 'a' && ch <= 'z') || isIdentifierPartUnicode(ch))
<     			{
<     				mIdentifierPart();
<     			}
<     			else
<     			{
<     				return;
<     			}
<     		}
<     		while (true);
<     	}
<     	else
<     	{
<     		throw new NoViableAltException();
<     	}
<     }
<     	
<     private final boolean isIdentifierPartUnicode(int ch)
<     {
<     	return Character.isJavaIdentifierPart(ch);
<     }
<     	
<     private final boolean isIdentifierStartUnicode(int ch)
<     {
<     	return Character.isJavaIdentifierStart(ch);
<     }
< 
<     public Token nextToken()
<     {
<     	Token result = super.nextToken();
<     	if (result.getChannel() == Token.DEFAULT_CHANNEL)
<     	{
<     		last = result;
<     	}
<     	return result;		
<     }
< 
< 
<     // delegates
<     // delegators
< 
<     public JavaScriptLexer() {;} 
<     public JavaScriptLexer(CharStream input) {
<         this(input, new RecognizerSharedState());
<     }
<     public JavaScriptLexer(CharStream input, RecognizerSharedState state) {
<         super(input,state);
< 
<     }
<     public String getGrammarFileName() { return "JavaScript.g"; }
< 
<     // $ANTLR start "NULL"
<     public final void mNULL() throws RecognitionException {
<         try {
<             int _type = NULL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:87:6: ( 'null' )
<             // JavaScript.g:87:8: 'null'
<             {
<             match("null"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NULL"
< 
<     // $ANTLR start "TRUE"
<     public final void mTRUE() throws RecognitionException {
<         try {
<             int _type = TRUE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:88:6: ( 'true' )
<             // JavaScript.g:88:8: 'true'
<             {
<             match("true"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TRUE"
< 
<     // $ANTLR start "FALSE"
<     public final void mFALSE() throws RecognitionException {
<         try {
<             int _type = FALSE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:89:7: ( 'false' )
<             // JavaScript.g:89:9: 'false'
<             {
<             match("false"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FALSE"
< 
<     // $ANTLR start "BREAK"
<     public final void mBREAK() throws RecognitionException {
<         try {
<             int _type = BREAK;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:90:7: ( 'break' )
<             // JavaScript.g:90:9: 'break'
<             {
<             match("break"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BREAK"
< 
<     // $ANTLR start "CASE"
<     public final void mCASE() throws RecognitionException {
<         try {
<             int _type = CASE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:91:6: ( 'case' )
<             // JavaScript.g:91:8: 'case'
<             {
<             match("case"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CASE"
< 
<     // $ANTLR start "CATCH"
<     public final void mCATCH() throws RecognitionException {
<         try {
<             int _type = CATCH;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:92:7: ( 'catch' )
<             // JavaScript.g:92:9: 'catch'
<             {
<             match("catch"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CATCH"
< 
<     // $ANTLR start "CONTINUE"
<     public final void mCONTINUE() throws RecognitionException {
<         try {
<             int _type = CONTINUE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:93:10: ( 'continue' )
<             // JavaScript.g:93:12: 'continue'
<             {
<             match("continue"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CONTINUE"
< 
<     // $ANTLR start "DEFAULT"
<     public final void mDEFAULT() throws RecognitionException {
<         try {
<             int _type = DEFAULT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:94:9: ( 'default' )
<             // JavaScript.g:94:11: 'default'
<             {
<             match("default"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DEFAULT"
< 
<     // $ANTLR start "DELETE"
<     public final void mDELETE() throws RecognitionException {
<         try {
<             int _type = DELETE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:95:8: ( 'delete' )
<             // JavaScript.g:95:10: 'delete'
<             {
<             match("delete"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DELETE"
< 
<     // $ANTLR start "DO"
<     public final void mDO() throws RecognitionException {
<         try {
<             int _type = DO;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:96:4: ( 'do' )
<             // JavaScript.g:96:6: 'do'
<             {
<             match("do"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DO"
< 
<     // $ANTLR start "ELSE"
<     public final void mELSE() throws RecognitionException {
<         try {
<             int _type = ELSE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:97:6: ( 'else' )
<             // JavaScript.g:97:8: 'else'
<             {
<             match("else"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ELSE"
< 
<     // $ANTLR start "FINALLY"
<     public final void mFINALLY() throws RecognitionException {
<         try {
<             int _type = FINALLY;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:98:9: ( 'finally' )
<             // JavaScript.g:98:11: 'finally'
<             {
<             match("finally"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FINALLY"
< 
<     // $ANTLR start "FOR"
<     public final void mFOR() throws RecognitionException {
<         try {
<             int _type = FOR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:99:5: ( 'for' )
<             // JavaScript.g:99:7: 'for'
<             {
<             match("for"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FOR"
< 
<     // $ANTLR start "FUNCTION"
<     public final void mFUNCTION() throws RecognitionException {
<         try {
<             int _type = FUNCTION;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:100:10: ( 'function' )
<             // JavaScript.g:100:12: 'function'
<             {
<             match("function"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FUNCTION"
< 
<     // $ANTLR start "IF"
<     public final void mIF() throws RecognitionException {
<         try {
<             int _type = IF;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:101:4: ( 'if' )
<             // JavaScript.g:101:6: 'if'
<             {
<             match("if"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IF"
< 
<     // $ANTLR start "IN"
<     public final void mIN() throws RecognitionException {
<         try {
<             int _type = IN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:102:4: ( 'in' )
<             // JavaScript.g:102:6: 'in'
<             {
<             match("in"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IN"
< 
<     // $ANTLR start "INSTANCEOF"
<     public final void mINSTANCEOF() throws RecognitionException {
<         try {
<             int _type = INSTANCEOF;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:103:12: ( 'instanceof' )
<             // JavaScript.g:103:14: 'instanceof'
<             {
<             match("instanceof"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INSTANCEOF"
< 
<     // $ANTLR start "NEW"
<     public final void mNEW() throws RecognitionException {
<         try {
<             int _type = NEW;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:104:5: ( 'new' )
<             // JavaScript.g:104:7: 'new'
<             {
<             match("new"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NEW"
< 
<     // $ANTLR start "RETURN"
<     public final void mRETURN() throws RecognitionException {
<         try {
<             int _type = RETURN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:105:8: ( 'return' )
<             // JavaScript.g:105:10: 'return'
<             {
<             match("return"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RETURN"
< 
<     // $ANTLR start "SWITCH"
<     public final void mSWITCH() throws RecognitionException {
<         try {
<             int _type = SWITCH;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:106:8: ( 'switch' )
<             // JavaScript.g:106:10: 'switch'
<             {
<             match("switch"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SWITCH"
< 
<     // $ANTLR start "THIS"
<     public final void mTHIS() throws RecognitionException {
<         try {
<             int _type = THIS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:107:6: ( 'this' )
<             // JavaScript.g:107:8: 'this'
<             {
<             match("this"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "THIS"
< 
<     // $ANTLR start "THROW"
<     public final void mTHROW() throws RecognitionException {
<         try {
<             int _type = THROW;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:108:7: ( 'throw' )
<             // JavaScript.g:108:9: 'throw'
<             {
<             match("throw"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "THROW"
< 
<     // $ANTLR start "TRY"
<     public final void mTRY() throws RecognitionException {
<         try {
<             int _type = TRY;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:109:5: ( 'try' )
<             // JavaScript.g:109:7: 'try'
<             {
<             match("try"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TRY"
< 
<     // $ANTLR start "TYPEOF"
<     public final void mTYPEOF() throws RecognitionException {
<         try {
<             int _type = TYPEOF;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:110:8: ( 'typeof' )
<             // JavaScript.g:110:10: 'typeof'
<             {
<             match("typeof"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TYPEOF"
< 
<     // $ANTLR start "VAR"
<     public final void mVAR() throws RecognitionException {
<         try {
<             int _type = VAR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:111:5: ( 'var' )
<             // JavaScript.g:111:7: 'var'
<             {
<             match("var"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VAR"
< 
<     // $ANTLR start "VOID"
<     public final void mVOID() throws RecognitionException {
<         try {
<             int _type = VOID;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:112:6: ( 'void' )
<             // JavaScript.g:112:8: 'void'
<             {
<             match("void"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VOID"
< 
<     // $ANTLR start "WHILE"
<     public final void mWHILE() throws RecognitionException {
<         try {
<             int _type = WHILE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:113:7: ( 'while' )
<             // JavaScript.g:113:9: 'while'
<             {
<             match("while"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "WHILE"
< 
<     // $ANTLR start "WITH"
<     public final void mWITH() throws RecognitionException {
<         try {
<             int _type = WITH;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:114:6: ( 'with' )
<             // JavaScript.g:114:8: 'with'
<             {
<             match("with"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "WITH"
< 
<     // $ANTLR start "ABSTRACT"
<     public final void mABSTRACT() throws RecognitionException {
<         try {
<             int _type = ABSTRACT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:115:10: ( 'abstract' )
<             // JavaScript.g:115:12: 'abstract'
<             {
<             match("abstract"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ABSTRACT"
< 
<     // $ANTLR start "BOOLEAN"
<     public final void mBOOLEAN() throws RecognitionException {
<         try {
<             int _type = BOOLEAN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:116:9: ( 'boolean' )
<             // JavaScript.g:116:11: 'boolean'
<             {
<             match("boolean"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BOOLEAN"
< 
<     // $ANTLR start "BYTE"
<     public final void mBYTE() throws RecognitionException {
<         try {
<             int _type = BYTE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:117:6: ( 'byte' )
<             // JavaScript.g:117:8: 'byte'
<             {
<             match("byte"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BYTE"
< 
<     // $ANTLR start "CHAR"
<     public final void mCHAR() throws RecognitionException {
<         try {
<             int _type = CHAR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:118:6: ( 'char' )
<             // JavaScript.g:118:8: 'char'
<             {
<             match("char"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CHAR"
< 
<     // $ANTLR start "CLASS"
<     public final void mCLASS() throws RecognitionException {
<         try {
<             int _type = CLASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:119:7: ( 'class' )
<             // JavaScript.g:119:9: 'class'
<             {
<             match("class"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CLASS"
< 
<     // $ANTLR start "CONST"
<     public final void mCONST() throws RecognitionException {
<         try {
<             int _type = CONST;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:120:7: ( 'const' )
<             // JavaScript.g:120:9: 'const'
<             {
<             match("const"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CONST"
< 
<     // $ANTLR start "DEBUGGER"
<     public final void mDEBUGGER() throws RecognitionException {
<         try {
<             int _type = DEBUGGER;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:121:10: ( 'debugger' )
<             // JavaScript.g:121:12: 'debugger'
<             {
<             match("debugger"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DEBUGGER"
< 
<     // $ANTLR start "DOUBLE"
<     public final void mDOUBLE() throws RecognitionException {
<         try {
<             int _type = DOUBLE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:122:8: ( 'double' )
<             // JavaScript.g:122:10: 'double'
<             {
<             match("double"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DOUBLE"
< 
<     // $ANTLR start "ENUM"
<     public final void mENUM() throws RecognitionException {
<         try {
<             int _type = ENUM;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:123:6: ( 'enum' )
<             // JavaScript.g:123:8: 'enum'
<             {
<             match("enum"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ENUM"
< 
<     // $ANTLR start "EXPORT"
<     public final void mEXPORT() throws RecognitionException {
<         try {
<             int _type = EXPORT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:124:8: ( 'export' )
<             // JavaScript.g:124:10: 'export'
<             {
<             match("export"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EXPORT"
< 
<     // $ANTLR start "EXTENDS"
<     public final void mEXTENDS() throws RecognitionException {
<         try {
<             int _type = EXTENDS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:125:9: ( 'extends' )
<             // JavaScript.g:125:11: 'extends'
<             {
<             match("extends"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EXTENDS"
< 
<     // $ANTLR start "FINAL"
<     public final void mFINAL() throws RecognitionException {
<         try {
<             int _type = FINAL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:126:7: ( 'final' )
<             // JavaScript.g:126:9: 'final'
<             {
<             match("final"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FINAL"
< 
<     // $ANTLR start "FLOAT"
<     public final void mFLOAT() throws RecognitionException {
<         try {
<             int _type = FLOAT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:127:7: ( 'float' )
<             // JavaScript.g:127:9: 'float'
<             {
<             match("float"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FLOAT"
< 
<     // $ANTLR start "GOTO"
<     public final void mGOTO() throws RecognitionException {
<         try {
<             int _type = GOTO;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:128:6: ( 'goto' )
<             // JavaScript.g:128:8: 'goto'
<             {
<             match("goto"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "GOTO"
< 
<     // $ANTLR start "IMPLEMENTS"
<     public final void mIMPLEMENTS() throws RecognitionException {
<         try {
<             int _type = IMPLEMENTS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:129:12: ( 'implements' )
<             // JavaScript.g:129:14: 'implements'
<             {
<             match("implements"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IMPLEMENTS"
< 
<     // $ANTLR start "IMPORT"
<     public final void mIMPORT() throws RecognitionException {
<         try {
<             int _type = IMPORT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:130:8: ( 'import' )
<             // JavaScript.g:130:10: 'import'
<             {
<             match("import"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IMPORT"
< 
<     // $ANTLR start "INT"
<     public final void mINT() throws RecognitionException {
<         try {
<             int _type = INT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:131:5: ( 'int' )
<             // JavaScript.g:131:7: 'int'
<             {
<             match("int"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INT"
< 
<     // $ANTLR start "INTERFACE"
<     public final void mINTERFACE() throws RecognitionException {
<         try {
<             int _type = INTERFACE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:132:11: ( 'interface' )
<             // JavaScript.g:132:13: 'interface'
<             {
<             match("interface"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INTERFACE"
< 
<     // $ANTLR start "LONG"
<     public final void mLONG() throws RecognitionException {
<         try {
<             int _type = LONG;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:133:6: ( 'long' )
<             // JavaScript.g:133:8: 'long'
<             {
<             match("long"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LONG"
< 
<     // $ANTLR start "NATIVE"
<     public final void mNATIVE() throws RecognitionException {
<         try {
<             int _type = NATIVE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:134:8: ( 'native' )
<             // JavaScript.g:134:10: 'native'
<             {
<             match("native"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NATIVE"
< 
<     // $ANTLR start "PACKAGE"
<     public final void mPACKAGE() throws RecognitionException {
<         try {
<             int _type = PACKAGE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:135:9: ( 'package' )
<             // JavaScript.g:135:11: 'package'
<             {
<             match("package"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PACKAGE"
< 
<     // $ANTLR start "PRIVATE"
<     public final void mPRIVATE() throws RecognitionException {
<         try {
<             int _type = PRIVATE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:136:9: ( 'private' )
<             // JavaScript.g:136:11: 'private'
<             {
<             match("private"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PRIVATE"
< 
<     // $ANTLR start "PROTECTED"
<     public final void mPROTECTED() throws RecognitionException {
<         try {
<             int _type = PROTECTED;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:137:11: ( 'protected' )
<             // JavaScript.g:137:13: 'protected'
<             {
<             match("protected"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PROTECTED"
< 
<     // $ANTLR start "PUBLIC"
<     public final void mPUBLIC() throws RecognitionException {
<         try {
<             int _type = PUBLIC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:138:8: ( 'public' )
<             // JavaScript.g:138:10: 'public'
<             {
<             match("public"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PUBLIC"
< 
<     // $ANTLR start "SHORT"
<     public final void mSHORT() throws RecognitionException {
<         try {
<             int _type = SHORT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:139:7: ( 'short' )
<             // JavaScript.g:139:9: 'short'
<             {
<             match("short"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHORT"
< 
<     // $ANTLR start "STATIC"
<     public final void mSTATIC() throws RecognitionException {
<         try {
<             int _type = STATIC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:140:8: ( 'static' )
<             // JavaScript.g:140:10: 'static'
<             {
<             match("static"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "STATIC"
< 
<     // $ANTLR start "SUPER"
<     public final void mSUPER() throws RecognitionException {
<         try {
<             int _type = SUPER;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:141:7: ( 'super' )
<             // JavaScript.g:141:9: 'super'
<             {
<             match("super"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SUPER"
< 
<     // $ANTLR start "SYNCHRONIZED"
<     public final void mSYNCHRONIZED() throws RecognitionException {
<         try {
<             int _type = SYNCHRONIZED;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:142:14: ( 'synchronized' )
<             // JavaScript.g:142:16: 'synchronized'
<             {
<             match("synchronized"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SYNCHRONIZED"
< 
<     // $ANTLR start "THROWS"
<     public final void mTHROWS() throws RecognitionException {
<         try {
<             int _type = THROWS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:143:8: ( 'throws' )
<             // JavaScript.g:143:10: 'throws'
<             {
<             match("throws"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "THROWS"
< 
<     // $ANTLR start "TRANSIENT"
<     public final void mTRANSIENT() throws RecognitionException {
<         try {
<             int _type = TRANSIENT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:144:11: ( 'transient' )
<             // JavaScript.g:144:13: 'transient'
<             {
<             match("transient"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TRANSIENT"
< 
<     // $ANTLR start "VOLATILE"
<     public final void mVOLATILE() throws RecognitionException {
<         try {
<             int _type = VOLATILE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:145:10: ( 'volatile' )
<             // JavaScript.g:145:12: 'volatile'
<             {
<             match("volatile"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VOLATILE"
< 
<     // $ANTLR start "LBRACE"
<     public final void mLBRACE() throws RecognitionException {
<         try {
<             int _type = LBRACE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:146:8: ( '{' )
<             // JavaScript.g:146:10: '{'
<             {
<             match('{'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LBRACE"
< 
<     // $ANTLR start "RBRACE"
<     public final void mRBRACE() throws RecognitionException {
<         try {
<             int _type = RBRACE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:147:8: ( '}' )
<             // JavaScript.g:147:10: '}'
<             {
<             match('}'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RBRACE"
< 
<     // $ANTLR start "LPAREN"
<     public final void mLPAREN() throws RecognitionException {
<         try {
<             int _type = LPAREN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:148:8: ( '(' )
<             // JavaScript.g:148:10: '('
<             {
<             match('('); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LPAREN"
< 
<     // $ANTLR start "RPAREN"
<     public final void mRPAREN() throws RecognitionException {
<         try {
<             int _type = RPAREN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:149:8: ( ')' )
<             // JavaScript.g:149:10: ')'
<             {
<             match(')'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RPAREN"
< 
<     // $ANTLR start "LBRACK"
<     public final void mLBRACK() throws RecognitionException {
<         try {
<             int _type = LBRACK;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:150:8: ( '[' )
<             // JavaScript.g:150:10: '['
<             {
<             match('['); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LBRACK"
< 
<     // $ANTLR start "RBRACK"
<     public final void mRBRACK() throws RecognitionException {
<         try {
<             int _type = RBRACK;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:151:8: ( ']' )
<             // JavaScript.g:151:10: ']'
<             {
<             match(']'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RBRACK"
< 
<     // $ANTLR start "DOT"
<     public final void mDOT() throws RecognitionException {
<         try {
<             int _type = DOT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:152:5: ( '.' )
<             // JavaScript.g:152:7: '.'
<             {
<             match('.'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DOT"
< 
<     // $ANTLR start "SEMIC"
<     public final void mSEMIC() throws RecognitionException {
<         try {
<             int _type = SEMIC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:153:7: ( ';' )
<             // JavaScript.g:153:9: ';'
<             {
<             match(';'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SEMIC"
< 
<     // $ANTLR start "COMMA"
<     public final void mCOMMA() throws RecognitionException {
<         try {
<             int _type = COMMA;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:154:7: ( ',' )
<             // JavaScript.g:154:9: ','
<             {
<             match(','); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "COMMA"
< 
<     // $ANTLR start "LT"
<     public final void mLT() throws RecognitionException {
<         try {
<             int _type = LT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:155:4: ( '<' )
<             // JavaScript.g:155:6: '<'
<             {
<             match('<'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LT"
< 
<     // $ANTLR start "GT"
<     public final void mGT() throws RecognitionException {
<         try {
<             int _type = GT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:156:4: ( '>' )
<             // JavaScript.g:156:6: '>'
<             {
<             match('>'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "GT"
< 
<     // $ANTLR start "LTE"
<     public final void mLTE() throws RecognitionException {
<         try {
<             int _type = LTE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:157:5: ( '<=' )
<             // JavaScript.g:157:7: '<='
<             {
<             match("<="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LTE"
< 
<     // $ANTLR start "GTE"
<     public final void mGTE() throws RecognitionException {
<         try {
<             int _type = GTE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:158:5: ( '>=' )
<             // JavaScript.g:158:7: '>='
<             {
<             match(">="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "GTE"
< 
<     // $ANTLR start "EQ"
<     public final void mEQ() throws RecognitionException {
<         try {
<             int _type = EQ;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:159:4: ( '==' )
<             // JavaScript.g:159:6: '=='
<             {
<             match("=="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EQ"
< 
<     // $ANTLR start "NEQ"
<     public final void mNEQ() throws RecognitionException {
<         try {
<             int _type = NEQ;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:160:5: ( '!=' )
<             // JavaScript.g:160:7: '!='
<             {
<             match("!="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NEQ"
< 
<     // $ANTLR start "SAME"
<     public final void mSAME() throws RecognitionException {
<         try {
<             int _type = SAME;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:161:6: ( '===' )
<             // JavaScript.g:161:8: '==='
<             {
<             match("==="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SAME"
< 
<     // $ANTLR start "NSAME"
<     public final void mNSAME() throws RecognitionException {
<         try {
<             int _type = NSAME;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:162:7: ( '!==' )
<             // JavaScript.g:162:9: '!=='
<             {
<             match("!=="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NSAME"
< 
<     // $ANTLR start "ADD"
<     public final void mADD() throws RecognitionException {
<         try {
<             int _type = ADD;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:163:5: ( '+' )
<             // JavaScript.g:163:7: '+'
<             {
<             match('+'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ADD"
< 
<     // $ANTLR start "SUB"
<     public final void mSUB() throws RecognitionException {
<         try {
<             int _type = SUB;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:164:5: ( '-' )
<             // JavaScript.g:164:7: '-'
<             {
<             match('-'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SUB"
< 
<     // $ANTLR start "MUL"
<     public final void mMUL() throws RecognitionException {
<         try {
<             int _type = MUL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:165:5: ( '*' )
<             // JavaScript.g:165:7: '*'
<             {
<             match('*'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MUL"
< 
<     // $ANTLR start "MOD"
<     public final void mMOD() throws RecognitionException {
<         try {
<             int _type = MOD;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:166:5: ( '%' )
<             // JavaScript.g:166:7: '%'
<             {
<             match('%'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MOD"
< 
<     // $ANTLR start "INC"
<     public final void mINC() throws RecognitionException {
<         try {
<             int _type = INC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:167:5: ( '++' )
<             // JavaScript.g:167:7: '++'
<             {
<             match("++"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INC"
< 
<     // $ANTLR start "DEC"
<     public final void mDEC() throws RecognitionException {
<         try {
<             int _type = DEC;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:168:5: ( '--' )
<             // JavaScript.g:168:7: '--'
<             {
<             match("--"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DEC"
< 
<     // $ANTLR start "SHL"
<     public final void mSHL() throws RecognitionException {
<         try {
<             int _type = SHL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:169:5: ( '<<' )
<             // JavaScript.g:169:7: '<<'
<             {
<             match("<<"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHL"
< 
<     // $ANTLR start "SHR"
<     public final void mSHR() throws RecognitionException {
<         try {
<             int _type = SHR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:170:5: ( '>>' )
<             // JavaScript.g:170:7: '>>'
<             {
<             match(">>"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHR"
< 
<     // $ANTLR start "SHU"
<     public final void mSHU() throws RecognitionException {
<         try {
<             int _type = SHU;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:171:5: ( '>>>' )
<             // JavaScript.g:171:7: '>>>'
<             {
<             match(">>>"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHU"
< 
<     // $ANTLR start "AND"
<     public final void mAND() throws RecognitionException {
<         try {
<             int _type = AND;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:172:5: ( '&' )
<             // JavaScript.g:172:7: '&'
<             {
<             match('&'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "AND"
< 
<     // $ANTLR start "OR"
<     public final void mOR() throws RecognitionException {
<         try {
<             int _type = OR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:173:4: ( '|' )
<             // JavaScript.g:173:6: '|'
<             {
<             match('|'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OR"
< 
<     // $ANTLR start "XOR"
<     public final void mXOR() throws RecognitionException {
<         try {
<             int _type = XOR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:174:5: ( '^' )
<             // JavaScript.g:174:7: '^'
<             {
<             match('^'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "XOR"
< 
<     // $ANTLR start "NOT"
<     public final void mNOT() throws RecognitionException {
<         try {
<             int _type = NOT;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:175:5: ( '!' )
<             // JavaScript.g:175:7: '!'
<             {
<             match('!'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NOT"
< 
<     // $ANTLR start "INV"
<     public final void mINV() throws RecognitionException {
<         try {
<             int _type = INV;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:176:5: ( '~' )
<             // JavaScript.g:176:7: '~'
<             {
<             match('~'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "INV"
< 
<     // $ANTLR start "LAND"
<     public final void mLAND() throws RecognitionException {
<         try {
<             int _type = LAND;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:177:6: ( '&&' )
<             // JavaScript.g:177:8: '&&'
<             {
<             match("&&"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LAND"
< 
<     // $ANTLR start "LOR"
<     public final void mLOR() throws RecognitionException {
<         try {
<             int _type = LOR;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:178:5: ( '||' )
<             // JavaScript.g:178:7: '||'
<             {
<             match("||"); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LOR"
< 
<     // $ANTLR start "QUE"
<     public final void mQUE() throws RecognitionException {
<         try {
<             int _type = QUE;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:179:5: ( '?' )
<             // JavaScript.g:179:7: '?'
<             {
<             match('?'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "QUE"
< 
<     // $ANTLR start "COLON"
<     public final void mCOLON() throws RecognitionException {
<         try {
<             int _type = COLON;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:180:7: ( ':' )
<             // JavaScript.g:180:9: ':'
<             {
<             match(':'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "COLON"
< 
<     // $ANTLR start "ASSIGN"
<     public final void mASSIGN() throws RecognitionException {
<         try {
<             int _type = ASSIGN;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:181:8: ( '=' )
<             // JavaScript.g:181:10: '='
<             {
<             match('='); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ASSIGN"
< 
<     // $ANTLR start "ADDASS"
<     public final void mADDASS() throws RecognitionException {
<         try {
<             int _type = ADDASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:182:8: ( '+=' )
<             // JavaScript.g:182:10: '+='
<             {
<             match("+="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ADDASS"
< 
<     // $ANTLR start "SUBASS"
<     public final void mSUBASS() throws RecognitionException {
<         try {
<             int _type = SUBASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:183:8: ( '-=' )
<             // JavaScript.g:183:10: '-='
<             {
<             match("-="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SUBASS"
< 
<     // $ANTLR start "MULASS"
<     public final void mMULASS() throws RecognitionException {
<         try {
<             int _type = MULASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:184:8: ( '*=' )
<             // JavaScript.g:184:10: '*='
<             {
<             match("*="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MULASS"
< 
<     // $ANTLR start "MODASS"
<     public final void mMODASS() throws RecognitionException {
<         try {
<             int _type = MODASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:185:8: ( '%=' )
<             // JavaScript.g:185:10: '%='
<             {
<             match("%="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MODASS"
< 
<     // $ANTLR start "SHLASS"
<     public final void mSHLASS() throws RecognitionException {
<         try {
<             int _type = SHLASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:186:8: ( '<<=' )
<             // JavaScript.g:186:10: '<<='
<             {
<             match("<<="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHLASS"
< 
<     // $ANTLR start "SHRASS"
<     public final void mSHRASS() throws RecognitionException {
<         try {
<             int _type = SHRASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:187:8: ( '>>=' )
<             // JavaScript.g:187:10: '>>='
<             {
<             match(">>="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHRASS"
< 
<     // $ANTLR start "SHUASS"
<     public final void mSHUASS() throws RecognitionException {
<         try {
<             int _type = SHUASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:188:8: ( '>>>=' )
<             // JavaScript.g:188:10: '>>>='
<             {
<             match(">>>="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SHUASS"
< 
<     // $ANTLR start "ANDASS"
<     public final void mANDASS() throws RecognitionException {
<         try {
<             int _type = ANDASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:189:8: ( '&=' )
<             // JavaScript.g:189:10: '&='
<             {
<             match("&="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ANDASS"
< 
<     // $ANTLR start "ORASS"
<     public final void mORASS() throws RecognitionException {
<         try {
<             int _type = ORASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:190:7: ( '|=' )
<             // JavaScript.g:190:9: '|='
<             {
<             match("|="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ORASS"
< 
<     // $ANTLR start "XORASS"
<     public final void mXORASS() throws RecognitionException {
<         try {
<             int _type = XORASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:191:8: ( '^=' )
<             // JavaScript.g:191:10: '^='
<             {
<             match("^="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "XORASS"
< 
<     // $ANTLR start "DIV"
<     public final void mDIV() throws RecognitionException {
<         try {
<             int _type = DIV;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:192:5: ( '/' )
<             // JavaScript.g:192:7: '/'
<             {
<             match('/'); 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DIV"
< 
<     // $ANTLR start "DIVASS"
<     public final void mDIVASS() throws RecognitionException {
<         try {
<             int _type = DIVASS;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:193:8: ( '/=' )
<             // JavaScript.g:193:10: '/='
<             {
<             match("/="); 
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DIVASS"
< 
<     // $ANTLR start "BSLASH"
<     public final void mBSLASH() throws RecognitionException {
<         try {
<             // JavaScript.g:412:2: ( '\\\\' )
<             // JavaScript.g:412:4: '\\\\'
<             {
<             match('\\'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BSLASH"
< 
<     // $ANTLR start "DQUOTE"
<     public final void mDQUOTE() throws RecognitionException {
<         try {
<             // JavaScript.g:416:2: ( '\"' )
<             // JavaScript.g:416:4: '\"'
<             {
<             match('\"'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DQUOTE"
< 
<     // $ANTLR start "SQUOTE"
<     public final void mSQUOTE() throws RecognitionException {
<         try {
<             // JavaScript.g:420:2: ( '\\'' )
<             // JavaScript.g:420:4: '\\''
<             {
<             match('\''); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SQUOTE"
< 
<     // $ANTLR start "TAB"
<     public final void mTAB() throws RecognitionException {
<         try {
<             // JavaScript.g:426:2: ( '\\u0009' )
<             // JavaScript.g:426:4: '\\u0009'
<             {
<             match('\t'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "TAB"
< 
<     // $ANTLR start "VT"
<     public final void mVT() throws RecognitionException {
<         try {
<             // JavaScript.g:430:2: ( '\\u000b' )
<             // JavaScript.g:430:4: '\\u000b'
<             {
<             match('\u000B'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "VT"
< 
<     // $ANTLR start "FF"
<     public final void mFF() throws RecognitionException {
<         try {
<             // JavaScript.g:434:2: ( '\\u000c' )
<             // JavaScript.g:434:4: '\\u000c'
<             {
<             match('\f'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "FF"
< 
<     // $ANTLR start "SP"
<     public final void mSP() throws RecognitionException {
<         try {
<             // JavaScript.g:438:2: ( '\\u0020' )
<             // JavaScript.g:438:4: '\\u0020'
<             {
<             match(' '); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SP"
< 
<     // $ANTLR start "NBSP"
<     public final void mNBSP() throws RecognitionException {
<         try {
<             // JavaScript.g:442:2: ( '\\u00a0' )
<             // JavaScript.g:442:4: '\\u00a0'
<             {
<             match('\u00A0'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "NBSP"
< 
<     // $ANTLR start "USP"
<     public final void mUSP() throws RecognitionException {
<         try {
<             // JavaScript.g:446:2: ( '\\u1680' | '\\u180E' | '\\u2000' | '\\u2001' | '\\u2002' | '\\u2003' | '\\u2004' | '\\u2005' | '\\u2006' | '\\u2007' | '\\u2008' | '\\u2009' | '\\u200A' | '\\u202F' | '\\u205F' | '\\u3000' )
<             // JavaScript.g:
<             {
<             if ( input.LA(1)=='\u1680'||input.LA(1)=='\u180E'||(input.LA(1)>='\u2000' && input.LA(1)<='\u200A')||input.LA(1)=='\u202F'||input.LA(1)=='\u205F'||input.LA(1)=='\u3000' ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "USP"
< 
<     // $ANTLR start "WhiteSpace"
<     public final void mWhiteSpace() throws RecognitionException {
<         try {
<             int _type = WhiteSpace;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:465:2: ( ( TAB | VT | FF | SP | NBSP | USP )+ )
<             // JavaScript.g:465:4: ( TAB | VT | FF | SP | NBSP | USP )+
<             {
<             // JavaScript.g:465:4: ( TAB | VT | FF | SP | NBSP | USP )+
<             int cnt1=0;
<             loop1:
<             do {
<                 int alt1=2;
<                 int LA1_0 = input.LA(1);
< 
<                 if ( (LA1_0=='\t'||(LA1_0>='\u000B' && LA1_0<='\f')||LA1_0==' '||LA1_0=='\u00A0'||LA1_0=='\u1680'||LA1_0=='\u180E'||(LA1_0>='\u2000' && LA1_0<='\u200A')||LA1_0=='\u202F'||LA1_0=='\u205F'||LA1_0=='\u3000') ) {
<                     alt1=1;
<                 }
< 
< 
<                 switch (alt1) {
<             	case 1 :
<             	    // JavaScript.g:
<             	    {
<             	    if ( input.LA(1)=='\t'||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||input.LA(1)==' '||input.LA(1)=='\u00A0'||input.LA(1)=='\u1680'||input.LA(1)=='\u180E'||(input.LA(1)>='\u2000' && input.LA(1)<='\u200A')||input.LA(1)=='\u202F'||input.LA(1)=='\u205F'||input.LA(1)=='\u3000' ) {
<             	        input.consume();
< 
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        recover(mse);
<             	        throw mse;}
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt1 >= 1 ) break loop1;
<                         EarlyExitException eee =
<                             new EarlyExitException(1, input);
<                         throw eee;
<                 }
<                 cnt1++;
<             } while (true);
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "WhiteSpace"
< 
<     // $ANTLR start "LF"
<     public final void mLF() throws RecognitionException {
<         try {
<             // JavaScript.g:473:2: ( '\\n' )
<             // JavaScript.g:473:4: '\\n'
<             {
<             match('\n'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LF"
< 
<     // $ANTLR start "CR"
<     public final void mCR() throws RecognitionException {
<         try {
<             // JavaScript.g:477:2: ( '\\r' )
<             // JavaScript.g:477:4: '\\r'
<             {
<             match('\r'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CR"
< 
<     // $ANTLR start "LS"
<     public final void mLS() throws RecognitionException {
<         try {
<             // JavaScript.g:481:2: ( '\\u2028' )
<             // JavaScript.g:481:4: '\\u2028'
<             {
<             match('\u2028'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LS"
< 
<     // $ANTLR start "PS"
<     public final void mPS() throws RecognitionException {
<         try {
<             // JavaScript.g:485:2: ( '\\u2029' )
<             // JavaScript.g:485:4: '\\u2029'
<             {
<             match('\u2029'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "PS"
< 
<     // $ANTLR start "LineTerminator"
<     public final void mLineTerminator() throws RecognitionException {
<         try {
<             // JavaScript.g:489:2: ( CR | LF | LS | PS )
<             // JavaScript.g:
<             {
<             if ( input.LA(1)=='\n'||input.LA(1)=='\r'||(input.LA(1)>='\u2028' && input.LA(1)<='\u2029') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "LineTerminator"
< 
<     // $ANTLR start "EOL"
<     public final void mEOL() throws RecognitionException {
<         try {
<             int _type = EOL;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:493:2: ( ( ( CR ( LF )? ) | LF | LS | PS ) )
<             // JavaScript.g:493:4: ( ( CR ( LF )? ) | LF | LS | PS )
<             {
<             // JavaScript.g:493:4: ( ( CR ( LF )? ) | LF | LS | PS )
<             int alt3=4;
<             switch ( input.LA(1) ) {
<             case '\r':
<                 {
<                 alt3=1;
<                 }
<                 break;
<             case '\n':
<                 {
<                 alt3=2;
<                 }
<                 break;
<             case '\u2028':
<                 {
<                 alt3=3;
<                 }
<                 break;
<             case '\u2029':
<                 {
<                 alt3=4;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 3, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt3) {
<                 case 1 :
<                     // JavaScript.g:493:6: ( CR ( LF )? )
<                     {
<                     // JavaScript.g:493:6: ( CR ( LF )? )
<                     // JavaScript.g:493:8: CR ( LF )?
<                     {
<                     mCR(); 
<                     // JavaScript.g:493:11: ( LF )?
<                     int alt2=2;
<                     int LA2_0 = input.LA(1);
< 
<                     if ( (LA2_0=='\n') ) {
<                         alt2=1;
<                     }
<                     switch (alt2) {
<                         case 1 :
<                             // JavaScript.g:493:11: LF
<                             {
<                             mLF(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:493:19: LF
<                     {
<                     mLF(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:493:24: LS
<                     {
<                     mLS(); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:493:29: PS
<                     {
<                     mPS(); 
< 
<                     }
<                     break;
< 
<             }
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EOL"
< 
<     // $ANTLR start "MultiLineComment"
<     public final void mMultiLineComment() throws RecognitionException {
<         try {
<             int _type = MultiLineComment;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:500:2: ( '/*' ( options {greedy=false; } : . )* '*/' )
<             // JavaScript.g:500:4: '/*' ( options {greedy=false; } : . )* '*/'
<             {
<             match("/*"); 
< 
<             // JavaScript.g:500:9: ( options {greedy=false; } : . )*
<             loop4:
<             do {
<                 int alt4=2;
<                 int LA4_0 = input.LA(1);
< 
<                 if ( (LA4_0=='*') ) {
<                     int LA4_1 = input.LA(2);
< 
<                     if ( (LA4_1=='/') ) {
<                         alt4=2;
<                     }
<                     else if ( ((LA4_1>='\u0000' && LA4_1<='.')||(LA4_1>='0' && LA4_1<='\uFFFF')) ) {
<                         alt4=1;
<                     }
< 
< 
<                 }
<                 else if ( ((LA4_0>='\u0000' && LA4_0<=')')||(LA4_0>='+' && LA4_0<='\uFFFF')) ) {
<                     alt4=1;
<                 }
< 
< 
<                 switch (alt4) {
<             	case 1 :
<             	    // JavaScript.g:500:41: .
<             	    {
<             	    matchAny(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop4;
<                 }
<             } while (true);
< 
<             match("*/"); 
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "MultiLineComment"
< 
<     // $ANTLR start "SingleLineComment"
<     public final void mSingleLineComment() throws RecognitionException {
<         try {
<             int _type = SingleLineComment;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:504:2: ( '//' (~ ( LineTerminator ) )* )
<             // JavaScript.g:504:4: '//' (~ ( LineTerminator ) )*
<             {
<             match("//"); 
< 
<             // JavaScript.g:504:9: (~ ( LineTerminator ) )*
<             loop5:
<             do {
<                 int alt5=2;
<                 int LA5_0 = input.LA(1);
< 
<                 if ( ((LA5_0>='\u0000' && LA5_0<='\t')||(LA5_0>='\u000B' && LA5_0<='\f')||(LA5_0>='\u000E' && LA5_0<='\u2027')||(LA5_0>='\u202A' && LA5_0<='\uFFFF')) ) {
<                     alt5=1;
<                 }
< 
< 
<                 switch (alt5) {
<             	case 1 :
<             	    // JavaScript.g:504:11: ~ ( LineTerminator )
<             	    {
<             	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<             	        input.consume();
< 
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        recover(mse);
<             	        throw mse;}
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop5;
<                 }
<             } while (true);
< 
<              _channel = HIDDEN; 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "SingleLineComment"
< 
<     // $ANTLR start "IdentifierStartASCII"
<     public final void mIdentifierStartASCII() throws RecognitionException {
<         try {
<             // JavaScript.g:605:2: ( 'a' .. 'z' | 'A' .. 'Z' | '$' | '_' | BSLASH 'u' HexDigit HexDigit HexDigit HexDigit )
<             int alt6=5;
<             switch ( input.LA(1) ) {
<             case 'a':
<             case 'b':
<             case 'c':
<             case 'd':
<             case 'e':
<             case 'f':
<             case 'g':
<             case 'h':
<             case 'i':
<             case 'j':
<             case 'k':
<             case 'l':
<             case 'm':
<             case 'n':
<             case 'o':
<             case 'p':
<             case 'q':
<             case 'r':
<             case 's':
<             case 't':
<             case 'u':
<             case 'v':
<             case 'w':
<             case 'x':
<             case 'y':
<             case 'z':
<                 {
<                 alt6=1;
<                 }
<                 break;
<             case 'A':
<             case 'B':
<             case 'C':
<             case 'D':
<             case 'E':
<             case 'F':
<             case 'G':
<             case 'H':
<             case 'I':
<             case 'J':
<             case 'K':
<             case 'L':
<             case 'M':
<             case 'N':
<             case 'O':
<             case 'P':
<             case 'Q':
<             case 'R':
<             case 'S':
<             case 'T':
<             case 'U':
<             case 'V':
<             case 'W':
<             case 'X':
<             case 'Y':
<             case 'Z':
<                 {
<                 alt6=2;
<                 }
<                 break;
<             case '$':
<                 {
<                 alt6=3;
<                 }
<                 break;
<             case '_':
<                 {
<                 alt6=4;
<                 }
<                 break;
<             case '\\':
<                 {
<                 alt6=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 6, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt6) {
<                 case 1 :
<                     // JavaScript.g:605:4: 'a' .. 'z'
<                     {
<                     matchRange('a','z'); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:605:15: 'A' .. 'Z'
<                     {
<                     matchRange('A','Z'); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:606:4: '$'
<                     {
<                     match('$'); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:607:4: '_'
<                     {
<                     match('_'); 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:608:4: BSLASH 'u' HexDigit HexDigit HexDigit HexDigit
<                     {
<                     mBSLASH(); 
<                     match('u'); 
<                     mHexDigit(); 
<                     mHexDigit(); 
<                     mHexDigit(); 
<                     mHexDigit(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IdentifierStartASCII"
< 
<     // $ANTLR start "IdentifierPart"
<     public final void mIdentifierPart() throws RecognitionException {
<         try {
<             // JavaScript.g:616:2: ( DecimalDigit | IdentifierStartASCII | {...}?)
<             int alt7=3;
<             switch ( input.LA(1) ) {
<             case '0':
<             case '1':
<             case '2':
<             case '3':
<             case '4':
<             case '5':
<             case '6':
<             case '7':
<             case '8':
<             case '9':
<                 {
<                 alt7=1;
<                 }
<                 break;
<             case '$':
<             case 'A':
<             case 'B':
<             case 'C':
<             case 'D':
<             case 'E':
<             case 'F':
<             case 'G':
<             case 'H':
<             case 'I':
<             case 'J':
<             case 'K':
<             case 'L':
<             case 'M':
<             case 'N':
<             case 'O':
<             case 'P':
<             case 'Q':
<             case 'R':
<             case 'S':
<             case 'T':
<             case 'U':
<             case 'V':
<             case 'W':
<             case 'X':
<             case 'Y':
<             case 'Z':
<             case '\\':
<             case '_':
<             case 'a':
<             case 'b':
<             case 'c':
<             case 'd':
<             case 'e':
<             case 'f':
<             case 'g':
<             case 'h':
<             case 'i':
<             case 'j':
<             case 'k':
<             case 'l':
<             case 'm':
<             case 'n':
<             case 'o':
<             case 'p':
<             case 'q':
<             case 'r':
<             case 's':
<             case 't':
<             case 'u':
<             case 'v':
<             case 'w':
<             case 'x':
<             case 'y':
<             case 'z':
<                 {
<                 alt7=2;
<                 }
<                 break;
<             default:
<                 alt7=3;}
< 
<             switch (alt7) {
<                 case 1 :
<                     // JavaScript.g:616:4: DecimalDigit
<                     {
<                     mDecimalDigit(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:617:4: IdentifierStartASCII
<                     {
<                     mIdentifierStartASCII(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:618:4: {...}?
<                     {
<                     if ( !(( isIdentifierPartUnicode(input.LA(1)) )) ) {
<                         throw new FailedPredicateException(input, "IdentifierPart", " isIdentifierPartUnicode(input.LA(1)) ");
<                     }
<                      matchAny(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IdentifierPart"
< 
<     // $ANTLR start "IdentifierNameASCIIStart"
<     public final void mIdentifierNameASCIIStart() throws RecognitionException {
<         try {
<             // JavaScript.g:622:2: ( IdentifierStartASCII ( IdentifierPart )* )
<             // JavaScript.g:622:4: IdentifierStartASCII ( IdentifierPart )*
<             {
<             mIdentifierStartASCII(); 
<             // JavaScript.g:622:25: ( IdentifierPart )*
<             loop8:
<             do {
<                 int alt8=2;
<                 int LA8_0 = input.LA(1);
< 
<                 if ( (LA8_0=='$'||(LA8_0>='0' && LA8_0<='9')||(LA8_0>='A' && LA8_0<='Z')||LA8_0=='\\'||LA8_0=='_'||(LA8_0>='a' && LA8_0<='z')) ) {
<                     alt8=1;
<                 }
<                 else if ( (( isIdentifierPartUnicode(input.LA(1)) )) ) {
<                     alt8=1;
<                 }
< 
< 
<                 switch (alt8) {
<             	case 1 :
<             	    // JavaScript.g:622:25: IdentifierPart
<             	    {
<             	    mIdentifierPart(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop8;
<                 }
<             } while (true);
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "IdentifierNameASCIIStart"
< 
<     // $ANTLR start "Identifier"
<     public final void mIdentifier() throws RecognitionException {
<         try {
<             int _type = Identifier;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:634:2: ( IdentifierNameASCIIStart | )
<             int alt9=2;
<             int LA9_0 = input.LA(1);
< 
<             if ( (LA9_0=='$'||(LA9_0>='A' && LA9_0<='Z')||LA9_0=='\\'||LA9_0=='_'||(LA9_0>='a' && LA9_0<='z')) ) {
<                 alt9=1;
<             }
<             else {
<                 alt9=2;}
<             switch (alt9) {
<                 case 1 :
<                     // JavaScript.g:634:4: IdentifierNameASCIIStart
<                     {
<                     mIdentifierNameASCIIStart(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:635:4: 
<                     {
<                      consumeIdentifierUnicodeStart(); 
< 
<                     }
<                     break;
< 
<             }
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "Identifier"
< 
<     // $ANTLR start "DecimalDigit"
<     public final void mDecimalDigit() throws RecognitionException {
<         try {
<             // JavaScript.g:718:2: ( '0' .. '9' )
<             // JavaScript.g:718:4: '0' .. '9'
<             {
<             matchRange('0','9'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DecimalDigit"
< 
<     // $ANTLR start "HexDigit"
<     public final void mHexDigit() throws RecognitionException {
<         try {
<             // JavaScript.g:722:2: ( DecimalDigit | 'a' .. 'f' | 'A' .. 'F' )
<             // JavaScript.g:
<             {
<             if ( (input.LA(1)>='0' && input.LA(1)<='9')||(input.LA(1)>='A' && input.LA(1)<='F')||(input.LA(1)>='a' && input.LA(1)<='f') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "HexDigit"
< 
<     // $ANTLR start "OctalDigit"
<     public final void mOctalDigit() throws RecognitionException {
<         try {
<             // JavaScript.g:726:2: ( '0' .. '7' )
<             // JavaScript.g:726:4: '0' .. '7'
<             {
<             matchRange('0','7'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OctalDigit"
< 
<     // $ANTLR start "ExponentPart"
<     public final void mExponentPart() throws RecognitionException {
<         try {
<             // JavaScript.g:730:2: ( ( 'e' | 'E' ) ( '+' | '-' )? ( DecimalDigit )+ )
<             // JavaScript.g:730:4: ( 'e' | 'E' ) ( '+' | '-' )? ( DecimalDigit )+
<             {
<             if ( input.LA(1)=='E'||input.LA(1)=='e' ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
<             // JavaScript.g:730:18: ( '+' | '-' )?
<             int alt10=2;
<             int LA10_0 = input.LA(1);
< 
<             if ( (LA10_0=='+'||LA10_0=='-') ) {
<                 alt10=1;
<             }
<             switch (alt10) {
<                 case 1 :
<                     // JavaScript.g:
<                     {
<                     if ( input.LA(1)=='+'||input.LA(1)=='-' ) {
<                         input.consume();
< 
<                     }
<                     else {
<                         MismatchedSetException mse = new MismatchedSetException(null,input);
<                         recover(mse);
<                         throw mse;}
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             // JavaScript.g:730:33: ( DecimalDigit )+
<             int cnt11=0;
<             loop11:
<             do {
<                 int alt11=2;
<                 int LA11_0 = input.LA(1);
< 
<                 if ( ((LA11_0>='0' && LA11_0<='9')) ) {
<                     alt11=1;
<                 }
< 
< 
<                 switch (alt11) {
<             	case 1 :
<             	    // JavaScript.g:730:33: DecimalDigit
<             	    {
<             	    mDecimalDigit(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt11 >= 1 ) break loop11;
<                         EarlyExitException eee =
<                             new EarlyExitException(11, input);
<                         throw eee;
<                 }
<                 cnt11++;
<             } while (true);
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ExponentPart"
< 
<     // $ANTLR start "DecimalIntegerLiteral"
<     public final void mDecimalIntegerLiteral() throws RecognitionException {
<         try {
<             // JavaScript.g:734:2: ( '0' | '1' .. '9' ( DecimalDigit )* )
<             int alt13=2;
<             int LA13_0 = input.LA(1);
< 
<             if ( (LA13_0=='0') ) {
<                 alt13=1;
<             }
<             else if ( ((LA13_0>='1' && LA13_0<='9')) ) {
<                 alt13=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 13, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt13) {
<                 case 1 :
<                     // JavaScript.g:734:4: '0'
<                     {
<                     match('0'); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:735:4: '1' .. '9' ( DecimalDigit )*
<                     {
<                     matchRange('1','9'); 
<                     // JavaScript.g:735:13: ( DecimalDigit )*
<                     loop12:
<                     do {
<                         int alt12=2;
<                         int LA12_0 = input.LA(1);
< 
<                         if ( ((LA12_0>='0' && LA12_0<='9')) ) {
<                             alt12=1;
<                         }
< 
< 
<                         switch (alt12) {
<                     	case 1 :
<                     	    // JavaScript.g:735:13: DecimalDigit
<                     	    {
<                     	    mDecimalDigit(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop12;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DecimalIntegerLiteral"
< 
<     // $ANTLR start "DecimalLiteral"
<     public final void mDecimalLiteral() throws RecognitionException {
<         try {
<             int _type = DecimalLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:739:2: ( DecimalIntegerLiteral '.' ( DecimalDigit )* ( ExponentPart )? | '.' ( DecimalDigit )+ ( ExponentPart )? | DecimalIntegerLiteral ( ExponentPart )? )
<             int alt19=3;
<             alt19 = dfa19.predict(input);
<             switch (alt19) {
<                 case 1 :
<                     // JavaScript.g:739:4: DecimalIntegerLiteral '.' ( DecimalDigit )* ( ExponentPart )?
<                     {
<                     mDecimalIntegerLiteral(); 
<                     match('.'); 
<                     // JavaScript.g:739:30: ( DecimalDigit )*
<                     loop14:
<                     do {
<                         int alt14=2;
<                         int LA14_0 = input.LA(1);
< 
<                         if ( ((LA14_0>='0' && LA14_0<='9')) ) {
<                             alt14=1;
<                         }
< 
< 
<                         switch (alt14) {
<                     	case 1 :
<                     	    // JavaScript.g:739:30: DecimalDigit
<                     	    {
<                     	    mDecimalDigit(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop14;
<                         }
<                     } while (true);
< 
<                     // JavaScript.g:739:44: ( ExponentPart )?
<                     int alt15=2;
<                     int LA15_0 = input.LA(1);
< 
<                     if ( (LA15_0=='E'||LA15_0=='e') ) {
<                         alt15=1;
<                     }
<                     switch (alt15) {
<                         case 1 :
<                             // JavaScript.g:739:44: ExponentPart
<                             {
<                             mExponentPart(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:740:4: '.' ( DecimalDigit )+ ( ExponentPart )?
<                     {
<                     match('.'); 
<                     // JavaScript.g:740:8: ( DecimalDigit )+
<                     int cnt16=0;
<                     loop16:
<                     do {
<                         int alt16=2;
<                         int LA16_0 = input.LA(1);
< 
<                         if ( ((LA16_0>='0' && LA16_0<='9')) ) {
<                             alt16=1;
<                         }
< 
< 
<                         switch (alt16) {
<                     	case 1 :
<                     	    // JavaScript.g:740:8: DecimalDigit
<                     	    {
<                     	    mDecimalDigit(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    if ( cnt16 >= 1 ) break loop16;
<                                 EarlyExitException eee =
<                                     new EarlyExitException(16, input);
<                                 throw eee;
<                         }
<                         cnt16++;
<                     } while (true);
< 
<                     // JavaScript.g:740:22: ( ExponentPart )?
<                     int alt17=2;
<                     int LA17_0 = input.LA(1);
< 
<                     if ( (LA17_0=='E'||LA17_0=='e') ) {
<                         alt17=1;
<                     }
<                     switch (alt17) {
<                         case 1 :
<                             // JavaScript.g:740:22: ExponentPart
<                             {
<                             mExponentPart(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:741:4: DecimalIntegerLiteral ( ExponentPart )?
<                     {
<                     mDecimalIntegerLiteral(); 
<                     // JavaScript.g:741:26: ( ExponentPart )?
<                     int alt18=2;
<                     int LA18_0 = input.LA(1);
< 
<                     if ( (LA18_0=='E'||LA18_0=='e') ) {
<                         alt18=1;
<                     }
<                     switch (alt18) {
<                         case 1 :
<                             // JavaScript.g:741:26: ExponentPart
<                             {
<                             mExponentPart(); 
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
< 
<             }
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "DecimalLiteral"
< 
<     // $ANTLR start "OctalIntegerLiteral"
<     public final void mOctalIntegerLiteral() throws RecognitionException {
<         try {
<             int _type = OctalIntegerLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:745:2: ( '0' ( OctalDigit )+ )
<             // JavaScript.g:745:4: '0' ( OctalDigit )+
<             {
<             match('0'); 
<             // JavaScript.g:745:8: ( OctalDigit )+
<             int cnt20=0;
<             loop20:
<             do {
<                 int alt20=2;
<                 int LA20_0 = input.LA(1);
< 
<                 if ( ((LA20_0>='0' && LA20_0<='7')) ) {
<                     alt20=1;
<                 }
< 
< 
<                 switch (alt20) {
<             	case 1 :
<             	    // JavaScript.g:745:8: OctalDigit
<             	    {
<             	    mOctalDigit(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt20 >= 1 ) break loop20;
<                         EarlyExitException eee =
<                             new EarlyExitException(20, input);
<                         throw eee;
<                 }
<                 cnt20++;
<             } while (true);
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OctalIntegerLiteral"
< 
<     // $ANTLR start "HexIntegerLiteral"
<     public final void mHexIntegerLiteral() throws RecognitionException {
<         try {
<             int _type = HexIntegerLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:749:2: ( ( '0x' | '0X' ) ( HexDigit )+ )
<             // JavaScript.g:749:4: ( '0x' | '0X' ) ( HexDigit )+
<             {
<             // JavaScript.g:749:4: ( '0x' | '0X' )
<             int alt21=2;
<             int LA21_0 = input.LA(1);
< 
<             if ( (LA21_0=='0') ) {
<                 int LA21_1 = input.LA(2);
< 
<                 if ( (LA21_1=='x') ) {
<                     alt21=1;
<                 }
<                 else if ( (LA21_1=='X') ) {
<                     alt21=2;
<                 }
<                 else {
<                     NoViableAltException nvae =
<                         new NoViableAltException("", 21, 1, input);
< 
<                     throw nvae;
<                 }
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 21, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt21) {
<                 case 1 :
<                     // JavaScript.g:749:6: '0x'
<                     {
<                     match("0x"); 
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:749:13: '0X'
<                     {
<                     match("0X"); 
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             // JavaScript.g:749:20: ( HexDigit )+
<             int cnt22=0;
<             loop22:
<             do {
<                 int alt22=2;
<                 int LA22_0 = input.LA(1);
< 
<                 if ( ((LA22_0>='0' && LA22_0<='9')||(LA22_0>='A' && LA22_0<='F')||(LA22_0>='a' && LA22_0<='f')) ) {
<                     alt22=1;
<                 }
< 
< 
<                 switch (alt22) {
<             	case 1 :
<             	    // JavaScript.g:749:20: HexDigit
<             	    {
<             	    mHexDigit(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    if ( cnt22 >= 1 ) break loop22;
<                         EarlyExitException eee =
<                             new EarlyExitException(22, input);
<                         throw eee;
<                 }
<                 cnt22++;
<             } while (true);
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "HexIntegerLiteral"
< 
<     // $ANTLR start "CharacterEscapeSequence"
<     public final void mCharacterEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:768:2: (~ ( DecimalDigit | 'x' | 'u' | LineTerminator ) )
<             // JavaScript.g:768:4: ~ ( DecimalDigit | 'x' | 'u' | LineTerminator )
<             {
<             if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='/')||(input.LA(1)>=':' && input.LA(1)<='t')||(input.LA(1)>='v' && input.LA(1)<='w')||(input.LA(1)>='y' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "CharacterEscapeSequence"
< 
<     // $ANTLR start "ZeroToThree"
<     public final void mZeroToThree() throws RecognitionException {
<         try {
<             // JavaScript.g:772:2: ( '0' .. '3' )
<             // JavaScript.g:772:4: '0' .. '3'
<             {
<             matchRange('0','3'); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "ZeroToThree"
< 
<     // $ANTLR start "OctalEscapeSequence"
<     public final void mOctalEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:776:2: ( OctalDigit | ZeroToThree OctalDigit | '4' .. '7' OctalDigit | ZeroToThree OctalDigit OctalDigit )
<             int alt23=4;
<             int LA23_0 = input.LA(1);
< 
<             if ( ((LA23_0>='0' && LA23_0<='3')) ) {
<                 int LA23_1 = input.LA(2);
< 
<                 if ( ((LA23_1>='0' && LA23_1<='7')) ) {
<                     int LA23_4 = input.LA(3);
< 
<                     if ( ((LA23_4>='0' && LA23_4<='7')) ) {
<                         alt23=4;
<                     }
<                     else {
<                         alt23=2;}
<                 }
<                 else {
<                     alt23=1;}
<             }
<             else if ( ((LA23_0>='4' && LA23_0<='7')) ) {
<                 int LA23_2 = input.LA(2);
< 
<                 if ( ((LA23_2>='0' && LA23_2<='7')) ) {
<                     alt23=3;
<                 }
<                 else {
<                     alt23=1;}
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 23, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt23) {
<                 case 1 :
<                     // JavaScript.g:776:4: OctalDigit
<                     {
<                     mOctalDigit(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:777:4: ZeroToThree OctalDigit
<                     {
<                     mZeroToThree(); 
<                     mOctalDigit(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:778:4: '4' .. '7' OctalDigit
<                     {
<                     matchRange('4','7'); 
<                     mOctalDigit(); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:779:4: ZeroToThree OctalDigit OctalDigit
<                     {
<                     mZeroToThree(); 
<                     mOctalDigit(); 
<                     mOctalDigit(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "OctalEscapeSequence"
< 
<     // $ANTLR start "HexEscapeSequence"
<     public final void mHexEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:783:2: ( 'x' HexDigit HexDigit )
<             // JavaScript.g:783:4: 'x' HexDigit HexDigit
<             {
<             match('x'); 
<             mHexDigit(); 
<             mHexDigit(); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "HexEscapeSequence"
< 
<     // $ANTLR start "UnicodeEscapeSequence"
<     public final void mUnicodeEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:787:2: ( 'u' HexDigit HexDigit HexDigit HexDigit )
<             // JavaScript.g:787:4: 'u' HexDigit HexDigit HexDigit HexDigit
<             {
<             match('u'); 
<             mHexDigit(); 
<             mHexDigit(); 
<             mHexDigit(); 
<             mHexDigit(); 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "UnicodeEscapeSequence"
< 
<     // $ANTLR start "EscapeSequence"
<     public final void mEscapeSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:791:2: ( BSLASH ( CharacterEscapeSequence | OctalEscapeSequence | HexEscapeSequence | UnicodeEscapeSequence ) )
<             // JavaScript.g:792:2: BSLASH ( CharacterEscapeSequence | OctalEscapeSequence | HexEscapeSequence | UnicodeEscapeSequence )
<             {
<             mBSLASH(); 
<             // JavaScript.g:793:2: ( CharacterEscapeSequence | OctalEscapeSequence | HexEscapeSequence | UnicodeEscapeSequence )
<             int alt24=4;
<             int LA24_0 = input.LA(1);
< 
<             if ( ((LA24_0>='\u0000' && LA24_0<='\t')||(LA24_0>='\u000B' && LA24_0<='\f')||(LA24_0>='\u000E' && LA24_0<='/')||(LA24_0>=':' && LA24_0<='t')||(LA24_0>='v' && LA24_0<='w')||(LA24_0>='y' && LA24_0<='\u2027')||(LA24_0>='\u202A' && LA24_0<='\uFFFF')) ) {
<                 alt24=1;
<             }
<             else if ( ((LA24_0>='0' && LA24_0<='7')) ) {
<                 alt24=2;
<             }
<             else if ( (LA24_0=='x') ) {
<                 alt24=3;
<             }
<             else if ( (LA24_0=='u') ) {
<                 alt24=4;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 24, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt24) {
<                 case 1 :
<                     // JavaScript.g:794:3: CharacterEscapeSequence
<                     {
<                     mCharacterEscapeSequence(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:795:5: OctalEscapeSequence
<                     {
<                     mOctalEscapeSequence(); 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:796:5: HexEscapeSequence
<                     {
<                     mHexEscapeSequence(); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:797:5: UnicodeEscapeSequence
<                     {
<                     mUnicodeEscapeSequence(); 
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "EscapeSequence"
< 
<     // $ANTLR start "StringLiteral"
<     public final void mStringLiteral() throws RecognitionException {
<         try {
<             int _type = StringLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:802:2: ( SQUOTE (~ ( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* SQUOTE | DQUOTE (~ ( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* DQUOTE )
<             int alt27=2;
<             int LA27_0 = input.LA(1);
< 
<             if ( (LA27_0=='\'') ) {
<                 alt27=1;
<             }
<             else if ( (LA27_0=='\"') ) {
<                 alt27=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 27, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt27) {
<                 case 1 :
<                     // JavaScript.g:802:4: SQUOTE (~ ( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* SQUOTE
<                     {
<                     mSQUOTE(); 
<                     // JavaScript.g:802:11: (~ ( SQUOTE | BSLASH | LineTerminator ) | EscapeSequence )*
<                     loop25:
<                     do {
<                         int alt25=3;
<                         int LA25_0 = input.LA(1);
< 
<                         if ( ((LA25_0>='\u0000' && LA25_0<='\t')||(LA25_0>='\u000B' && LA25_0<='\f')||(LA25_0>='\u000E' && LA25_0<='&')||(LA25_0>='(' && LA25_0<='[')||(LA25_0>=']' && LA25_0<='\u2027')||(LA25_0>='\u202A' && LA25_0<='\uFFFF')) ) {
<                             alt25=1;
<                         }
<                         else if ( (LA25_0=='\\') ) {
<                             alt25=2;
<                         }
< 
< 
<                         switch (alt25) {
<                     	case 1 :
<                     	    // JavaScript.g:802:13: ~ ( SQUOTE | BSLASH | LineTerminator )
<                     	    {
<                     	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='&')||(input.LA(1)>='(' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                     	        input.consume();
< 
<                     	    }
<                     	    else {
<                     	        MismatchedSetException mse = new MismatchedSetException(null,input);
<                     	        recover(mse);
<                     	        throw mse;}
< 
< 
<                     	    }
<                     	    break;
<                     	case 2 :
<                     	    // JavaScript.g:802:53: EscapeSequence
<                     	    {
<                     	    mEscapeSequence(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop25;
<                         }
<                     } while (true);
< 
<                     mSQUOTE(); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:803:4: DQUOTE (~ ( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )* DQUOTE
<                     {
<                     mDQUOTE(); 
<                     // JavaScript.g:803:11: (~ ( DQUOTE | BSLASH | LineTerminator ) | EscapeSequence )*
<                     loop26:
<                     do {
<                         int alt26=3;
<                         int LA26_0 = input.LA(1);
< 
<                         if ( ((LA26_0>='\u0000' && LA26_0<='\t')||(LA26_0>='\u000B' && LA26_0<='\f')||(LA26_0>='\u000E' && LA26_0<='!')||(LA26_0>='#' && LA26_0<='[')||(LA26_0>=']' && LA26_0<='\u2027')||(LA26_0>='\u202A' && LA26_0<='\uFFFF')) ) {
<                             alt26=1;
<                         }
<                         else if ( (LA26_0=='\\') ) {
<                             alt26=2;
<                         }
< 
< 
<                         switch (alt26) {
<                     	case 1 :
<                     	    // JavaScript.g:803:13: ~ ( DQUOTE | BSLASH | LineTerminator )
<                     	    {
<                     	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='!')||(input.LA(1)>='#' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                     	        input.consume();
< 
<                     	    }
<                     	    else {
<                     	        MismatchedSetException mse = new MismatchedSetException(null,input);
<                     	        recover(mse);
<                     	        throw mse;}
< 
< 
<                     	    }
<                     	    break;
<                     	case 2 :
<                     	    // JavaScript.g:803:53: EscapeSequence
<                     	    {
<                     	    mEscapeSequence(); 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop26;
<                         }
<                     } while (true);
< 
<                     mDQUOTE(); 
< 
<                     }
<                     break;
< 
<             }
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "StringLiteral"
< 
<     // $ANTLR start "BackslashSequence"
<     public final void mBackslashSequence() throws RecognitionException {
<         try {
<             // JavaScript.g:811:2: ( BSLASH ~ ( LineTerminator ) )
<             // JavaScript.g:811:4: BSLASH ~ ( LineTerminator )
<             {
<             mBSLASH(); 
<             if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                 input.consume();
< 
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 recover(mse);
<                 throw mse;}
< 
< 
<             }
< 
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "BackslashSequence"
< 
<     // $ANTLR start "RegularExpressionFirstChar"
<     public final void mRegularExpressionFirstChar() throws RecognitionException {
<         try {
<             // JavaScript.g:815:2: (~ ( LineTerminator | MUL | BSLASH | DIV ) | BackslashSequence )
<             int alt28=2;
<             int LA28_0 = input.LA(1);
< 
<             if ( ((LA28_0>='\u0000' && LA28_0<='\t')||(LA28_0>='\u000B' && LA28_0<='\f')||(LA28_0>='\u000E' && LA28_0<=')')||(LA28_0>='+' && LA28_0<='.')||(LA28_0>='0' && LA28_0<='[')||(LA28_0>=']' && LA28_0<='\u2027')||(LA28_0>='\u202A' && LA28_0<='\uFFFF')) ) {
<                 alt28=1;
<             }
<             else if ( (LA28_0=='\\') ) {
<                 alt28=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 28, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt28) {
<                 case 1 :
<                     // JavaScript.g:815:4: ~ ( LineTerminator | MUL | BSLASH | DIV )
<                     {
<                     if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<=')')||(input.LA(1)>='+' && input.LA(1)<='.')||(input.LA(1)>='0' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                         input.consume();
< 
<                     }
<                     else {
<                         MismatchedSetException mse = new MismatchedSetException(null,input);
<                         recover(mse);
<                         throw mse;}
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:816:4: BackslashSequence
<                     {
<                     mBackslashSequence(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RegularExpressionFirstChar"
< 
<     // $ANTLR start "RegularExpressionChar"
<     public final void mRegularExpressionChar() throws RecognitionException {
<         try {
<             // JavaScript.g:820:2: (~ ( LineTerminator | BSLASH | DIV ) | BackslashSequence )
<             int alt29=2;
<             int LA29_0 = input.LA(1);
< 
<             if ( ((LA29_0>='\u0000' && LA29_0<='\t')||(LA29_0>='\u000B' && LA29_0<='\f')||(LA29_0>='\u000E' && LA29_0<='.')||(LA29_0>='0' && LA29_0<='[')||(LA29_0>=']' && LA29_0<='\u2027')||(LA29_0>='\u202A' && LA29_0<='\uFFFF')) ) {
<                 alt29=1;
<             }
<             else if ( (LA29_0=='\\') ) {
<                 alt29=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 29, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt29) {
<                 case 1 :
<                     // JavaScript.g:820:4: ~ ( LineTerminator | BSLASH | DIV )
<                     {
<                     if ( (input.LA(1)>='\u0000' && input.LA(1)<='\t')||(input.LA(1)>='\u000B' && input.LA(1)<='\f')||(input.LA(1)>='\u000E' && input.LA(1)<='.')||(input.LA(1)>='0' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\u2027')||(input.LA(1)>='\u202A' && input.LA(1)<='\uFFFF') ) {
<                         input.consume();
< 
<                     }
<                     else {
<                         MismatchedSetException mse = new MismatchedSetException(null,input);
<                         recover(mse);
<                         throw mse;}
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:821:4: BackslashSequence
<                     {
<                     mBackslashSequence(); 
< 
<                     }
<                     break;
< 
<             }
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RegularExpressionChar"
< 
<     // $ANTLR start "RegularExpressionLiteral"
<     public final void mRegularExpressionLiteral() throws RecognitionException {
<         try {
<             int _type = RegularExpressionLiteral;
<             int _channel = DEFAULT_TOKEN_CHANNEL;
<             // JavaScript.g:825:2: ({...}? => DIV RegularExpressionFirstChar ( RegularExpressionChar )* DIV ( IdentifierPart )* )
<             // JavaScript.g:825:4: {...}? => DIV RegularExpressionFirstChar ( RegularExpressionChar )* DIV ( IdentifierPart )*
<             {
<             if ( !(( areRegularExpressionsEnabled() )) ) {
<                 throw new FailedPredicateException(input, "RegularExpressionLiteral", " areRegularExpressionsEnabled() ");
<             }
<             mDIV(); 
<             mRegularExpressionFirstChar(); 
<             // JavaScript.g:825:73: ( RegularExpressionChar )*
<             loop30:
<             do {
<                 int alt30=2;
<                 int LA30_0 = input.LA(1);
< 
<                 if ( ((LA30_0>='\u0000' && LA30_0<='\t')||(LA30_0>='\u000B' && LA30_0<='\f')||(LA30_0>='\u000E' && LA30_0<='.')||(LA30_0>='0' && LA30_0<='\u2027')||(LA30_0>='\u202A' && LA30_0<='\uFFFF')) ) {
<                     alt30=1;
<                 }
< 
< 
<                 switch (alt30) {
<             	case 1 :
<             	    // JavaScript.g:825:73: RegularExpressionChar
<             	    {
<             	    mRegularExpressionChar(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop30;
<                 }
<             } while (true);
< 
<             mDIV(); 
<             // JavaScript.g:825:100: ( IdentifierPart )*
<             loop31:
<             do {
<                 int alt31=2;
<                 int LA31_0 = input.LA(1);
< 
<                 if ( (LA31_0=='$'||(LA31_0>='0' && LA31_0<='9')||(LA31_0>='A' && LA31_0<='Z')||LA31_0=='\\'||LA31_0=='_'||(LA31_0>='a' && LA31_0<='z')) ) {
<                     alt31=1;
<                 }
<                 else if ( (( isIdentifierPartUnicode(input.LA(1)) )) ) {
<                     alt31=1;
<                 }
< 
< 
<                 switch (alt31) {
<             	case 1 :
<             	    // JavaScript.g:825:100: IdentifierPart
<             	    {
<             	    mIdentifierPart(); 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop31;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             state.type = _type;
<             state.channel = _channel;
<         }
<         finally {
<         }
<     }
<     // $ANTLR end "RegularExpressionLiteral"
< 
<     public void mTokens() throws RecognitionException {
<         // JavaScript.g:1:8: ( NULL | TRUE | FALSE | BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH | ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE | LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS | WhiteSpace | EOL | MultiLineComment | SingleLineComment | Identifier | DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral | StringLiteral | RegularExpressionLiteral )
<         int alt32=117;
<         alt32 = dfa32.predict(input);
<         switch (alt32) {
<             case 1 :
<                 // JavaScript.g:1:10: NULL
<                 {
<                 mNULL(); 
< 
<                 }
<                 break;
<             case 2 :
<                 // JavaScript.g:1:15: TRUE
<                 {
<                 mTRUE(); 
< 
<                 }
<                 break;
<             case 3 :
<                 // JavaScript.g:1:20: FALSE
<                 {
<                 mFALSE(); 
< 
<                 }
<                 break;
<             case 4 :
<                 // JavaScript.g:1:26: BREAK
<                 {
<                 mBREAK(); 
< 
<                 }
<                 break;
<             case 5 :
<                 // JavaScript.g:1:32: CASE
<                 {
<                 mCASE(); 
< 
<                 }
<                 break;
<             case 6 :
<                 // JavaScript.g:1:37: CATCH
<                 {
<                 mCATCH(); 
< 
<                 }
<                 break;
<             case 7 :
<                 // JavaScript.g:1:43: CONTINUE
<                 {
<                 mCONTINUE(); 
< 
<                 }
<                 break;
<             case 8 :
<                 // JavaScript.g:1:52: DEFAULT
<                 {
<                 mDEFAULT(); 
< 
<                 }
<                 break;
<             case 9 :
<                 // JavaScript.g:1:60: DELETE
<                 {
<                 mDELETE(); 
< 
<                 }
<                 break;
<             case 10 :
<                 // JavaScript.g:1:67: DO
<                 {
<                 mDO(); 
< 
<                 }
<                 break;
<             case 11 :
<                 // JavaScript.g:1:70: ELSE
<                 {
<                 mELSE(); 
< 
<                 }
<                 break;
<             case 12 :
<                 // JavaScript.g:1:75: FINALLY
<                 {
<                 mFINALLY(); 
< 
<                 }
<                 break;
<             case 13 :
<                 // JavaScript.g:1:83: FOR
<                 {
<                 mFOR(); 
< 
<                 }
<                 break;
<             case 14 :
<                 // JavaScript.g:1:87: FUNCTION
<                 {
<                 mFUNCTION(); 
< 
<                 }
<                 break;
<             case 15 :
<                 // JavaScript.g:1:96: IF
<                 {
<                 mIF(); 
< 
<                 }
<                 break;
<             case 16 :
<                 // JavaScript.g:1:99: IN
<                 {
<                 mIN(); 
< 
<                 }
<                 break;
<             case 17 :
<                 // JavaScript.g:1:102: INSTANCEOF
<                 {
<                 mINSTANCEOF(); 
< 
<                 }
<                 break;
<             case 18 :
<                 // JavaScript.g:1:113: NEW
<                 {
<                 mNEW(); 
< 
<                 }
<                 break;
<             case 19 :
<                 // JavaScript.g:1:117: RETURN
<                 {
<                 mRETURN(); 
< 
<                 }
<                 break;
<             case 20 :
<                 // JavaScript.g:1:124: SWITCH
<                 {
<                 mSWITCH(); 
< 
<                 }
<                 break;
<             case 21 :
<                 // JavaScript.g:1:131: THIS
<                 {
<                 mTHIS(); 
< 
<                 }
<                 break;
<             case 22 :
<                 // JavaScript.g:1:136: THROW
<                 {
<                 mTHROW(); 
< 
<                 }
<                 break;
<             case 23 :
<                 // JavaScript.g:1:142: TRY
<                 {
<                 mTRY(); 
< 
<                 }
<                 break;
<             case 24 :
<                 // JavaScript.g:1:146: TYPEOF
<                 {
<                 mTYPEOF(); 
< 
<                 }
<                 break;
<             case 25 :
<                 // JavaScript.g:1:153: VAR
<                 {
<                 mVAR(); 
< 
<                 }
<                 break;
<             case 26 :
<                 // JavaScript.g:1:157: VOID
<                 {
<                 mVOID(); 
< 
<                 }
<                 break;
<             case 27 :
<                 // JavaScript.g:1:162: WHILE
<                 {
<                 mWHILE(); 
< 
<                 }
<                 break;
<             case 28 :
<                 // JavaScript.g:1:168: WITH
<                 {
<                 mWITH(); 
< 
<                 }
<                 break;
<             case 29 :
<                 // JavaScript.g:1:173: ABSTRACT
<                 {
<                 mABSTRACT(); 
< 
<                 }
<                 break;
<             case 30 :
<                 // JavaScript.g:1:182: BOOLEAN
<                 {
<                 mBOOLEAN(); 
< 
<                 }
<                 break;
<             case 31 :
<                 // JavaScript.g:1:190: BYTE
<                 {
<                 mBYTE(); 
< 
<                 }
<                 break;
<             case 32 :
<                 // JavaScript.g:1:195: CHAR
<                 {
<                 mCHAR(); 
< 
<                 }
<                 break;
<             case 33 :
<                 // JavaScript.g:1:200: CLASS
<                 {
<                 mCLASS(); 
< 
<                 }
<                 break;
<             case 34 :
<                 // JavaScript.g:1:206: CONST
<                 {
<                 mCONST(); 
< 
<                 }
<                 break;
<             case 35 :
<                 // JavaScript.g:1:212: DEBUGGER
<                 {
<                 mDEBUGGER(); 
< 
<                 }
<                 break;
<             case 36 :
<                 // JavaScript.g:1:221: DOUBLE
<                 {
<                 mDOUBLE(); 
< 
<                 }
<                 break;
<             case 37 :
<                 // JavaScript.g:1:228: ENUM
<                 {
<                 mENUM(); 
< 
<                 }
<                 break;
<             case 38 :
<                 // JavaScript.g:1:233: EXPORT
<                 {
<                 mEXPORT(); 
< 
<                 }
<                 break;
<             case 39 :
<                 // JavaScript.g:1:240: EXTENDS
<                 {
<                 mEXTENDS(); 
< 
<                 }
<                 break;
<             case 40 :
<                 // JavaScript.g:1:248: FINAL
<                 {
<                 mFINAL(); 
< 
<                 }
<                 break;
<             case 41 :
<                 // JavaScript.g:1:254: FLOAT
<                 {
<                 mFLOAT(); 
< 
<                 }
<                 break;
<             case 42 :
<                 // JavaScript.g:1:260: GOTO
<                 {
<                 mGOTO(); 
< 
<                 }
<                 break;
<             case 43 :
<                 // JavaScript.g:1:265: IMPLEMENTS
<                 {
<                 mIMPLEMENTS(); 
< 
<                 }
<                 break;
<             case 44 :
<                 // JavaScript.g:1:276: IMPORT
<                 {
<                 mIMPORT(); 
< 
<                 }
<                 break;
<             case 45 :
<                 // JavaScript.g:1:283: INT
<                 {
<                 mINT(); 
< 
<                 }
<                 break;
<             case 46 :
<                 // JavaScript.g:1:287: INTERFACE
<                 {
<                 mINTERFACE(); 
< 
<                 }
<                 break;
<             case 47 :
<                 // JavaScript.g:1:297: LONG
<                 {
<                 mLONG(); 
< 
<                 }
<                 break;
<             case 48 :
<                 // JavaScript.g:1:302: NATIVE
<                 {
<                 mNATIVE(); 
< 
<                 }
<                 break;
<             case 49 :
<                 // JavaScript.g:1:309: PACKAGE
<                 {
<                 mPACKAGE(); 
< 
<                 }
<                 break;
<             case 50 :
<                 // JavaScript.g:1:317: PRIVATE
<                 {
<                 mPRIVATE(); 
< 
<                 }
<                 break;
<             case 51 :
<                 // JavaScript.g:1:325: PROTECTED
<                 {
<                 mPROTECTED(); 
< 
<                 }
<                 break;
<             case 52 :
<                 // JavaScript.g:1:335: PUBLIC
<                 {
<                 mPUBLIC(); 
< 
<                 }
<                 break;
<             case 53 :
<                 // JavaScript.g:1:342: SHORT
<                 {
<                 mSHORT(); 
< 
<                 }
<                 break;
<             case 54 :
<                 // JavaScript.g:1:348: STATIC
<                 {
<                 mSTATIC(); 
< 
<                 }
<                 break;
<             case 55 :
<                 // JavaScript.g:1:355: SUPER
<                 {
<                 mSUPER(); 
< 
<                 }
<                 break;
<             case 56 :
<                 // JavaScript.g:1:361: SYNCHRONIZED
<                 {
<                 mSYNCHRONIZED(); 
< 
<                 }
<                 break;
<             case 57 :
<                 // JavaScript.g:1:374: THROWS
<                 {
<                 mTHROWS(); 
< 
<                 }
<                 break;
<             case 58 :
<                 // JavaScript.g:1:381: TRANSIENT
<                 {
<                 mTRANSIENT(); 
< 
<                 }
<                 break;
<             case 59 :
<                 // JavaScript.g:1:391: VOLATILE
<                 {
<                 mVOLATILE(); 
< 
<                 }
<                 break;
<             case 60 :
<                 // JavaScript.g:1:400: LBRACE
<                 {
<                 mLBRACE(); 
< 
<                 }
<                 break;
<             case 61 :
<                 // JavaScript.g:1:407: RBRACE
<                 {
<                 mRBRACE(); 
< 
<                 }
<                 break;
<             case 62 :
<                 // JavaScript.g:1:414: LPAREN
<                 {
<                 mLPAREN(); 
< 
<                 }
<                 break;
<             case 63 :
<                 // JavaScript.g:1:421: RPAREN
<                 {
<                 mRPAREN(); 
< 
<                 }
<                 break;
<             case 64 :
<                 // JavaScript.g:1:428: LBRACK
<                 {
<                 mLBRACK(); 
< 
<                 }
<                 break;
<             case 65 :
<                 // JavaScript.g:1:435: RBRACK
<                 {
<                 mRBRACK(); 
< 
<                 }
<                 break;
<             case 66 :
<                 // JavaScript.g:1:442: DOT
<                 {
<                 mDOT(); 
< 
<                 }
<                 break;
<             case 67 :
<                 // JavaScript.g:1:446: SEMIC
<                 {
<                 mSEMIC(); 
< 
<                 }
<                 break;
<             case 68 :
<                 // JavaScript.g:1:452: COMMA
<                 {
<                 mCOMMA(); 
< 
<                 }
<                 break;
<             case 69 :
<                 // JavaScript.g:1:458: LT
<                 {
<                 mLT(); 
< 
<                 }
<                 break;
<             case 70 :
<                 // JavaScript.g:1:461: GT
<                 {
<                 mGT(); 
< 
<                 }
<                 break;
<             case 71 :
<                 // JavaScript.g:1:464: LTE
<                 {
<                 mLTE(); 
< 
<                 }
<                 break;
<             case 72 :
<                 // JavaScript.g:1:468: GTE
<                 {
<                 mGTE(); 
< 
<                 }
<                 break;
<             case 73 :
<                 // JavaScript.g:1:472: EQ
<                 {
<                 mEQ(); 
< 
<                 }
<                 break;
<             case 74 :
<                 // JavaScript.g:1:475: NEQ
<                 {
<                 mNEQ(); 
< 
<                 }
<                 break;
<             case 75 :
<                 // JavaScript.g:1:479: SAME
<                 {
<                 mSAME(); 
< 
<                 }
<                 break;
<             case 76 :
<                 // JavaScript.g:1:484: NSAME
<                 {
<                 mNSAME(); 
< 
<                 }
<                 break;
<             case 77 :
<                 // JavaScript.g:1:490: ADD
<                 {
<                 mADD(); 
< 
<                 }
<                 break;
<             case 78 :
<                 // JavaScript.g:1:494: SUB
<                 {
<                 mSUB(); 
< 
<                 }
<                 break;
<             case 79 :
<                 // JavaScript.g:1:498: MUL
<                 {
<                 mMUL(); 
< 
<                 }
<                 break;
<             case 80 :
<                 // JavaScript.g:1:502: MOD
<                 {
<                 mMOD(); 
< 
<                 }
<                 break;
<             case 81 :
<                 // JavaScript.g:1:506: INC
<                 {
<                 mINC(); 
< 
<                 }
<                 break;
<             case 82 :
<                 // JavaScript.g:1:510: DEC
<                 {
<                 mDEC(); 
< 
<                 }
<                 break;
<             case 83 :
<                 // JavaScript.g:1:514: SHL
<                 {
<                 mSHL(); 
< 
<                 }
<                 break;
<             case 84 :
<                 // JavaScript.g:1:518: SHR
<                 {
<                 mSHR(); 
< 
<                 }
<                 break;
<             case 85 :
<                 // JavaScript.g:1:522: SHU
<                 {
<                 mSHU(); 
< 
<                 }
<                 break;
<             case 86 :
<                 // JavaScript.g:1:526: AND
<                 {
<                 mAND(); 
< 
<                 }
<                 break;
<             case 87 :
<                 // JavaScript.g:1:530: OR
<                 {
<                 mOR(); 
< 
<                 }
<                 break;
<             case 88 :
<                 // JavaScript.g:1:533: XOR
<                 {
<                 mXOR(); 
< 
<                 }
<                 break;
<             case 89 :
<                 // JavaScript.g:1:537: NOT
<                 {
<                 mNOT(); 
< 
<                 }
<                 break;
<             case 90 :
<                 // JavaScript.g:1:541: INV
<                 {
<                 mINV(); 
< 
<                 }
<                 break;
<             case 91 :
<                 // JavaScript.g:1:545: LAND
<                 {
<                 mLAND(); 
< 
<                 }
<                 break;
<             case 92 :
<                 // JavaScript.g:1:550: LOR
<                 {
<                 mLOR(); 
< 
<                 }
<                 break;
<             case 93 :
<                 // JavaScript.g:1:554: QUE
<                 {
<                 mQUE(); 
< 
<                 }
<                 break;
<             case 94 :
<                 // JavaScript.g:1:558: COLON
<                 {
<                 mCOLON(); 
< 
<                 }
<                 break;
<             case 95 :
<                 // JavaScript.g:1:564: ASSIGN
<                 {
<                 mASSIGN(); 
< 
<                 }
<                 break;
<             case 96 :
<                 // JavaScript.g:1:571: ADDASS
<                 {
<                 mADDASS(); 
< 
<                 }
<                 break;
<             case 97 :
<                 // JavaScript.g:1:578: SUBASS
<                 {
<                 mSUBASS(); 
< 
<                 }
<                 break;
<             case 98 :
<                 // JavaScript.g:1:585: MULASS
<                 {
<                 mMULASS(); 
< 
<                 }
<                 break;
<             case 99 :
<                 // JavaScript.g:1:592: MODASS
<                 {
<                 mMODASS(); 
< 
<                 }
<                 break;
<             case 100 :
<                 // JavaScript.g:1:599: SHLASS
<                 {
<                 mSHLASS(); 
< 
<                 }
<                 break;
<             case 101 :
<                 // JavaScript.g:1:606: SHRASS
<                 {
<                 mSHRASS(); 
< 
<                 }
<                 break;
<             case 102 :
<                 // JavaScript.g:1:613: SHUASS
<                 {
<                 mSHUASS(); 
< 
<                 }
<                 break;
<             case 103 :
<                 // JavaScript.g:1:620: ANDASS
<                 {
<                 mANDASS(); 
< 
<                 }
<                 break;
<             case 104 :
<                 // JavaScript.g:1:627: ORASS
<                 {
<                 mORASS(); 
< 
<                 }
<                 break;
<             case 105 :
<                 // JavaScript.g:1:633: XORASS
<                 {
<                 mXORASS(); 
< 
<                 }
<                 break;
<             case 106 :
<                 // JavaScript.g:1:640: DIV
<                 {
<                 mDIV(); 
< 
<                 }
<                 break;
<             case 107 :
<                 // JavaScript.g:1:644: DIVASS
<                 {
<                 mDIVASS(); 
< 
<                 }
<                 break;
<             case 108 :
<                 // JavaScript.g:1:651: WhiteSpace
<                 {
<                 mWhiteSpace(); 
< 
<                 }
<                 break;
<             case 109 :
<                 // JavaScript.g:1:662: EOL
<                 {
<                 mEOL(); 
< 
<                 }
<                 break;
<             case 110 :
<                 // JavaScript.g:1:666: MultiLineComment
<                 {
<                 mMultiLineComment(); 
< 
<                 }
<                 break;
<             case 111 :
<                 // JavaScript.g:1:683: SingleLineComment
<                 {
<                 mSingleLineComment(); 
< 
<                 }
<                 break;
<             case 112 :
<                 // JavaScript.g:1:701: Identifier
<                 {
<                 mIdentifier(); 
< 
<                 }
<                 break;
<             case 113 :
<                 // JavaScript.g:1:712: DecimalLiteral
<                 {
<                 mDecimalLiteral(); 
< 
<                 }
<                 break;
<             case 114 :
<                 // JavaScript.g:1:727: OctalIntegerLiteral
<                 {
<                 mOctalIntegerLiteral(); 
< 
<                 }
<                 break;
<             case 115 :
<                 // JavaScript.g:1:747: HexIntegerLiteral
<                 {
<                 mHexIntegerLiteral(); 
< 
<                 }
<                 break;
<             case 116 :
<                 // JavaScript.g:1:765: StringLiteral
<                 {
<                 mStringLiteral(); 
< 
<                 }
<                 break;
<             case 117 :
<                 // JavaScript.g:1:779: RegularExpressionLiteral
<                 {
<                 mRegularExpressionLiteral(); 
< 
<                 }
<                 break;
< 
<         }
< 
<     }
< 
< 
<     protected DFA19 dfa19 = new DFA19(this);
<     protected DFA32 dfa32 = new DFA32(this);
<     static final String DFA19_eotS =
<         "\1\uffff\2\4\3\uffff\1\4";
<     static final String DFA19_eofS =
<         "\7\uffff";
<     static final String DFA19_minS =
<         "\3\56\3\uffff\1\56";
<     static final String DFA19_maxS =
<         "\1\71\1\56\1\71\3\uffff\1\71";
<     static final String DFA19_acceptS =
<         "\3\uffff\1\2\1\3\1\1\1\uffff";
<     static final String DFA19_specialS =
<         "\7\uffff}>";
<     static final String[] DFA19_transitionS = {
<             "\1\3\1\uffff\1\1\11\2",
<             "\1\5",
<             "\1\5\1\uffff\12\6",
<             "",
<             "",
<             "",
<             "\1\5\1\uffff\12\6"
<     };
< 
<     static final short[] DFA19_eot = DFA.unpackEncodedString(DFA19_eotS);
<     static final short[] DFA19_eof = DFA.unpackEncodedString(DFA19_eofS);
<     static final char[] DFA19_min = DFA.unpackEncodedStringToUnsignedChars(DFA19_minS);
<     static final char[] DFA19_max = DFA.unpackEncodedStringToUnsignedChars(DFA19_maxS);
<     static final short[] DFA19_accept = DFA.unpackEncodedString(DFA19_acceptS);
<     static final short[] DFA19_special = DFA.unpackEncodedString(DFA19_specialS);
<     static final short[][] DFA19_transition;
< 
<     static {
<         int numStates = DFA19_transitionS.length;
<         DFA19_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA19_transition[i] = DFA.unpackEncodedString(DFA19_transitionS[i]);
<         }
<     }
< 
<     class DFA19 extends DFA {
< 
<         public DFA19(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 19;
<             this.eot = DFA19_eot;
<             this.eof = DFA19_eof;
<             this.min = DFA19_min;
<             this.max = DFA19_max;
<             this.accept = DFA19_accept;
<             this.special = DFA19_special;
<             this.transition = DFA19_transition;
<         }
<         public String getDescription() {
<             return "738:1: DecimalLiteral : ( DecimalIntegerLiteral '.' ( DecimalDigit )* ( ExponentPart )? | '.' ( DecimalDigit )+ ( ExponentPart )? | DecimalIntegerLiteral ( ExponentPart )? );";
<         }
<     }
<     static final String DFA32_eotS =
<         "\21\53\6\uffff\1\131\2\uffff\1\134\1\137\1\141\1\143\1\146\1\151"+
<         "\1\153\1\155\1\160\1\163\1\165\3\uffff\1\171\3\uffff\1\55\2\uffff"+
<         "\23\53\1\u0097\3\53\1\u009c\1\u009f\21\53\2\uffff\1\u00b4\2\uffff"+
<         "\1\u00b7\1\uffff\1\u00b9\1\uffff\1\u00bb\23\uffff\1\u00bc\6\uffff"+
<         "\1\53\1\u00be\2\53\1\u00c1\6\53\1\u00c8\16\53\1\uffff\4\53\1\uffff"+
<         "\1\53\1\u00de\1\uffff\7\53\1\u00e7\13\53\2\uffff\1\u00f4\7\uffff"+
<         "\1\u00f5\1\uffff\1\53\1\u00f7\1\uffff\1\53\1\u00f9\4\53\1\uffff"+
<         "\4\53\1\u0102\1\u0103\3\53\1\u0107\5\53\1\u010d\1\u010e\4\53\1\uffff"+
<         "\10\53\1\uffff\1\u011b\2\53\1\u011e\1\53\1\u0120\1\u0121\4\53\3"+
<         "\uffff\1\53\1\uffff\1\53\1\uffff\1\u0129\1\53\1\u012b\1\u012d\1"+
<         "\53\1\u012f\1\u0130\1\53\2\uffff\1\u0132\1\53\1\u0134\1\uffff\1"+
<         "\u0135\4\53\2\uffff\10\53\1\u0142\1\53\1\u0144\1\53\1\uffff\1\53"+
<         "\1\u0147\1\uffff\1\53\2\uffff\4\53\1\u014d\1\53\1\u014f\1\uffff"+
<         "\1\u0150\1\uffff\1\53\1\uffff\1\53\2\uffff\1\53\1\uffff\1\53\2\uffff"+
<         "\1\53\1\u0156\1\53\1\u0158\1\u0159\4\53\1\u015e\1\u015f\1\u0160"+
<         "\1\uffff\1\u0161\1\uffff\2\53\1\uffff\4\53\1\u0168\1\uffff\1\53"+
<         "\2\uffff\1\u016a\1\53\1\u016c\1\53\1\u016e\1\uffff\1\53\2\uffff"+
<         "\1\u0170\3\53\4\uffff\3\53\1\u0177\1\u0178\1\53\1\uffff\1\53\1\uffff"+
<         "\1\u017b\1\uffff\1\u017c\1\uffff\1\u017d\1\uffff\4\53\1\u0182\1"+
<         "\u0183\2\uffff\1\53\1\u0185\3\uffff\1\53\1\u0187\2\53\2\uffff\1"+
<         "\u018a\1\uffff\1\u018b\1\uffff\1\u018c\1\53\3\uffff\1\53\1\u018f"+
<         "\1\uffff";
<     static final String DFA32_eofS =
<         "\u0190\uffff";
<     static final String DFA32_minS =
<         "\1\11\1\141\1\150\1\141\1\157\1\141\1\145\1\154\1\146\1\145\1\150"+
<         "\1\141\1\150\1\142\2\157\1\141\6\uffff\1\60\2\uffff\1\74\3\75\1"+
<         "\53\1\55\2\75\1\46\2\75\3\uffff\1\0\3\uffff\1\60\2\uffff\1\154\1"+
<         "\167\1\164\1\141\1\151\1\160\1\154\1\156\1\162\1\156\1\157\1\145"+
<         "\1\157\1\164\1\163\1\156\2\141\1\142\1\44\1\163\1\165\1\160\2\44"+
<         "\1\160\1\164\1\151\1\157\1\141\1\160\1\156\1\162\2\151\1\164\1\163"+
<         "\1\164\1\156\1\143\1\151\1\142\2\uffff\1\75\2\uffff\1\75\1\uffff"+
<         "\1\75\1\uffff\1\75\23\uffff\1\0\6\uffff\1\154\1\44\1\151\1\145\1"+
<         "\44\1\156\1\163\1\157\1\145\1\163\1\141\1\44\1\143\2\141\1\154\2"+
<         "\145\1\143\1\163\1\162\1\163\1\141\1\145\1\165\1\142\1\uffff\1\145"+
<         "\1\155\1\157\1\145\1\uffff\1\164\1\44\1\uffff\1\154\1\165\1\164"+
<         "\1\162\1\164\1\145\1\143\1\44\1\144\1\141\1\154\1\150\1\164\1\157"+
<         "\1\147\1\153\1\166\1\164\1\154\2\uffff\1\75\7\uffff\1\44\1\uffff"+
<         "\1\166\1\44\1\uffff\1\163\1\44\1\167\1\157\1\145\1\154\1\uffff\2"+
<         "\164\1\153\1\145\2\44\1\150\1\151\1\164\1\44\1\163\1\165\1\164\1"+
<         "\147\1\154\2\44\1\162\1\156\1\141\1\162\1\uffff\1\145\2\162\1\143"+
<         "\1\164\1\151\1\162\1\150\1\uffff\1\44\1\164\1\145\1\44\1\162\2\44"+
<         "\2\141\1\145\1\151\3\uffff\1\145\1\uffff\1\151\1\uffff\1\44\1\146"+
<         "\2\44\1\151\2\44\1\141\2\uffff\1\44\1\156\1\44\1\uffff\1\44\1\154"+
<         "\1\145\1\147\1\145\2\uffff\1\164\1\144\1\156\1\146\1\155\1\164\1"+
<         "\156\1\150\1\44\1\143\1\44\1\162\1\uffff\1\151\1\44\1\uffff\1\141"+
<         "\2\uffff\1\147\1\164\2\143\1\44\1\145\1\44\1\uffff\1\44\1\uffff"+
<         "\1\171\1\uffff\1\157\2\uffff\1\156\1\uffff\1\165\2\uffff\1\164\1"+
<         "\44\1\145\2\44\1\163\1\143\1\141\1\145\3\44\1\uffff\1\44\1\uffff"+
<         "\1\157\1\154\1\uffff\1\143\2\145\1\164\1\44\1\uffff\1\156\2\uffff"+
<         "\1\44\1\156\1\44\1\145\1\44\1\uffff\1\162\2\uffff\1\44\1\145\1\143"+
<         "\1\156\4\uffff\1\156\1\145\1\164\2\44\1\145\1\uffff\1\164\1\uffff"+
<         "\1\44\1\uffff\1\44\1\uffff\1\44\1\uffff\1\157\1\145\1\164\1\151"+
<         "\2\44\2\uffff\1\144\1\44\3\uffff\1\146\1\44\1\163\1\172\2\uffff"+
<         "\1\44\1\uffff\1\44\1\uffff\1\44\1\145\3\uffff\1\144\1\44\1\uffff";
<     static final String DFA32_maxS =
<         "\1\u3000\1\165\1\171\1\165\1\171\2\157\1\170\1\156\1\145\1\171\1"+
<         "\157\1\151\1\142\2\157\1\165\6\uffff\1\71\2\uffff\1\75\1\76\7\75"+
<         "\1\174\1\75\3\uffff\1\uffff\3\uffff\1\170\2\uffff\1\154\1\167\1"+
<         "\164\1\171\1\162\1\160\1\154\1\156\1\162\1\156\1\157\1\145\1\157"+
<         "\2\164\1\156\2\141\1\154\1\172\1\163\1\165\1\164\2\172\1\160\1\164"+
<         "\1\151\1\157\1\141\1\160\1\156\1\162\1\154\1\151\1\164\1\163\1\164"+
<         "\1\156\1\143\1\157\1\142\2\uffff\1\75\2\uffff\1\76\1\uffff\1\75"+
<         "\1\uffff\1\75\23\uffff\1\uffff\6\uffff\1\154\1\172\1\151\1\145\1"+
<         "\172\1\156\1\163\1\157\1\145\1\163\1\141\1\172\1\143\2\141\1\154"+
<         "\2\145\1\143\1\164\1\162\1\163\1\141\1\145\1\165\1\142\1\uffff\1"+
<         "\145\1\155\1\157\1\145\1\uffff\1\164\1\172\1\uffff\1\157\1\165\1"+
<         "\164\1\162\1\164\1\145\1\143\1\172\1\144\1\141\1\154\1\150\1\164"+
<         "\1\157\1\147\1\153\1\166\1\164\1\154\2\uffff\1\75\7\uffff\1\172"+
<         "\1\uffff\1\166\1\172\1\uffff\1\163\1\172\1\167\1\157\1\145\1\154"+
<         "\1\uffff\2\164\1\153\1\145\2\172\1\150\1\151\1\164\1\172\1\163\1"+
<         "\165\1\164\1\147\1\154\2\172\1\162\1\156\1\141\1\162\1\uffff\1\145"+
<         "\2\162\1\143\1\164\1\151\1\162\1\150\1\uffff\1\172\1\164\1\145\1"+
<         "\172\1\162\2\172\2\141\1\145\1\151\3\uffff\1\145\1\uffff\1\151\1"+
<         "\uffff\1\172\1\146\2\172\1\151\2\172\1\141\2\uffff\1\172\1\156\1"+
<         "\172\1\uffff\1\172\1\154\1\145\1\147\1\145\2\uffff\1\164\1\144\1"+
<         "\156\1\146\1\155\1\164\1\156\1\150\1\172\1\143\1\172\1\162\1\uffff"+
<         "\1\151\1\172\1\uffff\1\141\2\uffff\1\147\1\164\2\143\1\172\1\145"+
<         "\1\172\1\uffff\1\172\1\uffff\1\171\1\uffff\1\157\2\uffff\1\156\1"+
<         "\uffff\1\165\2\uffff\1\164\1\172\1\145\2\172\1\163\1\143\1\141\1"+
<         "\145\3\172\1\uffff\1\172\1\uffff\1\157\1\154\1\uffff\1\143\2\145"+
<         "\1\164\1\172\1\uffff\1\156\2\uffff\1\172\1\156\1\172\1\145\1\172"+
<         "\1\uffff\1\162\2\uffff\1\172\1\145\1\143\1\156\4\uffff\1\156\1\145"+
<         "\1\164\2\172\1\145\1\uffff\1\164\1\uffff\1\172\1\uffff\1\172\1\uffff"+
<         "\1\172\1\uffff\1\157\1\145\1\164\1\151\2\172\2\uffff\1\144\1\172"+
<         "\3\uffff\1\146\1\172\1\163\1\172\2\uffff\1\172\1\uffff\1\172\1\uffff"+
<         "\1\172\1\145\3\uffff\1\144\1\172\1\uffff";
<     static final String DFA32_acceptS =
<         "\21\uffff\1\74\1\75\1\76\1\77\1\100\1\101\1\uffff\1\103\1\104\13"+
<         "\uffff\1\132\1\135\1\136\1\uffff\1\154\1\155\1\160\1\uffff\1\161"+
<         "\1\164\52\uffff\1\102\1\107\1\uffff\1\105\1\110\1\uffff\1\106\1"+
<         "\uffff\1\137\1\uffff\1\131\1\121\1\140\1\115\1\122\1\141\1\116\1"+
<         "\142\1\117\1\143\1\120\1\133\1\147\1\126\1\134\1\150\1\127\1\151"+
<         "\1\130\1\uffff\1\156\1\157\1\152\1\165\1\163\1\162\32\uffff\1\12"+
<         "\4\uffff\1\17\2\uffff\1\20\23\uffff\1\144\1\123\1\uffff\1\145\1"+
<         "\124\1\113\1\111\1\114\1\112\1\153\1\uffff\1\22\2\uffff\1\27\6\uffff"+
<         "\1\15\25\uffff\1\55\10\uffff\1\31\13\uffff\1\146\1\125\1\1\1\uffff"+
<         "\1\2\1\uffff\1\25\10\uffff\1\37\1\5\3\uffff\1\40\5\uffff\1\13\1"+
<         "\45\14\uffff\1\32\2\uffff\1\34\1\uffff\1\52\1\57\7\uffff\1\26\1"+
<         "\uffff\1\3\1\uffff\1\50\1\uffff\1\51\1\4\1\uffff\1\6\1\uffff\1\42"+
<         "\1\41\14\uffff\1\65\1\uffff\1\67\2\uffff\1\33\5\uffff\1\60\1\uffff"+
<         "\1\71\1\30\5\uffff\1\11\1\uffff\1\44\1\46\4\uffff\1\54\1\23\1\24"+
<         "\1\66\6\uffff\1\64\1\uffff\1\14\1\uffff\1\36\1\uffff\1\10\1\uffff"+
<         "\1\47\6\uffff\1\61\1\62\2\uffff\1\16\1\7\1\43\4\uffff\1\73\1\35"+
<         "\1\uffff\1\72\1\uffff\1\56\2\uffff\1\63\1\21\1\53\2\uffff\1\70";
<     static final String DFA32_specialS =
<         "\50\uffff\1\0\115\uffff\1\1\u0119\uffff}>";
<     static final String[] DFA32_transitionS = {
<             "\1\51\1\52\2\51\1\52\22\uffff\1\51\1\35\1\56\2\uffff\1\41\1"+
<             "\42\1\56\1\23\1\24\1\40\1\36\1\31\1\37\1\27\1\50\1\54\11\55"+
<             "\1\47\1\30\1\32\1\34\1\33\1\46\33\uffff\1\25\1\uffff\1\26\1"+
<             "\44\2\uffff\1\15\1\4\1\5\1\6\1\7\1\3\1\16\1\uffff\1\10\2\uffff"+
<             "\1\17\1\uffff\1\1\1\uffff\1\20\1\uffff\1\11\1\12\1\2\1\uffff"+
<             "\1\13\1\14\3\uffff\1\21\1\43\1\22\1\45\41\uffff\1\51\u15df\uffff"+
<             "\1\51\u018d\uffff\1\51\u07f1\uffff\13\51\35\uffff\2\52\5\uffff"+
<             "\1\51\57\uffff\1\51\u0fa0\uffff\1\51",
<             "\1\61\3\uffff\1\60\17\uffff\1\57",
<             "\1\63\11\uffff\1\62\6\uffff\1\64",
<             "\1\65\7\uffff\1\66\2\uffff\1\71\2\uffff\1\67\5\uffff\1\70",
<             "\1\73\2\uffff\1\72\6\uffff\1\74",
<             "\1\75\6\uffff\1\77\3\uffff\1\100\2\uffff\1\76",
<             "\1\101\11\uffff\1\102",
<             "\1\103\1\uffff\1\104\11\uffff\1\105",
<             "\1\106\6\uffff\1\110\1\107",
<             "\1\111",
<             "\1\113\13\uffff\1\114\1\115\1\uffff\1\112\1\uffff\1\116",
<             "\1\117\15\uffff\1\120",
<             "\1\121\1\122",
<             "\1\123",
<             "\1\124",
<             "\1\125",
<             "\1\126\20\uffff\1\127\2\uffff\1\130",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\12\55",
<             "",
<             "",
<             "\1\133\1\132",
<             "\1\135\1\136",
<             "\1\140",
<             "\1\142",
<             "\1\144\21\uffff\1\145",
<             "\1\147\17\uffff\1\150",
<             "\1\152",
<             "\1\154",
<             "\1\156\26\uffff\1\157",
<             "\1\162\76\uffff\1\161",
<             "\1\164",
<             "",
<             "",
<             "",
<             "\12\172\1\uffff\2\172\1\uffff\34\172\1\167\4\172\1\170\15\172"+
<             "\1\166\u1fea\172\2\uffff\udfd6\172",
<             "",
<             "",
<             "",
<             "\10\174\40\uffff\1\173\37\uffff\1\173",
<             "",
<             "",
<             "\1\175",
<             "\1\176",
<             "\1\177",
<             "\1\u0082\23\uffff\1\u0080\3\uffff\1\u0081",
<             "\1\u0083\10\uffff\1\u0084",
<             "\1\u0085",
<             "\1\u0086",
<             "\1\u0087",
<             "\1\u0088",
<             "\1\u0089",
<             "\1\u008a",
<             "\1\u008b",
<             "\1\u008c",
<             "\1\u008d",
<             "\1\u008e\1\u008f",
<             "\1\u0090",
<             "\1\u0091",
<             "\1\u0092",
<             "\1\u0095\3\uffff\1\u0093\5\uffff\1\u0094",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\24\53\1\u0096\5\53",
<             "\1\u0098",
<             "\1\u0099",
<             "\1\u009a\3\uffff\1\u009b",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\22\53\1\u009d\1\u009e\6\53",
<             "\1\u00a0",
<             "\1\u00a1",
<             "\1\u00a2",
<             "\1\u00a3",
<             "\1\u00a4",
<             "\1\u00a5",
<             "\1\u00a6",
<             "\1\u00a7",
<             "\1\u00a8\2\uffff\1\u00a9",
<             "\1\u00aa",
<             "\1\u00ab",
<             "\1\u00ac",
<             "\1\u00ad",
<             "\1\u00ae",
<             "\1\u00af",
<             "\1\u00b0\5\uffff\1\u00b1",
<             "\1\u00b2",
<             "",
<             "",
<             "\1\u00b3",
<             "",
<             "",
<             "\1\u00b6\1\u00b5",
<             "",
<             "\1\u00b8",
<             "",
<             "\1\u00ba",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\12\172\1\uffff\2\172\1\uffff\u201a\172\2\uffff\udfd6\172",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\1\u00bd",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00bf",
<             "\1\u00c0",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00c2",
<             "\1\u00c3",
<             "\1\u00c4",
<             "\1\u00c5",
<             "\1\u00c6",
<             "\1\u00c7",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00c9",
<             "\1\u00ca",
<             "\1\u00cb",
<             "\1\u00cc",
<             "\1\u00cd",
<             "\1\u00ce",
<             "\1\u00cf",
<             "\1\u00d1\1\u00d0",
<             "\1\u00d2",
<             "\1\u00d3",
<             "\1\u00d4",
<             "\1\u00d5",
<             "\1\u00d6",
<             "\1\u00d7",
<             "",
<             "\1\u00d8",
<             "\1\u00d9",
<             "\1\u00da",
<             "\1\u00db",
<             "",
<             "\1\u00dc",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\4\53\1\u00dd\25\53",
<             "",
<             "\1\u00df\2\uffff\1\u00e0",
<             "\1\u00e1",
<             "\1\u00e2",
<             "\1\u00e3",
<             "\1\u00e4",
<             "\1\u00e5",
<             "\1\u00e6",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00e8",
<             "\1\u00e9",
<             "\1\u00ea",
<             "\1\u00eb",
<             "\1\u00ec",
<             "\1\u00ed",
<             "\1\u00ee",
<             "\1\u00ef",
<             "\1\u00f0",
<             "\1\u00f1",
<             "\1\u00f2",
<             "",
<             "",
<             "\1\u00f3",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u00f6",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u00f8",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u00fa",
<             "\1\u00fb",
<             "\1\u00fc",
<             "\1\u00fd",
<             "",
<             "\1\u00fe",
<             "\1\u00ff",
<             "\1\u0100",
<             "\1\u0101",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0104",
<             "\1\u0105",
<             "\1\u0106",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0108",
<             "\1\u0109",
<             "\1\u010a",
<             "\1\u010b",
<             "\1\u010c",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u010f",
<             "\1\u0110",
<             "\1\u0111",
<             "\1\u0112",
<             "",
<             "\1\u0113",
<             "\1\u0114",
<             "\1\u0115",
<             "\1\u0116",
<             "\1\u0117",
<             "\1\u0118",
<             "\1\u0119",
<             "\1\u011a",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u011c",
<             "\1\u011d",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u011f",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0122",
<             "\1\u0123",
<             "\1\u0124",
<             "\1\u0125",
<             "",
<             "",
<             "",
<             "\1\u0126",
<             "",
<             "\1\u0127",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\22\53\1\u0128\7\53",
<             "\1\u012a",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\13\53\1\u012c\16\53",
<             "\1\u012e",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0131",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0133",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0136",
<             "\1\u0137",
<             "\1\u0138",
<             "\1\u0139",
<             "",
<             "",
<             "\1\u013a",
<             "\1\u013b",
<             "\1\u013c",
<             "\1\u013d",
<             "\1\u013e",
<             "\1\u013f",
<             "\1\u0140",
<             "\1\u0141",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0143",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0145",
<             "",
<             "\1\u0146",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0148",
<             "",
<             "",
<             "\1\u0149",
<             "\1\u014a",
<             "\1\u014b",
<             "\1\u014c",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u014e",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0151",
<             "",
<             "\1\u0152",
<             "",
<             "",
<             "\1\u0153",
<             "",
<             "\1\u0154",
<             "",
<             "",
<             "\1\u0155",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0157",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u015a",
<             "\1\u015b",
<             "\1\u015c",
<             "\1\u015d",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0162",
<             "\1\u0163",
<             "",
<             "\1\u0164",
<             "\1\u0165",
<             "\1\u0166",
<             "\1\u0167",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u0169",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u016b",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u016d",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u016f",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0171",
<             "\1\u0172",
<             "\1\u0173",
<             "",
<             "",
<             "",
<             "",
<             "\1\u0174",
<             "\1\u0175",
<             "\1\u0176",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0179",
<             "",
<             "\1\u017a",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\u017e",
<             "\1\u017f",
<             "\1\u0180",
<             "\1\u0181",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "",
<             "\1\u0184",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "",
<             "",
<             "\1\u0186",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u0188",
<             "\1\u0189",
<             "",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             "\1\u018d",
<             "",
<             "",
<             "",
<             "\1\u018e",
<             "\1\53\13\uffff\12\53\7\uffff\32\53\1\uffff\1\53\2\uffff\1\53"+
<             "\1\uffff\32\53",
<             ""
<     };
< 
<     static final short[] DFA32_eot = DFA.unpackEncodedString(DFA32_eotS);
<     static final short[] DFA32_eof = DFA.unpackEncodedString(DFA32_eofS);
<     static final char[] DFA32_min = DFA.unpackEncodedStringToUnsignedChars(DFA32_minS);
<     static final char[] DFA32_max = DFA.unpackEncodedStringToUnsignedChars(DFA32_maxS);
<     static final short[] DFA32_accept = DFA.unpackEncodedString(DFA32_acceptS);
<     static final short[] DFA32_special = DFA.unpackEncodedString(DFA32_specialS);
<     static final short[][] DFA32_transition;
< 
<     static {
<         int numStates = DFA32_transitionS.length;
<         DFA32_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA32_transition[i] = DFA.unpackEncodedString(DFA32_transitionS[i]);
<         }
<     }
< 
<     class DFA32 extends DFA {
< 
<         public DFA32(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 32;
<             this.eot = DFA32_eot;
<             this.eof = DFA32_eof;
<             this.min = DFA32_min;
<             this.max = DFA32_max;
<             this.accept = DFA32_accept;
<             this.special = DFA32_special;
<             this.transition = DFA32_transition;
<         }
<         public String getDescription() {
<             return "1:1: Tokens : ( NULL | TRUE | FALSE | BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH | ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE | LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS | WhiteSpace | EOL | MultiLineComment | SingleLineComment | Identifier | DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral | StringLiteral | RegularExpressionLiteral );";
<         }
<         public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
<             IntStream input = _input;
<         	int _s = s;
<             switch ( s ) {
<                     case 0 : 
<                         int LA32_40 = input.LA(1);
< 
<                          
<                         int index32_40 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( (LA32_40=='=') ) {s = 118;}
< 
<                         else if ( (LA32_40=='*') ) {s = 119;}
< 
<                         else if ( (LA32_40=='/') ) {s = 120;}
< 
<                         else if ( ((LA32_40>='\u0000' && LA32_40<='\t')||(LA32_40>='\u000B' && LA32_40<='\f')||(LA32_40>='\u000E' && LA32_40<=')')||(LA32_40>='+' && LA32_40<='.')||(LA32_40>='0' && LA32_40<='<')||(LA32_40>='>' && LA32_40<='\u2027')||(LA32_40>='\u202A' && LA32_40<='\uFFFF')) && (( areRegularExpressionsEnabled() ))) {s = 122;}
< 
<                         else s = 121;
< 
<                          
<                         input.seek(index32_40);
<                         if ( s>=0 ) return s;
<                         break;
<                     case 1 : 
<                         int LA32_118 = input.LA(1);
< 
<                          
<                         int index32_118 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( ((LA32_118>='\u0000' && LA32_118<='\t')||(LA32_118>='\u000B' && LA32_118<='\f')||(LA32_118>='\u000E' && LA32_118<='\u2027')||(LA32_118>='\u202A' && LA32_118<='\uFFFF')) && (( areRegularExpressionsEnabled() ))) {s = 122;}
< 
<                         else s = 188;
< 
<                          
<                         input.seek(index32_118);
<                         if ( s>=0 ) return s;
<                         break;
<             }
<             NoViableAltException nvae =
<                 new NoViableAltException(getDescription(), 32, _s, input);
<             error(nvae);
<             throw nvae;
<         }
<     }
<  
< 
< }
\ No newline at end of file
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScriptParser.java.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScriptParser.java.svn-base
1,10124d0
< // $ANTLR 3.1.1 JavaScript.g 2009-03-06 21:11:52
< 
< import org.antlr.runtime.*;
< import java.util.Stack;
< import java.util.List;
< import java.util.ArrayList;
< 
< 
< import org.antlr.runtime.tree.*;
< 
< public class JavaScriptParser extends Parser {
<     public static final String[] tokenNames = new String[] {
<         "<invalid>", "<EOR>", "<DOWN>", "<UP>", "NULL", "TRUE", "FALSE", "BREAK", "CASE", "CATCH", "CONTINUE", "DEFAULT", "DELETE", "DO", "ELSE", "FINALLY", "FOR", "FUNCTION", "IF", "IN", "INSTANCEOF", "NEW", "RETURN", "SWITCH", "THIS", "THROW", "TRY", "TYPEOF", "VAR", "VOID", "WHILE", "WITH", "ABSTRACT", "BOOLEAN", "BYTE", "CHAR", "CLASS", "CONST", "DEBUGGER", "DOUBLE", "ENUM", "EXPORT", "EXTENDS", "FINAL", "FLOAT", "GOTO", "IMPLEMENTS", "IMPORT", "INT", "INTERFACE", "LONG", "NATIVE", "PACKAGE", "PRIVATE", "PROTECTED", "PUBLIC", "SHORT", "STATIC", "SUPER", "SYNCHRONIZED", "THROWS", "TRANSIENT", "VOLATILE", "LBRACE", "RBRACE", "LPAREN", "RPAREN", "LBRACK", "RBRACK", "DOT", "SEMIC", "COMMA", "LT", "GT", "LTE", "GTE", "EQ", "NEQ", "SAME", "NSAME", "ADD", "SUB", "MUL", "MOD", "INC", "DEC", "SHL", "SHR", "SHU", "AND", "OR", "XOR", "NOT", "INV", "LAND", "LOR", "QUE", "COLON", "ASSIGN", "ADDASS", "SUBASS", "MULASS", "MODASS", "SHLASS", "SHRASS", "SHUASS", "ANDASS", "ORASS", "XORASS", "DIV", "DIVASS", "ARGS", "ARRAY", "BLOCK", "BYFIELD", "BYINDEX", "CALL", "CEXPR", "EXPR", "FORITER", "FORSTEP", "ITEM", "LABELLED", "NAMEDVALUE", "NEG", "OBJECT", "PAREXPR", "PDEC", "PINC", "POS", "BSLASH", "DQUOTE", "SQUOTE", "TAB", "VT", "FF", "SP", "NBSP", "USP", "WhiteSpace", "LF", "CR", "LS", "PS", "LineTerminator", "EOL", "MultiLineComment", "SingleLineComment", "Identifier", "StringLiteral", "HexDigit", "IdentifierStartASCII", "DecimalDigit", "IdentifierPart", "IdentifierNameASCIIStart", "RegularExpressionLiteral", "OctalDigit", "ExponentPart", "DecimalIntegerLiteral", "DecimalLiteral", "OctalIntegerLiteral", "HexIntegerLiteral", "CharacterEscapeSequence", "ZeroToThree", "OctalEscapeSequence", "HexEscapeSequence", "UnicodeEscapeSequence", "EscapeSequence", "BackslashSequence", "RegularExpressionFirstChar", "RegularExpressionChar"
<     };
<     public static final int BackslashSequence=168;
<     public static final int CONST=37;
<     public static final int COMMA=71;
<     public static final int RegularExpressionLiteral=155;
<     public static final int ARGS=111;
<     public static final int ARRAY=112;
<     public static final int LF=140;
<     public static final int SYNCHRONIZED=59;
<     public static final int HexDigit=150;
<     public static final int DOUBLE=39;
<     public static final int EXPR=118;
<     public static final int ADDASS=99;
<     public static final int DecimalDigit=152;
<     public static final int FALSE=6;
<     public static final int USP=138;
<     public static final int ABSTRACT=32;
<     public static final int SP=136;
<     public static final int DQUOTE=131;
<     public static final int IMPORT=47;
<     public static final int SEMIC=70;
<     public static final int MODASS=102;
<     public static final int PACKAGE=52;
<     public static final int SQUOTE=132;
<     public static final int SHR=87;
<     public static final int CONTINUE=10;
<     public static final int DOT=69;
<     public static final int PRIVATE=53;
<     public static final int MultiLineComment=146;
<     public static final int HexIntegerLiteral=161;
<     public static final int AND=89;
<     public static final int RegularExpressionFirstChar=169;
<     public static final int DIVASS=110;
<     public static final int FUNCTION=17;
<     public static final int GTE=75;
<     public static final int OctalEscapeSequence=164;
<     public static final int HexEscapeSequence=165;
<     public static final int SingleLineComment=147;
<     public static final int UnicodeEscapeSequence=166;
<     public static final int POS=129;
<     public static final int RPAREN=66;
<     public static final int IdentifierStartASCII=151;
<     public static final int FINALLY=15;
<     public static final int IdentifierNameASCIIStart=154;
<     public static final int EXTENDS=42;
<     public static final int IdentifierPart=153;
<     public static final int SUPER=58;
<     public static final int Identifier=148;
<     public static final int SAME=78;
<     public static final int CHAR=35;
<     public static final int NEW=21;
<     public static final int EQ=76;
<     public static final int LT=72;
<     public static final int FINAL=43;
<     public static final int SUBASS=100;
<     public static final int VT=134;
<     public static final int LAND=94;
<     public static final int LBRACK=67;
<     public static final int CATCH=9;
<     public static final int STATIC=57;
<     public static final int CASE=8;
<     public static final int MUL=82;
<     public static final int INTERFACE=49;
<     public static final int ExponentPart=157;
<     public static final int INV=93;
<     public static final int BOOLEAN=33;
<     public static final int ELSE=14;
<     public static final int CharacterEscapeSequence=162;
<     public static final int BSLASH=130;
<     public static final int SHLASS=103;
<     public static final int DecimalLiteral=159;
<     public static final int BREAK=7;
<     public static final int NULL=4;
<     public static final int XOR=91;
<     public static final int COLON=97;
<     public static final int DIV=109;
<     public static final int ORASS=107;
<     public static final int TRUE=5;
<     public static final int ADD=80;
<     public static final int THROW=25;
<     public static final int SHORT=56;
<     public static final int LABELLED=122;
<     public static final int CR=141;
<     public static final int RegularExpressionChar=170;
<     public static final int PUBLIC=55;
<     public static final int SHL=86;
<     public static final int LONG=50;
<     public static final int LOR=95;
<     public static final int TYPEOF=27;
<     public static final int INC=84;
<     public static final int TRANSIENT=61;
<     public static final int TAB=133;
<     public static final int FLOAT=44;
<     public static final int ZeroToThree=163;
<     public static final int THROWS=60;
<     public static final int FF=135;
<     public static final int FORITER=119;
<     public static final int GOTO=45;
<     public static final int MOD=83;
<     public static final int EXPORT=41;
<     public static final int OR=90;
<     public static final int MULASS=101;
<     public static final int LBRACE=63;
<     public static final int BLOCK=113;
<     public static final int RBRACE=64;
<     public static final int PROTECTED=54;
<     public static final int ANDASS=106;
<     public static final int LineTerminator=144;
<     public static final int SHU=88;
<     public static final int EscapeSequence=167;
<     public static final int PAREXPR=126;
<     public static final int INT=48;
<     public static final int LS=142;
<     public static final int CEXPR=117;
<     public static final int ASSIGN=98;
<     public static final int VOID=29;
<     public static final int INSTANCEOF=20;
<     public static final int LPAREN=65;
<     public static final int WhiteSpace=139;
<     public static final int XORASS=108;
<     public static final int QUE=96;
<     public static final int NEQ=77;
<     public static final int NAMEDVALUE=123;
<     public static final int ENUM=40;
<     public static final int PS=143;
<     public static final int DEBUGGER=38;
<     public static final int DELETE=12;
<     public static final int OBJECT=125;
<     public static final int DO=13;
<     public static final int IMPLEMENTS=46;
<     public static final int OctalIntegerLiteral=160;
<     public static final int WHILE=30;
<     public static final int SWITCH=23;
<     public static final int BYINDEX=115;
<     public static final int FORSTEP=120;
<     public static final int OctalDigit=156;
<     public static final int PINC=128;
<     public static final int GT=73;
<     public static final int StringLiteral=149;
<     public static final int DecimalIntegerLiteral=158;
<     public static final int SHRASS=104;
<     public static final int ITEM=121;
<     public static final int SHUASS=105;
<     public static final int THIS=24;
<     public static final int WITH=31;
<     public static final int IN=19;
<     public static final int VAR=28;
<     public static final int LTE=74;
<     public static final int CLASS=36;
<     public static final int NATIVE=51;
<     public static final int DEC=85;
<     public static final int RETURN=22;
<     public static final int BYTE=34;
<     public static final int VOLATILE=62;
<     public static final int IF=18;
<     public static final int EOF=-1;
<     public static final int EOL=145;
<     public static final int NBSP=137;
<     public static final int CALL=116;
<     public static final int FOR=16;
<     public static final int RBRACK=68;
<     public static final int DEFAULT=11;
<     public static final int NEG=124;
<     public static final int SUB=81;
<     public static final int NOT=92;
<     public static final int TRY=26;
<     public static final int PDEC=127;
<     public static final int BYFIELD=114;
<     public static final int NSAME=79;
< 
<     // delegates
<     // delegators
< 
< 
<         public JavaScriptParser(TokenStream input) {
<             this(input, new RecognizerSharedState());
<         }
<         public JavaScriptParser(TokenStream input, RecognizerSharedState state) {
<             super(input, state);
<              
<         }
<         
<     protected TreeAdaptor adaptor = new CommonTreeAdaptor();
< 
<     public void setTreeAdaptor(TreeAdaptor adaptor) {
<         this.adaptor = adaptor;
<     }
<     public TreeAdaptor getTreeAdaptor() {
<         return adaptor;
<     }
< 
<     public String[] getTokenNames() { return JavaScriptParser.tokenNames; }
<     public String getGrammarFileName() { return "JavaScript.g"; }
< 
< 
<     private final boolean isLeftHandSideAssign(RuleReturnScope lhs, Object[] cached)
<     {
<     	if (cached[0] != null)
<     	{
<     		return ((Boolean)cached[0]).booleanValue();
<     	}
<     	
<     	boolean result;
<     	if (isLeftHandSideExpression(lhs))
<     	{
<     		switch (input.LA(1))
<     		{
<     			case ASSIGN:
<     			case MULASS:
<     			case DIVASS:
<     			case MODASS:
<     			case ADDASS:
<     			case SUBASS:
<     			case SHLASS:
<     			case SHRASS:
<     			case SHUASS:
<     			case ANDASS:
<     			case XORASS:
<     			case ORASS:
<     				result = true;
<     				break;
<     			default:
<     				result = false;
<     				break;
<     		}
<     	}
<     	else
<     	{
<     		result = false;
<     	}
<     	
<     	cached[0] = new Boolean(result);
<     	return result;
<     }
< 
<     private final static boolean isLeftHandSideExpression(RuleReturnScope lhs)
<     {
<     	if (lhs.getTree() == null) // e.g. during backtracking
<     	{
<     		return true;
<     	}
<     	else
<     	{
<     		switch (((Tree)lhs.getTree()).getType())
<     		{
<     		// primaryExpression
<     			case THIS:
<     			case Identifier:
<     			case NULL:
<     			case TRUE:
<     			case FALSE:
<     			case DecimalLiteral:
<     			case OctalIntegerLiteral:
<     			case HexIntegerLiteral:
<     			case StringLiteral:
<     			case RegularExpressionLiteral:
<     			case ARRAY:
<     			case OBJECT:
<     			case PAREXPR:
<     		// functionExpression
<     			case FUNCTION:
<     		// newExpression
<     			case NEW:
<     		// leftHandSideExpression
<     			case CALL:
<     			case BYFIELD:
<     			case BYINDEX:
<     				return true;
<     			
<     			default:
<     				return false;
<     		}
<     	}
<     }
<     	
<     private final boolean isLeftHandSideIn(RuleReturnScope lhs, Object[] cached)
<     {
<     	if (cached[0] != null)
<     	{
<     		return ((Boolean)cached[0]).booleanValue();
<     	}
<     	
<     	boolean result = isLeftHandSideExpression(lhs) && (input.LA(1) == IN);
<     	cached[0] = new Boolean(result);
<     	return result;
<     }
< 
<     private final void promoteEOL(ParserRuleReturnScope rule)
<     {
<     	// Get current token and its type (the possibly offending token).
<     	Token lt = input.LT(1);
<     	int la = lt.getType();
<     	
<     	// We only need to promote an EOL when the current token is offending (not a SEMIC, EOF, RBRACE, EOL or MultiLineComment).
<     	// EOL and MultiLineComment are not offending as they're already promoted in a previous call to this method.
<     	// Promoting an EOL means switching it from off channel to on channel.
<     	// A MultiLineComment gets promoted when it contains an EOL.
<     	if (!(la == SEMIC || la == EOF || la == RBRACE || la == EOL || la == MultiLineComment))
<     	{
<     		// Start on the possition before the current token and scan backwards off channel tokens until the previous on channel token.
<     		for (int ix = lt.getTokenIndex() - 1; ix > 0; ix--)
<     		{
<     			lt = input.get(ix);
<     			if (lt.getChannel() == Token.DEFAULT_CHANNEL)
<     			{
<     				// On channel token found: stop scanning.
<     				break;
<     			}
<     			else if (lt.getType() == EOL || (lt.getType() == MultiLineComment && lt.getText().matches("/.*\r\n|\r|\n")))
<     			{
<     				// We found our EOL: promote the token to on channel, position the input on it and reset the rule start.
<     				lt.setChannel(Token.DEFAULT_CHANNEL);
<     				input.seek(lt.getTokenIndex());
<     				if (rule != null)
<     				{
<     					rule.start = lt;
<     				}
<     				break;
<     			}
<     		}
<     	}
<     }	
< 
< 
<     public static class token_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "token"
<     // JavaScript.g:511:1: token : ( reservedWord | Identifier | punctuator | numericLiteral | StringLiteral );
<     public final JavaScriptParser.token_return token() throws RecognitionException {
<         JavaScriptParser.token_return retval = new JavaScriptParser.token_return();
<         retval.start = input.LT(1);
<         int token_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier2=null;
<         Token StringLiteral5=null;
<         JavaScriptParser.reservedWord_return reservedWord1 = null;
< 
<         JavaScriptParser.punctuator_return punctuator3 = null;
< 
<         JavaScriptParser.numericLiteral_return numericLiteral4 = null;
< 
< 
<         MyAstNode Identifier2_tree=null;
<         MyAstNode StringLiteral5_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 1) ) { return retval; }
<             // JavaScript.g:512:2: ( reservedWord | Identifier | punctuator | numericLiteral | StringLiteral )
<             int alt1=5;
<             switch ( input.LA(1) ) {
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case BREAK:
<             case CASE:
<             case CATCH:
<             case CONTINUE:
<             case DEFAULT:
<             case DELETE:
<             case DO:
<             case ELSE:
<             case FINALLY:
<             case FOR:
<             case FUNCTION:
<             case IF:
<             case IN:
<             case INSTANCEOF:
<             case NEW:
<             case RETURN:
<             case SWITCH:
<             case THIS:
<             case THROW:
<             case TRY:
<             case TYPEOF:
<             case VAR:
<             case VOID:
<             case WHILE:
<             case WITH:
<             case ABSTRACT:
<             case BOOLEAN:
<             case BYTE:
<             case CHAR:
<             case CLASS:
<             case CONST:
<             case DEBUGGER:
<             case DOUBLE:
<             case ENUM:
<             case EXPORT:
<             case EXTENDS:
<             case FINAL:
<             case FLOAT:
<             case GOTO:
<             case IMPLEMENTS:
<             case IMPORT:
<             case INT:
<             case INTERFACE:
<             case LONG:
<             case NATIVE:
<             case PACKAGE:
<             case PRIVATE:
<             case PROTECTED:
<             case PUBLIC:
<             case SHORT:
<             case STATIC:
<             case SUPER:
<             case SYNCHRONIZED:
<             case THROWS:
<             case TRANSIENT:
<             case VOLATILE:
<                 {
<                 alt1=1;
<                 }
<                 break;
<             case Identifier:
<                 {
<                 alt1=2;
<                 }
<                 break;
<             case LBRACE:
<             case RBRACE:
<             case LPAREN:
<             case RPAREN:
<             case LBRACK:
<             case RBRACK:
<             case DOT:
<             case SEMIC:
<             case COMMA:
<             case LT:
<             case GT:
<             case LTE:
<             case GTE:
<             case EQ:
<             case NEQ:
<             case SAME:
<             case NSAME:
<             case ADD:
<             case SUB:
<             case MUL:
<             case MOD:
<             case INC:
<             case DEC:
<             case SHL:
<             case SHR:
<             case SHU:
<             case AND:
<             case OR:
<             case XOR:
<             case NOT:
<             case INV:
<             case LAND:
<             case LOR:
<             case QUE:
<             case COLON:
<             case ASSIGN:
<             case ADDASS:
<             case SUBASS:
<             case MULASS:
<             case MODASS:
<             case SHLASS:
<             case SHRASS:
<             case SHUASS:
<             case ANDASS:
<             case ORASS:
<             case XORASS:
<             case DIV:
<             case DIVASS:
<                 {
<                 alt1=3;
<                 }
<                 break;
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt1=4;
<                 }
<                 break;
<             case StringLiteral:
<                 {
<                 alt1=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 1, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt1) {
<                 case 1 :
<                     // JavaScript.g:512:4: reservedWord
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_reservedWord_in_token1756);
<                     reservedWord1=reservedWord();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, reservedWord1.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:513:4: Identifier
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     Identifier2=(Token)match(input,Identifier,FOLLOW_Identifier_in_token1761); 
<                     Identifier2_tree = (MyAstNode)adaptor.create(Identifier2);
<                     adaptor.addChild(root_0, Identifier2_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:514:4: punctuator
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_punctuator_in_token1766);
<                     punctuator3=punctuator();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, punctuator3.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:515:4: numericLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_numericLiteral_in_token1771);
<                     numericLiteral4=numericLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, numericLiteral4.getTree());
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:516:4: StringLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     StringLiteral5=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_token1776); 
<                     StringLiteral5_tree = (MyAstNode)adaptor.create(StringLiteral5);
<                     adaptor.addChild(root_0, StringLiteral5_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "token"
< 
<     public static class reservedWord_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "reservedWord"
<     // JavaScript.g:521:1: reservedWord : ( keyword | futureReservedWord | NULL | booleanLiteral );
<     public final JavaScriptParser.reservedWord_return reservedWord() throws RecognitionException {
<         JavaScriptParser.reservedWord_return retval = new JavaScriptParser.reservedWord_return();
<         retval.start = input.LT(1);
<         int reservedWord_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token NULL8=null;
<         JavaScriptParser.keyword_return keyword6 = null;
< 
<         JavaScriptParser.futureReservedWord_return futureReservedWord7 = null;
< 
<         JavaScriptParser.booleanLiteral_return booleanLiteral9 = null;
< 
< 
<         MyAstNode NULL8_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 2) ) { return retval; }
<             // JavaScript.g:522:2: ( keyword | futureReservedWord | NULL | booleanLiteral )
<             int alt2=4;
<             switch ( input.LA(1) ) {
<             case BREAK:
<             case CASE:
<             case CATCH:
<             case CONTINUE:
<             case DEFAULT:
<             case DELETE:
<             case DO:
<             case ELSE:
<             case FINALLY:
<             case FOR:
<             case FUNCTION:
<             case IF:
<             case IN:
<             case INSTANCEOF:
<             case NEW:
<             case RETURN:
<             case SWITCH:
<             case THIS:
<             case THROW:
<             case TRY:
<             case TYPEOF:
<             case VAR:
<             case VOID:
<             case WHILE:
<             case WITH:
<                 {
<                 alt2=1;
<                 }
<                 break;
<             case ABSTRACT:
<             case BOOLEAN:
<             case BYTE:
<             case CHAR:
<             case CLASS:
<             case CONST:
<             case DEBUGGER:
<             case DOUBLE:
<             case ENUM:
<             case EXPORT:
<             case EXTENDS:
<             case FINAL:
<             case FLOAT:
<             case GOTO:
<             case IMPLEMENTS:
<             case IMPORT:
<             case INT:
<             case INTERFACE:
<             case LONG:
<             case NATIVE:
<             case PACKAGE:
<             case PRIVATE:
<             case PROTECTED:
<             case PUBLIC:
<             case SHORT:
<             case STATIC:
<             case SUPER:
<             case SYNCHRONIZED:
<             case THROWS:
<             case TRANSIENT:
<             case VOLATILE:
<                 {
<                 alt2=2;
<                 }
<                 break;
<             case NULL:
<                 {
<                 alt2=3;
<                 }
<                 break;
<             case TRUE:
<             case FALSE:
<                 {
<                 alt2=4;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 2, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt2) {
<                 case 1 :
<                     // JavaScript.g:522:4: keyword
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_keyword_in_reservedWord1789);
<                     keyword6=keyword();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, keyword6.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:523:4: futureReservedWord
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_futureReservedWord_in_reservedWord1794);
<                     futureReservedWord7=futureReservedWord();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, futureReservedWord7.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:524:4: NULL
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NULL8=(Token)match(input,NULL,FOLLOW_NULL_in_reservedWord1799); 
<                     NULL8_tree = (MyAstNode)adaptor.create(NULL8);
<                     adaptor.addChild(root_0, NULL8_tree);
< 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:525:4: booleanLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_booleanLiteral_in_reservedWord1804);
<                     booleanLiteral9=booleanLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, booleanLiteral9.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "reservedWord"
< 
<     public static class keyword_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "keyword"
<     // JavaScript.g:532:1: keyword : ( BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH );
<     public final JavaScriptParser.keyword_return keyword() throws RecognitionException {
<         JavaScriptParser.keyword_return retval = new JavaScriptParser.keyword_return();
<         retval.start = input.LT(1);
<         int keyword_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set10=null;
< 
<         MyAstNode set10_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 3) ) { return retval; }
<             // JavaScript.g:533:2: ( BREAK | CASE | CATCH | CONTINUE | DEFAULT | DELETE | DO | ELSE | FINALLY | FOR | FUNCTION | IF | IN | INSTANCEOF | NEW | RETURN | SWITCH | THIS | THROW | TRY | TYPEOF | VAR | VOID | WHILE | WITH )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set10=(Token)input.LT(1);
<             if ( (input.LA(1)>=BREAK && input.LA(1)<=WITH) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set10));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "keyword"
< 
<     public static class futureReservedWord_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "futureReservedWord"
<     // JavaScript.g:564:1: futureReservedWord : ( ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE );
<     public final JavaScriptParser.futureReservedWord_return futureReservedWord() throws RecognitionException {
<         JavaScriptParser.futureReservedWord_return retval = new JavaScriptParser.futureReservedWord_return();
<         retval.start = input.LT(1);
<         int futureReservedWord_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set11=null;
< 
<         MyAstNode set11_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 4) ) { return retval; }
<             // JavaScript.g:565:2: ( ABSTRACT | BOOLEAN | BYTE | CHAR | CLASS | CONST | DEBUGGER | DOUBLE | ENUM | EXPORT | EXTENDS | FINAL | FLOAT | GOTO | IMPLEMENTS | IMPORT | INT | INTERFACE | LONG | NATIVE | PACKAGE | PRIVATE | PROTECTED | PUBLIC | SHORT | STATIC | SUPER | SYNCHRONIZED | THROWS | TRANSIENT | VOLATILE )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set11=(Token)input.LT(1);
<             if ( (input.LA(1)>=ABSTRACT && input.LA(1)<=VOLATILE) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set11));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "futureReservedWord"
< 
<     public static class punctuator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "punctuator"
<     // JavaScript.g:642:1: punctuator : ( LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS );
<     public final JavaScriptParser.punctuator_return punctuator() throws RecognitionException {
<         JavaScriptParser.punctuator_return retval = new JavaScriptParser.punctuator_return();
<         retval.start = input.LT(1);
<         int punctuator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set12=null;
< 
<         MyAstNode set12_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 5) ) { return retval; }
<             // JavaScript.g:643:2: ( LBRACE | RBRACE | LPAREN | RPAREN | LBRACK | RBRACK | DOT | SEMIC | COMMA | LT | GT | LTE | GTE | EQ | NEQ | SAME | NSAME | ADD | SUB | MUL | MOD | INC | DEC | SHL | SHR | SHU | AND | OR | XOR | NOT | INV | LAND | LOR | QUE | COLON | ASSIGN | ADDASS | SUBASS | MULASS | MODASS | SHLASS | SHRASS | SHUASS | ANDASS | ORASS | XORASS | DIV | DIVASS )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set12=(Token)input.LT(1);
<             if ( (input.LA(1)>=LBRACE && input.LA(1)<=DIVASS) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set12));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "punctuator"
< 
<     public static class literal_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "literal"
<     // JavaScript.g:697:1: literal : ( NULL | booleanLiteral | numericLiteral | StringLiteral | RegularExpressionLiteral );
<     public final JavaScriptParser.literal_return literal() throws RecognitionException {
<         JavaScriptParser.literal_return retval = new JavaScriptParser.literal_return();
<         retval.start = input.LT(1);
<         int literal_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token NULL13=null;
<         Token StringLiteral16=null;
<         Token RegularExpressionLiteral17=null;
<         JavaScriptParser.booleanLiteral_return booleanLiteral14 = null;
< 
<         JavaScriptParser.numericLiteral_return numericLiteral15 = null;
< 
< 
<         MyAstNode NULL13_tree=null;
<         MyAstNode StringLiteral16_tree=null;
<         MyAstNode RegularExpressionLiteral17_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 6) ) { return retval; }
<             // JavaScript.g:698:2: ( NULL | booleanLiteral | numericLiteral | StringLiteral | RegularExpressionLiteral )
<             int alt3=5;
<             switch ( input.LA(1) ) {
<             case NULL:
<                 {
<                 alt3=1;
<                 }
<                 break;
<             case TRUE:
<             case FALSE:
<                 {
<                 alt3=2;
<                 }
<                 break;
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt3=3;
<                 }
<                 break;
<             case StringLiteral:
<                 {
<                 alt3=4;
<                 }
<                 break;
<             case RegularExpressionLiteral:
<                 {
<                 alt3=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 3, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt3) {
<                 case 1 :
<                     // JavaScript.g:698:4: NULL
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NULL13=(Token)match(input,NULL,FOLLOW_NULL_in_literal2485); 
<                     NULL13_tree = (MyAstNode)adaptor.create(NULL13);
<                     adaptor.addChild(root_0, NULL13_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:699:4: booleanLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_booleanLiteral_in_literal2490);
<                     booleanLiteral14=booleanLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, booleanLiteral14.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:700:4: numericLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_numericLiteral_in_literal2495);
<                     numericLiteral15=numericLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, numericLiteral15.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:701:4: StringLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     StringLiteral16=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_literal2500); 
<                     StringLiteral16_tree = (MyAstNode)adaptor.create(StringLiteral16);
<                     adaptor.addChild(root_0, StringLiteral16_tree);
< 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:702:4: RegularExpressionLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     RegularExpressionLiteral17=(Token)match(input,RegularExpressionLiteral,FOLLOW_RegularExpressionLiteral_in_literal2505); 
<                     RegularExpressionLiteral17_tree = (MyAstNode)adaptor.create(RegularExpressionLiteral17);
<                     adaptor.addChild(root_0, RegularExpressionLiteral17_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "literal"
< 
<     public static class booleanLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "booleanLiteral"
<     // JavaScript.g:705:1: booleanLiteral : ( TRUE | FALSE );
<     public final JavaScriptParser.booleanLiteral_return booleanLiteral() throws RecognitionException {
<         JavaScriptParser.booleanLiteral_return retval = new JavaScriptParser.booleanLiteral_return();
<         retval.start = input.LT(1);
<         int booleanLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set18=null;
< 
<         MyAstNode set18_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 7) ) { return retval; }
<             // JavaScript.g:706:2: ( TRUE | FALSE )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set18=(Token)input.LT(1);
<             if ( (input.LA(1)>=TRUE && input.LA(1)<=FALSE) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set18));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "booleanLiteral"
< 
<     public static class numericLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "numericLiteral"
<     // JavaScript.g:752:1: numericLiteral : ( DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral );
<     public final JavaScriptParser.numericLiteral_return numericLiteral() throws RecognitionException {
<         JavaScriptParser.numericLiteral_return retval = new JavaScriptParser.numericLiteral_return();
<         retval.start = input.LT(1);
<         int numericLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set19=null;
< 
<         MyAstNode set19_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 8) ) { return retval; }
<             // JavaScript.g:753:2: ( DecimalLiteral | OctalIntegerLiteral | HexIntegerLiteral )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set19=(Token)input.LT(1);
<             if ( (input.LA(1)>=DecimalLiteral && input.LA(1)<=HexIntegerLiteral) ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set19));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "numericLiteral"
< 
<     public static class primaryExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "primaryExpression"
<     // JavaScript.g:840:1: primaryExpression : ( THIS | Identifier | literal | arrayLiteral | objectLiteral | lpar= LPAREN expression RPAREN -> ^( PAREXPR[$lpar, \"PAREXPR\"] expression ) );
<     public final JavaScriptParser.primaryExpression_return primaryExpression() throws RecognitionException {
<         JavaScriptParser.primaryExpression_return retval = new JavaScriptParser.primaryExpression_return();
<         retval.start = input.LT(1);
<         int primaryExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lpar=null;
<         Token THIS20=null;
<         Token Identifier21=null;
<         Token RPAREN26=null;
<         JavaScriptParser.literal_return literal22 = null;
< 
<         JavaScriptParser.arrayLiteral_return arrayLiteral23 = null;
< 
<         JavaScriptParser.objectLiteral_return objectLiteral24 = null;
< 
<         JavaScriptParser.expression_return expression25 = null;
< 
< 
<         MyAstNode lpar_tree=null;
<         MyAstNode THIS20_tree=null;
<         MyAstNode Identifier21_tree=null;
<         MyAstNode RPAREN26_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 9) ) { return retval; }
<             // JavaScript.g:841:2: ( THIS | Identifier | literal | arrayLiteral | objectLiteral | lpar= LPAREN expression RPAREN -> ^( PAREXPR[$lpar, \"PAREXPR\"] expression ) )
<             int alt4=6;
<             switch ( input.LA(1) ) {
<             case THIS:
<                 {
<                 alt4=1;
<                 }
<                 break;
<             case Identifier:
<                 {
<                 alt4=2;
<                 }
<                 break;
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case StringLiteral:
<             case RegularExpressionLiteral:
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt4=3;
<                 }
<                 break;
<             case LBRACK:
<                 {
<                 alt4=4;
<                 }
<                 break;
<             case LBRACE:
<                 {
<                 alt4=5;
<                 }
<                 break;
<             case LPAREN:
<                 {
<                 alt4=6;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 4, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt4) {
<                 case 1 :
<                     // JavaScript.g:841:4: THIS
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     THIS20=(Token)match(input,THIS,FOLLOW_THIS_in_primaryExpression3118); 
<                     THIS20_tree = (MyAstNode)adaptor.create(THIS20);
<                     adaptor.addChild(root_0, THIS20_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:842:4: Identifier
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     Identifier21=(Token)match(input,Identifier,FOLLOW_Identifier_in_primaryExpression3123); 
<                     Identifier21_tree = (MyAstNode)adaptor.create(Identifier21);
<                     adaptor.addChild(root_0, Identifier21_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:843:4: literal
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_literal_in_primaryExpression3128);
<                     literal22=literal();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, literal22.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:844:4: arrayLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_arrayLiteral_in_primaryExpression3133);
<                     arrayLiteral23=arrayLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, arrayLiteral23.getTree());
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:845:4: objectLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_objectLiteral_in_primaryExpression3138);
<                     objectLiteral24=objectLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, objectLiteral24.getTree());
< 
<                     }
<                     break;
<                 case 6 :
<                     // JavaScript.g:846:4: lpar= LPAREN expression RPAREN
<                     {
<                     lpar=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primaryExpression3145);  
<                     stream_LPAREN.add(lpar);
< 
<                     pushFollow(FOLLOW_expression_in_primaryExpression3147);
<                     expression25=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(expression25.getTree());
<                     RPAREN26=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primaryExpression3149);  
<                     stream_RPAREN.add(RPAREN26);
< 
< 
< 
<                     // AST REWRITE
<                     // elements: expression
<                     // token labels: 
<                     // rule labels: retval
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 846:34: -> ^( PAREXPR[$lpar, \"PAREXPR\"] expression )
<                     {
<                         // JavaScript.g:846:37: ^( PAREXPR[$lpar, \"PAREXPR\"] expression )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(PAREXPR, lpar, "PAREXPR"), root_1);
< 
<                         adaptor.addChild(root_1, stream_expression.nextTree());
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "primaryExpression"
< 
<     public static class arrayLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "arrayLiteral"
<     // JavaScript.g:849:1: arrayLiteral : lb= LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK -> ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* ) ;
<     public final JavaScriptParser.arrayLiteral_return arrayLiteral() throws RecognitionException {
<         JavaScriptParser.arrayLiteral_return retval = new JavaScriptParser.arrayLiteral_return();
<         retval.start = input.LT(1);
<         int arrayLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token COMMA28=null;
<         Token RBRACK30=null;
<         JavaScriptParser.arrayItem_return arrayItem27 = null;
< 
<         JavaScriptParser.arrayItem_return arrayItem29 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode COMMA28_tree=null;
<         MyAstNode RBRACK30_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RBRACK=new RewriteRuleTokenStream(adaptor,"token RBRACK");
<         RewriteRuleTokenStream stream_LBRACK=new RewriteRuleTokenStream(adaptor,"token LBRACK");
<         RewriteRuleSubtreeStream stream_arrayItem=new RewriteRuleSubtreeStream(adaptor,"rule arrayItem");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 10) ) { return retval; }
<             // JavaScript.g:850:2: (lb= LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK -> ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* ) )
<             // JavaScript.g:850:4: lb= LBRACK ( arrayItem ( COMMA arrayItem )* )? RBRACK
<             {
<             lb=(Token)match(input,LBRACK,FOLLOW_LBRACK_in_arrayLiteral3173);  
<             stream_LBRACK.add(lb);
< 
<             // JavaScript.g:850:14: ( arrayItem ( COMMA arrayItem )* )?
<             int alt6=2;
<             int LA6_0 = input.LA(1);
< 
<             if ( ((LA6_0>=NULL && LA6_0<=FALSE)||LA6_0==DELETE||LA6_0==FUNCTION||LA6_0==NEW||LA6_0==THIS||LA6_0==TYPEOF||LA6_0==VOID||LA6_0==LBRACE||LA6_0==LPAREN||LA6_0==LBRACK||LA6_0==COMMA||(LA6_0>=ADD && LA6_0<=SUB)||(LA6_0>=INC && LA6_0<=DEC)||(LA6_0>=NOT && LA6_0<=INV)||(LA6_0>=Identifier && LA6_0<=StringLiteral)||LA6_0==RegularExpressionLiteral||(LA6_0>=DecimalLiteral && LA6_0<=HexIntegerLiteral)) ) {
<                 alt6=1;
<             }
<             else if ( (LA6_0==RBRACK) ) {
<                 int LA6_2 = input.LA(2);
< 
<                 if ( (( input.LA(1) == COMMA )) ) {
<                     alt6=1;
<                 }
<             }
<             switch (alt6) {
<                 case 1 :
<                     // JavaScript.g:850:16: arrayItem ( COMMA arrayItem )*
<                     {
<                     pushFollow(FOLLOW_arrayItem_in_arrayLiteral3177);
<                     arrayItem27=arrayItem();
< 
<                     state._fsp--;
< 
<                     stream_arrayItem.add(arrayItem27.getTree());
<                     // JavaScript.g:850:26: ( COMMA arrayItem )*
<                     loop5:
<                     do {
<                         int alt5=2;
<                         int LA5_0 = input.LA(1);
< 
<                         if ( (LA5_0==COMMA) ) {
<                             alt5=1;
<                         }
< 
< 
<                         switch (alt5) {
<                     	case 1 :
<                     	    // JavaScript.g:850:28: COMMA arrayItem
<                     	    {
<                     	    COMMA28=(Token)match(input,COMMA,FOLLOW_COMMA_in_arrayLiteral3181);  
<                     	    stream_COMMA.add(COMMA28);
< 
<                     	    pushFollow(FOLLOW_arrayItem_in_arrayLiteral3183);
<                     	    arrayItem29=arrayItem();
< 
<                     	    state._fsp--;
< 
<                     	    stream_arrayItem.add(arrayItem29.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop5;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RBRACK30=(Token)match(input,RBRACK,FOLLOW_RBRACK_in_arrayLiteral3191);  
<             stream_RBRACK.add(RBRACK30);
< 
< 
< 
<             // AST REWRITE
<             // elements: arrayItem
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 851:2: -> ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* )
<             {
<                 // JavaScript.g:851:5: ^( ARRAY[$lb, \"ARRAY\"] ( arrayItem )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ARRAY, lb, "ARRAY"), root_1);
< 
<                 // JavaScript.g:851:28: ( arrayItem )*
<                 while ( stream_arrayItem.hasNext() ) {
<                     adaptor.addChild(root_1, stream_arrayItem.nextTree());
< 
<                 }
<                 stream_arrayItem.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "arrayLiteral"
< 
<     public static class arrayItem_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "arrayItem"
<     // JavaScript.g:854:1: arrayItem : (expr= assignmentExpression | {...}?) -> ^( ITEM ( $expr)? ) ;
<     public final JavaScriptParser.arrayItem_return arrayItem() throws RecognitionException {
<         JavaScriptParser.arrayItem_return retval = new JavaScriptParser.arrayItem_return();
<         retval.start = input.LT(1);
<         int arrayItem_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.assignmentExpression_return expr = null;
< 
< 
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 11) ) { return retval; }
<             // JavaScript.g:855:2: ( (expr= assignmentExpression | {...}?) -> ^( ITEM ( $expr)? ) )
<             // JavaScript.g:855:4: (expr= assignmentExpression | {...}?)
<             {
<             // JavaScript.g:855:4: (expr= assignmentExpression | {...}?)
<             int alt7=2;
<             int LA7_0 = input.LA(1);
< 
<             if ( ((LA7_0>=NULL && LA7_0<=FALSE)||LA7_0==DELETE||LA7_0==FUNCTION||LA7_0==NEW||LA7_0==THIS||LA7_0==TYPEOF||LA7_0==VOID||LA7_0==LBRACE||LA7_0==LPAREN||LA7_0==LBRACK||(LA7_0>=ADD && LA7_0<=SUB)||(LA7_0>=INC && LA7_0<=DEC)||(LA7_0>=NOT && LA7_0<=INV)||(LA7_0>=Identifier && LA7_0<=StringLiteral)||LA7_0==RegularExpressionLiteral||(LA7_0>=DecimalLiteral && LA7_0<=HexIntegerLiteral)) ) {
<                 alt7=1;
<             }
<             else if ( (LA7_0==RBRACK||LA7_0==COMMA) ) {
<                 alt7=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 7, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt7) {
<                 case 1 :
<                     // JavaScript.g:855:6: expr= assignmentExpression
<                     {
<                     pushFollow(FOLLOW_assignmentExpression_in_arrayItem3219);
<                     expr=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     stream_assignmentExpression.add(expr.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:855:34: {...}?
<                     {
<                     if ( !(( input.LA(1) == COMMA )) ) {
<                         throw new FailedPredicateException(input, "arrayItem", " input.LA(1) == COMMA ");
<                     }
< 
<                     }
<                     break;
< 
<             }
< 
< 
< 
<             // AST REWRITE
<             // elements: expr
<             // token labels: 
<             // rule labels: expr, retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_expr=new RewriteRuleSubtreeStream(adaptor,"token expr",expr!=null?expr.tree:null);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 856:2: -> ^( ITEM ( $expr)? )
<             {
<                 // JavaScript.g:856:5: ^( ITEM ( $expr)? )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ITEM, "ITEM"), root_1);
< 
<                 // JavaScript.g:856:13: ( $expr)?
<                 if ( stream_expr.hasNext() ) {
<                     adaptor.addChild(root_1, stream_expr.nextTree());
< 
<                 }
<                 stream_expr.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "arrayItem"
< 
<     public static class objectLiteral_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "objectLiteral"
<     // JavaScript.g:859:1: objectLiteral : lb= LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE -> ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* ) ;
<     public final JavaScriptParser.objectLiteral_return objectLiteral() throws RecognitionException {
<         JavaScriptParser.objectLiteral_return retval = new JavaScriptParser.objectLiteral_return();
<         retval.start = input.LT(1);
<         int objectLiteral_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token COMMA32=null;
<         Token RBRACE34=null;
<         JavaScriptParser.nameValuePair_return nameValuePair31 = null;
< 
<         JavaScriptParser.nameValuePair_return nameValuePair33 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode COMMA32_tree=null;
<         MyAstNode RBRACE34_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_nameValuePair=new RewriteRuleSubtreeStream(adaptor,"rule nameValuePair");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 12) ) { return retval; }
<             // JavaScript.g:860:2: (lb= LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE -> ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* ) )
<             // JavaScript.g:860:4: lb= LBRACE ( nameValuePair ( COMMA nameValuePair )* )? RBRACE
<             {
<             lb=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_objectLiteral3251);  
<             stream_LBRACE.add(lb);
< 
<             // JavaScript.g:860:14: ( nameValuePair ( COMMA nameValuePair )* )?
<             int alt9=2;
<             int LA9_0 = input.LA(1);
< 
<             if ( ((LA9_0>=Identifier && LA9_0<=StringLiteral)||(LA9_0>=DecimalLiteral && LA9_0<=HexIntegerLiteral)) ) {
<                 alt9=1;
<             }
<             switch (alt9) {
<                 case 1 :
<                     // JavaScript.g:860:16: nameValuePair ( COMMA nameValuePair )*
<                     {
<                     pushFollow(FOLLOW_nameValuePair_in_objectLiteral3255);
<                     nameValuePair31=nameValuePair();
< 
<                     state._fsp--;
< 
<                     stream_nameValuePair.add(nameValuePair31.getTree());
<                     // JavaScript.g:860:30: ( COMMA nameValuePair )*
<                     loop8:
<                     do {
<                         int alt8=2;
<                         int LA8_0 = input.LA(1);
< 
<                         if ( (LA8_0==COMMA) ) {
<                             alt8=1;
<                         }
< 
< 
<                         switch (alt8) {
<                     	case 1 :
<                     	    // JavaScript.g:860:32: COMMA nameValuePair
<                     	    {
<                     	    COMMA32=(Token)match(input,COMMA,FOLLOW_COMMA_in_objectLiteral3259);  
<                     	    stream_COMMA.add(COMMA32);
< 
<                     	    pushFollow(FOLLOW_nameValuePair_in_objectLiteral3261);
<                     	    nameValuePair33=nameValuePair();
< 
<                     	    state._fsp--;
< 
<                     	    stream_nameValuePair.add(nameValuePair33.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop8;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RBRACE34=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_objectLiteral3269);  
<             stream_RBRACE.add(RBRACE34);
< 
< 
< 
<             // AST REWRITE
<             // elements: nameValuePair
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 861:2: -> ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* )
<             {
<                 // JavaScript.g:861:5: ^( OBJECT[$lb, \"OBJECT\"] ( nameValuePair )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(OBJECT, lb, "OBJECT"), root_1);
< 
<                 // JavaScript.g:861:30: ( nameValuePair )*
<                 while ( stream_nameValuePair.hasNext() ) {
<                     adaptor.addChild(root_1, stream_nameValuePair.nextTree());
< 
<                 }
<                 stream_nameValuePair.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "objectLiteral"
< 
<     public static class nameValuePair_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "nameValuePair"
<     // JavaScript.g:864:1: nameValuePair : propertyName COLON assignmentExpression -> ^( NAMEDVALUE propertyName assignmentExpression ) ;
<     public final JavaScriptParser.nameValuePair_return nameValuePair() throws RecognitionException {
<         JavaScriptParser.nameValuePair_return retval = new JavaScriptParser.nameValuePair_return();
<         retval.start = input.LT(1);
<         int nameValuePair_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token COLON36=null;
<         JavaScriptParser.propertyName_return propertyName35 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression37 = null;
< 
< 
<         MyAstNode COLON36_tree=null;
<         RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
<         RewriteRuleSubtreeStream stream_propertyName=new RewriteRuleSubtreeStream(adaptor,"rule propertyName");
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 13) ) { return retval; }
<             // JavaScript.g:865:2: ( propertyName COLON assignmentExpression -> ^( NAMEDVALUE propertyName assignmentExpression ) )
<             // JavaScript.g:865:4: propertyName COLON assignmentExpression
<             {
<             pushFollow(FOLLOW_propertyName_in_nameValuePair3294);
<             propertyName35=propertyName();
< 
<             state._fsp--;
< 
<             stream_propertyName.add(propertyName35.getTree());
<             COLON36=(Token)match(input,COLON,FOLLOW_COLON_in_nameValuePair3296);  
<             stream_COLON.add(COLON36);
< 
<             pushFollow(FOLLOW_assignmentExpression_in_nameValuePair3298);
<             assignmentExpression37=assignmentExpression();
< 
<             state._fsp--;
< 
<             stream_assignmentExpression.add(assignmentExpression37.getTree());
< 
< 
<             // AST REWRITE
<             // elements: assignmentExpression, propertyName
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 866:2: -> ^( NAMEDVALUE propertyName assignmentExpression )
<             {
<                 // JavaScript.g:866:5: ^( NAMEDVALUE propertyName assignmentExpression )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(NAMEDVALUE, "NAMEDVALUE"), root_1);
< 
<                 adaptor.addChild(root_1, stream_propertyName.nextTree());
<                 adaptor.addChild(root_1, stream_assignmentExpression.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "nameValuePair"
< 
<     public static class propertyName_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "propertyName"
<     // JavaScript.g:869:1: propertyName : ( Identifier | StringLiteral | numericLiteral );
<     public final JavaScriptParser.propertyName_return propertyName() throws RecognitionException {
<         JavaScriptParser.propertyName_return retval = new JavaScriptParser.propertyName_return();
<         retval.start = input.LT(1);
<         int propertyName_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier38=null;
<         Token StringLiteral39=null;
<         JavaScriptParser.numericLiteral_return numericLiteral40 = null;
< 
< 
<         MyAstNode Identifier38_tree=null;
<         MyAstNode StringLiteral39_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 14) ) { return retval; }
<             // JavaScript.g:870:2: ( Identifier | StringLiteral | numericLiteral )
<             int alt10=3;
<             switch ( input.LA(1) ) {
<             case Identifier:
<                 {
<                 alt10=1;
<                 }
<                 break;
<             case StringLiteral:
<                 {
<                 alt10=2;
<                 }
<                 break;
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt10=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 10, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt10) {
<                 case 1 :
<                     // JavaScript.g:870:4: Identifier
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     Identifier38=(Token)match(input,Identifier,FOLLOW_Identifier_in_propertyName3322); 
<                     Identifier38_tree = (MyAstNode)adaptor.create(Identifier38);
<                     adaptor.addChild(root_0, Identifier38_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:871:4: StringLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     StringLiteral39=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_propertyName3327); 
<                     StringLiteral39_tree = (MyAstNode)adaptor.create(StringLiteral39);
<                     adaptor.addChild(root_0, StringLiteral39_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:872:4: numericLiteral
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_numericLiteral_in_propertyName3332);
<                     numericLiteral40=numericLiteral();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, numericLiteral40.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "propertyName"
< 
<     public static class memberExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "memberExpression"
<     // JavaScript.g:884:1: memberExpression : ( primaryExpression | functionExpression | newExpression );
<     public final JavaScriptParser.memberExpression_return memberExpression() throws RecognitionException {
<         JavaScriptParser.memberExpression_return retval = new JavaScriptParser.memberExpression_return();
<         retval.start = input.LT(1);
<         int memberExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.primaryExpression_return primaryExpression41 = null;
< 
<         JavaScriptParser.functionExpression_return functionExpression42 = null;
< 
<         JavaScriptParser.newExpression_return newExpression43 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 15) ) { return retval; }
<             // JavaScript.g:885:2: ( primaryExpression | functionExpression | newExpression )
<             int alt11=3;
<             switch ( input.LA(1) ) {
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case THIS:
<             case LBRACE:
<             case LPAREN:
<             case LBRACK:
<             case Identifier:
<             case StringLiteral:
<             case RegularExpressionLiteral:
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt11=1;
<                 }
<                 break;
<             case FUNCTION:
<                 {
<                 alt11=2;
<                 }
<                 break;
<             case NEW:
<                 {
<                 alt11=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 11, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt11) {
<                 case 1 :
<                     // JavaScript.g:885:4: primaryExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_primaryExpression_in_memberExpression3350);
<                     primaryExpression41=primaryExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, primaryExpression41.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:886:4: functionExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_functionExpression_in_memberExpression3355);
<                     functionExpression42=functionExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, functionExpression42.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:887:4: newExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_newExpression_in_memberExpression3360);
<                     newExpression43=newExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, newExpression43.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "memberExpression"
< 
<     public static class newExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "newExpression"
<     // JavaScript.g:890:1: newExpression : ( NEW primaryExpression | NEW functionExpression );
<     public final JavaScriptParser.newExpression_return newExpression() throws RecognitionException {
<         JavaScriptParser.newExpression_return retval = new JavaScriptParser.newExpression_return();
<         retval.start = input.LT(1);
<         int newExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token NEW44=null;
<         Token NEW46=null;
<         JavaScriptParser.primaryExpression_return primaryExpression45 = null;
< 
<         JavaScriptParser.functionExpression_return functionExpression47 = null;
< 
< 
<         MyAstNode NEW44_tree=null;
<         MyAstNode NEW46_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 16) ) { return retval; }
<             // JavaScript.g:891:2: ( NEW primaryExpression | NEW functionExpression )
<             int alt12=2;
<             int LA12_0 = input.LA(1);
< 
<             if ( (LA12_0==NEW) ) {
<                 int LA12_1 = input.LA(2);
< 
<                 if ( (LA12_1==FUNCTION) ) {
<                     alt12=2;
<                 }
<                 else if ( ((LA12_1>=NULL && LA12_1<=FALSE)||LA12_1==THIS||LA12_1==LBRACE||LA12_1==LPAREN||LA12_1==LBRACK||(LA12_1>=Identifier && LA12_1<=StringLiteral)||LA12_1==RegularExpressionLiteral||(LA12_1>=DecimalLiteral && LA12_1<=HexIntegerLiteral)) ) {
<                     alt12=1;
<                 }
<                 else {
<                     NoViableAltException nvae =
<                         new NoViableAltException("", 12, 1, input);
< 
<                     throw nvae;
<                 }
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 12, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt12) {
<                 case 1 :
<                     // JavaScript.g:891:4: NEW primaryExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NEW44=(Token)match(input,NEW,FOLLOW_NEW_in_newExpression3371); 
<                     NEW44_tree = (MyAstNode)adaptor.create(NEW44);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(NEW44_tree, root_0);
< 
<                     pushFollow(FOLLOW_primaryExpression_in_newExpression3374);
<                     primaryExpression45=primaryExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, primaryExpression45.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:892:7: NEW functionExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NEW46=(Token)match(input,NEW,FOLLOW_NEW_in_newExpression3382); 
<                     NEW46_tree = (MyAstNode)adaptor.create(NEW46);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(NEW46_tree, root_0);
< 
<                     pushFollow(FOLLOW_functionExpression_in_newExpression3385);
<                     functionExpression47=functionExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, functionExpression47.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "newExpression"
< 
<     public static class arguments_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "arguments"
<     // JavaScript.g:896:1: arguments : LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN -> ^( ARGS ( assignmentExpression )* ) ;
<     public final JavaScriptParser.arguments_return arguments() throws RecognitionException {
<         JavaScriptParser.arguments_return retval = new JavaScriptParser.arguments_return();
<         retval.start = input.LT(1);
<         int arguments_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LPAREN48=null;
<         Token COMMA50=null;
<         Token RPAREN52=null;
<         JavaScriptParser.assignmentExpression_return assignmentExpression49 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression51 = null;
< 
< 
<         MyAstNode LPAREN48_tree=null;
<         MyAstNode COMMA50_tree=null;
<         MyAstNode RPAREN52_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 17) ) { return retval; }
<             // JavaScript.g:897:2: ( LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN -> ^( ARGS ( assignmentExpression )* ) )
<             // JavaScript.g:897:4: LPAREN ( assignmentExpression ( COMMA assignmentExpression )* )? RPAREN
<             {
<             LPAREN48=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_arguments3398);  
<             stream_LPAREN.add(LPAREN48);
< 
<             // JavaScript.g:897:11: ( assignmentExpression ( COMMA assignmentExpression )* )?
<             int alt14=2;
<             int LA14_0 = input.LA(1);
< 
<             if ( ((LA14_0>=NULL && LA14_0<=FALSE)||LA14_0==DELETE||LA14_0==FUNCTION||LA14_0==NEW||LA14_0==THIS||LA14_0==TYPEOF||LA14_0==VOID||LA14_0==LBRACE||LA14_0==LPAREN||LA14_0==LBRACK||(LA14_0>=ADD && LA14_0<=SUB)||(LA14_0>=INC && LA14_0<=DEC)||(LA14_0>=NOT && LA14_0<=INV)||(LA14_0>=Identifier && LA14_0<=StringLiteral)||LA14_0==RegularExpressionLiteral||(LA14_0>=DecimalLiteral && LA14_0<=HexIntegerLiteral)) ) {
<                 alt14=1;
<             }
<             switch (alt14) {
<                 case 1 :
<                     // JavaScript.g:897:13: assignmentExpression ( COMMA assignmentExpression )*
<                     {
<                     pushFollow(FOLLOW_assignmentExpression_in_arguments3402);
<                     assignmentExpression49=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     stream_assignmentExpression.add(assignmentExpression49.getTree());
<                     // JavaScript.g:897:34: ( COMMA assignmentExpression )*
<                     loop13:
<                     do {
<                         int alt13=2;
<                         int LA13_0 = input.LA(1);
< 
<                         if ( (LA13_0==COMMA) ) {
<                             alt13=1;
<                         }
< 
< 
<                         switch (alt13) {
<                     	case 1 :
<                     	    // JavaScript.g:897:36: COMMA assignmentExpression
<                     	    {
<                     	    COMMA50=(Token)match(input,COMMA,FOLLOW_COMMA_in_arguments3406);  
<                     	    stream_COMMA.add(COMMA50);
< 
<                     	    pushFollow(FOLLOW_assignmentExpression_in_arguments3408);
<                     	    assignmentExpression51=assignmentExpression();
< 
<                     	    state._fsp--;
< 
<                     	    stream_assignmentExpression.add(assignmentExpression51.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop13;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RPAREN52=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_arguments3416);  
<             stream_RPAREN.add(RPAREN52);
< 
< 
< 
<             // AST REWRITE
<             // elements: assignmentExpression
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 898:2: -> ^( ARGS ( assignmentExpression )* )
<             {
<                 // JavaScript.g:898:5: ^( ARGS ( assignmentExpression )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ARGS, "ARGS"), root_1);
< 
<                 // JavaScript.g:898:13: ( assignmentExpression )*
<                 while ( stream_assignmentExpression.hasNext() ) {
<                     adaptor.addChild(root_1, stream_assignmentExpression.nextTree());
< 
<                 }
<                 stream_assignmentExpression.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "arguments"
< 
<     public static class leftHandSideExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "leftHandSideExpression"
<     // JavaScript.g:901:1: leftHandSideExpression : ( memberExpression -> memberExpression ) ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )* ;
<     public final JavaScriptParser.leftHandSideExpression_return leftHandSideExpression() throws RecognitionException {
<         JavaScriptParser.leftHandSideExpression_return retval = new JavaScriptParser.leftHandSideExpression_return();
<         retval.start = input.LT(1);
<         int leftHandSideExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LBRACK55=null;
<         Token RBRACK57=null;
<         Token DOT58=null;
<         Token Identifier59=null;
<         JavaScriptParser.memberExpression_return memberExpression53 = null;
< 
<         JavaScriptParser.arguments_return arguments54 = null;
< 
<         JavaScriptParser.expression_return expression56 = null;
< 
< 
<         MyAstNode LBRACK55_tree=null;
<         MyAstNode RBRACK57_tree=null;
<         MyAstNode DOT58_tree=null;
<         MyAstNode Identifier59_tree=null;
<         RewriteRuleTokenStream stream_RBRACK=new RewriteRuleTokenStream(adaptor,"token RBRACK");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleTokenStream stream_LBRACK=new RewriteRuleTokenStream(adaptor,"token LBRACK");
<         RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
<         RewriteRuleSubtreeStream stream_arguments=new RewriteRuleSubtreeStream(adaptor,"rule arguments");
<         RewriteRuleSubtreeStream stream_memberExpression=new RewriteRuleSubtreeStream(adaptor,"rule memberExpression");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 18) ) { return retval; }
<             // JavaScript.g:902:2: ( ( memberExpression -> memberExpression ) ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )* )
<             // JavaScript.g:903:2: ( memberExpression -> memberExpression ) ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )*
<             {
<             // JavaScript.g:903:2: ( memberExpression -> memberExpression )
<             // JavaScript.g:904:3: memberExpression
<             {
<             pushFollow(FOLLOW_memberExpression_in_leftHandSideExpression3445);
<             memberExpression53=memberExpression();
< 
<             state._fsp--;
< 
<             stream_memberExpression.add(memberExpression53.getTree());
< 
< 
<             // AST REWRITE
<             // elements: memberExpression
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 904:22: -> memberExpression
<             {
<                 adaptor.addChild(root_0, stream_memberExpression.nextTree());
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             // JavaScript.g:906:2: ( arguments -> ^( CALL $leftHandSideExpression arguments ) | LBRACK expression RBRACK -> ^( BYINDEX $leftHandSideExpression expression ) | DOT Identifier -> ^( BYFIELD $leftHandSideExpression Identifier ) )*
<             loop15:
<             do {
<                 int alt15=4;
<                 switch ( input.LA(1) ) {
<                 case LPAREN:
<                     {
<                     alt15=1;
<                     }
<                     break;
<                 case LBRACK:
<                     {
<                     alt15=2;
<                     }
<                     break;
<                 case DOT:
<                     {
<                     alt15=3;
<                     }
<                     break;
< 
<                 }
< 
<                 switch (alt15) {
<             	case 1 :
<             	    // JavaScript.g:907:3: arguments
<             	    {
<             	    pushFollow(FOLLOW_arguments_in_leftHandSideExpression3461);
<             	    arguments54=arguments();
< 
<             	    state._fsp--;
< 
<             	    stream_arguments.add(arguments54.getTree());
< 
< 
<             	    // AST REWRITE
<             	    // elements: arguments, leftHandSideExpression
<             	    // token labels: 
<             	    // rule labels: retval
<             	    // token list labels: 
<             	    // rule list labels: 
<             	    retval.tree = root_0;
<             	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             	    root_0 = (MyAstNode)adaptor.nil();
<             	    // 907:15: -> ^( CALL $leftHandSideExpression arguments )
<             	    {
<             	        // JavaScript.g:907:18: ^( CALL $leftHandSideExpression arguments )
<             	        {
<             	        MyAstNode root_1 = (MyAstNode)adaptor.nil();
<             	        root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(CALL, "CALL"), root_1);
< 
<             	        adaptor.addChild(root_1, stream_retval.nextTree());
<             	        adaptor.addChild(root_1, stream_arguments.nextTree());
< 
<             	        adaptor.addChild(root_0, root_1);
<             	        }
< 
<             	    }
< 
<             	    retval.tree = root_0;
<             	    }
<             	    break;
<             	case 2 :
<             	    // JavaScript.g:908:5: LBRACK expression RBRACK
<             	    {
<             	    LBRACK55=(Token)match(input,LBRACK,FOLLOW_LBRACK_in_leftHandSideExpression3482);  
<             	    stream_LBRACK.add(LBRACK55);
< 
<             	    pushFollow(FOLLOW_expression_in_leftHandSideExpression3484);
<             	    expression56=expression();
< 
<             	    state._fsp--;
< 
<             	    stream_expression.add(expression56.getTree());
<             	    RBRACK57=(Token)match(input,RBRACK,FOLLOW_RBRACK_in_leftHandSideExpression3486);  
<             	    stream_RBRACK.add(RBRACK57);
< 
< 
< 
<             	    // AST REWRITE
<             	    // elements: expression, leftHandSideExpression
<             	    // token labels: 
<             	    // rule labels: retval
<             	    // token list labels: 
<             	    // rule list labels: 
<             	    retval.tree = root_0;
<             	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             	    root_0 = (MyAstNode)adaptor.nil();
<             	    // 908:30: -> ^( BYINDEX $leftHandSideExpression expression )
<             	    {
<             	        // JavaScript.g:908:33: ^( BYINDEX $leftHandSideExpression expression )
<             	        {
<             	        MyAstNode root_1 = (MyAstNode)adaptor.nil();
<             	        root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BYINDEX, "BYINDEX"), root_1);
< 
<             	        adaptor.addChild(root_1, stream_retval.nextTree());
<             	        adaptor.addChild(root_1, stream_expression.nextTree());
< 
<             	        adaptor.addChild(root_0, root_1);
<             	        }
< 
<             	    }
< 
<             	    retval.tree = root_0;
<             	    }
<             	    break;
<             	case 3 :
<             	    // JavaScript.g:909:5: DOT Identifier
<             	    {
<             	    DOT58=(Token)match(input,DOT,FOLLOW_DOT_in_leftHandSideExpression3505);  
<             	    stream_DOT.add(DOT58);
< 
<             	    Identifier59=(Token)match(input,Identifier,FOLLOW_Identifier_in_leftHandSideExpression3507);  
<             	    stream_Identifier.add(Identifier59);
< 
< 
< 
<             	    // AST REWRITE
<             	    // elements: Identifier, leftHandSideExpression
<             	    // token labels: 
<             	    // rule labels: retval
<             	    // token list labels: 
<             	    // rule list labels: 
<             	    retval.tree = root_0;
<             	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             	    root_0 = (MyAstNode)adaptor.nil();
<             	    // 909:21: -> ^( BYFIELD $leftHandSideExpression Identifier )
<             	    {
<             	        // JavaScript.g:909:24: ^( BYFIELD $leftHandSideExpression Identifier )
<             	        {
<             	        MyAstNode root_1 = (MyAstNode)adaptor.nil();
<             	        root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BYFIELD, "BYFIELD"), root_1);
< 
<             	        adaptor.addChild(root_1, stream_retval.nextTree());
<             	        adaptor.addChild(root_1, stream_Identifier.nextNode());
< 
<             	        adaptor.addChild(root_0, root_1);
<             	        }
< 
<             	    }
< 
<             	    retval.tree = root_0;
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop15;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "leftHandSideExpression"
< 
<     public static class postfixExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "postfixExpression"
<     // JavaScript.g:923:1: postfixExpression : leftHandSideExpression ( postfixOperator )? ;
<     public final JavaScriptParser.postfixExpression_return postfixExpression() throws RecognitionException {
<         JavaScriptParser.postfixExpression_return retval = new JavaScriptParser.postfixExpression_return();
<         retval.start = input.LT(1);
<         int postfixExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.leftHandSideExpression_return leftHandSideExpression60 = null;
< 
<         JavaScriptParser.postfixOperator_return postfixOperator61 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 19) ) { return retval; }
<             // JavaScript.g:924:2: ( leftHandSideExpression ( postfixOperator )? )
<             // JavaScript.g:924:4: leftHandSideExpression ( postfixOperator )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_leftHandSideExpression_in_postfixExpression3542);
<             leftHandSideExpression60=leftHandSideExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, leftHandSideExpression60.getTree());
<              if (input.LA(1) == INC || input.LA(1) == DEC) promoteEOL(null); 
<             // JavaScript.g:924:95: ( postfixOperator )?
<             int alt16=2;
<             int LA16_0 = input.LA(1);
< 
<             if ( ((LA16_0>=INC && LA16_0<=DEC)) ) {
<                 alt16=1;
<             }
<             switch (alt16) {
<                 case 1 :
<                     // JavaScript.g:924:97: postfixOperator
<                     {
<                     pushFollow(FOLLOW_postfixOperator_in_postfixExpression3548);
<                     postfixOperator61=postfixOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(postfixOperator61.getTree(), root_0);
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "postfixExpression"
< 
<     public static class postfixOperator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "postfixOperator"
<     // JavaScript.g:927:1: postfixOperator : (op= INC | op= DEC );
<     public final JavaScriptParser.postfixOperator_return postfixOperator() throws RecognitionException {
<         JavaScriptParser.postfixOperator_return retval = new JavaScriptParser.postfixOperator_return();
<         retval.start = input.LT(1);
<         int postfixOperator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token op=null;
< 
<         MyAstNode op_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 20) ) { return retval; }
<             // JavaScript.g:928:2: (op= INC | op= DEC )
<             int alt17=2;
<             int LA17_0 = input.LA(1);
< 
<             if ( (LA17_0==INC) ) {
<                 alt17=1;
<             }
<             else if ( (LA17_0==DEC) ) {
<                 alt17=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 17, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt17) {
<                 case 1 :
<                     // JavaScript.g:928:4: op= INC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,INC,FOLLOW_INC_in_postfixOperator3566); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(PINC); 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:929:4: op= DEC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,DEC,FOLLOW_DEC_in_postfixOperator3575); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(PDEC); 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "postfixOperator"
< 
<     public static class unaryExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "unaryExpression"
<     // JavaScript.g:936:1: unaryExpression : ( postfixExpression | unaryOperator unaryExpression );
<     public final JavaScriptParser.unaryExpression_return unaryExpression() throws RecognitionException {
<         JavaScriptParser.unaryExpression_return retval = new JavaScriptParser.unaryExpression_return();
<         retval.start = input.LT(1);
<         int unaryExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.postfixExpression_return postfixExpression62 = null;
< 
<         JavaScriptParser.unaryOperator_return unaryOperator63 = null;
< 
<         JavaScriptParser.unaryExpression_return unaryExpression64 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 21) ) { return retval; }
<             // JavaScript.g:937:2: ( postfixExpression | unaryOperator unaryExpression )
<             int alt18=2;
<             int LA18_0 = input.LA(1);
< 
<             if ( ((LA18_0>=NULL && LA18_0<=FALSE)||LA18_0==FUNCTION||LA18_0==NEW||LA18_0==THIS||LA18_0==LBRACE||LA18_0==LPAREN||LA18_0==LBRACK||(LA18_0>=Identifier && LA18_0<=StringLiteral)||LA18_0==RegularExpressionLiteral||(LA18_0>=DecimalLiteral && LA18_0<=HexIntegerLiteral)) ) {
<                 alt18=1;
<             }
<             else if ( (LA18_0==DELETE||LA18_0==TYPEOF||LA18_0==VOID||(LA18_0>=ADD && LA18_0<=SUB)||(LA18_0>=INC && LA18_0<=DEC)||(LA18_0>=NOT && LA18_0<=INV)) ) {
<                 alt18=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 18, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt18) {
<                 case 1 :
<                     // JavaScript.g:937:4: postfixExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_postfixExpression_in_unaryExpression3592);
<                     postfixExpression62=postfixExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, postfixExpression62.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:938:4: unaryOperator unaryExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_unaryOperator_in_unaryExpression3597);
<                     unaryOperator63=unaryOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(unaryOperator63.getTree(), root_0);
<                     pushFollow(FOLLOW_unaryExpression_in_unaryExpression3600);
<                     unaryExpression64=unaryExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, unaryExpression64.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "unaryExpression"
< 
<     public static class unaryOperator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "unaryOperator"
<     // JavaScript.g:941:1: unaryOperator : ( DELETE | VOID | TYPEOF | INC | DEC | op= ADD | op= SUB | INV | NOT );
<     public final JavaScriptParser.unaryOperator_return unaryOperator() throws RecognitionException {
<         JavaScriptParser.unaryOperator_return retval = new JavaScriptParser.unaryOperator_return();
<         retval.start = input.LT(1);
<         int unaryOperator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token op=null;
<         Token DELETE65=null;
<         Token VOID66=null;
<         Token TYPEOF67=null;
<         Token INC68=null;
<         Token DEC69=null;
<         Token INV70=null;
<         Token NOT71=null;
< 
<         MyAstNode op_tree=null;
<         MyAstNode DELETE65_tree=null;
<         MyAstNode VOID66_tree=null;
<         MyAstNode TYPEOF67_tree=null;
<         MyAstNode INC68_tree=null;
<         MyAstNode DEC69_tree=null;
<         MyAstNode INV70_tree=null;
<         MyAstNode NOT71_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 22) ) { return retval; }
<             // JavaScript.g:942:2: ( DELETE | VOID | TYPEOF | INC | DEC | op= ADD | op= SUB | INV | NOT )
<             int alt19=9;
<             switch ( input.LA(1) ) {
<             case DELETE:
<                 {
<                 alt19=1;
<                 }
<                 break;
<             case VOID:
<                 {
<                 alt19=2;
<                 }
<                 break;
<             case TYPEOF:
<                 {
<                 alt19=3;
<                 }
<                 break;
<             case INC:
<                 {
<                 alt19=4;
<                 }
<                 break;
<             case DEC:
<                 {
<                 alt19=5;
<                 }
<                 break;
<             case ADD:
<                 {
<                 alt19=6;
<                 }
<                 break;
<             case SUB:
<                 {
<                 alt19=7;
<                 }
<                 break;
<             case INV:
<                 {
<                 alt19=8;
<                 }
<                 break;
<             case NOT:
<                 {
<                 alt19=9;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 19, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt19) {
<                 case 1 :
<                     // JavaScript.g:942:4: DELETE
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     DELETE65=(Token)match(input,DELETE,FOLLOW_DELETE_in_unaryOperator3612); 
<                     DELETE65_tree = (MyAstNode)adaptor.create(DELETE65);
<                     adaptor.addChild(root_0, DELETE65_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:943:4: VOID
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     VOID66=(Token)match(input,VOID,FOLLOW_VOID_in_unaryOperator3617); 
<                     VOID66_tree = (MyAstNode)adaptor.create(VOID66);
<                     adaptor.addChild(root_0, VOID66_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:944:4: TYPEOF
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     TYPEOF67=(Token)match(input,TYPEOF,FOLLOW_TYPEOF_in_unaryOperator3622); 
<                     TYPEOF67_tree = (MyAstNode)adaptor.create(TYPEOF67);
<                     adaptor.addChild(root_0, TYPEOF67_tree);
< 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:945:4: INC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     INC68=(Token)match(input,INC,FOLLOW_INC_in_unaryOperator3627); 
<                     INC68_tree = (MyAstNode)adaptor.create(INC68);
<                     adaptor.addChild(root_0, INC68_tree);
< 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:946:4: DEC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     DEC69=(Token)match(input,DEC,FOLLOW_DEC_in_unaryOperator3632); 
<                     DEC69_tree = (MyAstNode)adaptor.create(DEC69);
<                     adaptor.addChild(root_0, DEC69_tree);
< 
< 
<                     }
<                     break;
<                 case 6 :
<                     // JavaScript.g:947:4: op= ADD
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,ADD,FOLLOW_ADD_in_unaryOperator3639); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(POS); 
< 
<                     }
<                     break;
<                 case 7 :
<                     // JavaScript.g:948:4: op= SUB
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     op=(Token)match(input,SUB,FOLLOW_SUB_in_unaryOperator3648); 
<                     op_tree = (MyAstNode)adaptor.create(op);
<                     adaptor.addChild(root_0, op_tree);
< 
<                      op.setType(NEG); 
< 
<                     }
<                     break;
<                 case 8 :
<                     // JavaScript.g:949:4: INV
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     INV70=(Token)match(input,INV,FOLLOW_INV_in_unaryOperator3655); 
<                     INV70_tree = (MyAstNode)adaptor.create(INV70);
<                     adaptor.addChild(root_0, INV70_tree);
< 
< 
<                     }
<                     break;
<                 case 9 :
<                     // JavaScript.g:950:4: NOT
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     NOT71=(Token)match(input,NOT,FOLLOW_NOT_in_unaryOperator3660); 
<                     NOT71_tree = (MyAstNode)adaptor.create(NOT71);
<                     adaptor.addChild(root_0, NOT71_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "unaryOperator"
< 
<     public static class multiplicativeExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "multiplicativeExpression"
<     // JavaScript.g:957:1: multiplicativeExpression : unaryExpression ( ( MUL | DIV | MOD ) unaryExpression )* ;
<     public final JavaScriptParser.multiplicativeExpression_return multiplicativeExpression() throws RecognitionException {
<         JavaScriptParser.multiplicativeExpression_return retval = new JavaScriptParser.multiplicativeExpression_return();
<         retval.start = input.LT(1);
<         int multiplicativeExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set73=null;
<         JavaScriptParser.unaryExpression_return unaryExpression72 = null;
< 
<         JavaScriptParser.unaryExpression_return unaryExpression74 = null;
< 
< 
<         MyAstNode set73_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 23) ) { return retval; }
<             // JavaScript.g:958:2: ( unaryExpression ( ( MUL | DIV | MOD ) unaryExpression )* )
<             // JavaScript.g:958:4: unaryExpression ( ( MUL | DIV | MOD ) unaryExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_unaryExpression_in_multiplicativeExpression3675);
<             unaryExpression72=unaryExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, unaryExpression72.getTree());
<             // JavaScript.g:958:20: ( ( MUL | DIV | MOD ) unaryExpression )*
<             loop20:
<             do {
<                 int alt20=2;
<                 int LA20_0 = input.LA(1);
< 
<                 if ( ((LA20_0>=MUL && LA20_0<=MOD)||LA20_0==DIV) ) {
<                     alt20=1;
<                 }
< 
< 
<                 switch (alt20) {
<             	case 1 :
<             	    // JavaScript.g:958:22: ( MUL | DIV | MOD ) unaryExpression
<             	    {
<             	    set73=(Token)input.LT(1);
<             	    set73=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=MUL && input.LA(1)<=MOD)||input.LA(1)==DIV ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set73), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_unaryExpression_in_multiplicativeExpression3694);
<             	    unaryExpression74=unaryExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, unaryExpression74.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop20;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "multiplicativeExpression"
< 
<     public static class additiveExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "additiveExpression"
<     // JavaScript.g:965:1: additiveExpression : multiplicativeExpression ( ( ADD | SUB ) multiplicativeExpression )* ;
<     public final JavaScriptParser.additiveExpression_return additiveExpression() throws RecognitionException {
<         JavaScriptParser.additiveExpression_return retval = new JavaScriptParser.additiveExpression_return();
<         retval.start = input.LT(1);
<         int additiveExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set76=null;
<         JavaScriptParser.multiplicativeExpression_return multiplicativeExpression75 = null;
< 
<         JavaScriptParser.multiplicativeExpression_return multiplicativeExpression77 = null;
< 
< 
<         MyAstNode set76_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 24) ) { return retval; }
<             // JavaScript.g:966:2: ( multiplicativeExpression ( ( ADD | SUB ) multiplicativeExpression )* )
<             // JavaScript.g:966:4: multiplicativeExpression ( ( ADD | SUB ) multiplicativeExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_multiplicativeExpression_in_additiveExpression3712);
<             multiplicativeExpression75=multiplicativeExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, multiplicativeExpression75.getTree());
<             // JavaScript.g:966:29: ( ( ADD | SUB ) multiplicativeExpression )*
<             loop21:
<             do {
<                 int alt21=2;
<                 int LA21_0 = input.LA(1);
< 
<                 if ( ((LA21_0>=ADD && LA21_0<=SUB)) ) {
<                     alt21=1;
<                 }
< 
< 
<                 switch (alt21) {
<             	case 1 :
<             	    // JavaScript.g:966:31: ( ADD | SUB ) multiplicativeExpression
<             	    {
<             	    set76=(Token)input.LT(1);
<             	    set76=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=ADD && input.LA(1)<=SUB) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set76), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_multiplicativeExpression_in_additiveExpression3727);
<             	    multiplicativeExpression77=multiplicativeExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, multiplicativeExpression77.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop21;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "additiveExpression"
< 
<     public static class shiftExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "shiftExpression"
<     // JavaScript.g:973:1: shiftExpression : additiveExpression ( ( SHL | SHR | SHU ) additiveExpression )* ;
<     public final JavaScriptParser.shiftExpression_return shiftExpression() throws RecognitionException {
<         JavaScriptParser.shiftExpression_return retval = new JavaScriptParser.shiftExpression_return();
<         retval.start = input.LT(1);
<         int shiftExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set79=null;
<         JavaScriptParser.additiveExpression_return additiveExpression78 = null;
< 
<         JavaScriptParser.additiveExpression_return additiveExpression80 = null;
< 
< 
<         MyAstNode set79_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 25) ) { return retval; }
<             // JavaScript.g:974:2: ( additiveExpression ( ( SHL | SHR | SHU ) additiveExpression )* )
<             // JavaScript.g:974:4: additiveExpression ( ( SHL | SHR | SHU ) additiveExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_additiveExpression_in_shiftExpression3746);
<             additiveExpression78=additiveExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, additiveExpression78.getTree());
<             // JavaScript.g:974:23: ( ( SHL | SHR | SHU ) additiveExpression )*
<             loop22:
<             do {
<                 int alt22=2;
<                 int LA22_0 = input.LA(1);
< 
<                 if ( ((LA22_0>=SHL && LA22_0<=SHU)) ) {
<                     alt22=1;
<                 }
< 
< 
<                 switch (alt22) {
<             	case 1 :
<             	    // JavaScript.g:974:25: ( SHL | SHR | SHU ) additiveExpression
<             	    {
<             	    set79=(Token)input.LT(1);
<             	    set79=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=SHL && input.LA(1)<=SHU) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set79), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_additiveExpression_in_shiftExpression3765);
<             	    additiveExpression80=additiveExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, additiveExpression80.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop22;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "shiftExpression"
< 
<     public static class relationalExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "relationalExpression"
<     // JavaScript.g:981:1: relationalExpression : shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )* ;
<     public final JavaScriptParser.relationalExpression_return relationalExpression() throws RecognitionException {
<         JavaScriptParser.relationalExpression_return retval = new JavaScriptParser.relationalExpression_return();
<         retval.start = input.LT(1);
<         int relationalExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set82=null;
<         JavaScriptParser.shiftExpression_return shiftExpression81 = null;
< 
<         JavaScriptParser.shiftExpression_return shiftExpression83 = null;
< 
< 
<         MyAstNode set82_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 26) ) { return retval; }
<             // JavaScript.g:982:2: ( shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )* )
<             // JavaScript.g:982:4: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_shiftExpression_in_relationalExpression3784);
<             shiftExpression81=shiftExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, shiftExpression81.getTree());
<             // JavaScript.g:982:20: ( ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression )*
<             loop23:
<             do {
<                 int alt23=2;
<                 int LA23_0 = input.LA(1);
< 
<                 if ( ((LA23_0>=IN && LA23_0<=INSTANCEOF)||(LA23_0>=LT && LA23_0<=GTE)) ) {
<                     alt23=1;
<                 }
< 
< 
<                 switch (alt23) {
<             	case 1 :
<             	    // JavaScript.g:982:22: ( LT | GT | LTE | GTE | INSTANCEOF | IN ) shiftExpression
<             	    {
<             	    set82=(Token)input.LT(1);
<             	    set82=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=IN && input.LA(1)<=INSTANCEOF)||(input.LA(1)>=LT && input.LA(1)<=GTE) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set82), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_shiftExpression_in_relationalExpression3815);
<             	    shiftExpression83=shiftExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, shiftExpression83.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop23;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "relationalExpression"
< 
<     public static class relationalExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "relationalExpressionNoIn"
<     // JavaScript.g:985:1: relationalExpressionNoIn : shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )* ;
<     public final JavaScriptParser.relationalExpressionNoIn_return relationalExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.relationalExpressionNoIn_return retval = new JavaScriptParser.relationalExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int relationalExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set85=null;
<         JavaScriptParser.shiftExpression_return shiftExpression84 = null;
< 
<         JavaScriptParser.shiftExpression_return shiftExpression86 = null;
< 
< 
<         MyAstNode set85_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 27) ) { return retval; }
<             // JavaScript.g:986:2: ( shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )* )
<             // JavaScript.g:986:4: shiftExpression ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_shiftExpression_in_relationalExpressionNoIn3829);
<             shiftExpression84=shiftExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, shiftExpression84.getTree());
<             // JavaScript.g:986:20: ( ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression )*
<             loop24:
<             do {
<                 int alt24=2;
<                 int LA24_0 = input.LA(1);
< 
<                 if ( (LA24_0==INSTANCEOF||(LA24_0>=LT && LA24_0<=GTE)) ) {
<                     alt24=1;
<                 }
< 
< 
<                 switch (alt24) {
<             	case 1 :
<             	    // JavaScript.g:986:22: ( LT | GT | LTE | GTE | INSTANCEOF ) shiftExpression
<             	    {
<             	    set85=(Token)input.LT(1);
<             	    set85=(Token)input.LT(1);
<             	    if ( input.LA(1)==INSTANCEOF||(input.LA(1)>=LT && input.LA(1)<=GTE) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set85), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_shiftExpression_in_relationalExpressionNoIn3856);
<             	    shiftExpression86=shiftExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, shiftExpression86.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop24;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "relationalExpressionNoIn"
< 
<     public static class equalityExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "equalityExpression"
<     // JavaScript.g:993:1: equalityExpression : relationalExpression ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )* ;
<     public final JavaScriptParser.equalityExpression_return equalityExpression() throws RecognitionException {
<         JavaScriptParser.equalityExpression_return retval = new JavaScriptParser.equalityExpression_return();
<         retval.start = input.LT(1);
<         int equalityExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set88=null;
<         JavaScriptParser.relationalExpression_return relationalExpression87 = null;
< 
<         JavaScriptParser.relationalExpression_return relationalExpression89 = null;
< 
< 
<         MyAstNode set88_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 28) ) { return retval; }
<             // JavaScript.g:994:2: ( relationalExpression ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )* )
<             // JavaScript.g:994:4: relationalExpression ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_relationalExpression_in_equalityExpression3875);
<             relationalExpression87=relationalExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, relationalExpression87.getTree());
<             // JavaScript.g:994:25: ( ( EQ | NEQ | SAME | NSAME ) relationalExpression )*
<             loop25:
<             do {
<                 int alt25=2;
<                 int LA25_0 = input.LA(1);
< 
<                 if ( ((LA25_0>=EQ && LA25_0<=NSAME)) ) {
<                     alt25=1;
<                 }
< 
< 
<                 switch (alt25) {
<             	case 1 :
<             	    // JavaScript.g:994:27: ( EQ | NEQ | SAME | NSAME ) relationalExpression
<             	    {
<             	    set88=(Token)input.LT(1);
<             	    set88=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=EQ && input.LA(1)<=NSAME) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set88), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_relationalExpression_in_equalityExpression3898);
<             	    relationalExpression89=relationalExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, relationalExpression89.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop25;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "equalityExpression"
< 
<     public static class equalityExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "equalityExpressionNoIn"
<     // JavaScript.g:997:1: equalityExpressionNoIn : relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )* ;
<     public final JavaScriptParser.equalityExpressionNoIn_return equalityExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.equalityExpressionNoIn_return retval = new JavaScriptParser.equalityExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int equalityExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set91=null;
<         JavaScriptParser.relationalExpressionNoIn_return relationalExpressionNoIn90 = null;
< 
<         JavaScriptParser.relationalExpressionNoIn_return relationalExpressionNoIn92 = null;
< 
< 
<         MyAstNode set91_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 29) ) { return retval; }
<             // JavaScript.g:998:2: ( relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )* )
<             // JavaScript.g:998:4: relationalExpressionNoIn ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3912);
<             relationalExpressionNoIn90=relationalExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, relationalExpressionNoIn90.getTree());
<             // JavaScript.g:998:29: ( ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn )*
<             loop26:
<             do {
<                 int alt26=2;
<                 int LA26_0 = input.LA(1);
< 
<                 if ( ((LA26_0>=EQ && LA26_0<=NSAME)) ) {
<                     alt26=1;
<                 }
< 
< 
<                 switch (alt26) {
<             	case 1 :
<             	    // JavaScript.g:998:31: ( EQ | NEQ | SAME | NSAME ) relationalExpressionNoIn
<             	    {
<             	    set91=(Token)input.LT(1);
<             	    set91=(Token)input.LT(1);
<             	    if ( (input.LA(1)>=EQ && input.LA(1)<=NSAME) ) {
<             	        input.consume();
<             	        root_0 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(set91), root_0);
<             	        state.errorRecovery=false;
<             	    }
<             	    else {
<             	        MismatchedSetException mse = new MismatchedSetException(null,input);
<             	        throw mse;
<             	    }
< 
<             	    pushFollow(FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3935);
<             	    relationalExpressionNoIn92=relationalExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, relationalExpressionNoIn92.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop26;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "equalityExpressionNoIn"
< 
<     public static class bitwiseANDExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseANDExpression"
<     // JavaScript.g:1005:1: bitwiseANDExpression : equalityExpression ( AND equalityExpression )* ;
<     public final JavaScriptParser.bitwiseANDExpression_return bitwiseANDExpression() throws RecognitionException {
<         JavaScriptParser.bitwiseANDExpression_return retval = new JavaScriptParser.bitwiseANDExpression_return();
<         retval.start = input.LT(1);
<         int bitwiseANDExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token AND94=null;
<         JavaScriptParser.equalityExpression_return equalityExpression93 = null;
< 
<         JavaScriptParser.equalityExpression_return equalityExpression95 = null;
< 
< 
<         MyAstNode AND94_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 30) ) { return retval; }
<             // JavaScript.g:1006:2: ( equalityExpression ( AND equalityExpression )* )
<             // JavaScript.g:1006:4: equalityExpression ( AND equalityExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_equalityExpression_in_bitwiseANDExpression3955);
<             equalityExpression93=equalityExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, equalityExpression93.getTree());
<             // JavaScript.g:1006:23: ( AND equalityExpression )*
<             loop27:
<             do {
<                 int alt27=2;
<                 int LA27_0 = input.LA(1);
< 
<                 if ( (LA27_0==AND) ) {
<                     alt27=1;
<                 }
< 
< 
<                 switch (alt27) {
<             	case 1 :
<             	    // JavaScript.g:1006:25: AND equalityExpression
<             	    {
<             	    AND94=(Token)match(input,AND,FOLLOW_AND_in_bitwiseANDExpression3959); 
<             	    AND94_tree = (MyAstNode)adaptor.create(AND94);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(AND94_tree, root_0);
< 
<             	    pushFollow(FOLLOW_equalityExpression_in_bitwiseANDExpression3962);
<             	    equalityExpression95=equalityExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, equalityExpression95.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop27;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseANDExpression"
< 
<     public static class bitwiseANDExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseANDExpressionNoIn"
<     // JavaScript.g:1009:1: bitwiseANDExpressionNoIn : equalityExpressionNoIn ( AND equalityExpressionNoIn )* ;
<     public final JavaScriptParser.bitwiseANDExpressionNoIn_return bitwiseANDExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.bitwiseANDExpressionNoIn_return retval = new JavaScriptParser.bitwiseANDExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int bitwiseANDExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token AND97=null;
<         JavaScriptParser.equalityExpressionNoIn_return equalityExpressionNoIn96 = null;
< 
<         JavaScriptParser.equalityExpressionNoIn_return equalityExpressionNoIn98 = null;
< 
< 
<         MyAstNode AND97_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 31) ) { return retval; }
<             // JavaScript.g:1010:2: ( equalityExpressionNoIn ( AND equalityExpressionNoIn )* )
<             // JavaScript.g:1010:4: equalityExpressionNoIn ( AND equalityExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3976);
<             equalityExpressionNoIn96=equalityExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, equalityExpressionNoIn96.getTree());
<             // JavaScript.g:1010:27: ( AND equalityExpressionNoIn )*
<             loop28:
<             do {
<                 int alt28=2;
<                 int LA28_0 = input.LA(1);
< 
<                 if ( (LA28_0==AND) ) {
<                     alt28=1;
<                 }
< 
< 
<                 switch (alt28) {
<             	case 1 :
<             	    // JavaScript.g:1010:29: AND equalityExpressionNoIn
<             	    {
<             	    AND97=(Token)match(input,AND,FOLLOW_AND_in_bitwiseANDExpressionNoIn3980); 
<             	    AND97_tree = (MyAstNode)adaptor.create(AND97);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(AND97_tree, root_0);
< 
<             	    pushFollow(FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3983);
<             	    equalityExpressionNoIn98=equalityExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, equalityExpressionNoIn98.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop28;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseANDExpressionNoIn"
< 
<     public static class bitwiseXORExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseXORExpression"
<     // JavaScript.g:1013:1: bitwiseXORExpression : bitwiseANDExpression ( XOR bitwiseANDExpression )* ;
<     public final JavaScriptParser.bitwiseXORExpression_return bitwiseXORExpression() throws RecognitionException {
<         JavaScriptParser.bitwiseXORExpression_return retval = new JavaScriptParser.bitwiseXORExpression_return();
<         retval.start = input.LT(1);
<         int bitwiseXORExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token XOR100=null;
<         JavaScriptParser.bitwiseANDExpression_return bitwiseANDExpression99 = null;
< 
<         JavaScriptParser.bitwiseANDExpression_return bitwiseANDExpression101 = null;
< 
< 
<         MyAstNode XOR100_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 32) ) { return retval; }
<             // JavaScript.g:1014:2: ( bitwiseANDExpression ( XOR bitwiseANDExpression )* )
<             // JavaScript.g:1014:4: bitwiseANDExpression ( XOR bitwiseANDExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression3999);
<             bitwiseANDExpression99=bitwiseANDExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseANDExpression99.getTree());
<             // JavaScript.g:1014:25: ( XOR bitwiseANDExpression )*
<             loop29:
<             do {
<                 int alt29=2;
<                 int LA29_0 = input.LA(1);
< 
<                 if ( (LA29_0==XOR) ) {
<                     alt29=1;
<                 }
< 
< 
<                 switch (alt29) {
<             	case 1 :
<             	    // JavaScript.g:1014:27: XOR bitwiseANDExpression
<             	    {
<             	    XOR100=(Token)match(input,XOR,FOLLOW_XOR_in_bitwiseXORExpression4003); 
<             	    XOR100_tree = (MyAstNode)adaptor.create(XOR100);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(XOR100_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression4006);
<             	    bitwiseANDExpression101=bitwiseANDExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseANDExpression101.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop29;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseXORExpression"
< 
<     public static class bitwiseXORExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseXORExpressionNoIn"
<     // JavaScript.g:1017:1: bitwiseXORExpressionNoIn : bitwiseANDExpressionNoIn ( XOR bitwiseANDExpressionNoIn )* ;
<     public final JavaScriptParser.bitwiseXORExpressionNoIn_return bitwiseXORExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.bitwiseXORExpressionNoIn_return retval = new JavaScriptParser.bitwiseXORExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int bitwiseXORExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token XOR103=null;
<         JavaScriptParser.bitwiseANDExpressionNoIn_return bitwiseANDExpressionNoIn102 = null;
< 
<         JavaScriptParser.bitwiseANDExpressionNoIn_return bitwiseANDExpressionNoIn104 = null;
< 
< 
<         MyAstNode XOR103_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 33) ) { return retval; }
<             // JavaScript.g:1018:2: ( bitwiseANDExpressionNoIn ( XOR bitwiseANDExpressionNoIn )* )
<             // JavaScript.g:1018:4: bitwiseANDExpressionNoIn ( XOR bitwiseANDExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4022);
<             bitwiseANDExpressionNoIn102=bitwiseANDExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseANDExpressionNoIn102.getTree());
<             // JavaScript.g:1018:29: ( XOR bitwiseANDExpressionNoIn )*
<             loop30:
<             do {
<                 int alt30=2;
<                 int LA30_0 = input.LA(1);
< 
<                 if ( (LA30_0==XOR) ) {
<                     alt30=1;
<                 }
< 
< 
<                 switch (alt30) {
<             	case 1 :
<             	    // JavaScript.g:1018:31: XOR bitwiseANDExpressionNoIn
<             	    {
<             	    XOR103=(Token)match(input,XOR,FOLLOW_XOR_in_bitwiseXORExpressionNoIn4026); 
<             	    XOR103_tree = (MyAstNode)adaptor.create(XOR103);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(XOR103_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4029);
<             	    bitwiseANDExpressionNoIn104=bitwiseANDExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseANDExpressionNoIn104.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop30;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseXORExpressionNoIn"
< 
<     public static class bitwiseORExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseORExpression"
<     // JavaScript.g:1021:1: bitwiseORExpression : bitwiseXORExpression ( OR bitwiseXORExpression )* ;
<     public final JavaScriptParser.bitwiseORExpression_return bitwiseORExpression() throws RecognitionException {
<         JavaScriptParser.bitwiseORExpression_return retval = new JavaScriptParser.bitwiseORExpression_return();
<         retval.start = input.LT(1);
<         int bitwiseORExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token OR106=null;
<         JavaScriptParser.bitwiseXORExpression_return bitwiseXORExpression105 = null;
< 
<         JavaScriptParser.bitwiseXORExpression_return bitwiseXORExpression107 = null;
< 
< 
<         MyAstNode OR106_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 34) ) { return retval; }
<             // JavaScript.g:1022:2: ( bitwiseXORExpression ( OR bitwiseXORExpression )* )
<             // JavaScript.g:1022:4: bitwiseXORExpression ( OR bitwiseXORExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4044);
<             bitwiseXORExpression105=bitwiseXORExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseXORExpression105.getTree());
<             // JavaScript.g:1022:25: ( OR bitwiseXORExpression )*
<             loop31:
<             do {
<                 int alt31=2;
<                 int LA31_0 = input.LA(1);
< 
<                 if ( (LA31_0==OR) ) {
<                     alt31=1;
<                 }
< 
< 
<                 switch (alt31) {
<             	case 1 :
<             	    // JavaScript.g:1022:27: OR bitwiseXORExpression
<             	    {
<             	    OR106=(Token)match(input,OR,FOLLOW_OR_in_bitwiseORExpression4048); 
<             	    OR106_tree = (MyAstNode)adaptor.create(OR106);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(OR106_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4051);
<             	    bitwiseXORExpression107=bitwiseXORExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseXORExpression107.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop31;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseORExpression"
< 
<     public static class bitwiseORExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "bitwiseORExpressionNoIn"
<     // JavaScript.g:1025:1: bitwiseORExpressionNoIn : bitwiseXORExpressionNoIn ( OR bitwiseXORExpressionNoIn )* ;
<     public final JavaScriptParser.bitwiseORExpressionNoIn_return bitwiseORExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.bitwiseORExpressionNoIn_return retval = new JavaScriptParser.bitwiseORExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int bitwiseORExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token OR109=null;
<         JavaScriptParser.bitwiseXORExpressionNoIn_return bitwiseXORExpressionNoIn108 = null;
< 
<         JavaScriptParser.bitwiseXORExpressionNoIn_return bitwiseXORExpressionNoIn110 = null;
< 
< 
<         MyAstNode OR109_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 35) ) { return retval; }
<             // JavaScript.g:1026:2: ( bitwiseXORExpressionNoIn ( OR bitwiseXORExpressionNoIn )* )
<             // JavaScript.g:1026:4: bitwiseXORExpressionNoIn ( OR bitwiseXORExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4066);
<             bitwiseXORExpressionNoIn108=bitwiseXORExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseXORExpressionNoIn108.getTree());
<             // JavaScript.g:1026:29: ( OR bitwiseXORExpressionNoIn )*
<             loop32:
<             do {
<                 int alt32=2;
<                 int LA32_0 = input.LA(1);
< 
<                 if ( (LA32_0==OR) ) {
<                     alt32=1;
<                 }
< 
< 
<                 switch (alt32) {
<             	case 1 :
<             	    // JavaScript.g:1026:31: OR bitwiseXORExpressionNoIn
<             	    {
<             	    OR109=(Token)match(input,OR,FOLLOW_OR_in_bitwiseORExpressionNoIn4070); 
<             	    OR109_tree = (MyAstNode)adaptor.create(OR109);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(OR109_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4073);
<             	    bitwiseXORExpressionNoIn110=bitwiseXORExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseXORExpressionNoIn110.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop32;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "bitwiseORExpressionNoIn"
< 
<     public static class logicalANDExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalANDExpression"
<     // JavaScript.g:1033:1: logicalANDExpression : bitwiseORExpression ( LAND bitwiseORExpression )* ;
<     public final JavaScriptParser.logicalANDExpression_return logicalANDExpression() throws RecognitionException {
<         JavaScriptParser.logicalANDExpression_return retval = new JavaScriptParser.logicalANDExpression_return();
<         retval.start = input.LT(1);
<         int logicalANDExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LAND112=null;
<         JavaScriptParser.bitwiseORExpression_return bitwiseORExpression111 = null;
< 
<         JavaScriptParser.bitwiseORExpression_return bitwiseORExpression113 = null;
< 
< 
<         MyAstNode LAND112_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 36) ) { return retval; }
<             // JavaScript.g:1034:2: ( bitwiseORExpression ( LAND bitwiseORExpression )* )
<             // JavaScript.g:1034:4: bitwiseORExpression ( LAND bitwiseORExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseORExpression_in_logicalANDExpression4092);
<             bitwiseORExpression111=bitwiseORExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseORExpression111.getTree());
<             // JavaScript.g:1034:24: ( LAND bitwiseORExpression )*
<             loop33:
<             do {
<                 int alt33=2;
<                 int LA33_0 = input.LA(1);
< 
<                 if ( (LA33_0==LAND) ) {
<                     alt33=1;
<                 }
< 
< 
<                 switch (alt33) {
<             	case 1 :
<             	    // JavaScript.g:1034:26: LAND bitwiseORExpression
<             	    {
<             	    LAND112=(Token)match(input,LAND,FOLLOW_LAND_in_logicalANDExpression4096); 
<             	    LAND112_tree = (MyAstNode)adaptor.create(LAND112);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LAND112_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseORExpression_in_logicalANDExpression4099);
<             	    bitwiseORExpression113=bitwiseORExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseORExpression113.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop33;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalANDExpression"
< 
<     public static class logicalANDExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalANDExpressionNoIn"
<     // JavaScript.g:1037:1: logicalANDExpressionNoIn : bitwiseORExpressionNoIn ( LAND bitwiseORExpressionNoIn )* ;
<     public final JavaScriptParser.logicalANDExpressionNoIn_return logicalANDExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.logicalANDExpressionNoIn_return retval = new JavaScriptParser.logicalANDExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int logicalANDExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LAND115=null;
<         JavaScriptParser.bitwiseORExpressionNoIn_return bitwiseORExpressionNoIn114 = null;
< 
<         JavaScriptParser.bitwiseORExpressionNoIn_return bitwiseORExpressionNoIn116 = null;
< 
< 
<         MyAstNode LAND115_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 37) ) { return retval; }
<             // JavaScript.g:1038:2: ( bitwiseORExpressionNoIn ( LAND bitwiseORExpressionNoIn )* )
<             // JavaScript.g:1038:4: bitwiseORExpressionNoIn ( LAND bitwiseORExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4113);
<             bitwiseORExpressionNoIn114=bitwiseORExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, bitwiseORExpressionNoIn114.getTree());
<             // JavaScript.g:1038:28: ( LAND bitwiseORExpressionNoIn )*
<             loop34:
<             do {
<                 int alt34=2;
<                 int LA34_0 = input.LA(1);
< 
<                 if ( (LA34_0==LAND) ) {
<                     alt34=1;
<                 }
< 
< 
<                 switch (alt34) {
<             	case 1 :
<             	    // JavaScript.g:1038:30: LAND bitwiseORExpressionNoIn
<             	    {
<             	    LAND115=(Token)match(input,LAND,FOLLOW_LAND_in_logicalANDExpressionNoIn4117); 
<             	    LAND115_tree = (MyAstNode)adaptor.create(LAND115);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LAND115_tree, root_0);
< 
<             	    pushFollow(FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4120);
<             	    bitwiseORExpressionNoIn116=bitwiseORExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, bitwiseORExpressionNoIn116.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop34;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalANDExpressionNoIn"
< 
<     public static class logicalORExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalORExpression"
<     // JavaScript.g:1041:1: logicalORExpression : logicalANDExpression ( LOR logicalANDExpression )* ;
<     public final JavaScriptParser.logicalORExpression_return logicalORExpression() throws RecognitionException {
<         JavaScriptParser.logicalORExpression_return retval = new JavaScriptParser.logicalORExpression_return();
<         retval.start = input.LT(1);
<         int logicalORExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LOR118=null;
<         JavaScriptParser.logicalANDExpression_return logicalANDExpression117 = null;
< 
<         JavaScriptParser.logicalANDExpression_return logicalANDExpression119 = null;
< 
< 
<         MyAstNode LOR118_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 38) ) { return retval; }
<             // JavaScript.g:1042:2: ( logicalANDExpression ( LOR logicalANDExpression )* )
<             // JavaScript.g:1042:4: logicalANDExpression ( LOR logicalANDExpression )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalANDExpression_in_logicalORExpression4135);
<             logicalANDExpression117=logicalANDExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalANDExpression117.getTree());
<             // JavaScript.g:1042:25: ( LOR logicalANDExpression )*
<             loop35:
<             do {
<                 int alt35=2;
<                 int LA35_0 = input.LA(1);
< 
<                 if ( (LA35_0==LOR) ) {
<                     alt35=1;
<                 }
< 
< 
<                 switch (alt35) {
<             	case 1 :
<             	    // JavaScript.g:1042:27: LOR logicalANDExpression
<             	    {
<             	    LOR118=(Token)match(input,LOR,FOLLOW_LOR_in_logicalORExpression4139); 
<             	    LOR118_tree = (MyAstNode)adaptor.create(LOR118);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LOR118_tree, root_0);
< 
<             	    pushFollow(FOLLOW_logicalANDExpression_in_logicalORExpression4142);
<             	    logicalANDExpression119=logicalANDExpression();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, logicalANDExpression119.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop35;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalORExpression"
< 
<     public static class logicalORExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "logicalORExpressionNoIn"
<     // JavaScript.g:1045:1: logicalORExpressionNoIn : logicalANDExpressionNoIn ( LOR logicalANDExpressionNoIn )* ;
<     public final JavaScriptParser.logicalORExpressionNoIn_return logicalORExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.logicalORExpressionNoIn_return retval = new JavaScriptParser.logicalORExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int logicalORExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LOR121=null;
<         JavaScriptParser.logicalANDExpressionNoIn_return logicalANDExpressionNoIn120 = null;
< 
<         JavaScriptParser.logicalANDExpressionNoIn_return logicalANDExpressionNoIn122 = null;
< 
< 
<         MyAstNode LOR121_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 39) ) { return retval; }
<             // JavaScript.g:1046:2: ( logicalANDExpressionNoIn ( LOR logicalANDExpressionNoIn )* )
<             // JavaScript.g:1046:4: logicalANDExpressionNoIn ( LOR logicalANDExpressionNoIn )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4157);
<             logicalANDExpressionNoIn120=logicalANDExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalANDExpressionNoIn120.getTree());
<             // JavaScript.g:1046:29: ( LOR logicalANDExpressionNoIn )*
<             loop36:
<             do {
<                 int alt36=2;
<                 int LA36_0 = input.LA(1);
< 
<                 if ( (LA36_0==LOR) ) {
<                     alt36=1;
<                 }
< 
< 
<                 switch (alt36) {
<             	case 1 :
<             	    // JavaScript.g:1046:31: LOR logicalANDExpressionNoIn
<             	    {
<             	    LOR121=(Token)match(input,LOR,FOLLOW_LOR_in_logicalORExpressionNoIn4161); 
<             	    LOR121_tree = (MyAstNode)adaptor.create(LOR121);
<             	    root_0 = (MyAstNode)adaptor.becomeRoot(LOR121_tree, root_0);
< 
<             	    pushFollow(FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4164);
<             	    logicalANDExpressionNoIn122=logicalANDExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, logicalANDExpressionNoIn122.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop36;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "logicalORExpressionNoIn"
< 
<     public static class conditionalExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "conditionalExpression"
<     // JavaScript.g:1053:1: conditionalExpression : logicalORExpression ( QUE assignmentExpression COLON assignmentExpression )? ;
<     public final JavaScriptParser.conditionalExpression_return conditionalExpression() throws RecognitionException {
<         JavaScriptParser.conditionalExpression_return retval = new JavaScriptParser.conditionalExpression_return();
<         retval.start = input.LT(1);
<         int conditionalExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token QUE124=null;
<         Token COLON126=null;
<         JavaScriptParser.logicalORExpression_return logicalORExpression123 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression125 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression127 = null;
< 
< 
<         MyAstNode QUE124_tree=null;
<         MyAstNode COLON126_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 40) ) { return retval; }
<             // JavaScript.g:1054:2: ( logicalORExpression ( QUE assignmentExpression COLON assignmentExpression )? )
<             // JavaScript.g:1054:4: logicalORExpression ( QUE assignmentExpression COLON assignmentExpression )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalORExpression_in_conditionalExpression4183);
<             logicalORExpression123=logicalORExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalORExpression123.getTree());
<             // JavaScript.g:1054:24: ( QUE assignmentExpression COLON assignmentExpression )?
<             int alt37=2;
<             int LA37_0 = input.LA(1);
< 
<             if ( (LA37_0==QUE) ) {
<                 alt37=1;
<             }
<             switch (alt37) {
<                 case 1 :
<                     // JavaScript.g:1054:26: QUE assignmentExpression COLON assignmentExpression
<                     {
<                     QUE124=(Token)match(input,QUE,FOLLOW_QUE_in_conditionalExpression4187); 
<                     QUE124_tree = (MyAstNode)adaptor.create(QUE124);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(QUE124_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpression_in_conditionalExpression4190);
<                     assignmentExpression125=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression125.getTree());
<                     COLON126=(Token)match(input,COLON,FOLLOW_COLON_in_conditionalExpression4192); 
<                     pushFollow(FOLLOW_assignmentExpression_in_conditionalExpression4195);
<                     assignmentExpression127=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression127.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "conditionalExpression"
< 
<     public static class conditionalExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "conditionalExpressionNoIn"
<     // JavaScript.g:1057:1: conditionalExpressionNoIn : logicalORExpressionNoIn ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )? ;
<     public final JavaScriptParser.conditionalExpressionNoIn_return conditionalExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.conditionalExpressionNoIn_return retval = new JavaScriptParser.conditionalExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int conditionalExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token QUE129=null;
<         Token COLON131=null;
<         JavaScriptParser.logicalORExpressionNoIn_return logicalORExpressionNoIn128 = null;
< 
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn130 = null;
< 
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn132 = null;
< 
< 
<         MyAstNode QUE129_tree=null;
<         MyAstNode COLON131_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 41) ) { return retval; }
<             // JavaScript.g:1058:2: ( logicalORExpressionNoIn ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )? )
<             // JavaScript.g:1058:4: logicalORExpressionNoIn ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_logicalORExpressionNoIn_in_conditionalExpressionNoIn4209);
<             logicalORExpressionNoIn128=logicalORExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, logicalORExpressionNoIn128.getTree());
<             // JavaScript.g:1058:28: ( QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn )?
<             int alt38=2;
<             int LA38_0 = input.LA(1);
< 
<             if ( (LA38_0==QUE) ) {
<                 alt38=1;
<             }
<             switch (alt38) {
<                 case 1 :
<                     // JavaScript.g:1058:30: QUE assignmentExpressionNoIn COLON assignmentExpressionNoIn
<                     {
<                     QUE129=(Token)match(input,QUE,FOLLOW_QUE_in_conditionalExpressionNoIn4213); 
<                     QUE129_tree = (MyAstNode)adaptor.create(QUE129);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(QUE129_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4216);
<                     assignmentExpressionNoIn130=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn130.getTree());
<                     COLON131=(Token)match(input,COLON,FOLLOW_COLON_in_conditionalExpressionNoIn4218); 
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4221);
<                     assignmentExpressionNoIn132=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn132.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "conditionalExpressionNoIn"
< 
<     public static class assignmentExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "assignmentExpression"
<     // JavaScript.g:1087:1: assignmentExpression : lhs= conditionalExpression ({...}? assignmentOperator assignmentExpression )? ;
<     public final JavaScriptParser.assignmentExpression_return assignmentExpression() throws RecognitionException {
<         JavaScriptParser.assignmentExpression_return retval = new JavaScriptParser.assignmentExpression_return();
<         retval.start = input.LT(1);
<         int assignmentExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.conditionalExpression_return lhs = null;
< 
<         JavaScriptParser.assignmentOperator_return assignmentOperator133 = null;
< 
<         JavaScriptParser.assignmentExpression_return assignmentExpression134 = null;
< 
< 
< 
< 
<         	Object[] isLhs = new Object[1];
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 42) ) { return retval; }
<             // JavaScript.g:1092:2: (lhs= conditionalExpression ({...}? assignmentOperator assignmentExpression )? )
<             // JavaScript.g:1092:4: lhs= conditionalExpression ({...}? assignmentOperator assignmentExpression )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_conditionalExpression_in_assignmentExpression4249);
<             lhs=conditionalExpression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, lhs.getTree());
<             // JavaScript.g:1093:2: ({...}? assignmentOperator assignmentExpression )?
<             int alt39=2;
<             int LA39_0 = input.LA(1);
< 
<             if ( ((LA39_0>=ASSIGN && LA39_0<=XORASS)||LA39_0==DIVASS) ) {
<                 int LA39_1 = input.LA(2);
< 
<                 if ( (( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                     alt39=1;
<                 }
<             }
<             switch (alt39) {
<                 case 1 :
<                     // JavaScript.g:1093:4: {...}? assignmentOperator assignmentExpression
<                     {
<                     if ( !(( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                         throw new FailedPredicateException(input, "assignmentExpression", " isLeftHandSideAssign(lhs, isLhs) ");
<                     }
<                     pushFollow(FOLLOW_assignmentOperator_in_assignmentExpression4256);
<                     assignmentOperator133=assignmentOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(assignmentOperator133.getTree(), root_0);
<                     pushFollow(FOLLOW_assignmentExpression_in_assignmentExpression4259);
<                     assignmentExpression134=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression134.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "assignmentExpression"
< 
<     public static class assignmentOperator_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "assignmentOperator"
<     // JavaScript.g:1096:1: assignmentOperator : ( ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS );
<     public final JavaScriptParser.assignmentOperator_return assignmentOperator() throws RecognitionException {
<         JavaScriptParser.assignmentOperator_return retval = new JavaScriptParser.assignmentOperator_return();
<         retval.start = input.LT(1);
<         int assignmentOperator_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token set135=null;
< 
<         MyAstNode set135_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 43) ) { return retval; }
<             // JavaScript.g:1097:2: ( ASSIGN | MULASS | DIVASS | MODASS | ADDASS | SUBASS | SHLASS | SHRASS | SHUASS | ANDASS | XORASS | ORASS )
<             // JavaScript.g:
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             set135=(Token)input.LT(1);
<             if ( (input.LA(1)>=ASSIGN && input.LA(1)<=XORASS)||input.LA(1)==DIVASS ) {
<                 input.consume();
<                 adaptor.addChild(root_0, (MyAstNode)adaptor.create(set135));
<                 state.errorRecovery=false;
<             }
<             else {
<                 MismatchedSetException mse = new MismatchedSetException(null,input);
<                 throw mse;
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "assignmentOperator"
< 
<     public static class assignmentExpressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "assignmentExpressionNoIn"
<     // JavaScript.g:1100:1: assignmentExpressionNoIn : lhs= conditionalExpressionNoIn ({...}? assignmentOperator assignmentExpressionNoIn )? ;
<     public final JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn() throws RecognitionException {
<         JavaScriptParser.assignmentExpressionNoIn_return retval = new JavaScriptParser.assignmentExpressionNoIn_return();
<         retval.start = input.LT(1);
<         int assignmentExpressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.conditionalExpressionNoIn_return lhs = null;
< 
<         JavaScriptParser.assignmentOperator_return assignmentOperator136 = null;
< 
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn137 = null;
< 
< 
< 
< 
<         	Object[] isLhs = new Object[1];
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 44) ) { return retval; }
<             // JavaScript.g:1105:2: (lhs= conditionalExpressionNoIn ({...}? assignmentOperator assignmentExpressionNoIn )? )
<             // JavaScript.g:1105:4: lhs= conditionalExpressionNoIn ({...}? assignmentOperator assignmentExpressionNoIn )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_conditionalExpressionNoIn_in_assignmentExpressionNoIn4336);
<             lhs=conditionalExpressionNoIn();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, lhs.getTree());
<             // JavaScript.g:1106:2: ({...}? assignmentOperator assignmentExpressionNoIn )?
<             int alt40=2;
<             int LA40_0 = input.LA(1);
< 
<             if ( ((LA40_0>=ASSIGN && LA40_0<=XORASS)||LA40_0==DIVASS) ) {
<                 int LA40_1 = input.LA(2);
< 
<                 if ( (( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                     alt40=1;
<                 }
<             }
<             switch (alt40) {
<                 case 1 :
<                     // JavaScript.g:1106:4: {...}? assignmentOperator assignmentExpressionNoIn
<                     {
<                     if ( !(( isLeftHandSideAssign(lhs, isLhs) )) ) {
<                         throw new FailedPredicateException(input, "assignmentExpressionNoIn", " isLeftHandSideAssign(lhs, isLhs) ");
<                     }
<                     pushFollow(FOLLOW_assignmentOperator_in_assignmentExpressionNoIn4343);
<                     assignmentOperator136=assignmentOperator();
< 
<                     state._fsp--;
< 
<                     root_0 = (MyAstNode)adaptor.becomeRoot(assignmentOperator136.getTree(), root_0);
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_assignmentExpressionNoIn4346);
<                     assignmentExpressionNoIn137=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn137.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "assignmentExpressionNoIn"
< 
<     public static class expression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "expression"
<     // JavaScript.g:1113:1: expression : exprs+= assignmentExpression ( COMMA exprs+= assignmentExpression )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs;
<     public final JavaScriptParser.expression_return expression() throws RecognitionException {
<         JavaScriptParser.expression_return retval = new JavaScriptParser.expression_return();
<         retval.start = input.LT(1);
<         int expression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token COMMA138=null;
<         List list_exprs=null;
<         RuleReturnScope exprs = null;
<         MyAstNode COMMA138_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleSubtreeStream stream_assignmentExpression=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 45) ) { return retval; }
<             // JavaScript.g:1114:2: (exprs+= assignmentExpression ( COMMA exprs+= assignmentExpression )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs)
<             // JavaScript.g:1114:4: exprs+= assignmentExpression ( COMMA exprs+= assignmentExpression )*
<             {
<             pushFollow(FOLLOW_assignmentExpression_in_expression4368);
<             exprs=assignmentExpression();
< 
<             state._fsp--;
< 
<             stream_assignmentExpression.add(exprs.getTree());
<             if (list_exprs==null) list_exprs=new ArrayList();
<             list_exprs.add(exprs.getTree());
< 
<             // JavaScript.g:1114:32: ( COMMA exprs+= assignmentExpression )*
<             loop41:
<             do {
<                 int alt41=2;
<                 int LA41_0 = input.LA(1);
< 
<                 if ( (LA41_0==COMMA) ) {
<                     alt41=1;
<                 }
< 
< 
<                 switch (alt41) {
<             	case 1 :
<             	    // JavaScript.g:1114:34: COMMA exprs+= assignmentExpression
<             	    {
<             	    COMMA138=(Token)match(input,COMMA,FOLLOW_COMMA_in_expression4372);  
<             	    stream_COMMA.add(COMMA138);
< 
<             	    pushFollow(FOLLOW_assignmentExpression_in_expression4376);
<             	    exprs=assignmentExpression();
< 
<             	    state._fsp--;
< 
<             	    stream_assignmentExpression.add(exprs.getTree());
<             	    if (list_exprs==null) list_exprs=new ArrayList();
<             	    list_exprs.add(exprs.getTree());
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop41;
<                 }
<             } while (true);
< 
< 
< 
<             // AST REWRITE
<             // elements: exprs, exprs
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: exprs
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<             RewriteRuleSubtreeStream stream_exprs=new RewriteRuleSubtreeStream(adaptor,"token exprs",list_exprs);
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1115:2: -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ )
<             if ( list_exprs.size() > 1 ) {
<                 // JavaScript.g:1115:28: ^( CEXPR ( $exprs)+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(CEXPR, "CEXPR"), root_1);
< 
<                 if ( !(stream_exprs.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_exprs.hasNext() ) {
<                     adaptor.addChild(root_1, stream_exprs.nextTree());
< 
<                 }
<                 stream_exprs.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
<             else // 1116:2: -> $exprs
<             {
<                 adaptor.addChild(root_0, stream_exprs.nextTree());
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "expression"
< 
<     public static class expressionNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "expressionNoIn"
<     // JavaScript.g:1119:1: expressionNoIn : exprs+= assignmentExpressionNoIn ( COMMA exprs+= assignmentExpressionNoIn )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs;
<     public final JavaScriptParser.expressionNoIn_return expressionNoIn() throws RecognitionException {
<         JavaScriptParser.expressionNoIn_return retval = new JavaScriptParser.expressionNoIn_return();
<         retval.start = input.LT(1);
<         int expressionNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token COMMA139=null;
<         List list_exprs=null;
<         RuleReturnScope exprs = null;
<         MyAstNode COMMA139_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleSubtreeStream stream_assignmentExpressionNoIn=new RewriteRuleSubtreeStream(adaptor,"rule assignmentExpressionNoIn");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 46) ) { return retval; }
<             // JavaScript.g:1120:2: (exprs+= assignmentExpressionNoIn ( COMMA exprs+= assignmentExpressionNoIn )* -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ ) -> $exprs)
<             // JavaScript.g:1120:4: exprs+= assignmentExpressionNoIn ( COMMA exprs+= assignmentExpressionNoIn )*
<             {
<             pushFollow(FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4413);
<             exprs=assignmentExpressionNoIn();
< 
<             state._fsp--;
< 
<             stream_assignmentExpressionNoIn.add(exprs.getTree());
<             if (list_exprs==null) list_exprs=new ArrayList();
<             list_exprs.add(exprs.getTree());
< 
<             // JavaScript.g:1120:36: ( COMMA exprs+= assignmentExpressionNoIn )*
<             loop42:
<             do {
<                 int alt42=2;
<                 int LA42_0 = input.LA(1);
< 
<                 if ( (LA42_0==COMMA) ) {
<                     alt42=1;
<                 }
< 
< 
<                 switch (alt42) {
<             	case 1 :
<             	    // JavaScript.g:1120:38: COMMA exprs+= assignmentExpressionNoIn
<             	    {
<             	    COMMA139=(Token)match(input,COMMA,FOLLOW_COMMA_in_expressionNoIn4417);  
<             	    stream_COMMA.add(COMMA139);
< 
<             	    pushFollow(FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4421);
<             	    exprs=assignmentExpressionNoIn();
< 
<             	    state._fsp--;
< 
<             	    stream_assignmentExpressionNoIn.add(exprs.getTree());
<             	    if (list_exprs==null) list_exprs=new ArrayList();
<             	    list_exprs.add(exprs.getTree());
< 
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop42;
<                 }
<             } while (true);
< 
< 
< 
<             // AST REWRITE
<             // elements: exprs, exprs
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: exprs
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<             RewriteRuleSubtreeStream stream_exprs=new RewriteRuleSubtreeStream(adaptor,"token exprs",list_exprs);
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1121:2: -> { $exprs.size() > 1 }? ^( CEXPR ( $exprs)+ )
<             if ( list_exprs.size() > 1 ) {
<                 // JavaScript.g:1121:28: ^( CEXPR ( $exprs)+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(CEXPR, "CEXPR"), root_1);
< 
<                 if ( !(stream_exprs.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_exprs.hasNext() ) {
<                     adaptor.addChild(root_1, stream_exprs.nextTree());
< 
<                 }
<                 stream_exprs.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
<             else // 1122:2: -> $exprs
<             {
<                 adaptor.addChild(root_0, stream_exprs.nextTree());
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "expressionNoIn"
< 
<     public static class semic_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "semic"
<     // JavaScript.g:1147:1: semic : ( SEMIC | EOF | RBRACE | EOL | MultiLineComment );
<     public final JavaScriptParser.semic_return semic() throws RecognitionException {
<         JavaScriptParser.semic_return retval = new JavaScriptParser.semic_return();
<         retval.start = input.LT(1);
<         int semic_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SEMIC140=null;
<         Token EOF141=null;
<         Token RBRACE142=null;
<         Token EOL143=null;
<         Token MultiLineComment144=null;
< 
<         MyAstNode SEMIC140_tree=null;
<         MyAstNode EOF141_tree=null;
<         MyAstNode RBRACE142_tree=null;
<         MyAstNode EOL143_tree=null;
<         MyAstNode MultiLineComment144_tree=null;
< 
< 
<         	// Mark current position so we can unconsume a RBRACE.
<         	int marker = input.mark();
<         	// Promote EOL if appropriate	
<         	promoteEOL(retval);
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 47) ) { return retval; }
<             // JavaScript.g:1155:2: ( SEMIC | EOF | RBRACE | EOL | MultiLineComment )
<             int alt43=5;
<             switch ( input.LA(1) ) {
<             case SEMIC:
<                 {
<                 alt43=1;
<                 }
<                 break;
<             case EOF:
<                 {
<                 alt43=2;
<                 }
<                 break;
<             case RBRACE:
<                 {
<                 alt43=3;
<                 }
<                 break;
<             case EOL:
<                 {
<                 alt43=4;
<                 }
<                 break;
<             case MultiLineComment:
<                 {
<                 alt43=5;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 43, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt43) {
<                 case 1 :
<                     // JavaScript.g:1155:4: SEMIC
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     SEMIC140=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_semic4472); 
<                     SEMIC140_tree = (MyAstNode)adaptor.create(SEMIC140);
<                     adaptor.addChild(root_0, SEMIC140_tree);
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1156:4: EOF
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     EOF141=(Token)match(input,EOF,FOLLOW_EOF_in_semic4477); 
<                     EOF141_tree = (MyAstNode)adaptor.create(EOF141);
<                     adaptor.addChild(root_0, EOF141_tree);
< 
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1157:4: RBRACE
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     RBRACE142=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_semic4482); 
<                     RBRACE142_tree = (MyAstNode)adaptor.create(RBRACE142);
<                     adaptor.addChild(root_0, RBRACE142_tree);
< 
<                      input.rewind(marker); 
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:1158:4: EOL
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     EOL143=(Token)match(input,EOL,FOLLOW_EOL_in_semic4489); 
<                     EOL143_tree = (MyAstNode)adaptor.create(EOL143);
<                     adaptor.addChild(root_0, EOL143_tree);
< 
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:1158:10: MultiLineComment
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     MultiLineComment144=(Token)match(input,MultiLineComment,FOLLOW_MultiLineComment_in_semic4493); 
<                     MultiLineComment144_tree = (MyAstNode)adaptor.create(MultiLineComment144);
<                     adaptor.addChild(root_0, MultiLineComment144_tree);
< 
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "semic"
< 
<     public static class statement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "statement"
<     // JavaScript.g:1166:1: statement options {k=1; } : ({...}? block | statementTail );
<     public final JavaScriptParser.statement_return statement() throws RecognitionException {
<         JavaScriptParser.statement_return retval = new JavaScriptParser.statement_return();
<         retval.start = input.LT(1);
<         int statement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.block_return block145 = null;
< 
<         JavaScriptParser.statementTail_return statementTail146 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 48) ) { return retval; }
<             // JavaScript.g:1175:2: ({...}? block | statementTail )
<             int alt44=2;
<             alt44 = dfa44.predict(input);
<             switch (alt44) {
<                 case 1 :
<                     // JavaScript.g:1175:4: {...}? block
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     if ( !(( input.LA(1) == LBRACE )) ) {
<                         throw new FailedPredicateException(input, "statement", " input.LA(1) == LBRACE ");
<                     }
<                     pushFollow(FOLLOW_block_in_statement4527);
<                     block145=block();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, block145.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1176:4: statementTail
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_statementTail_in_statement4532);
<                     statementTail146=statementTail();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, statementTail146.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
< 
<                     if(retval.tree != null)
<                         retval.tree.is_statement = true;
<                 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "statement"
< 
<     public static class statementTail_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "statementTail"
<     // JavaScript.g:1179:1: statementTail : ( variableStatement | emptyStatement | expressionStatement | ifStatement | iterationStatement | continueStatement | breakStatement | returnStatement | withStatement | labelledStatement | switchStatement | throwStatement | tryStatement );
<     public final JavaScriptParser.statementTail_return statementTail() throws RecognitionException {
<         JavaScriptParser.statementTail_return retval = new JavaScriptParser.statementTail_return();
<         retval.start = input.LT(1);
<         int statementTail_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.variableStatement_return variableStatement147 = null;
< 
<         JavaScriptParser.emptyStatement_return emptyStatement148 = null;
< 
<         JavaScriptParser.expressionStatement_return expressionStatement149 = null;
< 
<         JavaScriptParser.ifStatement_return ifStatement150 = null;
< 
<         JavaScriptParser.iterationStatement_return iterationStatement151 = null;
< 
<         JavaScriptParser.continueStatement_return continueStatement152 = null;
< 
<         JavaScriptParser.breakStatement_return breakStatement153 = null;
< 
<         JavaScriptParser.returnStatement_return returnStatement154 = null;
< 
<         JavaScriptParser.withStatement_return withStatement155 = null;
< 
<         JavaScriptParser.labelledStatement_return labelledStatement156 = null;
< 
<         JavaScriptParser.switchStatement_return switchStatement157 = null;
< 
<         JavaScriptParser.throwStatement_return throwStatement158 = null;
< 
<         JavaScriptParser.tryStatement_return tryStatement159 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 49) ) { return retval; }
<             // JavaScript.g:1180:2: ( variableStatement | emptyStatement | expressionStatement | ifStatement | iterationStatement | continueStatement | breakStatement | returnStatement | withStatement | labelledStatement | switchStatement | throwStatement | tryStatement )
<             int alt45=13;
<             alt45 = dfa45.predict(input);
<             switch (alt45) {
<                 case 1 :
<                     // JavaScript.g:1180:4: variableStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_variableStatement_in_statementTail4544);
<                     variableStatement147=variableStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, variableStatement147.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1181:4: emptyStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_emptyStatement_in_statementTail4549);
<                     emptyStatement148=emptyStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, emptyStatement148.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1182:4: expressionStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_expressionStatement_in_statementTail4554);
<                     expressionStatement149=expressionStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, expressionStatement149.getTree());
< 
<                     }
<                     break;
<                 case 4 :
<                     // JavaScript.g:1183:4: ifStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_ifStatement_in_statementTail4559);
<                     ifStatement150=ifStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, ifStatement150.getTree());
< 
<                     }
<                     break;
<                 case 5 :
<                     // JavaScript.g:1184:4: iterationStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_iterationStatement_in_statementTail4564);
<                     iterationStatement151=iterationStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, iterationStatement151.getTree());
< 
<                     }
<                     break;
<                 case 6 :
<                     // JavaScript.g:1185:4: continueStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_continueStatement_in_statementTail4569);
<                     continueStatement152=continueStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, continueStatement152.getTree());
< 
<                     }
<                     break;
<                 case 7 :
<                     // JavaScript.g:1186:4: breakStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_breakStatement_in_statementTail4574);
<                     breakStatement153=breakStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, breakStatement153.getTree());
< 
<                     }
<                     break;
<                 case 8 :
<                     // JavaScript.g:1187:4: returnStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_returnStatement_in_statementTail4579);
<                     returnStatement154=returnStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, returnStatement154.getTree());
< 
<                     }
<                     break;
<                 case 9 :
<                     // JavaScript.g:1188:4: withStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_withStatement_in_statementTail4584);
<                     withStatement155=withStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, withStatement155.getTree());
< 
<                     }
<                     break;
<                 case 10 :
<                     // JavaScript.g:1189:4: labelledStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_labelledStatement_in_statementTail4589);
<                     labelledStatement156=labelledStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, labelledStatement156.getTree());
< 
<                     }
<                     break;
<                 case 11 :
<                     // JavaScript.g:1190:4: switchStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_switchStatement_in_statementTail4594);
<                     switchStatement157=switchStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, switchStatement157.getTree());
< 
<                     }
<                     break;
<                 case 12 :
<                     // JavaScript.g:1191:4: throwStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_throwStatement_in_statementTail4599);
<                     throwStatement158=throwStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, throwStatement158.getTree());
< 
<                     }
<                     break;
<                 case 13 :
<                     // JavaScript.g:1192:4: tryStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_tryStatement_in_statementTail4604);
<                     tryStatement159=tryStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, tryStatement159.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "statementTail"
< 
<     public static class block_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "block"
<     // JavaScript.g:1197:1: block : lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) ;
<     public final JavaScriptParser.block_return block() throws RecognitionException {
<         JavaScriptParser.block_return retval = new JavaScriptParser.block_return();
<         retval.start = input.LT(1);
<         int block_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token RBRACE161=null;
<         JavaScriptParser.sourceElement_return sourceElement160 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode RBRACE161_tree=null;
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_sourceElement=new RewriteRuleSubtreeStream(adaptor,"rule sourceElement");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 50) ) { return retval; }
<             // JavaScript.g:1198:2: (lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) )
<             // JavaScript.g:1198:4: lb= LBRACE ( sourceElement )* RBRACE
<             {
<             lb=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_block4619);  
<             stream_LBRACE.add(lb);
< 
<             // JavaScript.g:1198:14: ( sourceElement )*
<             loop46:
<             do {
<                 int alt46=2;
<                 int LA46_0 = input.LA(1);
< 
<                 if ( ((LA46_0>=NULL && LA46_0<=BREAK)||LA46_0==CONTINUE||(LA46_0>=DELETE && LA46_0<=DO)||(LA46_0>=FOR && LA46_0<=IF)||(LA46_0>=NEW && LA46_0<=WITH)||LA46_0==LBRACE||LA46_0==LPAREN||LA46_0==LBRACK||LA46_0==SEMIC||(LA46_0>=ADD && LA46_0<=SUB)||(LA46_0>=INC && LA46_0<=DEC)||(LA46_0>=NOT && LA46_0<=INV)||(LA46_0>=Identifier && LA46_0<=StringLiteral)||LA46_0==RegularExpressionLiteral||(LA46_0>=DecimalLiteral && LA46_0<=HexIntegerLiteral)) ) {
<                     alt46=1;
<                 }
< 
< 
<                 switch (alt46) {
<             	case 1 :
<             	    // JavaScript.g:1198:14: sourceElement
<             	    {
<             	    pushFollow(FOLLOW_sourceElement_in_block4621);
<             	    sourceElement160=sourceElement();
< 
<             	    state._fsp--;
< 
<             	    stream_sourceElement.add(sourceElement160.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop46;
<                 }
<             } while (true);
< 
<             RBRACE161=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_block4624);  
<             stream_RBRACE.add(RBRACE161);
< 
< 
< 
<             // AST REWRITE
<             // elements: sourceElement
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1199:2: -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<             {
<                 // JavaScript.g:1199:5: ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BLOCK, lb, "BLOCK"), root_1);
< 
<                 // JavaScript.g:1199:28: ( sourceElement )*
<                 while ( stream_sourceElement.hasNext() ) {
<                     adaptor.addChild(root_1, stream_sourceElement.nextTree());
< 
<                 }
<                 stream_sourceElement.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "block"
< 
<     public static class variableStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "variableStatement"
<     // JavaScript.g:1206:1: variableStatement : VAR variableDeclaration ( COMMA variableDeclaration )* semic -> ^( VAR ( variableDeclaration )+ ) ;
<     public final JavaScriptParser.variableStatement_return variableStatement() throws RecognitionException {
<         JavaScriptParser.variableStatement_return retval = new JavaScriptParser.variableStatement_return();
<         retval.start = input.LT(1);
<         int variableStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token VAR162=null;
<         Token COMMA164=null;
<         JavaScriptParser.variableDeclaration_return variableDeclaration163 = null;
< 
<         JavaScriptParser.variableDeclaration_return variableDeclaration165 = null;
< 
<         JavaScriptParser.semic_return semic166 = null;
< 
< 
<         MyAstNode VAR162_tree=null;
<         MyAstNode COMMA164_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_VAR=new RewriteRuleTokenStream(adaptor,"token VAR");
<         RewriteRuleSubtreeStream stream_variableDeclaration=new RewriteRuleSubtreeStream(adaptor,"rule variableDeclaration");
<         RewriteRuleSubtreeStream stream_semic=new RewriteRuleSubtreeStream(adaptor,"rule semic");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 51) ) { return retval; }
<             // JavaScript.g:1207:2: ( VAR variableDeclaration ( COMMA variableDeclaration )* semic -> ^( VAR ( variableDeclaration )+ ) )
<             // JavaScript.g:1207:4: VAR variableDeclaration ( COMMA variableDeclaration )* semic
<             {
<             VAR162=(Token)match(input,VAR,FOLLOW_VAR_in_variableStatement4653);  
<             stream_VAR.add(VAR162);
< 
<             pushFollow(FOLLOW_variableDeclaration_in_variableStatement4655);
<             variableDeclaration163=variableDeclaration();
< 
<             state._fsp--;
< 
<             stream_variableDeclaration.add(variableDeclaration163.getTree());
<             // JavaScript.g:1207:28: ( COMMA variableDeclaration )*
<             loop47:
<             do {
<                 int alt47=2;
<                 int LA47_0 = input.LA(1);
< 
<                 if ( (LA47_0==COMMA) ) {
<                     alt47=1;
<                 }
< 
< 
<                 switch (alt47) {
<             	case 1 :
<             	    // JavaScript.g:1207:30: COMMA variableDeclaration
<             	    {
<             	    COMMA164=(Token)match(input,COMMA,FOLLOW_COMMA_in_variableStatement4659);  
<             	    stream_COMMA.add(COMMA164);
< 
<             	    pushFollow(FOLLOW_variableDeclaration_in_variableStatement4661);
<             	    variableDeclaration165=variableDeclaration();
< 
<             	    state._fsp--;
< 
<             	    stream_variableDeclaration.add(variableDeclaration165.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop47;
<                 }
<             } while (true);
< 
<             pushFollow(FOLLOW_semic_in_variableStatement4666);
<             semic166=semic();
< 
<             state._fsp--;
< 
<             stream_semic.add(semic166.getTree());
< 
< 
<             // AST REWRITE
<             // elements: variableDeclaration, VAR
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1208:2: -> ^( VAR ( variableDeclaration )+ )
<             {
<                 // JavaScript.g:1208:5: ^( VAR ( variableDeclaration )+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_VAR.nextNode(), root_1);
< 
<                 if ( !(stream_variableDeclaration.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_variableDeclaration.hasNext() ) {
<                     adaptor.addChild(root_1, stream_variableDeclaration.nextTree());
< 
<                 }
<                 stream_variableDeclaration.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "variableStatement"
< 
<     public static class variableDeclaration_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "variableDeclaration"
<     // JavaScript.g:1211:1: variableDeclaration : Identifier ( ASSIGN assignmentExpression )? ;
<     public final JavaScriptParser.variableDeclaration_return variableDeclaration() throws RecognitionException {
<         JavaScriptParser.variableDeclaration_return retval = new JavaScriptParser.variableDeclaration_return();
<         retval.start = input.LT(1);
<         int variableDeclaration_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier167=null;
<         Token ASSIGN168=null;
<         JavaScriptParser.assignmentExpression_return assignmentExpression169 = null;
< 
< 
<         MyAstNode Identifier167_tree=null;
<         MyAstNode ASSIGN168_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 52) ) { return retval; }
<             // JavaScript.g:1212:2: ( Identifier ( ASSIGN assignmentExpression )? )
<             // JavaScript.g:1212:4: Identifier ( ASSIGN assignmentExpression )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             Identifier167=(Token)match(input,Identifier,FOLLOW_Identifier_in_variableDeclaration4689); 
<             Identifier167_tree = (MyAstNode)adaptor.create(Identifier167);
<             adaptor.addChild(root_0, Identifier167_tree);
< 
<             // JavaScript.g:1212:15: ( ASSIGN assignmentExpression )?
<             int alt48=2;
<             int LA48_0 = input.LA(1);
< 
<             if ( (LA48_0==ASSIGN) ) {
<                 alt48=1;
<             }
<             switch (alt48) {
<                 case 1 :
<                     // JavaScript.g:1212:17: ASSIGN assignmentExpression
<                     {
<                     ASSIGN168=(Token)match(input,ASSIGN,FOLLOW_ASSIGN_in_variableDeclaration4693); 
<                     ASSIGN168_tree = (MyAstNode)adaptor.create(ASSIGN168);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(ASSIGN168_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpression_in_variableDeclaration4696);
<                     assignmentExpression169=assignmentExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpression169.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "variableDeclaration"
< 
<     public static class variableDeclarationNoIn_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "variableDeclarationNoIn"
<     // JavaScript.g:1215:1: variableDeclarationNoIn : Identifier ( ASSIGN assignmentExpressionNoIn )? ;
<     public final JavaScriptParser.variableDeclarationNoIn_return variableDeclarationNoIn() throws RecognitionException {
<         JavaScriptParser.variableDeclarationNoIn_return retval = new JavaScriptParser.variableDeclarationNoIn_return();
<         retval.start = input.LT(1);
<         int variableDeclarationNoIn_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier170=null;
<         Token ASSIGN171=null;
<         JavaScriptParser.assignmentExpressionNoIn_return assignmentExpressionNoIn172 = null;
< 
< 
<         MyAstNode Identifier170_tree=null;
<         MyAstNode ASSIGN171_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 53) ) { return retval; }
<             // JavaScript.g:1216:2: ( Identifier ( ASSIGN assignmentExpressionNoIn )? )
<             // JavaScript.g:1216:4: Identifier ( ASSIGN assignmentExpressionNoIn )?
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             Identifier170=(Token)match(input,Identifier,FOLLOW_Identifier_in_variableDeclarationNoIn4711); 
<             Identifier170_tree = (MyAstNode)adaptor.create(Identifier170);
<             adaptor.addChild(root_0, Identifier170_tree);
< 
<             // JavaScript.g:1216:15: ( ASSIGN assignmentExpressionNoIn )?
<             int alt49=2;
<             int LA49_0 = input.LA(1);
< 
<             if ( (LA49_0==ASSIGN) ) {
<                 alt49=1;
<             }
<             switch (alt49) {
<                 case 1 :
<                     // JavaScript.g:1216:17: ASSIGN assignmentExpressionNoIn
<                     {
<                     ASSIGN171=(Token)match(input,ASSIGN,FOLLOW_ASSIGN_in_variableDeclarationNoIn4715); 
<                     ASSIGN171_tree = (MyAstNode)adaptor.create(ASSIGN171);
<                     root_0 = (MyAstNode)adaptor.becomeRoot(ASSIGN171_tree, root_0);
< 
<                     pushFollow(FOLLOW_assignmentExpressionNoIn_in_variableDeclarationNoIn4718);
<                     assignmentExpressionNoIn172=assignmentExpressionNoIn();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, assignmentExpressionNoIn172.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "variableDeclarationNoIn"
< 
<     public static class emptyStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "emptyStatement"
<     // JavaScript.g:1223:1: emptyStatement : SEMIC ;
<     public final JavaScriptParser.emptyStatement_return emptyStatement() throws RecognitionException {
<         JavaScriptParser.emptyStatement_return retval = new JavaScriptParser.emptyStatement_return();
<         retval.start = input.LT(1);
<         int emptyStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SEMIC173=null;
< 
<         MyAstNode SEMIC173_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 54) ) { return retval; }
<             // JavaScript.g:1224:2: ( SEMIC )
<             // JavaScript.g:1224:4: SEMIC
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             SEMIC173=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_emptyStatement4737); 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "emptyStatement"
< 
<     public static class expressionStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "expressionStatement"
<     // JavaScript.g:1237:1: expressionStatement : expression semic ;
<     public final JavaScriptParser.expressionStatement_return expressionStatement() throws RecognitionException {
<         JavaScriptParser.expressionStatement_return retval = new JavaScriptParser.expressionStatement_return();
<         retval.start = input.LT(1);
<         int expressionStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.expression_return expression174 = null;
< 
<         JavaScriptParser.semic_return semic175 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 55) ) { return retval; }
<             // JavaScript.g:1238:2: ( expression semic )
<             // JavaScript.g:1238:4: expression semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             pushFollow(FOLLOW_expression_in_expressionStatement4756);
<             expression174=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression174.getTree());
<             pushFollow(FOLLOW_semic_in_expressionStatement4758);
<             semic175=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "expressionStatement"
< 
<     public static class ifStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "ifStatement"
<     // JavaScript.g:1245:1: ifStatement : IF LPAREN expression RPAREN statement ({...}? ELSE statement )? -> ^( IF expression ( statement )+ ) ;
<     public final JavaScriptParser.ifStatement_return ifStatement() throws RecognitionException {
<         JavaScriptParser.ifStatement_return retval = new JavaScriptParser.ifStatement_return();
<         retval.start = input.LT(1);
<         int ifStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token IF176=null;
<         Token LPAREN177=null;
<         Token RPAREN179=null;
<         Token ELSE181=null;
<         JavaScriptParser.expression_return expression178 = null;
< 
<         JavaScriptParser.statement_return statement180 = null;
< 
<         JavaScriptParser.statement_return statement182 = null;
< 
< 
<         MyAstNode IF176_tree=null;
<         MyAstNode LPAREN177_tree=null;
<         MyAstNode RPAREN179_tree=null;
<         MyAstNode ELSE181_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_ELSE=new RewriteRuleTokenStream(adaptor,"token ELSE");
<         RewriteRuleTokenStream stream_IF=new RewriteRuleTokenStream(adaptor,"token IF");
<         RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 56) ) { return retval; }
<             // JavaScript.g:1247:2: ( IF LPAREN expression RPAREN statement ({...}? ELSE statement )? -> ^( IF expression ( statement )+ ) )
<             // JavaScript.g:1247:4: IF LPAREN expression RPAREN statement ({...}? ELSE statement )?
<             {
<             IF176=(Token)match(input,IF,FOLLOW_IF_in_ifStatement4776);  
<             stream_IF.add(IF176);
< 
<             LPAREN177=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_ifStatement4778);  
<             stream_LPAREN.add(LPAREN177);
< 
<             pushFollow(FOLLOW_expression_in_ifStatement4780);
<             expression178=expression();
< 
<             state._fsp--;
< 
<             stream_expression.add(expression178.getTree());
<             RPAREN179=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_ifStatement4782);  
<             stream_RPAREN.add(RPAREN179);
< 
<             pushFollow(FOLLOW_statement_in_ifStatement4784);
<             statement180=statement();
< 
<             state._fsp--;
< 
<             stream_statement.add(statement180.getTree());
<             // JavaScript.g:1247:42: ({...}? ELSE statement )?
<             int alt50=2;
<             int LA50_0 = input.LA(1);
< 
<             if ( (LA50_0==ELSE) ) {
<                 int LA50_1 = input.LA(2);
< 
<                 if ( (( input.LA(1) == ELSE )) ) {
<                     alt50=1;
<                 }
<             }
<             switch (alt50) {
<                 case 1 :
<                     // JavaScript.g:1247:44: {...}? ELSE statement
<                     {
<                     if ( !(( input.LA(1) == ELSE )) ) {
<                         throw new FailedPredicateException(input, "ifStatement", " input.LA(1) == ELSE ");
<                     }
<                     ELSE181=(Token)match(input,ELSE,FOLLOW_ELSE_in_ifStatement4790);  
<                     stream_ELSE.add(ELSE181);
< 
<                     pushFollow(FOLLOW_statement_in_ifStatement4792);
<                     statement182=statement();
< 
<                     state._fsp--;
< 
<                     stream_statement.add(statement182.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
< 
<             // AST REWRITE
<             // elements: IF, statement, expression
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1248:2: -> ^( IF expression ( statement )+ )
<             {
<                 // JavaScript.g:1248:5: ^( IF expression ( statement )+ )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_IF.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_expression.nextTree());
<                 if ( !(stream_statement.hasNext()) ) {
<                     throw new RewriteEarlyExitException();
<                 }
<                 while ( stream_statement.hasNext() ) {
<                     adaptor.addChild(root_1, stream_statement.nextTree());
< 
<                 }
<                 stream_statement.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "ifStatement"
< 
<     public static class iterationStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "iterationStatement"
<     // JavaScript.g:1255:1: iterationStatement : ( doStatement | whileStatement | forStatement );
<     public final JavaScriptParser.iterationStatement_return iterationStatement() throws RecognitionException {
<         JavaScriptParser.iterationStatement_return retval = new JavaScriptParser.iterationStatement_return();
<         retval.start = input.LT(1);
<         int iterationStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.doStatement_return doStatement183 = null;
< 
<         JavaScriptParser.whileStatement_return whileStatement184 = null;
< 
<         JavaScriptParser.forStatement_return forStatement185 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 57) ) { return retval; }
<             // JavaScript.g:1256:2: ( doStatement | whileStatement | forStatement )
<             int alt51=3;
<             switch ( input.LA(1) ) {
<             case DO:
<                 {
<                 alt51=1;
<                 }
<                 break;
<             case WHILE:
<                 {
<                 alt51=2;
<                 }
<                 break;
<             case FOR:
<                 {
<                 alt51=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 51, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt51) {
<                 case 1 :
<                     // JavaScript.g:1256:4: doStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_doStatement_in_iterationStatement4825);
<                     doStatement183=doStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, doStatement183.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1257:4: whileStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_whileStatement_in_iterationStatement4830);
<                     whileStatement184=whileStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, whileStatement184.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1258:4: forStatement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forStatement_in_iterationStatement4835);
<                     forStatement185=forStatement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forStatement185.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "iterationStatement"
< 
<     public static class doStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "doStatement"
<     // JavaScript.g:1261:1: doStatement : DO statement WHILE LPAREN expression RPAREN semic -> ^( DO statement expression ) ;
<     public final JavaScriptParser.doStatement_return doStatement() throws RecognitionException {
<         JavaScriptParser.doStatement_return retval = new JavaScriptParser.doStatement_return();
<         retval.start = input.LT(1);
<         int doStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token DO186=null;
<         Token WHILE188=null;
<         Token LPAREN189=null;
<         Token RPAREN191=null;
<         JavaScriptParser.statement_return statement187 = null;
< 
<         JavaScriptParser.expression_return expression190 = null;
< 
<         JavaScriptParser.semic_return semic192 = null;
< 
< 
<         MyAstNode DO186_tree=null;
<         MyAstNode WHILE188_tree=null;
<         MyAstNode LPAREN189_tree=null;
<         MyAstNode RPAREN191_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_DO=new RewriteRuleTokenStream(adaptor,"token DO");
<         RewriteRuleTokenStream stream_WHILE=new RewriteRuleTokenStream(adaptor,"token WHILE");
<         RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");
<         RewriteRuleSubtreeStream stream_semic=new RewriteRuleSubtreeStream(adaptor,"rule semic");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 58) ) { return retval; }
<             // JavaScript.g:1262:2: ( DO statement WHILE LPAREN expression RPAREN semic -> ^( DO statement expression ) )
<             // JavaScript.g:1262:4: DO statement WHILE LPAREN expression RPAREN semic
<             {
<             DO186=(Token)match(input,DO,FOLLOW_DO_in_doStatement4847);  
<             stream_DO.add(DO186);
< 
<             pushFollow(FOLLOW_statement_in_doStatement4849);
<             statement187=statement();
< 
<             state._fsp--;
< 
<             stream_statement.add(statement187.getTree());
<             WHILE188=(Token)match(input,WHILE,FOLLOW_WHILE_in_doStatement4851);  
<             stream_WHILE.add(WHILE188);
< 
<             LPAREN189=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_doStatement4853);  
<             stream_LPAREN.add(LPAREN189);
< 
<             pushFollow(FOLLOW_expression_in_doStatement4855);
<             expression190=expression();
< 
<             state._fsp--;
< 
<             stream_expression.add(expression190.getTree());
<             RPAREN191=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_doStatement4857);  
<             stream_RPAREN.add(RPAREN191);
< 
<             pushFollow(FOLLOW_semic_in_doStatement4859);
<             semic192=semic();
< 
<             state._fsp--;
< 
<             stream_semic.add(semic192.getTree());
< 
< 
<             // AST REWRITE
<             // elements: statement, expression, DO
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1263:2: -> ^( DO statement expression )
<             {
<                 // JavaScript.g:1263:5: ^( DO statement expression )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_DO.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_statement.nextTree());
<                 adaptor.addChild(root_1, stream_expression.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "doStatement"
< 
<     public static class whileStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "whileStatement"
<     // JavaScript.g:1266:1: whileStatement : WHILE LPAREN expression RPAREN statement ;
<     public final JavaScriptParser.whileStatement_return whileStatement() throws RecognitionException {
<         JavaScriptParser.whileStatement_return retval = new JavaScriptParser.whileStatement_return();
<         retval.start = input.LT(1);
<         int whileStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token WHILE193=null;
<         Token LPAREN194=null;
<         Token RPAREN196=null;
<         JavaScriptParser.expression_return expression195 = null;
< 
<         JavaScriptParser.statement_return statement197 = null;
< 
< 
<         MyAstNode WHILE193_tree=null;
<         MyAstNode LPAREN194_tree=null;
<         MyAstNode RPAREN196_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 59) ) { return retval; }
<             // JavaScript.g:1267:2: ( WHILE LPAREN expression RPAREN statement )
<             // JavaScript.g:1267:4: WHILE LPAREN expression RPAREN statement
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             WHILE193=(Token)match(input,WHILE,FOLLOW_WHILE_in_whileStatement4884); 
<             WHILE193_tree = (MyAstNode)adaptor.create(WHILE193);
<             root_0 = (MyAstNode)adaptor.becomeRoot(WHILE193_tree, root_0);
< 
<             LPAREN194=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_whileStatement4887); 
<             pushFollow(FOLLOW_expression_in_whileStatement4890);
<             expression195=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression195.getTree());
<             RPAREN196=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_whileStatement4892); 
<             pushFollow(FOLLOW_statement_in_whileStatement4895);
<             statement197=statement();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, statement197.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "whileStatement"
< 
<     public static class forStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forStatement"
<     // JavaScript.g:1311:1: forStatement : FOR LPAREN forControl RPAREN statement ;
<     public final JavaScriptParser.forStatement_return forStatement() throws RecognitionException {
<         JavaScriptParser.forStatement_return retval = new JavaScriptParser.forStatement_return();
<         retval.start = input.LT(1);
<         int forStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token FOR198=null;
<         Token LPAREN199=null;
<         Token RPAREN201=null;
<         JavaScriptParser.forControl_return forControl200 = null;
< 
<         JavaScriptParser.statement_return statement202 = null;
< 
< 
<         MyAstNode FOR198_tree=null;
<         MyAstNode LPAREN199_tree=null;
<         MyAstNode RPAREN201_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 60) ) { return retval; }
<             // JavaScript.g:1312:2: ( FOR LPAREN forControl RPAREN statement )
<             // JavaScript.g:1312:4: FOR LPAREN forControl RPAREN statement
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             FOR198=(Token)match(input,FOR,FOLLOW_FOR_in_forStatement4908); 
<             FOR198_tree = (MyAstNode)adaptor.create(FOR198);
<             root_0 = (MyAstNode)adaptor.becomeRoot(FOR198_tree, root_0);
< 
<             LPAREN199=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_forStatement4911); 
<             pushFollow(FOLLOW_forControl_in_forStatement4914);
<             forControl200=forControl();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, forControl200.getTree());
<             RPAREN201=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_forStatement4916); 
<             pushFollow(FOLLOW_statement_in_forStatement4919);
<             statement202=statement();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, statement202.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forStatement"
< 
<     public static class forControl_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControl"
<     // JavaScript.g:1315:1: forControl : ( forControlVar | forControlExpression | forControlSemic );
<     public final JavaScriptParser.forControl_return forControl() throws RecognitionException {
<         JavaScriptParser.forControl_return retval = new JavaScriptParser.forControl_return();
<         retval.start = input.LT(1);
<         int forControl_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.forControlVar_return forControlVar203 = null;
< 
<         JavaScriptParser.forControlExpression_return forControlExpression204 = null;
< 
<         JavaScriptParser.forControlSemic_return forControlSemic205 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 61) ) { return retval; }
<             // JavaScript.g:1316:2: ( forControlVar | forControlExpression | forControlSemic )
<             int alt52=3;
<             switch ( input.LA(1) ) {
<             case VAR:
<                 {
<                 alt52=1;
<                 }
<                 break;
<             case NULL:
<             case TRUE:
<             case FALSE:
<             case DELETE:
<             case FUNCTION:
<             case NEW:
<             case THIS:
<             case TYPEOF:
<             case VOID:
<             case LBRACE:
<             case LPAREN:
<             case LBRACK:
<             case ADD:
<             case SUB:
<             case INC:
<             case DEC:
<             case NOT:
<             case INV:
<             case Identifier:
<             case StringLiteral:
<             case RegularExpressionLiteral:
<             case DecimalLiteral:
<             case OctalIntegerLiteral:
<             case HexIntegerLiteral:
<                 {
<                 alt52=2;
<                 }
<                 break;
<             case SEMIC:
<                 {
<                 alt52=3;
<                 }
<                 break;
<             default:
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 52, 0, input);
< 
<                 throw nvae;
<             }
< 
<             switch (alt52) {
<                 case 1 :
<                     // JavaScript.g:1316:4: forControlVar
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forControlVar_in_forControl4930);
<                     forControlVar203=forControlVar();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forControlVar203.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1317:4: forControlExpression
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forControlExpression_in_forControl4935);
<                     forControlExpression204=forControlExpression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forControlExpression204.getTree());
< 
<                     }
<                     break;
<                 case 3 :
<                     // JavaScript.g:1318:4: forControlSemic
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_forControlSemic_in_forControl4940);
<                     forControlSemic205=forControlSemic();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, forControlSemic205.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControl"
< 
<     public static class forControlVar_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControlVar"
<     // JavaScript.g:1321:1: forControlVar : VAR variableDeclarationNoIn ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) ) ;
<     public final JavaScriptParser.forControlVar_return forControlVar() throws RecognitionException {
<         JavaScriptParser.forControlVar_return retval = new JavaScriptParser.forControlVar_return();
<         retval.start = input.LT(1);
<         int forControlVar_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token VAR206=null;
<         Token IN208=null;
<         Token COMMA210=null;
<         Token SEMIC212=null;
<         Token SEMIC213=null;
<         JavaScriptParser.expression_return ex1 = null;
< 
<         JavaScriptParser.expression_return ex2 = null;
< 
<         JavaScriptParser.variableDeclarationNoIn_return variableDeclarationNoIn207 = null;
< 
<         JavaScriptParser.expression_return expression209 = null;
< 
<         JavaScriptParser.variableDeclarationNoIn_return variableDeclarationNoIn211 = null;
< 
< 
<         MyAstNode VAR206_tree=null;
<         MyAstNode IN208_tree=null;
<         MyAstNode COMMA210_tree=null;
<         MyAstNode SEMIC212_tree=null;
<         MyAstNode SEMIC213_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_VAR=new RewriteRuleTokenStream(adaptor,"token VAR");
<         RewriteRuleTokenStream stream_SEMIC=new RewriteRuleTokenStream(adaptor,"token SEMIC");
<         RewriteRuleTokenStream stream_IN=new RewriteRuleTokenStream(adaptor,"token IN");
<         RewriteRuleSubtreeStream stream_variableDeclarationNoIn=new RewriteRuleSubtreeStream(adaptor,"rule variableDeclarationNoIn");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 62) ) { return retval; }
<             // JavaScript.g:1322:2: ( VAR variableDeclarationNoIn ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) ) )
<             // JavaScript.g:1322:4: VAR variableDeclarationNoIn ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) )
<             {
<             VAR206=(Token)match(input,VAR,FOLLOW_VAR_in_forControlVar4951);  
<             stream_VAR.add(VAR206);
< 
<             pushFollow(FOLLOW_variableDeclarationNoIn_in_forControlVar4953);
<             variableDeclarationNoIn207=variableDeclarationNoIn();
< 
<             state._fsp--;
< 
<             stream_variableDeclarationNoIn.add(variableDeclarationNoIn207.getTree());
<             // JavaScript.g:1323:2: ( ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) ) | ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ) )
<             int alt56=2;
<             int LA56_0 = input.LA(1);
< 
<             if ( (LA56_0==IN) ) {
<                 alt56=1;
<             }
<             else if ( ((LA56_0>=SEMIC && LA56_0<=COMMA)) ) {
<                 alt56=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 56, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt56) {
<                 case 1 :
<                     // JavaScript.g:1324:3: ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) )
<                     {
<                     // JavaScript.g:1324:3: ( IN expression -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) ) )
<                     // JavaScript.g:1325:4: IN expression
<                     {
<                     IN208=(Token)match(input,IN,FOLLOW_IN_in_forControlVar4965);  
<                     stream_IN.add(IN208);
< 
<                     pushFollow(FOLLOW_expression_in_forControlVar4967);
<                     expression209=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(expression209.getTree());
< 
< 
<                     // AST REWRITE
<                     // elements: expression, VAR, variableDeclarationNoIn
<                     // token labels: 
<                     // rule labels: retval
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1326:4: -> ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) )
<                     {
<                         // JavaScript.g:1326:7: ^( FORITER ^( VAR variableDeclarationNoIn ) ^( EXPR expression ) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORITER, "FORITER"), root_1);
< 
<                         // JavaScript.g:1326:18: ^( VAR variableDeclarationNoIn )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot(stream_VAR.nextNode(), root_2);
< 
<                         adaptor.addChild(root_2, stream_variableDeclarationNoIn.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1326:51: ^( EXPR expression )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_expression.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1329:3: ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) )
<                     {
<                     // JavaScript.g:1329:3: ( ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) )
<                     // JavaScript.g:1330:4: ( COMMA variableDeclarationNoIn )* SEMIC (ex1= expression )? SEMIC (ex2= expression )?
<                     {
<                     // JavaScript.g:1330:4: ( COMMA variableDeclarationNoIn )*
<                     loop53:
<                     do {
<                         int alt53=2;
<                         int LA53_0 = input.LA(1);
< 
<                         if ( (LA53_0==COMMA) ) {
<                             alt53=1;
<                         }
< 
< 
<                         switch (alt53) {
<                     	case 1 :
<                     	    // JavaScript.g:1330:6: COMMA variableDeclarationNoIn
<                     	    {
<                     	    COMMA210=(Token)match(input,COMMA,FOLLOW_COMMA_in_forControlVar5013);  
<                     	    stream_COMMA.add(COMMA210);
< 
<                     	    pushFollow(FOLLOW_variableDeclarationNoIn_in_forControlVar5015);
<                     	    variableDeclarationNoIn211=variableDeclarationNoIn();
< 
<                     	    state._fsp--;
< 
<                     	    stream_variableDeclarationNoIn.add(variableDeclarationNoIn211.getTree());
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop53;
<                         }
<                     } while (true);
< 
<                     SEMIC212=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlVar5020);  
<                     stream_SEMIC.add(SEMIC212);
< 
<                     // JavaScript.g:1330:48: (ex1= expression )?
<                     int alt54=2;
<                     int LA54_0 = input.LA(1);
< 
<                     if ( ((LA54_0>=NULL && LA54_0<=FALSE)||LA54_0==DELETE||LA54_0==FUNCTION||LA54_0==NEW||LA54_0==THIS||LA54_0==TYPEOF||LA54_0==VOID||LA54_0==LBRACE||LA54_0==LPAREN||LA54_0==LBRACK||(LA54_0>=ADD && LA54_0<=SUB)||(LA54_0>=INC && LA54_0<=DEC)||(LA54_0>=NOT && LA54_0<=INV)||(LA54_0>=Identifier && LA54_0<=StringLiteral)||LA54_0==RegularExpressionLiteral||(LA54_0>=DecimalLiteral && LA54_0<=HexIntegerLiteral)) ) {
<                         alt54=1;
<                     }
<                     switch (alt54) {
<                         case 1 :
<                             // JavaScript.g:1330:48: ex1= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlVar5024);
<                             ex1=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex1.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
<                     SEMIC213=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlVar5027);  
<                     stream_SEMIC.add(SEMIC213);
< 
<                     // JavaScript.g:1330:70: (ex2= expression )?
<                     int alt55=2;
<                     int LA55_0 = input.LA(1);
< 
<                     if ( ((LA55_0>=NULL && LA55_0<=FALSE)||LA55_0==DELETE||LA55_0==FUNCTION||LA55_0==NEW||LA55_0==THIS||LA55_0==TYPEOF||LA55_0==VOID||LA55_0==LBRACE||LA55_0==LPAREN||LA55_0==LBRACK||(LA55_0>=ADD && LA55_0<=SUB)||(LA55_0>=INC && LA55_0<=DEC)||(LA55_0>=NOT && LA55_0<=INV)||(LA55_0>=Identifier && LA55_0<=StringLiteral)||LA55_0==RegularExpressionLiteral||(LA55_0>=DecimalLiteral && LA55_0<=HexIntegerLiteral)) ) {
<                         alt55=1;
<                     }
<                     switch (alt55) {
<                         case 1 :
<                             // JavaScript.g:1330:70: ex2= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlVar5031);
<                             ex2=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex2.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
< 
< 
<                     // AST REWRITE
<                     // elements: ex1, variableDeclarationNoIn, ex2, VAR
<                     // token labels: 
<                     // rule labels: ex2, retval, ex1
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<                     RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1331:4: -> ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<                     {
<                         // JavaScript.g:1331:7: ^( FORSTEP ^( VAR ( variableDeclarationNoIn )+ ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORSTEP, "FORSTEP"), root_1);
< 
<                         // JavaScript.g:1331:18: ^( VAR ( variableDeclarationNoIn )+ )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot(stream_VAR.nextNode(), root_2);
< 
<                         if ( !(stream_variableDeclarationNoIn.hasNext()) ) {
<                             throw new RewriteEarlyExitException();
<                         }
<                         while ( stream_variableDeclarationNoIn.hasNext() ) {
<                             adaptor.addChild(root_2, stream_variableDeclarationNoIn.nextTree());
< 
<                         }
<                         stream_variableDeclarationNoIn.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1331:52: ^( EXPR ( $ex1)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1331:60: ( $ex1)?
<                         if ( stream_ex1.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                         }
<                         stream_ex1.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1331:68: ^( EXPR ( $ex2)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1331:76: ( $ex2)?
<                         if ( stream_ex2.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                         }
<                         stream_ex2.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControlVar"
< 
<     public static class forControlExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControlExpression"
<     // JavaScript.g:1336:1: forControlExpression : ex1= expressionNoIn ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) ) ;
<     public final JavaScriptParser.forControlExpression_return forControlExpression() throws RecognitionException {
<         JavaScriptParser.forControlExpression_return retval = new JavaScriptParser.forControlExpression_return();
<         retval.start = input.LT(1);
<         int forControlExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token IN214=null;
<         Token SEMIC215=null;
<         Token SEMIC216=null;
<         JavaScriptParser.expressionNoIn_return ex1 = null;
< 
<         JavaScriptParser.expression_return ex2 = null;
< 
<         JavaScriptParser.expression_return ex3 = null;
< 
< 
<         MyAstNode IN214_tree=null;
<         MyAstNode SEMIC215_tree=null;
<         MyAstNode SEMIC216_tree=null;
<         RewriteRuleTokenStream stream_SEMIC=new RewriteRuleTokenStream(adaptor,"token SEMIC");
<         RewriteRuleTokenStream stream_IN=new RewriteRuleTokenStream(adaptor,"token IN");
<         RewriteRuleSubtreeStream stream_expressionNoIn=new RewriteRuleSubtreeStream(adaptor,"rule expressionNoIn");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
< 
<         	Object[] isLhs = new Object[1];
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 63) ) { return retval; }
<             // JavaScript.g:1341:2: (ex1= expressionNoIn ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) ) )
<             // JavaScript.g:1341:4: ex1= expressionNoIn ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) )
<             {
<             pushFollow(FOLLOW_expressionNoIn_in_forControlExpression5097);
<             ex1=expressionNoIn();
< 
<             state._fsp--;
< 
<             stream_expressionNoIn.add(ex1.getTree());
<             // JavaScript.g:1342:2: ({...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) ) | ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) ) )
<             int alt59=2;
<             int LA59_0 = input.LA(1);
< 
<             if ( (LA59_0==IN) ) {
<                 alt59=1;
<             }
<             else if ( (LA59_0==SEMIC) ) {
<                 alt59=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 59, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt59) {
<                 case 1 :
<                     // JavaScript.g:1343:3: {...}? ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) )
<                     {
<                     if ( !(( isLeftHandSideIn(ex1, isLhs) )) ) {
<                         throw new FailedPredicateException(input, "forControlExpression", " isLeftHandSideIn(ex1, isLhs) ");
<                     }
<                     // JavaScript.g:1343:37: ( IN ex2= expression -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) ) )
<                     // JavaScript.g:1344:4: IN ex2= expression
<                     {
<                     IN214=(Token)match(input,IN,FOLLOW_IN_in_forControlExpression5112);  
<                     stream_IN.add(IN214);
< 
<                     pushFollow(FOLLOW_expression_in_forControlExpression5116);
<                     ex2=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(ex2.getTree());
< 
< 
<                     // AST REWRITE
<                     // elements: ex2, ex1
<                     // token labels: 
<                     // rule labels: ex2, retval, ex1
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<                     RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1345:4: -> ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) )
<                     {
<                         // JavaScript.g:1345:7: ^( FORITER ^( EXPR $ex1) ^( EXPR $ex2) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORITER, "FORITER"), root_1);
< 
<                         // JavaScript.g:1345:18: ^( EXPR $ex1)
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1345:33: ^( EXPR $ex2)
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1348:3: ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) )
<                     {
<                     // JavaScript.g:1348:3: ( SEMIC (ex2= expression )? SEMIC (ex3= expression )? -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) ) )
<                     // JavaScript.g:1349:4: SEMIC (ex2= expression )? SEMIC (ex3= expression )?
<                     {
<                     SEMIC215=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlExpression5162);  
<                     stream_SEMIC.add(SEMIC215);
< 
<                     // JavaScript.g:1349:13: (ex2= expression )?
<                     int alt57=2;
<                     int LA57_0 = input.LA(1);
< 
<                     if ( ((LA57_0>=NULL && LA57_0<=FALSE)||LA57_0==DELETE||LA57_0==FUNCTION||LA57_0==NEW||LA57_0==THIS||LA57_0==TYPEOF||LA57_0==VOID||LA57_0==LBRACE||LA57_0==LPAREN||LA57_0==LBRACK||(LA57_0>=ADD && LA57_0<=SUB)||(LA57_0>=INC && LA57_0<=DEC)||(LA57_0>=NOT && LA57_0<=INV)||(LA57_0>=Identifier && LA57_0<=StringLiteral)||LA57_0==RegularExpressionLiteral||(LA57_0>=DecimalLiteral && LA57_0<=HexIntegerLiteral)) ) {
<                         alt57=1;
<                     }
<                     switch (alt57) {
<                         case 1 :
<                             // JavaScript.g:1349:13: ex2= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlExpression5166);
<                             ex2=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex2.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
<                     SEMIC216=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlExpression5169);  
<                     stream_SEMIC.add(SEMIC216);
< 
<                     // JavaScript.g:1349:35: (ex3= expression )?
<                     int alt58=2;
<                     int LA58_0 = input.LA(1);
< 
<                     if ( ((LA58_0>=NULL && LA58_0<=FALSE)||LA58_0==DELETE||LA58_0==FUNCTION||LA58_0==NEW||LA58_0==THIS||LA58_0==TYPEOF||LA58_0==VOID||LA58_0==LBRACE||LA58_0==LPAREN||LA58_0==LBRACK||(LA58_0>=ADD && LA58_0<=SUB)||(LA58_0>=INC && LA58_0<=DEC)||(LA58_0>=NOT && LA58_0<=INV)||(LA58_0>=Identifier && LA58_0<=StringLiteral)||LA58_0==RegularExpressionLiteral||(LA58_0>=DecimalLiteral && LA58_0<=HexIntegerLiteral)) ) {
<                         alt58=1;
<                     }
<                     switch (alt58) {
<                         case 1 :
<                             // JavaScript.g:1349:35: ex3= expression
<                             {
<                             pushFollow(FOLLOW_expression_in_forControlExpression5173);
<                             ex3=expression();
< 
<                             state._fsp--;
< 
<                             stream_expression.add(ex3.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
< 
< 
<                     // AST REWRITE
<                     // elements: ex1, ex2, ex3
<                     // token labels: 
<                     // rule labels: ex2, retval, ex1, ex3
<                     // token list labels: 
<                     // rule list labels: 
<                     retval.tree = root_0;
<                     RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<                     RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<                     RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
<                     RewriteRuleSubtreeStream stream_ex3=new RewriteRuleSubtreeStream(adaptor,"token ex3",ex3!=null?ex3.tree:null);
< 
<                     root_0 = (MyAstNode)adaptor.nil();
<                     // 1350:4: -> ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) )
<                     {
<                         // JavaScript.g:1350:7: ^( FORSTEP ^( EXPR $ex1) ^( EXPR ( $ex2)? ) ^( EXPR ( $ex3)? ) )
<                         {
<                         MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                         root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORSTEP, "FORSTEP"), root_1);
< 
<                         // JavaScript.g:1350:18: ^( EXPR $ex1)
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1350:33: ^( EXPR ( $ex2)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1350:41: ( $ex2)?
<                         if ( stream_ex2.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                         }
<                         stream_ex2.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
<                         // JavaScript.g:1350:49: ^( EXPR ( $ex3)? )
<                         {
<                         MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                         root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                         // JavaScript.g:1350:57: ( $ex3)?
<                         if ( stream_ex3.hasNext() ) {
<                             adaptor.addChild(root_2, stream_ex3.nextTree());
< 
<                         }
<                         stream_ex3.reset();
< 
<                         adaptor.addChild(root_1, root_2);
<                         }
< 
<                         adaptor.addChild(root_0, root_1);
<                         }
< 
<                     }
< 
<                     retval.tree = root_0;
<                     }
< 
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControlExpression"
< 
<     public static class forControlSemic_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "forControlSemic"
<     // JavaScript.g:1355:1: forControlSemic : SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) ;
<     public final JavaScriptParser.forControlSemic_return forControlSemic() throws RecognitionException {
<         JavaScriptParser.forControlSemic_return retval = new JavaScriptParser.forControlSemic_return();
<         retval.start = input.LT(1);
<         int forControlSemic_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SEMIC217=null;
<         Token SEMIC218=null;
<         JavaScriptParser.expression_return ex1 = null;
< 
<         JavaScriptParser.expression_return ex2 = null;
< 
< 
<         MyAstNode SEMIC217_tree=null;
<         MyAstNode SEMIC218_tree=null;
<         RewriteRuleTokenStream stream_SEMIC=new RewriteRuleTokenStream(adaptor,"token SEMIC");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 64) ) { return retval; }
<             // JavaScript.g:1356:2: ( SEMIC (ex1= expression )? SEMIC (ex2= expression )? -> ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) ) )
<             // JavaScript.g:1356:4: SEMIC (ex1= expression )? SEMIC (ex2= expression )?
<             {
<             SEMIC217=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlSemic5232);  
<             stream_SEMIC.add(SEMIC217);
< 
<             // JavaScript.g:1356:13: (ex1= expression )?
<             int alt60=2;
<             int LA60_0 = input.LA(1);
< 
<             if ( ((LA60_0>=NULL && LA60_0<=FALSE)||LA60_0==DELETE||LA60_0==FUNCTION||LA60_0==NEW||LA60_0==THIS||LA60_0==TYPEOF||LA60_0==VOID||LA60_0==LBRACE||LA60_0==LPAREN||LA60_0==LBRACK||(LA60_0>=ADD && LA60_0<=SUB)||(LA60_0>=INC && LA60_0<=DEC)||(LA60_0>=NOT && LA60_0<=INV)||(LA60_0>=Identifier && LA60_0<=StringLiteral)||LA60_0==RegularExpressionLiteral||(LA60_0>=DecimalLiteral && LA60_0<=HexIntegerLiteral)) ) {
<                 alt60=1;
<             }
<             switch (alt60) {
<                 case 1 :
<                     // JavaScript.g:1356:13: ex1= expression
<                     {
<                     pushFollow(FOLLOW_expression_in_forControlSemic5236);
<                     ex1=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(ex1.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
<             SEMIC218=(Token)match(input,SEMIC,FOLLOW_SEMIC_in_forControlSemic5239);  
<             stream_SEMIC.add(SEMIC218);
< 
<             // JavaScript.g:1356:35: (ex2= expression )?
<             int alt61=2;
<             int LA61_0 = input.LA(1);
< 
<             if ( ((LA61_0>=NULL && LA61_0<=FALSE)||LA61_0==DELETE||LA61_0==FUNCTION||LA61_0==NEW||LA61_0==THIS||LA61_0==TYPEOF||LA61_0==VOID||LA61_0==LBRACE||LA61_0==LPAREN||LA61_0==LBRACK||(LA61_0>=ADD && LA61_0<=SUB)||(LA61_0>=INC && LA61_0<=DEC)||(LA61_0>=NOT && LA61_0<=INV)||(LA61_0>=Identifier && LA61_0<=StringLiteral)||LA61_0==RegularExpressionLiteral||(LA61_0>=DecimalLiteral && LA61_0<=HexIntegerLiteral)) ) {
<                 alt61=1;
<             }
<             switch (alt61) {
<                 case 1 :
<                     // JavaScript.g:1356:35: ex2= expression
<                     {
<                     pushFollow(FOLLOW_expression_in_forControlSemic5243);
<                     ex2=expression();
< 
<                     state._fsp--;
< 
<                     stream_expression.add(ex2.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
< 
<             // AST REWRITE
<             // elements: ex2, ex1
<             // token labels: 
<             // rule labels: ex2, retval, ex1
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_ex2=new RewriteRuleSubtreeStream(adaptor,"token ex2",ex2!=null?ex2.tree:null);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
<             RewriteRuleSubtreeStream stream_ex1=new RewriteRuleSubtreeStream(adaptor,"token ex1",ex1!=null?ex1.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1357:2: -> ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<             {
<                 // JavaScript.g:1357:5: ^( FORSTEP ^( EXPR ) ^( EXPR ( $ex1)? ) ^( EXPR ( $ex2)? ) )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(FORSTEP, "FORSTEP"), root_1);
< 
<                 // JavaScript.g:1357:16: ^( EXPR )
<                 {
<                 MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                 root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                 adaptor.addChild(root_1, root_2);
<                 }
<                 // JavaScript.g:1357:26: ^( EXPR ( $ex1)? )
<                 {
<                 MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                 root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                 // JavaScript.g:1357:34: ( $ex1)?
<                 if ( stream_ex1.hasNext() ) {
<                     adaptor.addChild(root_2, stream_ex1.nextTree());
< 
<                 }
<                 stream_ex1.reset();
< 
<                 adaptor.addChild(root_1, root_2);
<                 }
<                 // JavaScript.g:1357:42: ^( EXPR ( $ex2)? )
<                 {
<                 MyAstNode root_2 = (MyAstNode)adaptor.nil();
<                 root_2 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(EXPR, "EXPR"), root_2);
< 
<                 // JavaScript.g:1357:50: ( $ex2)?
<                 if ( stream_ex2.hasNext() ) {
<                     adaptor.addChild(root_2, stream_ex2.nextTree());
< 
<                 }
<                 stream_ex2.reset();
< 
<                 adaptor.addChild(root_1, root_2);
<                 }
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "forControlSemic"
< 
<     public static class continueStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "continueStatement"
<     // JavaScript.g:1369:1: continueStatement : CONTINUE ( Identifier )? semic ;
<     public final JavaScriptParser.continueStatement_return continueStatement() throws RecognitionException {
<         JavaScriptParser.continueStatement_return retval = new JavaScriptParser.continueStatement_return();
<         retval.start = input.LT(1);
<         int continueStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token CONTINUE219=null;
<         Token Identifier220=null;
<         JavaScriptParser.semic_return semic221 = null;
< 
< 
<         MyAstNode CONTINUE219_tree=null;
<         MyAstNode Identifier220_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 65) ) { return retval; }
<             // JavaScript.g:1370:2: ( CONTINUE ( Identifier )? semic )
<             // JavaScript.g:1370:4: CONTINUE ( Identifier )? semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             CONTINUE219=(Token)match(input,CONTINUE,FOLLOW_CONTINUE_in_continueStatement5297); 
<             CONTINUE219_tree = (MyAstNode)adaptor.create(CONTINUE219);
<             root_0 = (MyAstNode)adaptor.becomeRoot(CONTINUE219_tree, root_0);
< 
<              if (input.LA(1) == Identifier) promoteEOL(null); 
<             // JavaScript.g:1370:67: ( Identifier )?
<             int alt62=2;
<             int LA62_0 = input.LA(1);
< 
<             if ( (LA62_0==Identifier) ) {
<                 alt62=1;
<             }
<             switch (alt62) {
<                 case 1 :
<                     // JavaScript.g:1370:67: Identifier
<                     {
<                     Identifier220=(Token)match(input,Identifier,FOLLOW_Identifier_in_continueStatement5302); 
<                     Identifier220_tree = (MyAstNode)adaptor.create(Identifier220);
<                     adaptor.addChild(root_0, Identifier220_tree);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_semic_in_continueStatement5305);
<             semic221=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "continueStatement"
< 
<     public static class breakStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "breakStatement"
<     // JavaScript.g:1382:1: breakStatement : BREAK ( Identifier )? semic ;
<     public final JavaScriptParser.breakStatement_return breakStatement() throws RecognitionException {
<         JavaScriptParser.breakStatement_return retval = new JavaScriptParser.breakStatement_return();
<         retval.start = input.LT(1);
<         int breakStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token BREAK222=null;
<         Token Identifier223=null;
<         JavaScriptParser.semic_return semic224 = null;
< 
< 
<         MyAstNode BREAK222_tree=null;
<         MyAstNode Identifier223_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 66) ) { return retval; }
<             // JavaScript.g:1383:2: ( BREAK ( Identifier )? semic )
<             // JavaScript.g:1383:4: BREAK ( Identifier )? semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             BREAK222=(Token)match(input,BREAK,FOLLOW_BREAK_in_breakStatement5324); 
<             BREAK222_tree = (MyAstNode)adaptor.create(BREAK222);
<             root_0 = (MyAstNode)adaptor.becomeRoot(BREAK222_tree, root_0);
< 
<              if (input.LA(1) == Identifier) promoteEOL(null); 
<             // JavaScript.g:1383:64: ( Identifier )?
<             int alt63=2;
<             int LA63_0 = input.LA(1);
< 
<             if ( (LA63_0==Identifier) ) {
<                 alt63=1;
<             }
<             switch (alt63) {
<                 case 1 :
<                     // JavaScript.g:1383:64: Identifier
<                     {
<                     Identifier223=(Token)match(input,Identifier,FOLLOW_Identifier_in_breakStatement5329); 
<                     Identifier223_tree = (MyAstNode)adaptor.create(Identifier223);
<                     adaptor.addChild(root_0, Identifier223_tree);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_semic_in_breakStatement5332);
<             semic224=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "breakStatement"
< 
<     public static class returnStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "returnStatement"
<     // JavaScript.g:1403:1: returnStatement : RETURN ( expression )? semic ;
<     public final JavaScriptParser.returnStatement_return returnStatement() throws RecognitionException {
<         JavaScriptParser.returnStatement_return retval = new JavaScriptParser.returnStatement_return();
<         retval.start = input.LT(1);
<         int returnStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token RETURN225=null;
<         JavaScriptParser.expression_return expression226 = null;
< 
<         JavaScriptParser.semic_return semic227 = null;
< 
< 
<         MyAstNode RETURN225_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 67) ) { return retval; }
<             // JavaScript.g:1404:2: ( RETURN ( expression )? semic )
<             // JavaScript.g:1404:4: RETURN ( expression )? semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             RETURN225=(Token)match(input,RETURN,FOLLOW_RETURN_in_returnStatement5351); 
<             RETURN225_tree = (MyAstNode)adaptor.create(RETURN225);
<             root_0 = (MyAstNode)adaptor.becomeRoot(RETURN225_tree, root_0);
< 
<              promoteEOL(null); 
<             // JavaScript.g:1404:34: ( expression )?
<             int alt64=2;
<             int LA64_0 = input.LA(1);
< 
<             if ( ((LA64_0>=NULL && LA64_0<=FALSE)||LA64_0==DELETE||LA64_0==FUNCTION||LA64_0==NEW||LA64_0==THIS||LA64_0==TYPEOF||LA64_0==VOID||LA64_0==LBRACE||LA64_0==LPAREN||LA64_0==LBRACK||(LA64_0>=ADD && LA64_0<=SUB)||(LA64_0>=INC && LA64_0<=DEC)||(LA64_0>=NOT && LA64_0<=INV)||(LA64_0>=Identifier && LA64_0<=StringLiteral)||LA64_0==RegularExpressionLiteral||(LA64_0>=DecimalLiteral && LA64_0<=HexIntegerLiteral)) ) {
<                 alt64=1;
<             }
<             switch (alt64) {
<                 case 1 :
<                     // JavaScript.g:1404:34: expression
<                     {
<                     pushFollow(FOLLOW_expression_in_returnStatement5356);
<                     expression226=expression();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, expression226.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_semic_in_returnStatement5359);
<             semic227=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "returnStatement"
< 
<     public static class withStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "withStatement"
<     // JavaScript.g:1411:1: withStatement : WITH LPAREN expression RPAREN statement ;
<     public final JavaScriptParser.withStatement_return withStatement() throws RecognitionException {
<         JavaScriptParser.withStatement_return retval = new JavaScriptParser.withStatement_return();
<         retval.start = input.LT(1);
<         int withStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token WITH228=null;
<         Token LPAREN229=null;
<         Token RPAREN231=null;
<         JavaScriptParser.expression_return expression230 = null;
< 
<         JavaScriptParser.statement_return statement232 = null;
< 
< 
<         MyAstNode WITH228_tree=null;
<         MyAstNode LPAREN229_tree=null;
<         MyAstNode RPAREN231_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 68) ) { return retval; }
<             // JavaScript.g:1412:2: ( WITH LPAREN expression RPAREN statement )
<             // JavaScript.g:1412:4: WITH LPAREN expression RPAREN statement
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             WITH228=(Token)match(input,WITH,FOLLOW_WITH_in_withStatement5376); 
<             WITH228_tree = (MyAstNode)adaptor.create(WITH228);
<             root_0 = (MyAstNode)adaptor.becomeRoot(WITH228_tree, root_0);
< 
<             LPAREN229=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_withStatement5379); 
<             pushFollow(FOLLOW_expression_in_withStatement5382);
<             expression230=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression230.getTree());
<             RPAREN231=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_withStatement5384); 
<             pushFollow(FOLLOW_statement_in_withStatement5387);
<             statement232=statement();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, statement232.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "withStatement"
< 
<     public static class switchStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "switchStatement"
<     // JavaScript.g:1419:1: switchStatement : SWITCH LPAREN expression RPAREN LBRACE ({...}? => defaultClause | caseClause )* RBRACE -> ^( SWITCH expression ( defaultClause )? ( caseClause )* ) ;
<     public final JavaScriptParser.switchStatement_return switchStatement() throws RecognitionException {
<         JavaScriptParser.switchStatement_return retval = new JavaScriptParser.switchStatement_return();
<         retval.start = input.LT(1);
<         int switchStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token SWITCH233=null;
<         Token LPAREN234=null;
<         Token RPAREN236=null;
<         Token LBRACE237=null;
<         Token RBRACE240=null;
<         JavaScriptParser.expression_return expression235 = null;
< 
<         JavaScriptParser.defaultClause_return defaultClause238 = null;
< 
<         JavaScriptParser.caseClause_return caseClause239 = null;
< 
< 
<         MyAstNode SWITCH233_tree=null;
<         MyAstNode LPAREN234_tree=null;
<         MyAstNode RPAREN236_tree=null;
<         MyAstNode LBRACE237_tree=null;
<         MyAstNode RBRACE240_tree=null;
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_SWITCH=new RewriteRuleTokenStream(adaptor,"token SWITCH");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_caseClause=new RewriteRuleSubtreeStream(adaptor,"rule caseClause");
<         RewriteRuleSubtreeStream stream_defaultClause=new RewriteRuleSubtreeStream(adaptor,"rule defaultClause");
<         RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
< 
<         	int defaultClauseCount = 0;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 69) ) { return retval; }
<             // JavaScript.g:1424:2: ( SWITCH LPAREN expression RPAREN LBRACE ({...}? => defaultClause | caseClause )* RBRACE -> ^( SWITCH expression ( defaultClause )? ( caseClause )* ) )
<             // JavaScript.g:1424:4: SWITCH LPAREN expression RPAREN LBRACE ({...}? => defaultClause | caseClause )* RBRACE
<             {
<             SWITCH233=(Token)match(input,SWITCH,FOLLOW_SWITCH_in_switchStatement5408);  
<             stream_SWITCH.add(SWITCH233);
< 
<             LPAREN234=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_switchStatement5410);  
<             stream_LPAREN.add(LPAREN234);
< 
<             pushFollow(FOLLOW_expression_in_switchStatement5412);
<             expression235=expression();
< 
<             state._fsp--;
< 
<             stream_expression.add(expression235.getTree());
<             RPAREN236=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_switchStatement5414);  
<             stream_RPAREN.add(RPAREN236);
< 
<             LBRACE237=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_switchStatement5416);  
<             stream_LBRACE.add(LBRACE237);
< 
<             // JavaScript.g:1424:43: ({...}? => defaultClause | caseClause )*
<             loop65:
<             do {
<                 int alt65=3;
<                 int LA65_0 = input.LA(1);
< 
<                 if ( (LA65_0==DEFAULT) && (( defaultClauseCount == 0 ))) {
<                     alt65=1;
<                 }
<                 else if ( (LA65_0==CASE) ) {
<                     alt65=2;
<                 }
< 
< 
<                 switch (alt65) {
<             	case 1 :
<             	    // JavaScript.g:1424:45: {...}? => defaultClause
<             	    {
<             	    if ( !(( defaultClauseCount == 0 )) ) {
<             	        throw new FailedPredicateException(input, "switchStatement", " defaultClauseCount == 0 ");
<             	    }
<             	    pushFollow(FOLLOW_defaultClause_in_switchStatement5423);
<             	    defaultClause238=defaultClause();
< 
<             	    state._fsp--;
< 
<             	    stream_defaultClause.add(defaultClause238.getTree());
<             	     defaultClauseCount++; 
< 
<             	    }
<             	    break;
<             	case 2 :
<             	    // JavaScript.g:1424:118: caseClause
<             	    {
<             	    pushFollow(FOLLOW_caseClause_in_switchStatement5429);
<             	    caseClause239=caseClause();
< 
<             	    state._fsp--;
< 
<             	    stream_caseClause.add(caseClause239.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop65;
<                 }
<             } while (true);
< 
<             RBRACE240=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_switchStatement5434);  
<             stream_RBRACE.add(RBRACE240);
< 
< 
< 
<             // AST REWRITE
<             // elements: defaultClause, SWITCH, expression, caseClause
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1425:2: -> ^( SWITCH expression ( defaultClause )? ( caseClause )* )
<             {
<                 // JavaScript.g:1425:5: ^( SWITCH expression ( defaultClause )? ( caseClause )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_SWITCH.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_expression.nextTree());
<                 // JavaScript.g:1425:26: ( defaultClause )?
<                 if ( stream_defaultClause.hasNext() ) {
<                     adaptor.addChild(root_1, stream_defaultClause.nextTree());
< 
<                 }
<                 stream_defaultClause.reset();
<                 // JavaScript.g:1425:41: ( caseClause )*
<                 while ( stream_caseClause.hasNext() ) {
<                     adaptor.addChild(root_1, stream_caseClause.nextTree());
< 
<                 }
<                 stream_caseClause.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "switchStatement"
< 
<     public static class caseClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "caseClause"
<     // JavaScript.g:1428:1: caseClause : CASE expression COLON ( statement )* ;
<     public final JavaScriptParser.caseClause_return caseClause() throws RecognitionException {
<         JavaScriptParser.caseClause_return retval = new JavaScriptParser.caseClause_return();
<         retval.start = input.LT(1);
<         int caseClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token CASE241=null;
<         Token COLON243=null;
<         JavaScriptParser.expression_return expression242 = null;
< 
<         JavaScriptParser.statement_return statement244 = null;
< 
< 
<         MyAstNode CASE241_tree=null;
<         MyAstNode COLON243_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 70) ) { return retval; }
<             // JavaScript.g:1429:2: ( CASE expression COLON ( statement )* )
<             // JavaScript.g:1429:4: CASE expression COLON ( statement )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             CASE241=(Token)match(input,CASE,FOLLOW_CASE_in_caseClause5462); 
<             CASE241_tree = (MyAstNode)adaptor.create(CASE241);
<             root_0 = (MyAstNode)adaptor.becomeRoot(CASE241_tree, root_0);
< 
<             pushFollow(FOLLOW_expression_in_caseClause5465);
<             expression242=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression242.getTree());
<             COLON243=(Token)match(input,COLON,FOLLOW_COLON_in_caseClause5467); 
<             // JavaScript.g:1429:28: ( statement )*
<             loop66:
<             do {
<                 int alt66=2;
<                 int LA66_0 = input.LA(1);
< 
<                 if ( ((LA66_0>=NULL && LA66_0<=BREAK)||LA66_0==CONTINUE||(LA66_0>=DELETE && LA66_0<=DO)||(LA66_0>=FOR && LA66_0<=IF)||(LA66_0>=NEW && LA66_0<=WITH)||LA66_0==LBRACE||LA66_0==LPAREN||LA66_0==LBRACK||LA66_0==SEMIC||(LA66_0>=ADD && LA66_0<=SUB)||(LA66_0>=INC && LA66_0<=DEC)||(LA66_0>=NOT && LA66_0<=INV)||(LA66_0>=Identifier && LA66_0<=StringLiteral)||LA66_0==RegularExpressionLiteral||(LA66_0>=DecimalLiteral && LA66_0<=HexIntegerLiteral)) ) {
<                     alt66=1;
<                 }
< 
< 
<                 switch (alt66) {
<             	case 1 :
<             	    // JavaScript.g:1429:28: statement
<             	    {
<             	    pushFollow(FOLLOW_statement_in_caseClause5470);
<             	    statement244=statement();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, statement244.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop66;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "caseClause"
< 
<     public static class defaultClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "defaultClause"
<     // JavaScript.g:1432:1: defaultClause : DEFAULT COLON ( statement )* ;
<     public final JavaScriptParser.defaultClause_return defaultClause() throws RecognitionException {
<         JavaScriptParser.defaultClause_return retval = new JavaScriptParser.defaultClause_return();
<         retval.start = input.LT(1);
<         int defaultClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token DEFAULT245=null;
<         Token COLON246=null;
<         JavaScriptParser.statement_return statement247 = null;
< 
< 
<         MyAstNode DEFAULT245_tree=null;
<         MyAstNode COLON246_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 71) ) { return retval; }
<             // JavaScript.g:1433:2: ( DEFAULT COLON ( statement )* )
<             // JavaScript.g:1433:4: DEFAULT COLON ( statement )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             DEFAULT245=(Token)match(input,DEFAULT,FOLLOW_DEFAULT_in_defaultClause5483); 
<             DEFAULT245_tree = (MyAstNode)adaptor.create(DEFAULT245);
<             root_0 = (MyAstNode)adaptor.becomeRoot(DEFAULT245_tree, root_0);
< 
<             COLON246=(Token)match(input,COLON,FOLLOW_COLON_in_defaultClause5486); 
<             // JavaScript.g:1433:20: ( statement )*
<             loop67:
<             do {
<                 int alt67=2;
<                 int LA67_0 = input.LA(1);
< 
<                 if ( ((LA67_0>=NULL && LA67_0<=BREAK)||LA67_0==CONTINUE||(LA67_0>=DELETE && LA67_0<=DO)||(LA67_0>=FOR && LA67_0<=IF)||(LA67_0>=NEW && LA67_0<=WITH)||LA67_0==LBRACE||LA67_0==LPAREN||LA67_0==LBRACK||LA67_0==SEMIC||(LA67_0>=ADD && LA67_0<=SUB)||(LA67_0>=INC && LA67_0<=DEC)||(LA67_0>=NOT && LA67_0<=INV)||(LA67_0>=Identifier && LA67_0<=StringLiteral)||LA67_0==RegularExpressionLiteral||(LA67_0>=DecimalLiteral && LA67_0<=HexIntegerLiteral)) ) {
<                     alt67=1;
<                 }
< 
< 
<                 switch (alt67) {
<             	case 1 :
<             	    // JavaScript.g:1433:20: statement
<             	    {
<             	    pushFollow(FOLLOW_statement_in_defaultClause5489);
<             	    statement247=statement();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, statement247.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop67;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "defaultClause"
< 
<     public static class labelledStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "labelledStatement"
<     // JavaScript.g:1440:1: labelledStatement : Identifier COLON statement -> ^( LABELLED Identifier statement ) ;
<     public final JavaScriptParser.labelledStatement_return labelledStatement() throws RecognitionException {
<         JavaScriptParser.labelledStatement_return retval = new JavaScriptParser.labelledStatement_return();
<         retval.start = input.LT(1);
<         int labelledStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token Identifier248=null;
<         Token COLON249=null;
<         JavaScriptParser.statement_return statement250 = null;
< 
< 
<         MyAstNode Identifier248_tree=null;
<         MyAstNode COLON249_tree=null;
<         RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 72) ) { return retval; }
<             // JavaScript.g:1441:2: ( Identifier COLON statement -> ^( LABELLED Identifier statement ) )
<             // JavaScript.g:1441:4: Identifier COLON statement
<             {
<             Identifier248=(Token)match(input,Identifier,FOLLOW_Identifier_in_labelledStatement5506);  
<             stream_Identifier.add(Identifier248);
< 
<             COLON249=(Token)match(input,COLON,FOLLOW_COLON_in_labelledStatement5508);  
<             stream_COLON.add(COLON249);
< 
<             pushFollow(FOLLOW_statement_in_labelledStatement5510);
<             statement250=statement();
< 
<             state._fsp--;
< 
<             stream_statement.add(statement250.getTree());
< 
< 
<             // AST REWRITE
<             // elements: statement, Identifier
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1442:2: -> ^( LABELLED Identifier statement )
<             {
<                 // JavaScript.g:1442:5: ^( LABELLED Identifier statement )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(LABELLED, "LABELLED"), root_1);
< 
<                 adaptor.addChild(root_1, stream_Identifier.nextNode());
<                 adaptor.addChild(root_1, stream_statement.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "labelledStatement"
< 
<     public static class throwStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "throwStatement"
<     // JavaScript.g:1464:1: throwStatement : THROW expression semic ;
<     public final JavaScriptParser.throwStatement_return throwStatement() throws RecognitionException {
<         JavaScriptParser.throwStatement_return retval = new JavaScriptParser.throwStatement_return();
<         retval.start = input.LT(1);
<         int throwStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token THROW251=null;
<         JavaScriptParser.expression_return expression252 = null;
< 
<         JavaScriptParser.semic_return semic253 = null;
< 
< 
<         MyAstNode THROW251_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 73) ) { return retval; }
<             // JavaScript.g:1465:2: ( THROW expression semic )
<             // JavaScript.g:1465:4: THROW expression semic
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             THROW251=(Token)match(input,THROW,FOLLOW_THROW_in_throwStatement5541); 
<             THROW251_tree = (MyAstNode)adaptor.create(THROW251);
<             root_0 = (MyAstNode)adaptor.becomeRoot(THROW251_tree, root_0);
< 
<              promoteEOL(null); 
<             pushFollow(FOLLOW_expression_in_throwStatement5546);
<             expression252=expression();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, expression252.getTree());
<             pushFollow(FOLLOW_semic_in_throwStatement5548);
<             semic253=semic();
< 
<             state._fsp--;
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "throwStatement"
< 
<     public static class tryStatement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "tryStatement"
<     // JavaScript.g:1472:1: tryStatement : TRY block ( catchClause ( finallyClause )? | finallyClause ) ;
<     public final JavaScriptParser.tryStatement_return tryStatement() throws RecognitionException {
<         JavaScriptParser.tryStatement_return retval = new JavaScriptParser.tryStatement_return();
<         retval.start = input.LT(1);
<         int tryStatement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token TRY254=null;
<         JavaScriptParser.block_return block255 = null;
< 
<         JavaScriptParser.catchClause_return catchClause256 = null;
< 
<         JavaScriptParser.finallyClause_return finallyClause257 = null;
< 
<         JavaScriptParser.finallyClause_return finallyClause258 = null;
< 
< 
<         MyAstNode TRY254_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 74) ) { return retval; }
<             // JavaScript.g:1473:2: ( TRY block ( catchClause ( finallyClause )? | finallyClause ) )
<             // JavaScript.g:1473:4: TRY block ( catchClause ( finallyClause )? | finallyClause )
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             TRY254=(Token)match(input,TRY,FOLLOW_TRY_in_tryStatement5565); 
<             TRY254_tree = (MyAstNode)adaptor.create(TRY254);
<             root_0 = (MyAstNode)adaptor.becomeRoot(TRY254_tree, root_0);
< 
<             pushFollow(FOLLOW_block_in_tryStatement5568);
<             block255=block();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, block255.getTree());
<             // JavaScript.g:1473:15: ( catchClause ( finallyClause )? | finallyClause )
<             int alt69=2;
<             int LA69_0 = input.LA(1);
< 
<             if ( (LA69_0==CATCH) ) {
<                 alt69=1;
<             }
<             else if ( (LA69_0==FINALLY) ) {
<                 alt69=2;
<             }
<             else {
<                 NoViableAltException nvae =
<                     new NoViableAltException("", 69, 0, input);
< 
<                 throw nvae;
<             }
<             switch (alt69) {
<                 case 1 :
<                     // JavaScript.g:1473:17: catchClause ( finallyClause )?
<                     {
<                     pushFollow(FOLLOW_catchClause_in_tryStatement5572);
<                     catchClause256=catchClause();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, catchClause256.getTree());
<                     // JavaScript.g:1473:29: ( finallyClause )?
<                     int alt68=2;
<                     int LA68_0 = input.LA(1);
< 
<                     if ( (LA68_0==FINALLY) ) {
<                         alt68=1;
<                     }
<                     switch (alt68) {
<                         case 1 :
<                             // JavaScript.g:1473:29: finallyClause
<                             {
<                             pushFollow(FOLLOW_finallyClause_in_tryStatement5574);
<                             finallyClause257=finallyClause();
< 
<                             state._fsp--;
< 
<                             adaptor.addChild(root_0, finallyClause257.getTree());
< 
<                             }
<                             break;
< 
<                     }
< 
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1473:46: finallyClause
<                     {
<                     pushFollow(FOLLOW_finallyClause_in_tryStatement5579);
<                     finallyClause258=finallyClause();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, finallyClause258.getTree());
< 
<                     }
<                     break;
< 
<             }
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "tryStatement"
< 
<     public static class catchClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "catchClause"
<     // JavaScript.g:1476:1: catchClause : CATCH LPAREN Identifier RPAREN block ;
<     public final JavaScriptParser.catchClause_return catchClause() throws RecognitionException {
<         JavaScriptParser.catchClause_return retval = new JavaScriptParser.catchClause_return();
<         retval.start = input.LT(1);
<         int catchClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token CATCH259=null;
<         Token LPAREN260=null;
<         Token Identifier261=null;
<         Token RPAREN262=null;
<         JavaScriptParser.block_return block263 = null;
< 
< 
<         MyAstNode CATCH259_tree=null;
<         MyAstNode LPAREN260_tree=null;
<         MyAstNode Identifier261_tree=null;
<         MyAstNode RPAREN262_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 75) ) { return retval; }
<             // JavaScript.g:1477:2: ( CATCH LPAREN Identifier RPAREN block )
<             // JavaScript.g:1477:4: CATCH LPAREN Identifier RPAREN block
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             CATCH259=(Token)match(input,CATCH,FOLLOW_CATCH_in_catchClause5593); 
<             CATCH259_tree = (MyAstNode)adaptor.create(CATCH259);
<             root_0 = (MyAstNode)adaptor.becomeRoot(CATCH259_tree, root_0);
< 
<             LPAREN260=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_catchClause5596); 
<             Identifier261=(Token)match(input,Identifier,FOLLOW_Identifier_in_catchClause5599); 
<             Identifier261_tree = (MyAstNode)adaptor.create(Identifier261);
<             adaptor.addChild(root_0, Identifier261_tree);
< 
<             RPAREN262=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_catchClause5601); 
<             pushFollow(FOLLOW_block_in_catchClause5604);
<             block263=block();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, block263.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "catchClause"
< 
<     public static class finallyClause_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "finallyClause"
<     // JavaScript.g:1480:1: finallyClause : FINALLY block ;
<     public final JavaScriptParser.finallyClause_return finallyClause() throws RecognitionException {
<         JavaScriptParser.finallyClause_return retval = new JavaScriptParser.finallyClause_return();
<         retval.start = input.LT(1);
<         int finallyClause_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token FINALLY264=null;
<         JavaScriptParser.block_return block265 = null;
< 
< 
<         MyAstNode FINALLY264_tree=null;
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 76) ) { return retval; }
<             // JavaScript.g:1481:2: ( FINALLY block )
<             // JavaScript.g:1481:4: FINALLY block
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             FINALLY264=(Token)match(input,FINALLY,FOLLOW_FINALLY_in_finallyClause5616); 
<             FINALLY264_tree = (MyAstNode)adaptor.create(FINALLY264);
<             root_0 = (MyAstNode)adaptor.becomeRoot(FINALLY264_tree, root_0);
< 
<             pushFollow(FOLLOW_block_in_finallyClause5619);
<             block265=block();
< 
<             state._fsp--;
< 
<             adaptor.addChild(root_0, block265.getTree());
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "finallyClause"
< 
<     public static class functionDeclaration_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "functionDeclaration"
<     // JavaScript.g:1494:1: functionDeclaration : FUNCTION name= Identifier formalParameterList functionBody -> ^( FUNCTION $name formalParameterList functionBody ) ;
<     public final JavaScriptParser.functionDeclaration_return functionDeclaration() throws RecognitionException {
<         JavaScriptParser.functionDeclaration_return retval = new JavaScriptParser.functionDeclaration_return();
<         retval.start = input.LT(1);
<         int functionDeclaration_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token name=null;
<         Token FUNCTION266=null;
<         JavaScriptParser.formalParameterList_return formalParameterList267 = null;
< 
<         JavaScriptParser.functionBody_return functionBody268 = null;
< 
< 
<         MyAstNode name_tree=null;
<         MyAstNode FUNCTION266_tree=null;
<         RewriteRuleTokenStream stream_FUNCTION=new RewriteRuleTokenStream(adaptor,"token FUNCTION");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleSubtreeStream stream_formalParameterList=new RewriteRuleSubtreeStream(adaptor,"rule formalParameterList");
<         RewriteRuleSubtreeStream stream_functionBody=new RewriteRuleSubtreeStream(adaptor,"rule functionBody");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 77) ) { return retval; }
<             // JavaScript.g:1495:2: ( FUNCTION name= Identifier formalParameterList functionBody -> ^( FUNCTION $name formalParameterList functionBody ) )
<             // JavaScript.g:1495:4: FUNCTION name= Identifier formalParameterList functionBody
<             {
<             FUNCTION266=(Token)match(input,FUNCTION,FOLLOW_FUNCTION_in_functionDeclaration5640);  
<             stream_FUNCTION.add(FUNCTION266);
< 
<             name=(Token)match(input,Identifier,FOLLOW_Identifier_in_functionDeclaration5644);  
<             stream_Identifier.add(name);
< 
<             pushFollow(FOLLOW_formalParameterList_in_functionDeclaration5646);
<             formalParameterList267=formalParameterList();
< 
<             state._fsp--;
< 
<             stream_formalParameterList.add(formalParameterList267.getTree());
<             pushFollow(FOLLOW_functionBody_in_functionDeclaration5648);
<             functionBody268=functionBody();
< 
<             state._fsp--;
< 
<             stream_functionBody.add(functionBody268.getTree());
< 
< 
<             // AST REWRITE
<             // elements: name, FUNCTION, functionBody, formalParameterList
<             // token labels: name
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1496:2: -> ^( FUNCTION $name formalParameterList functionBody )
<             {
<                 // JavaScript.g:1496:5: ^( FUNCTION $name formalParameterList functionBody )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_FUNCTION.nextNode(), root_1);
< 
<                 adaptor.addChild(root_1, stream_name.nextNode());
<                 adaptor.addChild(root_1, stream_formalParameterList.nextTree());
<                 adaptor.addChild(root_1, stream_functionBody.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "functionDeclaration"
< 
<     public static class functionExpression_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "functionExpression"
<     // JavaScript.g:1499:1: functionExpression : FUNCTION (name= Identifier )? formalParameterList functionBody -> ^( FUNCTION ( $name)? formalParameterList functionBody ) ;
<     public final JavaScriptParser.functionExpression_return functionExpression() throws RecognitionException {
<         JavaScriptParser.functionExpression_return retval = new JavaScriptParser.functionExpression_return();
<         retval.start = input.LT(1);
<         int functionExpression_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token name=null;
<         Token FUNCTION269=null;
<         JavaScriptParser.formalParameterList_return formalParameterList270 = null;
< 
<         JavaScriptParser.functionBody_return functionBody271 = null;
< 
< 
<         MyAstNode name_tree=null;
<         MyAstNode FUNCTION269_tree=null;
<         RewriteRuleTokenStream stream_FUNCTION=new RewriteRuleTokenStream(adaptor,"token FUNCTION");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
<         RewriteRuleSubtreeStream stream_formalParameterList=new RewriteRuleSubtreeStream(adaptor,"rule formalParameterList");
<         RewriteRuleSubtreeStream stream_functionBody=new RewriteRuleSubtreeStream(adaptor,"rule functionBody");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 78) ) { return retval; }
<             // JavaScript.g:1500:2: ( FUNCTION (name= Identifier )? formalParameterList functionBody -> ^( FUNCTION ( $name)? formalParameterList functionBody ) )
<             // JavaScript.g:1500:4: FUNCTION (name= Identifier )? formalParameterList functionBody
<             {
<             FUNCTION269=(Token)match(input,FUNCTION,FOLLOW_FUNCTION_in_functionExpression5675);  
<             stream_FUNCTION.add(FUNCTION269);
< 
<             // JavaScript.g:1500:17: (name= Identifier )?
<             int alt70=2;
<             int LA70_0 = input.LA(1);
< 
<             if ( (LA70_0==Identifier) ) {
<                 alt70=1;
<             }
<             switch (alt70) {
<                 case 1 :
<                     // JavaScript.g:1500:17: name= Identifier
<                     {
<                     name=(Token)match(input,Identifier,FOLLOW_Identifier_in_functionExpression5679);  
<                     stream_Identifier.add(name);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             pushFollow(FOLLOW_formalParameterList_in_functionExpression5682);
<             formalParameterList270=formalParameterList();
< 
<             state._fsp--;
< 
<             stream_formalParameterList.add(formalParameterList270.getTree());
<             pushFollow(FOLLOW_functionBody_in_functionExpression5684);
<             functionBody271=functionBody();
< 
<             state._fsp--;
< 
<             stream_functionBody.add(functionBody271.getTree());
< 
< 
<             // AST REWRITE
<             // elements: functionBody, formalParameterList, FUNCTION, name
<             // token labels: name
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1501:2: -> ^( FUNCTION ( $name)? formalParameterList functionBody )
<             {
<                 // JavaScript.g:1501:5: ^( FUNCTION ( $name)? formalParameterList functionBody )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot(stream_FUNCTION.nextNode(), root_1);
< 
<                 // JavaScript.g:1501:17: ( $name)?
<                 if ( stream_name.hasNext() ) {
<                     adaptor.addChild(root_1, stream_name.nextNode());
< 
<                 }
<                 stream_name.reset();
<                 adaptor.addChild(root_1, stream_formalParameterList.nextTree());
<                 adaptor.addChild(root_1, stream_functionBody.nextTree());
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "functionExpression"
< 
<     public static class formalParameterList_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "formalParameterList"
<     // JavaScript.g:1504:1: formalParameterList : LPAREN (args+= Identifier ( COMMA args+= Identifier )* )? RPAREN -> ^( ARGS ( $args)* ) ;
<     public final JavaScriptParser.formalParameterList_return formalParameterList() throws RecognitionException {
<         JavaScriptParser.formalParameterList_return retval = new JavaScriptParser.formalParameterList_return();
<         retval.start = input.LT(1);
<         int formalParameterList_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token LPAREN272=null;
<         Token COMMA273=null;
<         Token RPAREN274=null;
<         Token args=null;
<         List list_args=null;
< 
<         MyAstNode LPAREN272_tree=null;
<         MyAstNode COMMA273_tree=null;
<         MyAstNode RPAREN274_tree=null;
<         MyAstNode args_tree=null;
<         RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
<         RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
<         RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
<         RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 79) ) { return retval; }
<             // JavaScript.g:1505:2: ( LPAREN (args+= Identifier ( COMMA args+= Identifier )* )? RPAREN -> ^( ARGS ( $args)* ) )
<             // JavaScript.g:1505:4: LPAREN (args+= Identifier ( COMMA args+= Identifier )* )? RPAREN
<             {
<             LPAREN272=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_formalParameterList5712);  
<             stream_LPAREN.add(LPAREN272);
< 
<             // JavaScript.g:1505:11: (args+= Identifier ( COMMA args+= Identifier )* )?
<             int alt72=2;
<             int LA72_0 = input.LA(1);
< 
<             if ( (LA72_0==Identifier) ) {
<                 alt72=1;
<             }
<             switch (alt72) {
<                 case 1 :
<                     // JavaScript.g:1505:13: args+= Identifier ( COMMA args+= Identifier )*
<                     {
<                     args=(Token)match(input,Identifier,FOLLOW_Identifier_in_formalParameterList5718);  
<                     stream_Identifier.add(args);
< 
<                     if (list_args==null) list_args=new ArrayList();
<                     list_args.add(args);
< 
<                     // JavaScript.g:1505:30: ( COMMA args+= Identifier )*
<                     loop71:
<                     do {
<                         int alt71=2;
<                         int LA71_0 = input.LA(1);
< 
<                         if ( (LA71_0==COMMA) ) {
<                             alt71=1;
<                         }
< 
< 
<                         switch (alt71) {
<                     	case 1 :
<                     	    // JavaScript.g:1505:32: COMMA args+= Identifier
<                     	    {
<                     	    COMMA273=(Token)match(input,COMMA,FOLLOW_COMMA_in_formalParameterList5722);  
<                     	    stream_COMMA.add(COMMA273);
< 
<                     	    args=(Token)match(input,Identifier,FOLLOW_Identifier_in_formalParameterList5726);  
<                     	    stream_Identifier.add(args);
< 
<                     	    if (list_args==null) list_args=new ArrayList();
<                     	    list_args.add(args);
< 
< 
<                     	    }
<                     	    break;
< 
<                     	default :
<                     	    break loop71;
<                         }
<                     } while (true);
< 
< 
<                     }
<                     break;
< 
<             }
< 
<             RPAREN274=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_formalParameterList5734);  
<             stream_RPAREN.add(RPAREN274);
< 
< 
< 
<             // AST REWRITE
<             // elements: args
<             // token labels: 
<             // rule labels: retval
<             // token list labels: args
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleTokenStream stream_args=new RewriteRuleTokenStream(adaptor,"token args", list_args);
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1506:2: -> ^( ARGS ( $args)* )
<             {
<                 // JavaScript.g:1506:5: ^( ARGS ( $args)* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(ARGS, "ARGS"), root_1);
< 
<                 // JavaScript.g:1506:13: ( $args)*
<                 while ( stream_args.hasNext() ) {
<                     adaptor.addChild(root_1, stream_args.nextNode());
< 
<                 }
<                 stream_args.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "formalParameterList"
< 
<     public static class functionBody_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "functionBody"
<     // JavaScript.g:1509:1: functionBody : lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) ;
<     public final JavaScriptParser.functionBody_return functionBody() throws RecognitionException {
<         JavaScriptParser.functionBody_return retval = new JavaScriptParser.functionBody_return();
<         retval.start = input.LT(1);
<         int functionBody_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         Token lb=null;
<         Token RBRACE276=null;
<         JavaScriptParser.sourceElement_return sourceElement275 = null;
< 
< 
<         MyAstNode lb_tree=null;
<         MyAstNode RBRACE276_tree=null;
<         RewriteRuleTokenStream stream_RBRACE=new RewriteRuleTokenStream(adaptor,"token RBRACE");
<         RewriteRuleTokenStream stream_LBRACE=new RewriteRuleTokenStream(adaptor,"token LBRACE");
<         RewriteRuleSubtreeStream stream_sourceElement=new RewriteRuleSubtreeStream(adaptor,"rule sourceElement");
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 80) ) { return retval; }
<             // JavaScript.g:1510:2: (lb= LBRACE ( sourceElement )* RBRACE -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* ) )
<             // JavaScript.g:1510:4: lb= LBRACE ( sourceElement )* RBRACE
<             {
<             lb=(Token)match(input,LBRACE,FOLLOW_LBRACE_in_functionBody5760);  
<             stream_LBRACE.add(lb);
< 
<             // JavaScript.g:1510:14: ( sourceElement )*
<             loop73:
<             do {
<                 int alt73=2;
<                 int LA73_0 = input.LA(1);
< 
<                 if ( ((LA73_0>=NULL && LA73_0<=BREAK)||LA73_0==CONTINUE||(LA73_0>=DELETE && LA73_0<=DO)||(LA73_0>=FOR && LA73_0<=IF)||(LA73_0>=NEW && LA73_0<=WITH)||LA73_0==LBRACE||LA73_0==LPAREN||LA73_0==LBRACK||LA73_0==SEMIC||(LA73_0>=ADD && LA73_0<=SUB)||(LA73_0>=INC && LA73_0<=DEC)||(LA73_0>=NOT && LA73_0<=INV)||(LA73_0>=Identifier && LA73_0<=StringLiteral)||LA73_0==RegularExpressionLiteral||(LA73_0>=DecimalLiteral && LA73_0<=HexIntegerLiteral)) ) {
<                     alt73=1;
<                 }
< 
< 
<                 switch (alt73) {
<             	case 1 :
<             	    // JavaScript.g:1510:14: sourceElement
<             	    {
<             	    pushFollow(FOLLOW_sourceElement_in_functionBody5762);
<             	    sourceElement275=sourceElement();
< 
<             	    state._fsp--;
< 
<             	    stream_sourceElement.add(sourceElement275.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop73;
<                 }
<             } while (true);
< 
<             RBRACE276=(Token)match(input,RBRACE,FOLLOW_RBRACE_in_functionBody5765);  
<             stream_RBRACE.add(RBRACE276);
< 
< 
< 
<             // AST REWRITE
<             // elements: sourceElement
<             // token labels: 
<             // rule labels: retval
<             // token list labels: 
<             // rule list labels: 
<             retval.tree = root_0;
<             RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"token retval",retval!=null?retval.tree:null);
< 
<             root_0 = (MyAstNode)adaptor.nil();
<             // 1511:2: -> ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<             {
<                 // JavaScript.g:1511:5: ^( BLOCK[$lb, \"BLOCK\"] ( sourceElement )* )
<                 {
<                 MyAstNode root_1 = (MyAstNode)adaptor.nil();
<                 root_1 = (MyAstNode)adaptor.becomeRoot((MyAstNode)adaptor.create(BLOCK, lb, "BLOCK"), root_1);
< 
<                 // JavaScript.g:1511:28: ( sourceElement )*
<                 while ( stream_sourceElement.hasNext() ) {
<                     adaptor.addChild(root_1, stream_sourceElement.nextTree());
< 
<                 }
<                 stream_sourceElement.reset();
< 
<                 adaptor.addChild(root_0, root_1);
<                 }
< 
<             }
< 
<             retval.tree = root_0;
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "functionBody"
< 
<     public static class program_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "program"
<     // JavaScript.g:1518:1: program : ( sourceElement )* ;
<     public final JavaScriptParser.program_return program() throws RecognitionException {
<         JavaScriptParser.program_return retval = new JavaScriptParser.program_return();
<         retval.start = input.LT(1);
<         int program_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.sourceElement_return sourceElement277 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 81) ) { return retval; }
<             // JavaScript.g:1519:2: ( ( sourceElement )* )
<             // JavaScript.g:1519:4: ( sourceElement )*
<             {
<             root_0 = (MyAstNode)adaptor.nil();
< 
<             // JavaScript.g:1519:4: ( sourceElement )*
<             loop74:
<             do {
<                 int alt74=2;
<                 int LA74_0 = input.LA(1);
< 
<                 if ( ((LA74_0>=NULL && LA74_0<=BREAK)||LA74_0==CONTINUE||(LA74_0>=DELETE && LA74_0<=DO)||(LA74_0>=FOR && LA74_0<=IF)||(LA74_0>=NEW && LA74_0<=WITH)||LA74_0==LBRACE||LA74_0==LPAREN||LA74_0==LBRACK||LA74_0==SEMIC||(LA74_0>=ADD && LA74_0<=SUB)||(LA74_0>=INC && LA74_0<=DEC)||(LA74_0>=NOT && LA74_0<=INV)||(LA74_0>=Identifier && LA74_0<=StringLiteral)||LA74_0==RegularExpressionLiteral||(LA74_0>=DecimalLiteral && LA74_0<=HexIntegerLiteral)) ) {
<                     alt74=1;
<                 }
< 
< 
<                 switch (alt74) {
<             	case 1 :
<             	    // JavaScript.g:1519:4: sourceElement
<             	    {
<             	    pushFollow(FOLLOW_sourceElement_in_program5794);
<             	    sourceElement277=sourceElement();
< 
<             	    state._fsp--;
< 
<             	    adaptor.addChild(root_0, sourceElement277.getTree());
< 
<             	    }
<             	    break;
< 
<             	default :
<             	    break loop74;
<                 }
<             } while (true);
< 
< 
<             }
< 
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "program"
< 
<     public static class sourceElement_return extends ParserRuleReturnScope {
<         MyAstNode tree;
<         public Object getTree() { return tree; }
<     };
< 
<     // $ANTLR start "sourceElement"
<     // JavaScript.g:1527:1: sourceElement options {k=1; } : ({...}? functionDeclaration | statement );
<     public final JavaScriptParser.sourceElement_return sourceElement() throws RecognitionException {
<         JavaScriptParser.sourceElement_return retval = new JavaScriptParser.sourceElement_return();
<         retval.start = input.LT(1);
<         int sourceElement_StartIndex = input.index();
<         MyAstNode root_0 = null;
< 
<         JavaScriptParser.functionDeclaration_return functionDeclaration278 = null;
< 
<         JavaScriptParser.statement_return statement279 = null;
< 
< 
< 
<         try {
<             if ( state.backtracking>0 && alreadyParsedRule(input, 82) ) { return retval; }
<             // JavaScript.g:1532:2: ({...}? functionDeclaration | statement )
<             int alt75=2;
<             alt75 = dfa75.predict(input);
<             switch (alt75) {
<                 case 1 :
<                     // JavaScript.g:1532:4: {...}? functionDeclaration
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     if ( !(( input.LA(1) == FUNCTION )) ) {
<                         throw new FailedPredicateException(input, "sourceElement", " input.LA(1) == FUNCTION ");
<                     }
<                     pushFollow(FOLLOW_functionDeclaration_in_sourceElement5823);
<                     functionDeclaration278=functionDeclaration();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, functionDeclaration278.getTree());
< 
<                     }
<                     break;
<                 case 2 :
<                     // JavaScript.g:1533:4: statement
<                     {
<                     root_0 = (MyAstNode)adaptor.nil();
< 
<                     pushFollow(FOLLOW_statement_in_sourceElement5828);
<                     statement279=statement();
< 
<                     state._fsp--;
< 
<                     adaptor.addChild(root_0, statement279.getTree());
< 
<                     }
<                     break;
< 
<             }
<             retval.stop = input.LT(-1);
< 
<             retval.tree = (MyAstNode)adaptor.rulePostProcessing(root_0);
<             adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
< 
<         }
<         catch (RecognitionException re) {
<             reportError(re);
<             recover(input,re);
<     	retval.tree = (MyAstNode)adaptor.errorNode(input, retval.start, input.LT(-1), re);
< 
<         }
<         finally {
<         }
<         return retval;
<     }
<     // $ANTLR end "sourceElement"
< 
<     // Delegated rules
< 
< 
<     protected DFA44 dfa44 = new DFA44(this);
<     protected DFA45 dfa45 = new DFA45(this);
<     protected DFA75 dfa75 = new DFA75(this);
<     static final String DFA44_eotS =
<         "\44\uffff";
<     static final String DFA44_eofS =
<         "\44\uffff";
<     static final String DFA44_minS =
<         "\1\4\1\0\42\uffff";
<     static final String DFA44_maxS =
<         "\1\u00a1\1\0\42\uffff";
<     static final String DFA44_acceptS =
<         "\2\uffff\1\2\40\uffff\1\1";
<     static final String DFA44_specialS =
<         "\1\uffff\1\0\42\uffff}>";
<     static final String[] DFA44_transitionS = {
<             "\4\2\2\uffff\1\2\1\uffff\2\2\2\uffff\3\2\2\uffff\13\2\37\uffff"+
<             "\1\1\1\uffff\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff\2\2\2\uffff"+
<             "\2\2\6\uffff\2\2\66\uffff\2\2\5\uffff\1\2\3\uffff\3\2",
<             "\1\uffff",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             ""
<     };
< 
<     static final short[] DFA44_eot = DFA.unpackEncodedString(DFA44_eotS);
<     static final short[] DFA44_eof = DFA.unpackEncodedString(DFA44_eofS);
<     static final char[] DFA44_min = DFA.unpackEncodedStringToUnsignedChars(DFA44_minS);
<     static final char[] DFA44_max = DFA.unpackEncodedStringToUnsignedChars(DFA44_maxS);
<     static final short[] DFA44_accept = DFA.unpackEncodedString(DFA44_acceptS);
<     static final short[] DFA44_special = DFA.unpackEncodedString(DFA44_specialS);
<     static final short[][] DFA44_transition;
< 
<     static {
<         int numStates = DFA44_transitionS.length;
<         DFA44_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA44_transition[i] = DFA.unpackEncodedString(DFA44_transitionS[i]);
<         }
<     }
< 
<     class DFA44 extends DFA {
< 
<         public DFA44(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 44;
<             this.eot = DFA44_eot;
<             this.eof = DFA44_eof;
<             this.min = DFA44_min;
<             this.max = DFA44_max;
<             this.accept = DFA44_accept;
<             this.special = DFA44_special;
<             this.transition = DFA44_transition;
<         }
<         public String getDescription() {
<             return "1166:1: statement options {k=1; } : ({...}? block | statementTail );";
<         }
<         public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
<             TokenStream input = (TokenStream)_input;
<         	int _s = s;
<             switch ( s ) {
<                     case 0 : 
<                         int LA44_1 = input.LA(1);
< 
<                          
<                         int index44_1 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( (( input.LA(1) == LBRACE )) ) {s = 35;}
< 
<                         else if ( (true) ) {s = 2;}
< 
<                          
<                         input.seek(index44_1);
<                         if ( s>=0 ) return s;
<                         break;
<             }
<             NoViableAltException nvae =
<                 new NoViableAltException(getDescription(), 44, _s, input);
<             error(nvae);
<             throw nvae;
<         }
<     }
<     static final String DFA45_eotS =
<         "\17\uffff";
<     static final String DFA45_eofS =
<         "\4\uffff\1\3\12\uffff";
<     static final String DFA45_minS =
<         "\1\4\3\uffff\1\23\12\uffff";
<     static final String DFA45_maxS =
<         "\1\u00a1\3\uffff\1\u0092\12\uffff";
<     static final String DFA45_acceptS =
<         "\1\uffff\1\1\1\2\1\3\1\uffff\1\4\1\5\1\6\1\7\1\10\1\11\1\13\1\14"+
<         "\1\15\1\12";
<     static final String DFA45_specialS =
<         "\17\uffff}>";
<     static final String[] DFA45_transitionS = {
<             "\3\3\1\10\2\uffff\1\7\1\uffff\1\3\1\6\2\uffff\1\6\1\3\1\5\2"+
<             "\uffff\1\3\1\11\1\13\1\3\1\14\1\15\1\3\1\1\1\3\1\6\1\12\37\uffff"+
<             "\1\3\1\uffff\1\3\1\uffff\1\3\2\uffff\1\2\11\uffff\2\3\2\uffff"+
<             "\2\3\6\uffff\2\3\66\uffff\1\4\1\3\5\uffff\1\3\3\uffff\3\3",
<             "",
<             "",
<             "",
<             "\2\3\53\uffff\2\3\1\uffff\1\3\1\uffff\27\3\2\uffff\3\3\1\16"+
<             "\15\3\42\uffff\2\3",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             ""
<     };
< 
<     static final short[] DFA45_eot = DFA.unpackEncodedString(DFA45_eotS);
<     static final short[] DFA45_eof = DFA.unpackEncodedString(DFA45_eofS);
<     static final char[] DFA45_min = DFA.unpackEncodedStringToUnsignedChars(DFA45_minS);
<     static final char[] DFA45_max = DFA.unpackEncodedStringToUnsignedChars(DFA45_maxS);
<     static final short[] DFA45_accept = DFA.unpackEncodedString(DFA45_acceptS);
<     static final short[] DFA45_special = DFA.unpackEncodedString(DFA45_specialS);
<     static final short[][] DFA45_transition;
< 
<     static {
<         int numStates = DFA45_transitionS.length;
<         DFA45_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA45_transition[i] = DFA.unpackEncodedString(DFA45_transitionS[i]);
<         }
<     }
< 
<     class DFA45 extends DFA {
< 
<         public DFA45(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 45;
<             this.eot = DFA45_eot;
<             this.eof = DFA45_eof;
<             this.min = DFA45_min;
<             this.max = DFA45_max;
<             this.accept = DFA45_accept;
<             this.special = DFA45_special;
<             this.transition = DFA45_transition;
<         }
<         public String getDescription() {
<             return "1179:1: statementTail : ( variableStatement | emptyStatement | expressionStatement | ifStatement | iterationStatement | continueStatement | breakStatement | returnStatement | withStatement | labelledStatement | switchStatement | throwStatement | tryStatement );";
<         }
<     }
<     static final String DFA75_eotS =
<         "\44\uffff";
<     static final String DFA75_eofS =
<         "\44\uffff";
<     static final String DFA75_minS =
<         "\1\4\1\0\42\uffff";
<     static final String DFA75_maxS =
<         "\1\u00a1\1\0\42\uffff";
<     static final String DFA75_acceptS =
<         "\2\uffff\1\2\40\uffff\1\1";
<     static final String DFA75_specialS =
<         "\1\uffff\1\0\42\uffff}>";
<     static final String[] DFA75_transitionS = {
<             "\4\2\2\uffff\1\2\1\uffff\2\2\2\uffff\1\2\1\1\1\2\2\uffff\13"+
<             "\2\37\uffff\1\2\1\uffff\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff"+
<             "\2\2\2\uffff\2\2\6\uffff\2\2\66\uffff\2\2\5\uffff\1\2\3\uffff"+
<             "\3\2",
<             "\1\uffff",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             "",
<             ""
<     };
< 
<     static final short[] DFA75_eot = DFA.unpackEncodedString(DFA75_eotS);
<     static final short[] DFA75_eof = DFA.unpackEncodedString(DFA75_eofS);
<     static final char[] DFA75_min = DFA.unpackEncodedStringToUnsignedChars(DFA75_minS);
<     static final char[] DFA75_max = DFA.unpackEncodedStringToUnsignedChars(DFA75_maxS);
<     static final short[] DFA75_accept = DFA.unpackEncodedString(DFA75_acceptS);
<     static final short[] DFA75_special = DFA.unpackEncodedString(DFA75_specialS);
<     static final short[][] DFA75_transition;
< 
<     static {
<         int numStates = DFA75_transitionS.length;
<         DFA75_transition = new short[numStates][];
<         for (int i=0; i<numStates; i++) {
<             DFA75_transition[i] = DFA.unpackEncodedString(DFA75_transitionS[i]);
<         }
<     }
< 
<     class DFA75 extends DFA {
< 
<         public DFA75(BaseRecognizer recognizer) {
<             this.recognizer = recognizer;
<             this.decisionNumber = 75;
<             this.eot = DFA75_eot;
<             this.eof = DFA75_eof;
<             this.min = DFA75_min;
<             this.max = DFA75_max;
<             this.accept = DFA75_accept;
<             this.special = DFA75_special;
<             this.transition = DFA75_transition;
<         }
<         public String getDescription() {
<             return "1527:1: sourceElement options {k=1; } : ({...}? functionDeclaration | statement );";
<         }
<         public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
<             TokenStream input = (TokenStream)_input;
<         	int _s = s;
<             switch ( s ) {
<                     case 0 : 
<                         int LA75_1 = input.LA(1);
< 
<                          
<                         int index75_1 = input.index();
<                         input.rewind();
<                         s = -1;
<                         if ( (( input.LA(1) == FUNCTION )) ) {s = 35;}
< 
<                         else if ( (true) ) {s = 2;}
< 
<                          
<                         input.seek(index75_1);
<                         if ( s>=0 ) return s;
<                         break;
<             }
<             NoViableAltException nvae =
<                 new NoViableAltException(getDescription(), 75, _s, input);
<             error(nvae);
<             throw nvae;
<         }
<     }
<  
< 
<     public static final BitSet FOLLOW_reservedWord_in_token1756 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_token1761 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_punctuator_in_token1766 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_numericLiteral_in_token1771 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_StringLiteral_in_token1776 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_keyword_in_reservedWord1789 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_futureReservedWord_in_reservedWord1794 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NULL_in_reservedWord1799 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_booleanLiteral_in_reservedWord1804 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_keyword0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_futureReservedWord0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_punctuator0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NULL_in_literal2485 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_booleanLiteral_in_literal2490 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_numericLiteral_in_literal2495 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_StringLiteral_in_literal2500 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_RegularExpressionLiteral_in_literal2505 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_booleanLiteral0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_numericLiteral0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_THIS_in_primaryExpression3118 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_primaryExpression3123 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_literal_in_primaryExpression3128 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_arrayLiteral_in_primaryExpression3133 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_objectLiteral_in_primaryExpression3138 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_primaryExpression3145 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_primaryExpression3147 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_primaryExpression3149 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACK_in_arrayLiteral3173 = new BitSet(new long[]{0x8000000029221070L,0x000000003033009AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_arrayItem_in_arrayLiteral3177 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000090L});
<     public static final BitSet FOLLOW_COMMA_in_arrayLiteral3181 = new BitSet(new long[]{0x8000000029221070L,0x000000003033009AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_arrayItem_in_arrayLiteral3183 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000090L});
<     public static final BitSet FOLLOW_RBRACK_in_arrayLiteral3191 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_assignmentExpression_in_arrayItem3219 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACE_in_objectLiteral3251 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000001L,0x0000000380300000L});
<     public static final BitSet FOLLOW_nameValuePair_in_objectLiteral3255 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000081L});
<     public static final BitSet FOLLOW_COMMA_in_objectLiteral3259 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000380300000L});
<     public static final BitSet FOLLOW_nameValuePair_in_objectLiteral3261 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000081L});
<     public static final BitSet FOLLOW_RBRACE_in_objectLiteral3269 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_propertyName_in_nameValuePair3294 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_nameValuePair3296 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_nameValuePair3298 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_propertyName3322 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_StringLiteral_in_propertyName3327 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_numericLiteral_in_propertyName3332 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_primaryExpression_in_memberExpression3350 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_functionExpression_in_memberExpression3355 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_newExpression_in_memberExpression3360 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NEW_in_newExpression3371 = new BitSet(new long[]{0x8000000001000070L,0x000000000000000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_primaryExpression_in_newExpression3374 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NEW_in_newExpression3382 = new BitSet(new long[]{0x0000000000020000L});
<     public static final BitSet FOLLOW_functionExpression_in_newExpression3385 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_arguments3398 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000EL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_arguments3402 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_COMMA_in_arguments3406 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_arguments3408 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_RPAREN_in_arguments3416 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_memberExpression_in_leftHandSideExpression3445 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_arguments_in_leftHandSideExpression3461 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_LBRACK_in_leftHandSideExpression3482 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_leftHandSideExpression3484 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
<     public static final BitSet FOLLOW_RBRACK_in_leftHandSideExpression3486 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_DOT_in_leftHandSideExpression3505 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_leftHandSideExpression3507 = new BitSet(new long[]{0x0000000000000002L,0x000000000000002AL});
<     public static final BitSet FOLLOW_leftHandSideExpression_in_postfixExpression3542 = new BitSet(new long[]{0x0000000000000002L,0x0000000000300000L});
<     public static final BitSet FOLLOW_postfixOperator_in_postfixExpression3548 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_INC_in_postfixOperator3566 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DEC_in_postfixOperator3575 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_postfixExpression_in_unaryExpression3592 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_unaryOperator_in_unaryExpression3597 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_unaryExpression_in_unaryExpression3600 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DELETE_in_unaryOperator3612 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_VOID_in_unaryOperator3617 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_TYPEOF_in_unaryOperator3622 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_INC_in_unaryOperator3627 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DEC_in_unaryOperator3632 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_ADD_in_unaryOperator3639 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SUB_in_unaryOperator3648 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_INV_in_unaryOperator3655 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_NOT_in_unaryOperator3660 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_unaryExpression_in_multiplicativeExpression3675 = new BitSet(new long[]{0x0000000000000002L,0x00002000000C0000L});
<     public static final BitSet FOLLOW_set_in_multiplicativeExpression3679 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_unaryExpression_in_multiplicativeExpression3694 = new BitSet(new long[]{0x0000000000000002L,0x00002000000C0000L});
<     public static final BitSet FOLLOW_multiplicativeExpression_in_additiveExpression3712 = new BitSet(new long[]{0x0000000000000002L,0x0000000000030000L});
<     public static final BitSet FOLLOW_set_in_additiveExpression3716 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_multiplicativeExpression_in_additiveExpression3727 = new BitSet(new long[]{0x0000000000000002L,0x0000000000030000L});
<     public static final BitSet FOLLOW_additiveExpression_in_shiftExpression3746 = new BitSet(new long[]{0x0000000000000002L,0x0000000001C00000L});
<     public static final BitSet FOLLOW_set_in_shiftExpression3750 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_additiveExpression_in_shiftExpression3765 = new BitSet(new long[]{0x0000000000000002L,0x0000000001C00000L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpression3784 = new BitSet(new long[]{0x0000000000180002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_set_in_relationalExpression3788 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpression3815 = new BitSet(new long[]{0x0000000000180002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpressionNoIn3829 = new BitSet(new long[]{0x0000000000100002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_set_in_relationalExpressionNoIn3833 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_shiftExpression_in_relationalExpressionNoIn3856 = new BitSet(new long[]{0x0000000000100002L,0x0000000000000F00L});
<     public static final BitSet FOLLOW_relationalExpression_in_equalityExpression3875 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_set_in_equalityExpression3879 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_relationalExpression_in_equalityExpression3898 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3912 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_set_in_equalityExpressionNoIn3916 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_relationalExpressionNoIn_in_equalityExpressionNoIn3935 = new BitSet(new long[]{0x0000000000000002L,0x000000000000F000L});
<     public static final BitSet FOLLOW_equalityExpression_in_bitwiseANDExpression3955 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_AND_in_bitwiseANDExpression3959 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_equalityExpression_in_bitwiseANDExpression3962 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3976 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_AND_in_bitwiseANDExpressionNoIn3980 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_equalityExpressionNoIn_in_bitwiseANDExpressionNoIn3983 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
<     public static final BitSet FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression3999 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_XOR_in_bitwiseXORExpression4003 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseANDExpression_in_bitwiseXORExpression4006 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4022 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_XOR_in_bitwiseXORExpressionNoIn4026 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseANDExpressionNoIn_in_bitwiseXORExpressionNoIn4029 = new BitSet(new long[]{0x0000000000000002L,0x0000000008000000L});
<     public static final BitSet FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4044 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_OR_in_bitwiseORExpression4048 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseXORExpression_in_bitwiseORExpression4051 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4066 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_OR_in_bitwiseORExpressionNoIn4070 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseXORExpressionNoIn_in_bitwiseORExpressionNoIn4073 = new BitSet(new long[]{0x0000000000000002L,0x0000000004000000L});
<     public static final BitSet FOLLOW_bitwiseORExpression_in_logicalANDExpression4092 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_LAND_in_logicalANDExpression4096 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseORExpression_in_logicalANDExpression4099 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4113 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_LAND_in_logicalANDExpressionNoIn4117 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_bitwiseORExpressionNoIn_in_logicalANDExpressionNoIn4120 = new BitSet(new long[]{0x0000000000000002L,0x0000000040000000L});
<     public static final BitSet FOLLOW_logicalANDExpression_in_logicalORExpression4135 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_LOR_in_logicalORExpression4139 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_logicalANDExpression_in_logicalORExpression4142 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4157 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_LOR_in_logicalORExpressionNoIn4161 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_logicalANDExpressionNoIn_in_logicalORExpressionNoIn4164 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
<     public static final BitSet FOLLOW_logicalORExpression_in_conditionalExpression4183 = new BitSet(new long[]{0x0000000000000002L,0x0000000100000000L});
<     public static final BitSet FOLLOW_QUE_in_conditionalExpression4187 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_conditionalExpression4190 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_conditionalExpression4192 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_conditionalExpression4195 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_logicalORExpressionNoIn_in_conditionalExpressionNoIn4209 = new BitSet(new long[]{0x0000000000000002L,0x0000000100000000L});
<     public static final BitSet FOLLOW_QUE_in_conditionalExpressionNoIn4213 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4216 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_conditionalExpressionNoIn4218 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_conditionalExpressionNoIn4221 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_conditionalExpression_in_assignmentExpression4249 = new BitSet(new long[]{0x0000000000000002L,0x00005FFC00000000L});
<     public static final BitSet FOLLOW_assignmentOperator_in_assignmentExpression4256 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_assignmentExpression4259 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_set_in_assignmentOperator0 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_conditionalExpressionNoIn_in_assignmentExpressionNoIn4336 = new BitSet(new long[]{0x0000000000000002L,0x00005FFC00000000L});
<     public static final BitSet FOLLOW_assignmentOperator_in_assignmentExpressionNoIn4343 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_assignmentExpressionNoIn4346 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_assignmentExpression_in_expression4368 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_COMMA_in_expression4372 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_expression4376 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4413 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_COMMA_in_expressionNoIn4417 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_expressionNoIn4421 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000080L});
<     public static final BitSet FOLLOW_SEMIC_in_semic4472 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_EOF_in_semic4477 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_RBRACE_in_semic4482 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_EOL_in_semic4489 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_MultiLineComment_in_semic4493 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_block_in_statement4527 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_statementTail_in_statement4532 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_variableStatement_in_statementTail4544 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_emptyStatement_in_statementTail4549 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_expressionStatement_in_statementTail4554 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_ifStatement_in_statementTail4559 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_iterationStatement_in_statementTail4564 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_continueStatement_in_statementTail4569 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_breakStatement_in_statementTail4574 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_returnStatement_in_statementTail4579 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_withStatement_in_statementTail4584 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_labelledStatement_in_statementTail4589 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_switchStatement_in_statementTail4594 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_throwStatement_in_statementTail4599 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_tryStatement_in_statementTail4604 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACE_in_block4619 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_sourceElement_in_block4621 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_RBRACE_in_block4624 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_VAR_in_variableStatement4653 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclaration_in_variableStatement4655 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_COMMA_in_variableStatement4659 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclaration_in_variableStatement4661 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_variableStatement4666 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_variableDeclaration4689 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L});
<     public static final BitSet FOLLOW_ASSIGN_in_variableDeclaration4693 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpression_in_variableDeclaration4696 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_Identifier_in_variableDeclarationNoIn4711 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L});
<     public static final BitSet FOLLOW_ASSIGN_in_variableDeclarationNoIn4715 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_assignmentExpressionNoIn_in_variableDeclarationNoIn4718 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SEMIC_in_emptyStatement4737 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_expression_in_expressionStatement4756 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_expressionStatement4758 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_IF_in_ifStatement4776 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_ifStatement4778 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_ifStatement4780 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_ifStatement4782 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_ifStatement4784 = new BitSet(new long[]{0x0000000000004002L});
<     public static final BitSet FOLLOW_ELSE_in_ifStatement4790 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_ifStatement4792 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_doStatement_in_iterationStatement4825 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_whileStatement_in_iterationStatement4830 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forStatement_in_iterationStatement4835 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_DO_in_doStatement4847 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_doStatement4849 = new BitSet(new long[]{0x0000000040000000L});
<     public static final BitSet FOLLOW_WHILE_in_doStatement4851 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_doStatement4853 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_doStatement4855 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_doStatement4857 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_doStatement4859 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_WHILE_in_whileStatement4884 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_whileStatement4887 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_whileStatement4890 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_whileStatement4892 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_whileStatement4895 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FOR_in_forStatement4908 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_forStatement4911 = new BitSet(new long[]{0x8000000039221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_forControl_in_forStatement4914 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_forStatement4916 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_forStatement4919 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forControlVar_in_forControl4930 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forControlExpression_in_forControl4935 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_forControlSemic_in_forControl4940 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_VAR_in_forControlVar4951 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclarationNoIn_in_forControlVar4953 = new BitSet(new long[]{0x0000000000080000L,0x00000000000000C0L});
<     public static final BitSet FOLLOW_IN_in_forControlVar4965 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlVar4967 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_COMMA_in_forControlVar5013 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_variableDeclarationNoIn_in_forControlVar5015 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C0L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlVar5020 = new BitSet(new long[]{0x8000000029221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlVar5024 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlVar5027 = new BitSet(new long[]{0x8000000029221072L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlVar5031 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_expressionNoIn_in_forControlExpression5097 = new BitSet(new long[]{0x0000000000080000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_IN_in_forControlExpression5112 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlExpression5116 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlExpression5162 = new BitSet(new long[]{0x8000000029221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlExpression5166 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlExpression5169 = new BitSet(new long[]{0x8000000029221072L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlExpression5173 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlSemic5232 = new BitSet(new long[]{0x8000000029221070L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlSemic5236 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
<     public static final BitSet FOLLOW_SEMIC_in_forControlSemic5239 = new BitSet(new long[]{0x8000000029221072L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_forControlSemic5243 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_CONTINUE_in_continueStatement5297 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000160000L});
<     public static final BitSet FOLLOW_Identifier_in_continueStatement5302 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_continueStatement5305 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_BREAK_in_breakStatement5324 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000160000L});
<     public static final BitSet FOLLOW_Identifier_in_breakStatement5329 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_breakStatement5332 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_RETURN_in_returnStatement5351 = new BitSet(new long[]{0x8000000029221070L,0x00000000303300CBL,0x0000000388360000L});
<     public static final BitSet FOLLOW_expression_in_returnStatement5356 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_returnStatement5359 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_WITH_in_withStatement5376 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_withStatement5379 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_withStatement5382 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_withStatement5384 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_withStatement5387 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_SWITCH_in_switchStatement5408 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_switchStatement5410 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_switchStatement5412 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_switchStatement5414 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_LBRACE_in_switchStatement5416 = new BitSet(new long[]{0x0000000000000900L,0x0000000000000001L});
<     public static final BitSet FOLLOW_defaultClause_in_switchStatement5423 = new BitSet(new long[]{0x0000000000000900L,0x0000000000000001L});
<     public static final BitSet FOLLOW_caseClause_in_switchStatement5429 = new BitSet(new long[]{0x0000000000000900L,0x0000000000000001L});
<     public static final BitSet FOLLOW_RBRACE_in_switchStatement5434 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_CASE_in_caseClause5462 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_caseClause5465 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_caseClause5467 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_caseClause5470 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_DEFAULT_in_defaultClause5483 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_defaultClause5486 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_defaultClause5489 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_Identifier_in_labelledStatement5506 = new BitSet(new long[]{0x0000000000000000L,0x0000000200000000L});
<     public static final BitSet FOLLOW_COLON_in_labelledStatement5508 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_statement_in_labelledStatement5510 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_THROW_in_throwStatement5541 = new BitSet(new long[]{0x8000000029221070L,0x000000003033000AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_expression_in_throwStatement5546 = new BitSet(new long[]{0x0000000000000000L,0x00000000000000C1L,0x0000000000060000L});
<     public static final BitSet FOLLOW_semic_in_throwStatement5548 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_TRY_in_tryStatement5565 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_block_in_tryStatement5568 = new BitSet(new long[]{0x0000000000008200L});
<     public static final BitSet FOLLOW_catchClause_in_tryStatement5572 = new BitSet(new long[]{0x0000000000008202L});
<     public static final BitSet FOLLOW_finallyClause_in_tryStatement5574 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_finallyClause_in_tryStatement5579 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_CATCH_in_catchClause5593 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_catchClause5596 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_catchClause5599 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
<     public static final BitSet FOLLOW_RPAREN_in_catchClause5601 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_block_in_catchClause5604 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FINALLY_in_finallyClause5616 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_block_in_finallyClause5619 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FUNCTION_in_functionDeclaration5640 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_functionDeclaration5644 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_formalParameterList_in_functionDeclaration5646 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_functionBody_in_functionDeclaration5648 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_FUNCTION_in_functionExpression5675 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_functionExpression5679 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
<     public static final BitSet FOLLOW_formalParameterList_in_functionExpression5682 = new BitSet(new long[]{0x8000000000000000L});
<     public static final BitSet FOLLOW_functionBody_in_functionExpression5684 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LPAREN_in_formalParameterList5712 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_formalParameterList5718 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_COMMA_in_formalParameterList5722 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
<     public static final BitSet FOLLOW_Identifier_in_formalParameterList5726 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000084L});
<     public static final BitSet FOLLOW_RPAREN_in_formalParameterList5734 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_LBRACE_in_functionBody5760 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_sourceElement_in_functionBody5762 = new BitSet(new long[]{0x80000000FFE734F0L,0x000000003033004BL,0x0000000388300000L});
<     public static final BitSet FOLLOW_RBRACE_in_functionBody5765 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_sourceElement_in_program5794 = new BitSet(new long[]{0x80000000FFE734F2L,0x000000003033004AL,0x0000000388300000L});
<     public static final BitSet FOLLOW_functionDeclaration_in_sourceElement5823 = new BitSet(new long[]{0x0000000000000002L});
<     public static final BitSet FOLLOW_statement_in_sourceElement5828 = new BitSet(new long[]{0x0000000000000002L});
< 
< }
\ No newline at end of file
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScript.tokens.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/JavaScript.tokens.svn-base
1,274d0
< BackslashSequence=168
< CONST=37
< COMMA=71
< RegularExpressionLiteral=155
< ARGS=111
< ARRAY=112
< LF=140
< SYNCHRONIZED=59
< HexDigit=150
< DOUBLE=39
< EXPR=118
< ADDASS=99
< DecimalDigit=152
< FALSE=6
< USP=138
< ABSTRACT=32
< SP=136
< DQUOTE=131
< IMPORT=47
< SEMIC=70
< MODASS=102
< PACKAGE=52
< SQUOTE=132
< SHR=87
< CONTINUE=10
< DOT=69
< PRIVATE=53
< MultiLineComment=146
< HexIntegerLiteral=161
< AND=89
< RegularExpressionFirstChar=169
< DIVASS=110
< FUNCTION=17
< GTE=75
< OctalEscapeSequence=164
< HexEscapeSequence=165
< SingleLineComment=147
< UnicodeEscapeSequence=166
< POS=129
< RPAREN=66
< IdentifierStartASCII=151
< FINALLY=15
< IdentifierNameASCIIStart=154
< EXTENDS=42
< IdentifierPart=153
< SUPER=58
< Identifier=148
< SAME=78
< CHAR=35
< NEW=21
< EQ=76
< LT=72
< FINAL=43
< SUBASS=100
< VT=134
< LAND=94
< LBRACK=67
< CATCH=9
< STATIC=57
< CASE=8
< MUL=82
< INTERFACE=49
< ExponentPart=157
< INV=93
< BOOLEAN=33
< ELSE=14
< CharacterEscapeSequence=162
< BSLASH=130
< SHLASS=103
< DecimalLiteral=159
< BREAK=7
< NULL=4
< XOR=91
< COLON=97
< DIV=109
< ORASS=107
< TRUE=5
< ADD=80
< THROW=25
< SHORT=56
< LABELLED=122
< CR=141
< RegularExpressionChar=170
< PUBLIC=55
< SHL=86
< LONG=50
< LOR=95
< TYPEOF=27
< INC=84
< TRANSIENT=61
< TAB=133
< FLOAT=44
< ZeroToThree=163
< THROWS=60
< FF=135
< FORITER=119
< GOTO=45
< MOD=83
< EXPORT=41
< OR=90
< MULASS=101
< LBRACE=63
< BLOCK=113
< RBRACE=64
< PROTECTED=54
< ANDASS=106
< LineTerminator=144
< SHU=88
< EscapeSequence=167
< PAREXPR=126
< INT=48
< LS=142
< CEXPR=117
< ASSIGN=98
< VOID=29
< INSTANCEOF=20
< LPAREN=65
< WhiteSpace=139
< XORASS=108
< QUE=96
< NEQ=77
< NAMEDVALUE=123
< ENUM=40
< PS=143
< DEBUGGER=38
< DELETE=12
< OBJECT=125
< DO=13
< IMPLEMENTS=46
< OctalIntegerLiteral=160
< WHILE=30
< SWITCH=23
< BYINDEX=115
< FORSTEP=120
< OctalDigit=156
< PINC=128
< GT=73
< StringLiteral=149
< DecimalIntegerLiteral=158
< SHRASS=104
< ITEM=121
< SHUASS=105
< THIS=24
< WITH=31
< IN=19
< VAR=28
< LTE=74
< CLASS=36
< NATIVE=51
< DEC=85
< RETURN=22
< BYTE=34
< VOLATILE=62
< IF=18
< EOL=145
< NBSP=137
< CALL=116
< FOR=16
< RBRACK=68
< DEFAULT=11
< NEG=124
< SUB=81
< NOT=92
< TRY=26
< PDEC=127
< BYFIELD=114
< NSAME=79
< '<'=72
< 'goto'=45
< '>'=73
< 'try'=26
< 'function'=17
< 'with'=31
< '-'=81
< '>>>='=105
< '?'=96
< '!='=77
< '>='=75
< 'do'=13
< '<<'=86
< 'double'=39
< '<='=74
< '='=98
< 'native'=51
< 'void'=29
< 'catch'=9
< ':'=97
< '*'=82
< '>>>'=88
< '<<='=103
< 'synchronized'=59
< 'true'=5
< 'false'=6
< ','=71
< '&&'=94
< 'this'=24
< 'continue'=10
< 'const'=37
< 'debugger'=38
< 'enum'=40
< 'return'=22
< ')'=66
< '=='=76
< 'static'=57
< 'implements'=46
< 'import'=47
< 'typeof'=27
< 'char'=35
< '!'=92
< '+='=99
< 'switch'=23
< 'delete'=12
< 'extends'=42
< '^='=108
< 'class'=36
< 'null'=4
< '+'=80
< 'interface'=49
< '-='=100
< 'case'=8
< 'boolean'=33
< 'else'=14
< '/='=110
< 'package'=52
< '%='=102
< 'var'=28
< '||'=95
< '*='=101
< 'volatile'=62
< 'instanceof'=20
< 'super'=58
< '|='=107
< '++'=84
< '{'=63
< 'throws'=60
< 'float'=44
< 'new'=21
< 'for'=16
< '.'=69
< 'short'=56
< '}'=64
< '~'=93
< 'finally'=15
< 'break'=7
< '%'=83
< 'final'=43
< ';'=70
< 'default'=11
< ']'=68
< '&'=89
< 'int'=48
< '!=='=79
< '&='=106
< 'while'=30
< '['=67
< '/'=109
< 'long'=50
< '^'=91
< 'private'=53
< '|'=90
< '>>='=104
< 'throw'=25
< 'protected'=54
< 'if'=18
< '('=65
< 'byte'=34
< 'transient'=61
< '==='=78
< '>>'=87
< '--'=85
< 'export'=41
< 'in'=19
< 'abstract'=32
< 'public'=55
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/license.txt.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/license.txt.svn-base
1,30d0
< Software License Agreement (BSD License)
< 
< Copyright (c) 2008, Xebic Research B.V.
< All rights reserved.
< 
< Redistribution and use of this software in source and binary forms, with or without modification, are
< permitted provided that the following conditions are met:
< 
< * Redistributions of source code must retain the above
<   copyright notice, this list of conditions and the
<   following disclaimer.
< 
< * Redistributions in binary form must reproduce the above
<   copyright notice, this list of conditions and the
<   following disclaimer in the documentation and/or other
<   materials provided with the distribution.
< 
< * Neither the name of Xebic Research B.V. nor the names of its
<   contributors may be used to endorse or promote products
<   derived from this software without specific prior
<   written permission of Xebic Research B.V.
< 
< THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED
< WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
< PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
< ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
< LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
< INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
< TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
< ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
\ No newline at end of file
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/MyAstNodeAdaptor.java.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/MyAstNodeAdaptor.java.svn-base
1,8d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< class MyAstNodeAdaptor extends CommonTreeAdaptor {
<     public Object create(Token t) {
< 	return new MyAstNode(t);
<     }
< };
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/MyAstNode.java.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/MyAstNode.java.svn-base
1,11d0
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.Token;
< 
< import java.io.*;
< 
< public class MyAstNode extends CommonTree {
<     boolean is_statement = false;
<     public MyAstNode(Token t) {
< 	super(t);
<     }
< }
Binary files code-worker/tasks/clonedigger/js_antlr/.svn/text-base/TreeProducer.jar.svn-base and code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/TreeProducer.jar.svn-base differ
diff -r -N code-worker/tasks/clonedigger/js_antlr/.svn/text-base/TreeProducer.java.svn-base code-worker/code-worker/tasks/clonedigger/js_antlr/.svn/text-base/TreeProducer.java.svn-base
1,118d0
< /*  Copyright 2008 Peter Bulychev
<  *
<  *  This file is part of Clone Digger.
<  *
<  *  Clone Digger is free software: you can redistribute it and/or modify
<  *  it under the terms of the GNU General Public License as published by
<  *  the Free Software Foundation, either version 3 of the License, or
<  *  (at your option) any later version.
<  *
<  *  Clone Digger is distributed in the hope that it will be useful,
<  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
<  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<  *  GNU General Public License for more details.
<  *
<  *  You should have received a copy of the GNU General Public License
<  *  along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
<  */
< import org.antlr.runtime.*;
< import org.antlr.stringtemplate.*;
< import org.antlr.runtime.tree.*;
< import java.lang.reflect.*;
< import java.io.*;
< import java.util.*;
< import java.text.*;
< import java.lang.*;
< 
< public class TreeProducer
< {
<     public TreeProducer ()
<     {
< 	super ();
<     }
< 
<     /*
<      * forXml function was taken from http://www.javapractices.com/topic/TopicAction.do?Id=96
<      * the license is: http://creativecommons.org/licenses/by/3.0/
<      */
<     public static String forXML (String aText)
<     {
< 	final StringBuilder result = new StringBuilder ();
< 	final StringCharacterIterator iterator =
< 	    new StringCharacterIterator (aText);
< 	char character = iterator.current ();
< 	while (character != CharacterIterator.DONE)
< 	{
< 	    if (character == '<')
< 	    {
< 		result.append ("&lt;");
< 	    }
< 	    else if (character == '>')
< 	    {
< 		result.append ("&gt;");
< 	    }
< 	    else if (character == '\"')
< 	    {
< 		result.append ("&quot;");
< 	    }
< 	    else if (character == '\'')
< 	    {
< 		result.append ("&#039;");
< 	    }
< 	    else if (character == '&')
< 	    {
< 		result.append ("&amp;");
< 	    }
< 	    else
< 	    {
< 		//the char is not a special one
< 		//        //add it to the result as is
< 		result.append (character);
< 	    }
< 	    character = iterator.next ();
< 	}
< 	return result.toString ();
<     }
<     //                                      }
< 
<     public static void printTree (MyAstNode tree, PrintWriter outputStream,	String indent)
< {
<     String xml_node_name = (tree.is_statement?"statement_node":"node");
<     int start_index;
<     int stop_index;
<     if (tree.token == null) {
<         // Sometimes we get the 'nil' node when parsering compressed JS,
<         start_index = 0;
<         stop_index = 0;
<     } else {
<         start_index = ((CommonToken) tree.token).getStartIndex(); 
<         stop_index = ((CommonToken) tree.token).getStopIndex();
<     }
<     outputStream.println (indent + "<" + xml_node_name + " name=\"" + forXML ("" + tree) + "\"" + 
< 	    " line_number=\"" + tree.getLine () + "\" " + 
< 	    "start=\"" +  start_index + "\" " + 
< 	    "stop=\"" + stop_index + "\">");
<     
<     for (int i = 0; i < tree.getChildCount (); i += 1)
<     {
< 	printTree ((MyAstNode )tree.getChild (i), outputStream, indent + "  ");
<     }
<     outputStream.println (indent + "</"+xml_node_name+">");
< }
< 
< public static void main (String[]args) throws Exception
< {
<     ANTLRFileStream input = new ANTLRFileStream (args[0]);
<     JavaScriptLexer lexer = new JavaScriptLexer (input);
<     CommonTokenStream tokens = new CommonTokenStream (lexer);
<     JavaScriptParser parser = new JavaScriptParser (tokens);
<     MyAstNodeAdaptor adaptor = new MyAstNodeAdaptor ();
<     parser.setTreeAdaptor (adaptor);
<     MyAstNode tree = (MyAstNode) parser.program ().getTree ();
<     PrintWriter outputStream =
< 	new PrintWriter (new FileWriter (args[1], false));
<     outputStream.println ("<?xml version=\"1.0\" ?>");
<     printTree (tree, outputStream, "");
<     outputStream.close ();
< }
< }
Binary files code-worker/tasks/clonedigger/js_antlr/TreeProducer.jar and code-worker/code-worker/tasks/clonedigger/js_antlr/TreeProducer.jar differ
diff -r -N code-worker/tasks/clonedigger/js_antlr/TreeProducer.java code-worker/code-worker/tasks/clonedigger/js_antlr/TreeProducer.java
1,118d0
< /*  Copyright 2008 Peter Bulychev
<  *
<  *  This file is part of Clone Digger.
<  *
<  *  Clone Digger is free software: you can redistribute it and/or modify
<  *  it under the terms of the GNU General Public License as published by
<  *  the Free Software Foundation, either version 3 of the License, or
<  *  (at your option) any later version.
<  *
<  *  Clone Digger is distributed in the hope that it will be useful,
<  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
<  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<  *  GNU General Public License for more details.
<  *
<  *  You should have received a copy of the GNU General Public License
<  *  along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
<  */
< import org.antlr.runtime.*;
< import org.antlr.stringtemplate.*;
< import org.antlr.runtime.tree.*;
< import java.lang.reflect.*;
< import java.io.*;
< import java.util.*;
< import java.text.*;
< import java.lang.*;
< 
< public class TreeProducer
< {
<     public TreeProducer ()
<     {
< 	super ();
<     }
< 
<     /*
<      * forXml function was taken from http://www.javapractices.com/topic/TopicAction.do?Id=96
<      * the license is: http://creativecommons.org/licenses/by/3.0/
<      */
<     public static String forXML (String aText)
<     {
< 	final StringBuilder result = new StringBuilder ();
< 	final StringCharacterIterator iterator =
< 	    new StringCharacterIterator (aText);
< 	char character = iterator.current ();
< 	while (character != CharacterIterator.DONE)
< 	{
< 	    if (character == '<')
< 	    {
< 		result.append ("&lt;");
< 	    }
< 	    else if (character == '>')
< 	    {
< 		result.append ("&gt;");
< 	    }
< 	    else if (character == '\"')
< 	    {
< 		result.append ("&quot;");
< 	    }
< 	    else if (character == '\'')
< 	    {
< 		result.append ("&#039;");
< 	    }
< 	    else if (character == '&')
< 	    {
< 		result.append ("&amp;");
< 	    }
< 	    else
< 	    {
< 		//the char is not a special one
< 		//        //add it to the result as is
< 		result.append (character);
< 	    }
< 	    character = iterator.next ();
< 	}
< 	return result.toString ();
<     }
<     //                                      }
< 
<     public static void printTree (MyAstNode tree, PrintWriter outputStream,	String indent)
< {
<     String xml_node_name = (tree.is_statement?"statement_node":"node");
<     int start_index;
<     int stop_index;
<     if (tree.token == null) {
<         // Sometimes we get the 'nil' node when parsering compressed JS,
<         start_index = 0;
<         stop_index = 0;
<     } else {
<         start_index = ((CommonToken) tree.token).getStartIndex(); 
<         stop_index = ((CommonToken) tree.token).getStopIndex();
<     }
<     outputStream.println (indent + "<" + xml_node_name + " name=\"" + forXML ("" + tree) + "\"" + 
< 	    " line_number=\"" + tree.getLine () + "\" " + 
< 	    "start=\"" +  start_index + "\" " + 
< 	    "stop=\"" + stop_index + "\">");
<     
<     for (int i = 0; i < tree.getChildCount (); i += 1)
<     {
< 	printTree ((MyAstNode )tree.getChild (i), outputStream, indent + "  ");
<     }
<     outputStream.println (indent + "</"+xml_node_name+">");
< }
< 
< public static void main (String[]args) throws Exception
< {
<     ANTLRFileStream input = new ANTLRFileStream (args[0]);
<     JavaScriptLexer lexer = new JavaScriptLexer (input);
<     CommonTokenStream tokens = new CommonTokenStream (lexer);
<     JavaScriptParser parser = new JavaScriptParser (tokens);
<     MyAstNodeAdaptor adaptor = new MyAstNodeAdaptor ();
<     parser.setTreeAdaptor (adaptor);
<     MyAstNode tree = (MyAstNode) parser.program ().getTree ();
<     PrintWriter outputStream =
< 	new PrintWriter (new FileWriter (args[1], false));
<     outputStream.println ("<?xml version=\"1.0\" ?>");
<     printTree (tree, outputStream, "");
<     outputStream.close ();
< }
< }
diff -r -N code-worker/tasks/clonedigger/js_antlr.py code-worker/code-worker/tasks/clonedigger/js_antlr.py
1,81d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>. 
< 
< import os
< import xml.parsers.expat
< 
< from abstract_syntax_tree import *
< 
< class JsANTLRSourceFile (SourceFile):
<     extension = 'js'
<     size_threshold = 5
<     distance_threshold = 5
<     def __init__(self, file_name):
<         SourceFile.__init__(self, file_name)
<         class ExpatHandler:
<             def __init__(self, start_node, parent):
<                 self.parent = parent
<                 self.stack = [start_node]
<             def start_element(expat_self, xml_node_name, attrs):
<                 line_number = int(attrs["line_number"])-1
<                 line_numbers = [line_number]
<                 if line_numbers == [-1]:
<                     line_numbers = []
<                 name = attrs["name"]
<                 r = AbstractSyntaxTree(name, line_numbers, self)
<                 if xml_node_name == "statement_node":
<                 #if name in ["CALL", "BLOCK"]:
<                     r.markAsStatement()
<                 else:
<                     assert(xml_node_name == "node")
<                 expat_self.stack[-1].addChild(r)
<                 expat_self.stack.append(r)
<             def end_element(self, name):
<                 self.stack.pop()
< 
<         tree_file_name  = 'temporary_ast.xml'
<         producer_class_path = os.path.join('.','js_antlr', 'TreeProducer.jar')
<         antlr_class_path = os.path.join('.','antlr_runtime', 'antlr-3.1.1.jar')
<         if os.name in ['mac', 'posix']:
<             class_path_delimeter = ':'
<         elif os.name in ['nt', 'dos', 'ce']:
<             class_path_delimeter = ';'
<         else:
<             print 'unsupported OS'
<             assert(0)
< 
<         if os.system('java -classpath ' + producer_class_path + class_path_delimeter + antlr_class_path + ' TreeProducer %s %s 2>err.log'%(file_name, tree_file_name)):
<             f = open('err.log')
<             s = f.read()
<             f.close()
<             raise Exception(s)
<         f = open('err.log')
<         s = f.read()
<         f.close()
<         if s:
<             print s
<         
<         self._tree = AbstractSyntaxTree('program')
<         handler = ExpatHandler(self._tree, self)
<         p = xml.parsers.expat.ParserCreate()
<         p.StartElementHandler = handler.start_element
<         p.EndElementHandler = handler.end_element
<         f = open(tree_file_name)
<         p.ParseFile(f)
<         f.close()
< #       os.remove(tree_file_name)
diff -r -N code-worker/tasks/clonedigger/LICENSE.txt code-worker/code-worker/tasks/clonedigger/LICENSE.txt
1,674d0
<                     GNU GENERAL PUBLIC LICENSE
<                        Version 3, 29 June 2007
< 
<  Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
<  Everyone is permitted to copy and distribute verbatim copies
<  of this license document, but changing it is not allowed.
< 
<                             Preamble
< 
<   The GNU General Public License is a free, copyleft license for
< software and other kinds of works.
< 
<   The licenses for most software and other practical works are designed
< to take away your freedom to share and change the works.  By contrast,
< the GNU General Public License is intended to guarantee your freedom to
< share and change all versions of a program--to make sure it remains free
< software for all its users.  We, the Free Software Foundation, use the
< GNU General Public License for most of our software; it applies also to
< any other work released this way by its authors.  You can apply it to
< your programs, too.
< 
<   When we speak of free software, we are referring to freedom, not
< price.  Our General Public Licenses are designed to make sure that you
< have the freedom to distribute copies of free software (and charge for
< them if you wish), that you receive source code or can get it if you
< want it, that you can change the software or use pieces of it in new
< free programs, and that you know you can do these things.
< 
<   To protect your rights, we need to prevent others from denying you
< these rights or asking you to surrender the rights.  Therefore, you have
< certain responsibilities if you distribute copies of the software, or if
< you modify it: responsibilities to respect the freedom of others.
< 
<   For example, if you distribute copies of such a program, whether
< gratis or for a fee, you must pass on to the recipients the same
< freedoms that you received.  You must make sure that they, too, receive
< or can get the source code.  And you must show them these terms so they
< know their rights.
< 
<   Developers that use the GNU GPL protect your rights with two steps:
< (1) assert copyright on the software, and (2) offer you this License
< giving you legal permission to copy, distribute and/or modify it.
< 
<   For the developers' and authors' protection, the GPL clearly explains
< that there is no warranty for this free software.  For both users' and
< authors' sake, the GPL requires that modified versions be marked as
< changed, so that their problems will not be attributed erroneously to
< authors of previous versions.
< 
<   Some devices are designed to deny users access to install or run
< modified versions of the software inside them, although the manufacturer
< can do so.  This is fundamentally incompatible with the aim of
< protecting users' freedom to change the software.  The systematic
< pattern of such abuse occurs in the area of products for individuals to
< use, which is precisely where it is most unacceptable.  Therefore, we
< have designed this version of the GPL to prohibit the practice for those
< products.  If such problems arise substantially in other domains, we
< stand ready to extend this provision to those domains in future versions
< of the GPL, as needed to protect the freedom of users.
< 
<   Finally, every program is threatened constantly by software patents.
< States should not allow patents to restrict development and use of
< software on general-purpose computers, but in those that do, we wish to
< avoid the special danger that patents applied to a free program could
< make it effectively proprietary.  To prevent this, the GPL assures that
< patents cannot be used to render the program non-free.
< 
<   The precise terms and conditions for copying, distribution and
< modification follow.
< 
<                        TERMS AND CONDITIONS
< 
<   0. Definitions.
< 
<   "This License" refers to version 3 of the GNU General Public License.
< 
<   "Copyright" also means copyright-like laws that apply to other kinds of
< works, such as semiconductor masks.
< 
<   "The Program" refers to any copyrightable work licensed under this
< License.  Each licensee is addressed as "you".  "Licensees" and
< "recipients" may be individuals or organizations.
< 
<   To "modify" a work means to copy from or adapt all or part of the work
< in a fashion requiring copyright permission, other than the making of an
< exact copy.  The resulting work is called a "modified version" of the
< earlier work or a work "based on" the earlier work.
< 
<   A "covered work" means either the unmodified Program or a work based
< on the Program.
< 
<   To "propagate" a work means to do anything with it that, without
< permission, would make you directly or secondarily liable for
< infringement under applicable copyright law, except executing it on a
< computer or modifying a private copy.  Propagation includes copying,
< distribution (with or without modification), making available to the
< public, and in some countries other activities as well.
< 
<   To "convey" a work means any kind of propagation that enables other
< parties to make or receive copies.  Mere interaction with a user through
< a computer network, with no transfer of a copy, is not conveying.
< 
<   An interactive user interface displays "Appropriate Legal Notices"
< to the extent that it includes a convenient and prominently visible
< feature that (1) displays an appropriate copyright notice, and (2)
< tells the user that there is no warranty for the work (except to the
< extent that warranties are provided), that licensees may convey the
< work under this License, and how to view a copy of this License.  If
< the interface presents a list of user commands or options, such as a
< menu, a prominent item in the list meets this criterion.
< 
<   1. Source Code.
< 
<   The "source code" for a work means the preferred form of the work
< for making modifications to it.  "Object code" means any non-source
< form of a work.
< 
<   A "Standard Interface" means an interface that either is an official
< standard defined by a recognized standards body, or, in the case of
< interfaces specified for a particular programming language, one that
< is widely used among developers working in that language.
< 
<   The "System Libraries" of an executable work include anything, other
< than the work as a whole, that (a) is included in the normal form of
< packaging a Major Component, but which is not part of that Major
< Component, and (b) serves only to enable use of the work with that
< Major Component, or to implement a Standard Interface for which an
< implementation is available to the public in source code form.  A
< "Major Component", in this context, means a major essential component
< (kernel, window system, and so on) of the specific operating system
< (if any) on which the executable work runs, or a compiler used to
< produce the work, or an object code interpreter used to run it.
< 
<   The "Corresponding Source" for a work in object code form means all
< the source code needed to generate, install, and (for an executable
< work) run the object code and to modify the work, including scripts to
< control those activities.  However, it does not include the work's
< System Libraries, or general-purpose tools or generally available free
< programs which are used unmodified in performing those activities but
< which are not part of the work.  For example, Corresponding Source
< includes interface definition files associated with source files for
< the work, and the source code for shared libraries and dynamically
< linked subprograms that the work is specifically designed to require,
< such as by intimate data communication or control flow between those
< subprograms and other parts of the work.
< 
<   The Corresponding Source need not include anything that users
< can regenerate automatically from other parts of the Corresponding
< Source.
< 
<   The Corresponding Source for a work in source code form is that
< same work.
< 
<   2. Basic Permissions.
< 
<   All rights granted under this License are granted for the term of
< copyright on the Program, and are irrevocable provided the stated
< conditions are met.  This License explicitly affirms your unlimited
< permission to run the unmodified Program.  The output from running a
< covered work is covered by this License only if the output, given its
< content, constitutes a covered work.  This License acknowledges your
< rights of fair use or other equivalent, as provided by copyright law.
< 
<   You may make, run and propagate covered works that you do not
< convey, without conditions so long as your license otherwise remains
< in force.  You may convey covered works to others for the sole purpose
< of having them make modifications exclusively for you, or provide you
< with facilities for running those works, provided that you comply with
< the terms of this License in conveying all material for which you do
< not control copyright.  Those thus making or running the covered works
< for you must do so exclusively on your behalf, under your direction
< and control, on terms that prohibit them from making any copies of
< your copyrighted material outside their relationship with you.
< 
<   Conveying under any other circumstances is permitted solely under
< the conditions stated below.  Sublicensing is not allowed; section 10
< makes it unnecessary.
< 
<   3. Protecting Users' Legal Rights From Anti-Circumvention Law.
< 
<   No covered work shall be deemed part of an effective technological
< measure under any applicable law fulfilling obligations under article
< 11 of the WIPO copyright treaty adopted on 20 December 1996, or
< similar laws prohibiting or restricting circumvention of such
< measures.
< 
<   When you convey a covered work, you waive any legal power to forbid
< circumvention of technological measures to the extent such circumvention
< is effected by exercising rights under this License with respect to
< the covered work, and you disclaim any intention to limit operation or
< modification of the work as a means of enforcing, against the work's
< users, your or third parties' legal rights to forbid circumvention of
< technological measures.
< 
<   4. Conveying Verbatim Copies.
< 
<   You may convey verbatim copies of the Program's source code as you
< receive it, in any medium, provided that you conspicuously and
< appropriately publish on each copy an appropriate copyright notice;
< keep intact all notices stating that this License and any
< non-permissive terms added in accord with section 7 apply to the code;
< keep intact all notices of the absence of any warranty; and give all
< recipients a copy of this License along with the Program.
< 
<   You may charge any price or no price for each copy that you convey,
< and you may offer support or warranty protection for a fee.
< 
<   5. Conveying Modified Source Versions.
< 
<   You may convey a work based on the Program, or the modifications to
< produce it from the Program, in the form of source code under the
< terms of section 4, provided that you also meet all of these conditions:
< 
<     a) The work must carry prominent notices stating that you modified
<     it, and giving a relevant date.
< 
<     b) The work must carry prominent notices stating that it is
<     released under this License and any conditions added under section
<     7.  This requirement modifies the requirement in section 4 to
<     "keep intact all notices".
< 
<     c) You must license the entire work, as a whole, under this
<     License to anyone who comes into possession of a copy.  This
<     License will therefore apply, along with any applicable section 7
<     additional terms, to the whole of the work, and all its parts,
<     regardless of how they are packaged.  This License gives no
<     permission to license the work in any other way, but it does not
<     invalidate such permission if you have separately received it.
< 
<     d) If the work has interactive user interfaces, each must display
<     Appropriate Legal Notices; however, if the Program has interactive
<     interfaces that do not display Appropriate Legal Notices, your
<     work need not make them do so.
< 
<   A compilation of a covered work with other separate and independent
< works, which are not by their nature extensions of the covered work,
< and which are not combined with it such as to form a larger program,
< in or on a volume of a storage or distribution medium, is called an
< "aggregate" if the compilation and its resulting copyright are not
< used to limit the access or legal rights of the compilation's users
< beyond what the individual works permit.  Inclusion of a covered work
< in an aggregate does not cause this License to apply to the other
< parts of the aggregate.
< 
<   6. Conveying Non-Source Forms.
< 
<   You may convey a covered work in object code form under the terms
< of sections 4 and 5, provided that you also convey the
< machine-readable Corresponding Source under the terms of this License,
< in one of these ways:
< 
<     a) Convey the object code in, or embodied in, a physical product
<     (including a physical distribution medium), accompanied by the
<     Corresponding Source fixed on a durable physical medium
<     customarily used for software interchange.
< 
<     b) Convey the object code in, or embodied in, a physical product
<     (including a physical distribution medium), accompanied by a
<     written offer, valid for at least three years and valid for as
<     long as you offer spare parts or customer support for that product
<     model, to give anyone who possesses the object code either (1) a
<     copy of the Corresponding Source for all the software in the
<     product that is covered by this License, on a durable physical
<     medium customarily used for software interchange, for a price no
<     more than your reasonable cost of physically performing this
<     conveying of source, or (2) access to copy the
<     Corresponding Source from a network server at no charge.
< 
<     c) Convey individual copies of the object code with a copy of the
<     written offer to provide the Corresponding Source.  This
<     alternative is allowed only occasionally and noncommercially, and
<     only if you received the object code with such an offer, in accord
<     with subsection 6b.
< 
<     d) Convey the object code by offering access from a designated
<     place (gratis or for a charge), and offer equivalent access to the
<     Corresponding Source in the same way through the same place at no
<     further charge.  You need not require recipients to copy the
<     Corresponding Source along with the object code.  If the place to
<     copy the object code is a network server, the Corresponding Source
<     may be on a different server (operated by you or a third party)
<     that supports equivalent copying facilities, provided you maintain
<     clear directions next to the object code saying where to find the
<     Corresponding Source.  Regardless of what server hosts the
<     Corresponding Source, you remain obligated to ensure that it is
<     available for as long as needed to satisfy these requirements.
< 
<     e) Convey the object code using peer-to-peer transmission, provided
<     you inform other peers where the object code and Corresponding
<     Source of the work are being offered to the general public at no
<     charge under subsection 6d.
< 
<   A separable portion of the object code, whose source code is excluded
< from the Corresponding Source as a System Library, need not be
< included in conveying the object code work.
< 
<   A "User Product" is either (1) a "consumer product", which means any
< tangible personal property which is normally used for personal, family,
< or household purposes, or (2) anything designed or sold for incorporation
< into a dwelling.  In determining whether a product is a consumer product,
< doubtful cases shall be resolved in favor of coverage.  For a particular
< product received by a particular user, "normally used" refers to a
< typical or common use of that class of product, regardless of the status
< of the particular user or of the way in which the particular user
< actually uses, or expects or is expected to use, the product.  A product
< is a consumer product regardless of whether the product has substantial
< commercial, industrial or non-consumer uses, unless such uses represent
< the only significant mode of use of the product.
< 
<   "Installation Information" for a User Product means any methods,
< procedures, authorization keys, or other information required to install
< and execute modified versions of a covered work in that User Product from
< a modified version of its Corresponding Source.  The information must
< suffice to ensure that the continued functioning of the modified object
< code is in no case prevented or interfered with solely because
< modification has been made.
< 
<   If you convey an object code work under this section in, or with, or
< specifically for use in, a User Product, and the conveying occurs as
< part of a transaction in which the right of possession and use of the
< User Product is transferred to the recipient in perpetuity or for a
< fixed term (regardless of how the transaction is characterized), the
< Corresponding Source conveyed under this section must be accompanied
< by the Installation Information.  But this requirement does not apply
< if neither you nor any third party retains the ability to install
< modified object code on the User Product (for example, the work has
< been installed in ROM).
< 
<   The requirement to provide Installation Information does not include a
< requirement to continue to provide support service, warranty, or updates
< for a work that has been modified or installed by the recipient, or for
< the User Product in which it has been modified or installed.  Access to a
< network may be denied when the modification itself materially and
< adversely affects the operation of the network or violates the rules and
< protocols for communication across the network.
< 
<   Corresponding Source conveyed, and Installation Information provided,
< in accord with this section must be in a format that is publicly
< documented (and with an implementation available to the public in
< source code form), and must require no special password or key for
< unpacking, reading or copying.
< 
<   7. Additional Terms.
< 
<   "Additional permissions" are terms that supplement the terms of this
< License by making exceptions from one or more of its conditions.
< Additional permissions that are applicable to the entire Program shall
< be treated as though they were included in this License, to the extent
< that they are valid under applicable law.  If additional permissions
< apply only to part of the Program, that part may be used separately
< under those permissions, but the entire Program remains governed by
< this License without regard to the additional permissions.
< 
<   When you convey a copy of a covered work, you may at your option
< remove any additional permissions from that copy, or from any part of
< it.  (Additional permissions may be written to require their own
< removal in certain cases when you modify the work.)  You may place
< additional permissions on material, added by you to a covered work,
< for which you have or can give appropriate copyright permission.
< 
<   Notwithstanding any other provision of this License, for material you
< add to a covered work, you may (if authorized by the copyright holders of
< that material) supplement the terms of this License with terms:
< 
<     a) Disclaiming warranty or limiting liability differently from the
<     terms of sections 15 and 16 of this License; or
< 
<     b) Requiring preservation of specified reasonable legal notices or
<     author attributions in that material or in the Appropriate Legal
<     Notices displayed by works containing it; or
< 
<     c) Prohibiting misrepresentation of the origin of that material, or
<     requiring that modified versions of such material be marked in
<     reasonable ways as different from the original version; or
< 
<     d) Limiting the use for publicity purposes of names of licensors or
<     authors of the material; or
< 
<     e) Declining to grant rights under trademark law for use of some
<     trade names, trademarks, or service marks; or
< 
<     f) Requiring indemnification of licensors and authors of that
<     material by anyone who conveys the material (or modified versions of
<     it) with contractual assumptions of liability to the recipient, for
<     any liability that these contractual assumptions directly impose on
<     those licensors and authors.
< 
<   All other non-permissive additional terms are considered "further
< restrictions" within the meaning of section 10.  If the Program as you
< received it, or any part of it, contains a notice stating that it is
< governed by this License along with a term that is a further
< restriction, you may remove that term.  If a license document contains
< a further restriction but permits relicensing or conveying under this
< License, you may add to a covered work material governed by the terms
< of that license document, provided that the further restriction does
< not survive such relicensing or conveying.
< 
<   If you add terms to a covered work in accord with this section, you
< must place, in the relevant source files, a statement of the
< additional terms that apply to those files, or a notice indicating
< where to find the applicable terms.
< 
<   Additional terms, permissive or non-permissive, may be stated in the
< form of a separately written license, or stated as exceptions;
< the above requirements apply either way.
< 
<   8. Termination.
< 
<   You may not propagate or modify a covered work except as expressly
< provided under this License.  Any attempt otherwise to propagate or
< modify it is void, and will automatically terminate your rights under
< this License (including any patent licenses granted under the third
< paragraph of section 11).
< 
<   However, if you cease all violation of this License, then your
< license from a particular copyright holder is reinstated (a)
< provisionally, unless and until the copyright holder explicitly and
< finally terminates your license, and (b) permanently, if the copyright
< holder fails to notify you of the violation by some reasonable means
< prior to 60 days after the cessation.
< 
<   Moreover, your license from a particular copyright holder is
< reinstated permanently if the copyright holder notifies you of the
< violation by some reasonable means, this is the first time you have
< received notice of violation of this License (for any work) from that
< copyright holder, and you cure the violation prior to 30 days after
< your receipt of the notice.
< 
<   Termination of your rights under this section does not terminate the
< licenses of parties who have received copies or rights from you under
< this License.  If your rights have been terminated and not permanently
< reinstated, you do not qualify to receive new licenses for the same
< material under section 10.
< 
<   9. Acceptance Not Required for Having Copies.
< 
<   You are not required to accept this License in order to receive or
< run a copy of the Program.  Ancillary propagation of a covered work
< occurring solely as a consequence of using peer-to-peer transmission
< to receive a copy likewise does not require acceptance.  However,
< nothing other than this License grants you permission to propagate or
< modify any covered work.  These actions infringe copyright if you do
< not accept this License.  Therefore, by modifying or propagating a
< covered work, you indicate your acceptance of this License to do so.
< 
<   10. Automatic Licensing of Downstream Recipients.
< 
<   Each time you convey a covered work, the recipient automatically
< receives a license from the original licensors, to run, modify and
< propagate that work, subject to this License.  You are not responsible
< for enforcing compliance by third parties with this License.
< 
<   An "entity transaction" is a transaction transferring control of an
< organization, or substantially all assets of one, or subdividing an
< organization, or merging organizations.  If propagation of a covered
< work results from an entity transaction, each party to that
< transaction who receives a copy of the work also receives whatever
< licenses to the work the party's predecessor in interest had or could
< give under the previous paragraph, plus a right to possession of the
< Corresponding Source of the work from the predecessor in interest, if
< the predecessor has it or can get it with reasonable efforts.
< 
<   You may not impose any further restrictions on the exercise of the
< rights granted or affirmed under this License.  For example, you may
< not impose a license fee, royalty, or other charge for exercise of
< rights granted under this License, and you may not initiate litigation
< (including a cross-claim or counterclaim in a lawsuit) alleging that
< any patent claim is infringed by making, using, selling, offering for
< sale, or importing the Program or any portion of it.
< 
<   11. Patents.
< 
<   A "contributor" is a copyright holder who authorizes use under this
< License of the Program or a work on which the Program is based.  The
< work thus licensed is called the contributor's "contributor version".
< 
<   A contributor's "essential patent claims" are all patent claims
< owned or controlled by the contributor, whether already acquired or
< hereafter acquired, that would be infringed by some manner, permitted
< by this License, of making, using, or selling its contributor version,
< but do not include claims that would be infringed only as a
< consequence of further modification of the contributor version.  For
< purposes of this definition, "control" includes the right to grant
< patent sublicenses in a manner consistent with the requirements of
< this License.
< 
<   Each contributor grants you a non-exclusive, worldwide, royalty-free
< patent license under the contributor's essential patent claims, to
< make, use, sell, offer for sale, import and otherwise run, modify and
< propagate the contents of its contributor version.
< 
<   In the following three paragraphs, a "patent license" is any express
< agreement or commitment, however denominated, not to enforce a patent
< (such as an express permission to practice a patent or covenant not to
< sue for patent infringement).  To "grant" such a patent license to a
< party means to make such an agreement or commitment not to enforce a
< patent against the party.
< 
<   If you convey a covered work, knowingly relying on a patent license,
< and the Corresponding Source of the work is not available for anyone
< to copy, free of charge and under the terms of this License, through a
< publicly available network server or other readily accessible means,
< then you must either (1) cause the Corresponding Source to be so
< available, or (2) arrange to deprive yourself of the benefit of the
< patent license for this particular work, or (3) arrange, in a manner
< consistent with the requirements of this License, to extend the patent
< license to downstream recipients.  "Knowingly relying" means you have
< actual knowledge that, but for the patent license, your conveying the
< covered work in a country, or your recipient's use of the covered work
< in a country, would infringe one or more identifiable patents in that
< country that you have reason to believe are valid.
< 
<   If, pursuant to or in connection with a single transaction or
< arrangement, you convey, or propagate by procuring conveyance of, a
< covered work, and grant a patent license to some of the parties
< receiving the covered work authorizing them to use, propagate, modify
< or convey a specific copy of the covered work, then the patent license
< you grant is automatically extended to all recipients of the covered
< work and works based on it.
< 
<   A patent license is "discriminatory" if it does not include within
< the scope of its coverage, prohibits the exercise of, or is
< conditioned on the non-exercise of one or more of the rights that are
< specifically granted under this License.  You may not convey a covered
< work if you are a party to an arrangement with a third party that is
< in the business of distributing software, under which you make payment
< to the third party based on the extent of your activity of conveying
< the work, and under which the third party grants, to any of the
< parties who would receive the covered work from you, a discriminatory
< patent license (a) in connection with copies of the covered work
< conveyed by you (or copies made from those copies), or (b) primarily
< for and in connection with specific products or compilations that
< contain the covered work, unless you entered into that arrangement,
< or that patent license was granted, prior to 28 March 2007.
< 
<   Nothing in this License shall be construed as excluding or limiting
< any implied license or other defenses to infringement that may
< otherwise be available to you under applicable patent law.
< 
<   12. No Surrender of Others' Freedom.
< 
<   If conditions are imposed on you (whether by court order, agreement or
< otherwise) that contradict the conditions of this License, they do not
< excuse you from the conditions of this License.  If you cannot convey a
< covered work so as to satisfy simultaneously your obligations under this
< License and any other pertinent obligations, then as a consequence you may
< not convey it at all.  For example, if you agree to terms that obligate you
< to collect a royalty for further conveying from those to whom you convey
< the Program, the only way you could satisfy both those terms and this
< License would be to refrain entirely from conveying the Program.
< 
<   13. Use with the GNU Affero General Public License.
< 
<   Notwithstanding any other provision of this License, you have
< permission to link or combine any covered work with a work licensed
< under version 3 of the GNU Affero General Public License into a single
< combined work, and to convey the resulting work.  The terms of this
< License will continue to apply to the part which is the covered work,
< but the special requirements of the GNU Affero General Public License,
< section 13, concerning interaction through a network will apply to the
< combination as such.
< 
<   14. Revised Versions of this License.
< 
<   The Free Software Foundation may publish revised and/or new versions of
< the GNU General Public License from time to time.  Such new versions will
< be similar in spirit to the present version, but may differ in detail to
< address new problems or concerns.
< 
<   Each version is given a distinguishing version number.  If the
< Program specifies that a certain numbered version of the GNU General
< Public License "or any later version" applies to it, you have the
< option of following the terms and conditions either of that numbered
< version or of any later version published by the Free Software
< Foundation.  If the Program does not specify a version number of the
< GNU General Public License, you may choose any version ever published
< by the Free Software Foundation.
< 
<   If the Program specifies that a proxy can decide which future
< versions of the GNU General Public License can be used, that proxy's
< public statement of acceptance of a version permanently authorizes you
< to choose that version for the Program.
< 
<   Later license versions may give you additional or different
< permissions.  However, no additional obligations are imposed on any
< author or copyright holder as a result of your choosing to follow a
< later version.
< 
<   15. Disclaimer of Warranty.
< 
<   THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
< APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
< HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
< OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
< THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
< PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
< IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
< ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
< 
<   16. Limitation of Liability.
< 
<   IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
< WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
< THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
< GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
< USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
< DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
< PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
< EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
< SUCH DAMAGES.
< 
<   17. Interpretation of Sections 15 and 16.
< 
<   If the disclaimer of warranty and limitation of liability provided
< above cannot be given local legal effect according to their terms,
< reviewing courts shall apply local law that most closely approximates
< an absolute waiver of all civil liability in connection with the
< Program, unless a warranty or assumption of liability accompanies a
< copy of the Program in return for a fee.
< 
<                      END OF TERMS AND CONDITIONS
< 
<             How to Apply These Terms to Your New Programs
< 
<   If you develop a new program, and you want it to be of the greatest
< possible use to the public, the best way to achieve this is to make it
< free software which everyone can redistribute and change under these terms.
< 
<   To do so, attach the following notices to the program.  It is safest
< to attach them to the start of each source file to most effectively
< state the exclusion of warranty; and each file should have at least
< the "copyright" line and a pointer to where the full notice is found.
< 
<     <one line to give the program's name and a brief idea of what it does.>
<     Copyright (C) <year>  <name of author>
< 
<     This program is free software: you can redistribute it and/or modify
<     it under the terms of the GNU General Public License as published by
<     the Free Software Foundation, either version 3 of the License, or
<     (at your option) any later version.
< 
<     This program is distributed in the hope that it will be useful,
<     but WITHOUT ANY WARRANTY; without even the implied warranty of
<     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<     GNU General Public License for more details.
< 
<     You should have received a copy of the GNU General Public License
<     along with this program.  If not, see <http://www.gnu.org/licenses/>.
< 
< Also add information on how to contact you by electronic and paper mail.
< 
<   If the program does terminal interaction, make it output a short
< notice like this when it starts in an interactive mode:
< 
<     <program>  Copyright (C) <year>  <name of author>
<     This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
<     This is free software, and you are welcome to redistribute it
<     under certain conditions; type `show c' for details.
< 
< The hypothetical commands `show w' and `show c' should show the appropriate
< parts of the General Public License.  Of course, your program's commands
< might be different; for a GUI interface, you would use an "about box".
< 
<   You should also get your employer (if you work as a programmer) or school,
< if any, to sign a "copyright disclaimer" for the program, if necessary.
< For more information on this, and how to apply and follow the GNU GPL, see
< <http://www.gnu.org/licenses/>.
< 
<   The GNU General Public License does not permit incorporating your program
< into proprietary programs.  If your program is a subroutine library, you
< may consider it more useful to permit linking proprietary applications with
< the library.  If this is what you want to do, use the GNU Lesser General
< Public License instead of this License.  But first, please read
< <http://www.gnu.org/philosophy/why-not-lgpl.html>.
diff -r -N code-worker/tasks/clonedigger/logilab/astng/astutils.py code-worker/code-worker/tasks/clonedigger/logilab/astng/astutils.py
1,79d0
< # Copyright (c) 2003 Sylvain Thenault (thenault@nerim.net)
< # Copyright (c) 2003 Logilab
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some usefull functions to manipulate ast tuples
< """
< 
< __author__ = u"Sylvain Thenault"
< 
< import symbol
< import token
< from types import TupleType
< 
< def debuild(ast_tuple):
<     """
<     reverse ast_tuple to string
<     """
<     if type(ast_tuple[1]) is TupleType:
<         result = ''
<         for child in ast_tuple[1:]: 
<             result = '%s%s' % (result, debuild(child))
<         return result
<     else:
<         return ast_tuple[1]
< 
< def clean(ast_tuple):
<     """
<     reverse ast tuple to a list of tokens
<     merge sequences (token.NAME, token.DOT, token.NAME)
<     """
<     result = []
<     last = None
<     for couple in _clean(ast_tuple):
<         if couple[0] == token.NAME and last == token.DOT:
<             result[-1][1] += couple[1]
<         elif couple[0] == token.DOT and last == token.NAME:
<             result[-1][1] += couple[1]
<         else:
<             result.append(couple)
<         last = couple[0]
<     return result
< 
< def _clean(ast_tuple):
<     """ transform the ast into as list of tokens (i.e. final elements)
<     """
<     if type(ast_tuple[1]) is TupleType:
<         v = []
<         for c in ast_tuple[1:]:
<             v += _clean(c)
<         return v
<     else:
<         return [list(ast_tuple[:2])]
<     
< def cvrtr(tuple):
<     """debug method returning an ast string in a readable fashion"""
<     if type(tuple) is TupleType:
<         try:
<             try:
<                 txt = 'token.'+token.tok_name[tuple[0]]
<             except:
<                 txt = 'symbol.'+symbol.sym_name[tuple[0]]
<         except:
<             txt =  'Unknown token/symbol'
<         return [txt] + map(cvrtr, tuple[1:])
<     else:
<         return tuple
< 
< __all__ = ('debuild', 'clean', 'cvrtr')
diff -r -N code-worker/tasks/clonedigger/logilab/astng/builder.py code-worker/code-worker/tasks/clonedigger/logilab/astng/builder.py
1,597d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """The ASTNGBuilder makes astng from living object and / or from compiler.ast
< 
< The builder is not thread safe and can't be used to parse different sources
< at the same time.
< 
< TODO:
<  - more complet representation on inspect build
<    (imported modules ? use dis.dis ?)
< 
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< from os.path import splitext, basename, dirname, exists, abspath
< from parser import ParserError
< from compiler import parse
< from inspect import isfunction, ismethod, ismethoddescriptor, isclass, \
<      isbuiltin
< from inspect import isdatadescriptor
< 
< from clonedigger.logilab.common.fileutils import norm_read
< from clonedigger.logilab.common.modutils import modpath_from_file
< 
< from clonedigger.logilab.astng import nodes, YES, Instance
< from clonedigger.logilab.astng.utils import ASTWalker
< from clonedigger.logilab.astng._exceptions import ASTNGBuildingException, InferenceError
< from clonedigger.logilab.astng.raw_building import *
< from clonedigger.logilab.astng.astutils import cvrtr
< 
< import token
< from compiler import transformer, consts
< from types import TupleType
< 
< def fromto_lineno(asttuple):
<     """return the minimum and maximum line number of the given ast tuple"""
<     return from_lineno(asttuple), to_lineno(asttuple)
< def from_lineno(asttuple):
<     """return the minimum line number of the given ast tuple"""
<     if type(asttuple[1]) is TupleType:
<         return from_lineno(asttuple[1])
<     return asttuple[2]
< def to_lineno(asttuple):
<     """return the maximum line number of the given ast tuple"""
<     if type(asttuple[-1]) is TupleType:
<         return to_lineno(asttuple[-1])
<     return asttuple[2]
< 
< def fix_lineno(node, fromast, toast=None):
<     if 'fromlineno' in node.__dict__:
<         return node    
<     #print 'fixing', id(node), id(node.__dict__), node.__dict__.keys(), repr(node)
<     if isinstance(node, nodes.Stmt):
<         node.fromlineno = from_lineno(fromast)#node.nodes[0].fromlineno
<         node.tolineno = node.nodes[-1].tolineno
<         return node
<     if toast is None:
<         node.fromlineno, node.tolineno = fromto_lineno(fromast)
<     else:
<         node.fromlineno, node.tolineno = from_lineno(fromast), to_lineno(toast)
<     #print 'fixed', id(node)
<     return node
< 
< BaseTransformer = transformer.Transformer
< 
< COORD_MAP = {
<     # if: test ':' suite ('elif' test ':' suite)* ['else' ':' suite]
<     'if': (0, 0),
<     # 'while' test ':' suite ['else' ':' suite]
<     'while': (0, 1),
<     # 'for' exprlist 'in' exprlist ':' suite ['else' ':' suite]
<     'for': (0, 3),
<     # 'try' ':' suite (except_clause ':' suite)+ ['else' ':' suite]
<     'try': (0, 0),
<     # | 'try' ':' suite 'finally' ':' suite
<     
<     }
< 
< def fixlineno_wrap(function, stype):
<     def fixlineno_wrapper(self, nodelist):
<         node = function(self, nodelist)            
<         idx1, idx2 = COORD_MAP.get(stype, (0, -1))
<         return fix_lineno(node, nodelist[idx1], nodelist[idx2])
<     return fixlineno_wrapper
< nodes.Module.fromlineno = 0
< nodes.Module.tolineno = 0
< class ASTNGTransformer(BaseTransformer):
<     """ovverides transformer for a better source line number handling"""
<     def com_NEWLINE(self, *args):
<         # A ';' at the end of a line can make a NEWLINE token appear
<         # here, Render it harmless. (genc discards ('discard',
<         # ('const', xxxx)) Nodes)
<         lineno = args[0][1]
<         # don't put fromlineno/tolineno on Const None to mark it as dynamically
<         # added, without "physical" reference in the source
<         n = nodes.Discard(nodes.Const(None))
<         n.fromlineno = n.tolineno = lineno
<         return n    
<     def com_node(self, node):
<         res = self._dispatch[node[0]](node[1:])
<         return fix_lineno(res, node)
<     def com_assign(self, node, assigning):
<         res = BaseTransformer.com_assign(self, node, assigning)
<         return fix_lineno(res, node)
<     def com_apply_trailer(self, primaryNode, nodelist):
<         node = BaseTransformer.com_apply_trailer(self, primaryNode, nodelist)
<         return fix_lineno(node, nodelist)
<     
< ##     def atom(self, nodelist):
< ##         node = BaseTransformer.atom(self, nodelist)
< ##         return fix_lineno(node, nodelist[0], nodelist[-1])
<     
<     def funcdef(self, nodelist):
<         node = BaseTransformer.funcdef(self, nodelist)
<         # XXX decorators
<         return fix_lineno(node, nodelist[-5], nodelist[-3])
<     def classdef(self, nodelist):
<         node = BaseTransformer.classdef(self, nodelist)
<         return fix_lineno(node, nodelist[0], nodelist[-2])
<             
< # wrap *_stmt methods
< for name in dir(BaseTransformer):
<     if name.endswith('_stmt') and not (name in ('com_stmt',
<                                                 'com_append_stmt')
<                                        or name in ASTNGTransformer.__dict__):
<         setattr(BaseTransformer, name,
<                 fixlineno_wrap(getattr(BaseTransformer, name), name[:-5]))
<             
< transformer.Transformer = ASTNGTransformer
< 
< # ast NG builder ##############################################################
< 
< class ASTNGBuilder:
<     """provide astng building methods
<     """
<     
<     def __init__(self, manager=None):
<         if manager is None:
<             from clonedigger.logilab.astng import MANAGER as manager
<         self._manager = manager
<         self._module = None
<         self._file = None
<         self._done = None
<         self._stack, self._par_stack = None, None
<         self._metaclass = None        
<         self._walker = ASTWalker(self)
<         self._dyn_modname_map = {'gtk': 'gtk._gtk'}
<         self._delayed = []
<         
<     def module_build(self, module, modname=None):
<         """build an astng from a living module instance
<         """
<         node = None
<         self._module = module
<         path = getattr(module, '__file__', None)
<         if path is not None:
<             path_, ext = splitext(module.__file__)
<             if ext in ('.py', '.pyc', '.pyo') and exists(path_ + '.py'):
<                 node = self.file_build(path_ + '.py', modname)
<         if node is None:
<             # this is a built-in module
<             # get a partial representation by introspection
<             node = self.inspect_build(module, modname=modname, path=path)
<         return node
< 
<     def inspect_build(self, module, modname=None, path=None):
<         """build astng from a living module (i.e. using inspect)
<         this is used when there is no python source code available (either
<         because it's a built-in module or because the .py is not available)
<         """
<         self._module = module
<         node = build_module(modname or module.__name__, module.__doc__)
<         node.file = node.path = path and abspath(path) or path
<         if self._manager is not None:
<             self._manager._cache[node.file] = self._manager._cache[node.name] = node
<         node.package = hasattr(module, '__path__')
<         attach___dict__(node)
<         self._done = {}
<         self.object_build(node, module)
<         return node
<     
<     def file_build(self, path, modname=None):
<         """build astng from a source code file (i.e. from an ast)
< 
<         path is expected to be a python source file
<         """
<         try:
<             data = norm_read(path)
<         except IOError, ex:
<             msg = 'Unable to load file %r (%s)' % (path, ex)
<             raise ASTNGBuildingException(msg)
<         self._file = path
<         # get module name if necessary, *before modifying sys.path*
<         if modname is None:
<             try:
<                 modname = '.'.join(modpath_from_file(path))
<             except ImportError:
<                 modname = splitext(basename(path))[0]
<         # build astng representation
<         try:
<             sys.path.insert(0, dirname(path))
<             node = self.string_build(data, modname, path)
<             node.file = abspath(path)
<         finally:
<             self._file = None
<             sys.path.pop(0)
<         
<         return node
<     
<     def string_build(self, data, modname='', path=None):
<         """build astng from a source code stream (i.e. from an ast)"""
<         return self.ast_build(parse(data + '\n'), modname, path)
<        
<     def ast_build(self, node, modname=None, path=None):
<         """recurse on the ast (soon ng) to add some arguments et method
<         """
<         if path is not None:
<             node.file = node.path = abspath(path)
<         else:
<             node.file = node.path = '<?>'
<         if modname.endswith('.__init__'):
<             modname = modname[:-9]
<             node.package = True
<         else:
<             node.package = path and path.find('__init__.py') > -1 or False
<         node.name = modname 
<         node.pure_python = True
<         if self._manager is not None:
<             self._manager._cache[node.file] = node
<             if self._file:
<                 self._manager._cache[abspath(self._file)] = node
<         self._walker.walk(node)
<         while self._delayed:
<             dnode = self._delayed.pop(0)
<             getattr(self, 'delayed_visit_%s' % dnode.__class__.__name__.lower())(dnode)
<         return node
< 
<     # callbacks to build from an existing compiler.ast tree ###################
< 
<     def visit_module(self, node):
<         """visit a stmt.Module node -> init node and push the corresponding
<         object or None on the top of the stack
<         """
<         self._stack = [self._module]
<         self._par_stack = [node]
<         self._metaclass = ['']
<         self._global_names = []
<         node.parent = None
<         node.globals = node.locals = {}
<         for name, value in ( ('__name__', node.name),
<                              ('__file__', node.path),
<                              ('__doc__', node.doc) ):
<             const = nodes.Const(value)
<             const.parent = node
<             node.locals[name] = [const]
<         attach___dict__(node)
<         if node.package:
<             # FIXME: List(Const())
<             const = nodes.Const(dirname(node.path))
<             const.parent = node
<             node.locals['__path__'] = [const]
<             
< 
<     def leave_module(self, _):
<         """leave a stmt.Module node -> pop the last item on the stack and check
<         the stack is empty
<         """
<         self._stack.pop()
<         assert not self._stack, 'Stack is not empty : %s' % self._stack
<         self._par_stack.pop()
<         assert not self._par_stack, \
<                'Parent stack is not empty : %s' % self._par_stack
<         
<     def visit_class(self, node):
<         """visit a stmt.Class node -> init node and push the corresponding
<         object or None on the top of the stack
<         """
<         self.visit_default(node)
<         node.instance_attrs = {}
<         node.basenames = [b_node for b_node in node.bases]
<         self._push(node)
<         for name, value in ( ('__name__', node.name),
<                              ('__module__', node.root().name),
<                              ('__doc__', node.doc) ):
<             const = nodes.Const(value)
<             const.parent = node
<             node.locals[name] = [const]
<         attach___dict__(node)
<         self._metaclass.append(self._metaclass[-1])
<         
<     def leave_class(self, node):
<         """leave a stmt.Class node -> pop the last item on the stack
<         """
<         self.leave_default(node)
<         self._stack.pop()
<         metaclass = self._metaclass.pop()
<         if not node.bases:
<             # no base classes, detect new / style old style according to
<             # current scope
<             node._newstyle = metaclass == 'type'
<         
<     def visit_function(self, node):
<         """visit a stmt.Function node -> init node and push the corresponding
<         object or None on the top of the stack
<         """
<         self.visit_default(node)
<         self._global_names.append({})
<         node.argnames = list(node.argnames)
<         if isinstance(node.parent.frame(), nodes.Class):
<             node.type = 'method'
<             if node.name == '__new__':
<                 node.type = 'classmethod'
<         self._push(node)
<         register_arguments(node, node.argnames)
<         
<     def leave_function(self, node):
<         """leave a stmt.Function node -> pop the last item on the stack
<         """
<         self.leave_default(node)
<         self._stack.pop()
<         self._global_names.pop()
<         
<     def visit_lambda(self, node):
<         """visit a stmt.Lambda node -> init node locals
<         """
<         self.visit_default(node)
<         node.argnames = list(node.argnames)
<         node.locals = {}
<         register_arguments(node, node.argnames)
<         
<     def visit_genexpr(self, node):
<         """visit a stmt.GenExpr node -> init node locals
<         """
<         self.visit_default(node)
<         node.locals = {}
<         
<     def visit_global(self, node):
<         """visit a stmt.Global node -> add declared names to locals
<         """
<         self.visit_default(node)
<         if not self._global_names: # global at the module level, no effect
<             return
<         for name in node.names:
<             self._global_names[-1].setdefault(name, []).append(node)
< #             node.parent.set_local(name, node)
< #         module = node.root()
< #         if module is not node.frame():
< #             for name in node.names:
< #                 module.set_local(name, node)
<             
<     def visit_import(self, node):
<         """visit a stmt.Import node -> add imported names to locals
<         """
<         self.visit_default(node)
<         for (name, asname) in node.names:
<             name = asname or name
<             node.parent.set_local(name.split('.')[0], node)
<             
<     def visit_from(self, node):
<         """visit a stmt.From node -> add imported names to locals
<         """
<         self.visit_default(node)
<         # add names imported by the import to locals
<         for (name, asname) in node.names:
<             if name == '*':
<                 try:
<                     imported = node.root().import_module(node.modname)
<                 except ASTNGBuildingException:
<                     #import traceback
<                     #traceback.print_exc()
<                     continue
<                     # FIXME: log error
<                     #print >> sys.stderr, \
<                     #      'Unable to get imported names for %r line %s"' % (
<                     #    node.modname, node.lineno)
<                 for name in imported.wildcard_import_names():
<                     node.parent.set_local(name, node)
<             else:
<                 node.parent.set_local(asname or name, node)
< 
<     def leave_decorators(self, node):
<         """python >= 2.4
<         visit a stmt.Decorator node -> check for classmethod and staticmethod
<         """
<         func = node.parent
<         for decorator_expr in node.nodes:
<             if isinstance(decorator_expr, nodes.Name) and \
<                    decorator_expr.name in ('classmethod', 'staticmethod'):
<                 func.type = decorator_expr.name
<         self.leave_default(node)
<         
<     def visit_assign(self, node):
<         """visit a stmt.Assign node -> check for classmethod and staticmethod
<         + __metaclass__
<         """
<         self.visit_default(node)
<         klass = node.parent.frame()
<         #print node
<         if isinstance(klass, nodes.Class) and \
<             isinstance(node.expr, nodes.CallFunc) and \
<             isinstance(node.expr.node, nodes.Name):
<             func_name = node.expr.node.name
<             if func_name in ('classmethod', 'staticmethod'):
<                 for ass_node in node.nodes:
<                     if isinstance(ass_node, nodes.AssName):
<                         try:
<                             meth = klass[ass_node.name]
<                             if isinstance(meth, nodes.Function):
<                                 meth.type = func_name
<                             #else:
<                             #    print >> sys.stderr, 'FIXME 1', meth
<                         except KeyError:
<                             #print >> sys.stderr, 'FIXME 2', ass_node.name
<                             continue
<         elif (isinstance(node.nodes[0], nodes.AssName)
<               and node.nodes[0].name == '__metaclass__'): # XXX check more...
<             self._metaclass[-1] = 'type' # XXX get the actual metaclass
< 
<     def visit_assname(self, node):
<         """visit a stmt.AssName node -> add name to locals
<         """
<         self.visit_default(node)
<         self._add_local(node, node.name)
< 
<     def visit_augassign(self, node):
<         """visit a stmt.AssName node -> add name to locals
<         """
<         self.visit_default(node)
<         if not isinstance(node.node, nodes.Name):
<             return  # XXX
<         self._add_local(node, node.node.name)
< 
<     def _add_local(self, node, name):
<         if self._global_names and name in self._global_names[-1]:
<             node.root().set_local(name, node)
<         else:
<             node.parent.set_local(name, node)
<         
<     def visit_assattr(self, node):
<         """visit a stmt.AssAttr node -> delay it to handle members
<         definition later
<         """
<         self.visit_default(node)
<         self._delayed.append(node)
<     
<     def delayed_visit_assattr(self, node):
<         """visit a stmt.AssAttr node -> add name to locals, handle members
<         definition
<         """
<         try:
<             frame = node.frame()
<             for infered in node.expr.infer():
<                 if infered is YES:
<                     continue
<                 try:
<                     if infered.__class__ is Instance:
<                         infered = infered._proxied
<                         iattrs = infered.instance_attrs
<                     else:
<                         iattrs = infered.locals
<                 except AttributeError:
<                     continue
<                 values = iattrs.setdefault(node.attrname, [])
<                 if node in values:
<                     continue
<                 # get assign in __init__ first XXX useful ?
<                 if frame.name == '__init__' and values and not \
<                        values[0].frame().name == '__init__':
<                     values.insert(0, node)
<                 else:
<                     values.append(node)
<                 #print node.attrname, infered, values
<         except InferenceError:
<             #print frame, node
<             pass
<         
<     def visit_default(self, node):
<         """default visit method, handle the parent attribute
<         """
<         node.parent = self._par_stack[-1]
<         assert node.parent is not node
<         self._par_stack.append(node)
< 
<     def leave_default(self, _):       
<         """default leave method, handle the parent attribute
<         """
<         self._par_stack.pop()             
< 
<     def _push(self, node):
<         """update the stack and init some parts of the Function or Class node
<         """
<         obj = getattr(self._stack[-1], node.name, None)
<         self._stack.append(obj)
<         node.locals = {}
<         node.parent.frame().set_local(node.name, node)
< 
<     # astng from living objects ###############################################
<     #
<     # this is actually a really minimal representation, including only Module,
<     # Function and Class nodes and some others as guessed
<     
<     def object_build(self, node, obj):
<         """recursive method which create a partial ast from real objects
<          (only function, class, and method are handled)
<         """
<         if self._done.has_key(obj):
<             return self._done[obj]
<         self._done[obj] = node
<         modname = self._module.__name__
<         modfile = getattr(self._module, '__file__', None)
<         for name in dir(obj):
<             try:
<                 member = getattr(obj, name)
<             except AttributeError:
<                 # damned ExtensionClass.Base, I know you're there !
<                 attach_dummy_node(node, name)
<                 continue
<             if ismethod(member):
<                 member = member.im_func
<             if isfunction(member):
<                 # verify this is not an imported function
<                 if member.func_code.co_filename != modfile:
<                     attach_dummy_node(node, name, member)
<                     continue
<                 object_build_function(node, member)
<             elif isbuiltin(member):
<                 # verify this is not an imported member
<                 if self._member_module(member) != modname:
<                     imported_member(node, member, name)
<                     continue
<                 object_build_methoddescriptor(node, member)                
<             elif isclass(member):
<                 # verify this is not an imported class
<                 if self._member_module(member) != modname:
<                     imported_member(node, member, name)
<                     continue
<                 if member in self._done:
<                     class_node = self._done[member]
<                     node.add_local_node(class_node, name)
<                 else:
<                     class_node = object_build_class(node, member)
<                 # recursion
<                 self.object_build(class_node, member)
<             elif ismethoddescriptor(member):
<                 assert isinstance(member, object)
<                 object_build_methoddescriptor(node, member)
<             elif isdatadescriptor(member):
<                 assert isinstance(member, object)
<                 object_build_datadescriptor(node, member, name)
<             elif isinstance(member, (int, long, float, str, unicode)) or member is None:
<                 attach_const_node(node, name, member)
<             else:
<                 # create an empty node so that the name is actually defined
<                 attach_dummy_node(node, name, member)
< 
<     def _member_module(self, member):
<         modname = getattr(member, '__module__', None)
<         return self._dyn_modname_map.get(modname, modname)
<         
< def imported_member(node, member, name):
<     """consider a class/builtin member where __module__ != current module name
< 
<     check if it's sound valid and then add an import node, else use a dummy node
<     """
<     # /!\ some classes like ExtensionClass doesn't have a 
<     # __module__ attribute !
<     member_module = getattr(member, '__module__', '__builtin__')
<     try:
<         getattr(sys.modules[member_module], name)
<     except (KeyError, AttributeError):
<         attach_dummy_node(node, name, member)
<     else:
<         attach_import_node(node, member_module, name)
<     
< # optimize the tokenize module
< #from logilab.common.bind import optimize_module
< #import tokenize
< #optimize_module(sys.modules['tokenize'], tokenize.__dict__)
< #optimize_module(sys.modules[__name__], sys.modules[__name__].__dict__)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/_exceptions.py code-worker/code-worker/tasks/clonedigger/logilab/astng/_exceptions.py
1,52d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains exceptions used in the astng library
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __doctype__ = "restructuredtext en"
< 
< class ASTNGError(Exception):
<     """base exception class for all astng related exceptions
<     """
< 
< class ASTNGBuildingException(ASTNGError):
<     """exception class when we are not able to build an astng representation"""
< 
< class ResolveError(ASTNGError):
<     """base class of astng resolution/inference error"""
< 
< class NotFoundError(ResolveError):
<     """raised when we are unabled to resolve a name"""
< 
< class InferenceError(ResolveError):
<     """raised when we are unabled to infer a node"""
< 
< class UnresolvableName(InferenceError):
<     """raised when we are unabled to resolve a name"""
< 
< 
< class NoDefault(ASTNGError):
<     """raised by function's `default_value` method when an argument has
<     no default value
<     """
< 
< class IgnoreChild(Exception):
<     """exception that maybe raised by visit methods to avoid children traversal
<     """
<     
diff -r -N code-worker/tasks/clonedigger/logilab/astng/inference.py code-worker/code-worker/tasks/clonedigger/logilab/astng/inference.py
1,723d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains a set of functions to handle inference on astng trees
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2008 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< from __future__ import generators
< 
< __doctype__ = "restructuredtext en"
< 
< from copy import copy
< 
< from clonedigger.logilab.common.compat import imap, chain, set
< 
< from clonedigger.logilab.astng import MANAGER, YES, InferenceContext, Instance, Generator, \
<      unpack_infer, _infer_stmts, nodes, copy_context
< from clonedigger.logilab.astng import ASTNGError, InferenceError, UnresolvableName, \
<      NoDefault, NotFoundError, ASTNGBuildingException
< 
<     
< def path_wrapper(func):
<     """return the given infer function wrapped to handle the path"""
<     def wrapped(node, context=None, _func=func, **kwargs):
<         """wrapper function handling context"""
<         if context is None:
<             context = InferenceContext(node)
<         context.push(node)
<         yielded = set()
<         try:
<             for res in _func(node, context, **kwargs):
<                 # unproxy only true instance, not const, tuple, dict...
<                 if res.__class__ is Instance:
<                     ares = res._proxied
<                 else:
<                     ares = res
<                 if not ares in yielded:
<                     yield res
<                     yielded.add(ares)
<             context.pop()
<         except:
<             context.pop()
<             raise
<     return wrapped
< 
< # .infer method ###############################################################
< 
< def infer_default(self, context=None):
<     """we don't know how to resolve a statement by default"""
<     #print 'inference error', self, name, path
<     raise InferenceError(self.__class__.__name__)
< 
< #infer_default = infer_default
< nodes.Node.infer = infer_default
< 
< 
< def infer_end(self, context=None):
<     """inference's end for node such as Module, Class, Function, Const...
<     """
<     yield self
< 
< #infer_end = path_wrapper(infer_end)
< nodes.Module.infer = nodes.Class.infer = infer_end
< nodes.List.infer = infer_end
< nodes.Tuple.infer = infer_end
< nodes.Dict.infer = infer_end
< nodes.Const.infer = infer_end
< 
< def infer_empty_node(self, context=None):
<     if not self.has_underlying_object():
<         yield YES
<     else:
<         try:
<             for infered in MANAGER.infer_astng_from_something(self.object,
<                                                               context=context):
<                 yield infered
<         except ASTNGError:
<             yield YES
< nodes.EmptyNode.infer = path_wrapper(infer_empty_node)
<     
< 
< 
< class CallContext:
<     """when infering a function call, this class is used to remember values
<     given as argument
<     """
<     def __init__(self, args, starargs, dstarargs):
<         self.args = []
<         self.nargs = {}
<         for arg in args:
<             if isinstance(arg, nodes.Keyword):
<                 self.nargs[arg.name] = arg.expr
<             else:
<                 self.args.append(arg)
<         self.starargs = starargs
<         self.dstarargs = dstarargs
< 
<     def infer_argument(self, funcnode, name, context):
<         """infer a function argument value according the the call context"""
<         # 1. search in named keywords
<         try:
<             return self.nargs[name].infer(context)
<         except KeyError:
<             # Function.argnames can be None in astng (means that we don't have
<             # information on argnames)
<             if funcnode.argnames is not None:
<                 try:
<                     argindex = funcnode.argnames.index(name)
<                 except ValueError:
<                     pass
<                 else:
<                     # 2. first argument of instance/class method
<                     if argindex == 0 and funcnode.type in ('method', 'classmethod'):
<                         if context.boundnode is not None:
<                             boundnode = context.boundnode
<                         else:
<                             # XXX can do better ?
<                             boundnode = funcnode.parent.frame()
<                         if funcnode.type == 'method':
<                             return iter((Instance(boundnode),))
<                         if funcnode.type == 'classmethod':
<                             return iter((boundnode,))                            
<                     # 2. search arg index
<                     try:
<                         return self.args[argindex].infer(context)
<                     except IndexError:
<                         pass
<                     # 3. search in *args (.starargs)
<                     if self.starargs is not None:
<                         its = []
<                         for infered in self.starargs.infer(context):
<                             if infered is YES:
<                                 its.append((YES,))
<                                 continue
<                             try:
<                                 its.append(infered.getitem(argindex).infer(context))
<                             except (InferenceError, AttributeError):
<                                 its.append((YES,))
<                             except IndexError:
<                                 continue
<                         if its:
<                             return chain(*its)
<         # 4. XXX search in **kwargs (.dstarargs)
<         if self.dstarargs is not None:
<             its = []
<             for infered in self.dstarargs.infer(context):
<                 if infered is YES:
<                     its.append((YES,))
<                     continue
<                 try:
<                     its.append(infered.getitem(name).infer(context))
<                 except (InferenceError, AttributeError):
<                     its.append((YES,))
<                 except IndexError:
<                     continue
<             if its:
<                 return chain(*its)
<         # 5. */** argument, (Tuple or Dict)
<         mularg = funcnode.mularg_class(name)
<         if mularg is not None: 
<             # XXX should be able to compute values inside
<             return iter((mularg,))
<         # 6. return default value if any
<         try:
<             return funcnode.default_value(name).infer(context)
<         except NoDefault:
<             raise InferenceError(name)
<         
<         
< def infer_function(self, context=None):
<     """infer on Function nodes must be take with care since it
<     may be called to infer one of it's argument (in which case <name>
<     should be given)
<     """
<     name = context.lookupname
<     # no name is given, we are infering the function itself
<     if name is None:
<         yield self
<         return
<     if context.callcontext:
<         # reset call context/name
<         callcontext = context.callcontext
<         context = copy_context(context)
<         context.callcontext = None
<         for infered in callcontext.infer_argument(self, name, context):
<             yield infered
<         return
<     # Function.argnames can be None in astng (means that we don't have
<     # information on argnames), in which case we can't do anything more
<     if self.argnames is None:
<         yield YES
<         return
<     if not name in self.argnames:
<         raise InferenceError()
<     # first argument of instance/class method
<     if name == self.argnames[0]:
<         if self.type == 'method':
<             yield Instance(self.parent.frame())
<             return
<         if self.type == 'classmethod':
<             yield self.parent.frame()
<             return
<     mularg = self.mularg_class(name)
<     if mularg is not None: # */** argument, no doubt it's a Tuple or Dict
<         yield mularg
<         return
<     # if there is a default value, yield it. And then yield YES to reflect
<     # we can't guess given argument value
<     try:
<         context = copy_context(context)
<         for infered in self.default_value(name).infer(context):
<             yield infered
<         yield YES
<     except NoDefault:
<         yield YES
< 
< nodes.Function.infer = path_wrapper(infer_function)
< nodes.Lambda.infer = path_wrapper(infer_function)
< 
< 
< def infer_name(self, context=None):
<     """infer a Name: use name lookup rules"""
<     context = context.clone()
<     context.lookupname = self.name
<     frame, stmts = self.lookup(self.name)
<     if not stmts:
<         raise UnresolvableName(self.name)
<     return _infer_stmts(stmts, context, frame)
< 
< nodes.Name.infer = path_wrapper(infer_name)
< 
< 
< def infer_assname(self, context=None):
<     """infer a AssName/AssAttr: need to inspect the RHS part of the
<     assign node
<     """
<     stmts = self.assigned_stmts(context=context)
<     return _infer_stmts(stmts, context)
<     
< nodes.AssName.infer = path_wrapper(infer_assname)
< 
< 
< def infer_assattr(self, context=None):
<     """infer a AssName/AssAttr: need to inspect the RHS part of the
<     assign node
<     """
<     stmts = self.assigned_stmts(context=context)
<     return _infer_stmts(stmts, context)
<     
< nodes.AssAttr.infer = path_wrapper(infer_assattr)
< 
<         
< def infer_callfunc(self, context=None):
<     """infer a CallFunc node by trying to guess what's the function is
<     returning
<     """
<     one_infered = False
<     context = context.clone()
<     context.callcontext = CallContext(self.args, self.star_args, self.dstar_args)
<     for callee in self.node.infer(context):
<         if callee is YES:
<             yield callee
<             one_infered = True
<             continue
<         try:
<             for infered in callee.infer_call_result(self, context):
<                 yield infered
<                 one_infered = True
<         except (AttributeError, InferenceError):
<             ## XXX log error ?
<             continue
<     if not one_infered:
<         raise InferenceError()
< 
< nodes.CallFunc.infer = path_wrapper(infer_callfunc)
< 
< 
< def infer_getattr(self, context=None):
<     """infer a Getattr node by using getattr on the associated object
<     """
<     one_infered = False
<     # XXX
<     #context = context.clone()
<     for owner in self.expr.infer(context):
<         if owner is YES:
<             yield owner
<             one_infered = True
<             continue
<         try:
<             context.boundnode = owner
<             for obj in owner.igetattr(self.attrname, context):
<                 yield obj
<                 one_infered = True
<             context.boundnode = None
<         except (NotFoundError, InferenceError):
<             continue
<         except AttributeError:
<             # XXX method / function
<             continue
<     if not one_infered:
<         raise InferenceError()
<                 
< nodes.Getattr.infer = path_wrapper(infer_getattr)
< 
< 
< def _imported_module_astng(node, modname):
<     """return the ast for a module whose name is <modname> imported by <node>
<     """
<     # handle special case where we are on a package node importing a module
<     # using the same name as the package, which may end in an infinite loop
<     # on relative imports
<     # XXX: no more needed ?
<     mymodule = node.root()
<     if mymodule.relative_name(modname) == mymodule.name:
<         # FIXME: I don't know what to do here...
<         raise InferenceError(modname)
<     try:
<         return mymodule.import_module(modname)
<     except (ASTNGBuildingException, SyntaxError):
<         raise InferenceError(modname)
<         
< def infer_import(self, context=None, asname=True):
<     """self resolve on From / Import nodes return the imported module/object"""
<     name = context.lookupname
<     if name is None:
<         raise InferenceError()
<     if asname:
<         yield _imported_module_astng(self, self.real_name(name))
<     else:
<         yield _imported_module_astng(self, name)
<     
< nodes.Import.infer = path_wrapper(infer_import)
< 
< def infer_from(self, context=None, asname=True):
<     """self resolve on From / Import nodes return the imported module/object"""
<     name = context.lookupname
<     if name is None:
<         raise InferenceError()
<     if asname:
<         name = self.real_name(name)
<     module = _imported_module_astng(self, self.modname)
<     try:
<         context = copy_context(context)
<         context.lookupname = name
<         return _infer_stmts(module.getattr(name), context)
<     except NotFoundError:
<         raise InferenceError(name)
< 
< nodes.From.infer = path_wrapper(infer_from)
< 
< 
< def infer_global(self, context=None):
<     if context.lookupname is None:
<         raise InferenceError()
<     try:
<         return _infer_stmts(self.root().getattr(context.lookupname), context)
<     except NotFoundError:
<         raise InferenceError()
< nodes.Global.infer = path_wrapper(infer_global)
< 
< 
< def infer_subscript(self, context=None):
<     """infer simple subscription such as [1,2,3][0] or (1,2,3)[-1]
<     """
<     if len(self.subs) == 1:
<         index = self.subs[0].infer(context).next()
<         if index is YES:
<             yield YES
<             return
<         try:
<             # suppose it's a Tuple/List node (attribute error else)
<             assigned = self.expr.getitem(index.value)
<         except AttributeError:
<             raise InferenceError()
<         except IndexError:
<             yield YES
<             return
<         for infered in assigned.infer(context):
<             yield infered
<     else:
<         raise InferenceError()
< nodes.Subscript.infer = path_wrapper(infer_subscript)
< 
< def infer_unarysub(self, context=None):
<     for infered in self.expr.infer(context):
<         try:
<             value = -infered.value
<         except (TypeError, AttributeError):
<             yield YES
<             continue
<         node = copy(self.expr)
<         node.value = value
<         yield node
< nodes.UnarySub.infer = path_wrapper(infer_unarysub)
< 
< def infer_unaryadd(self, context=None):
<     return self.expr.infer(context)
< nodes.UnaryAdd.infer = infer_unaryadd
< 
< def _py_value(node):
<     try:
<         return node.value
<     except AttributeError:
<         # not a constant
<         if isinstance(node, nodes.Dict):
<             return {}
<         if isinstance(node, nodes.List):
<             return []
<         if isinstance(node, nodes.Tuple):
<             return ()
<     raise ValueError()
< 
< def _infer_operator(self, context=None, impl=None, meth='__method__'):
<     for lhs in self.left.infer(context):
<         try:
<             lhsvalue = _py_value(lhs)
<         except ValueError:
<             # not a constant
<             try:
<                 # XXX just suppose if the type implement meth, returned type
<                 # will be the same
<                 lhs.getattr(meth)
<                 yield lhs
<             except:
<                 yield YES
<             continue
<         for rhs in self.right.infer(context):
<             try:
<                 rhsvalue = _py_value(rhs)
<             except ValueError:
<                 try:
<                     # XXX just suppose if the type implement meth, returned type
<                     # will be the same
<                     rhs.getattr(meth)
<                     yield rhs
<                 except:
<                     yield YES
<                 continue
<             try:
<                 value = impl(lhsvalue, rhsvalue)
<             except TypeError:
<                 yield YES
<                 continue
<             if type(value) is type(lhsvalue):
<                 node = copy(lhs)
<             else:
<                 node = copy(rhs)
<             # XXX may be dict, tuple...
<             node.value = value
<             yield node
< 
< def infer_sub(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a-b, meth='__sub__')
< nodes.Sub.infer = path_wrapper(infer_sub)
< 
< def infer_add(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a+b, meth='__add__')
< nodes.Add.infer = path_wrapper(infer_add)
< 
< def infer_mul(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a*b, meth='__mul__')
< nodes.Mul.infer = path_wrapper(infer_mul)
< 
< def infer_div(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a/b, meth='__div__')
< nodes.Div.infer = path_wrapper(infer_div)
<     
< # .infer_call_result method ###################################################
< def callable_default(self):
<     return False
< nodes.Node.callable = callable_default
< def callable_true(self):
<     return True
< nodes.Function.callable = callable_true
< nodes.Lambda.callable = callable_true
< nodes.Class.callable = callable_true
< 
< def infer_call_result_function(self, caller, context=None):
<     """infer what's a function is returning when called"""
<     if self.is_generator():
<         yield Generator(self)
<         return
<     returns = self.nodes_of_class(nodes.Return, skip_klass=nodes.Function)
<     for returnnode in returns:
<         try:
<             for infered in returnnode.value.infer(context):
<                 yield infered
<         except InferenceError:
<             yield YES
< nodes.Function.infer_call_result = infer_call_result_function
< 
< def infer_call_result_lambda(self, caller, context=None):
<     """infer what's a function is returning when called"""
<     return self.code.infer(context)
< nodes.Lambda.infer_call_result = infer_call_result_lambda
< 
< def infer_call_result_class(self, caller, context=None):
<     """infer what's a class is returning when called"""
<     yield Instance(self)
< 
< nodes.Class.infer_call_result = infer_call_result_class
< 
< 
< # Assignment related nodes ####################################################
< """the assigned_stmts method is responsible to return the assigned statement
< (eg not infered) according to the assignment type.
< 
< The `asspath` argument is used to record the lhs path of the original node.
< For instance if we want assigned statements for 'c' in 'a, (b,c)', asspath
< will be [1, 1] once arrived to the Assign node.
< 
< The `context` argument is the current inference context which should be given
< to any intermediary inference necessary.
< """
< def assend_assigned_stmts(self, context=None):
<     # only infer *real* assignments
<     if self.flags == 'OP_DELETE':
<         raise InferenceError()
<     return self.parent.assigned_stmts(self, context=context)
<     
< nodes.AssName.assigned_stmts = assend_assigned_stmts
< nodes.AssAttr.assigned_stmts = assend_assigned_stmts
< 
< def mulass_assigned_stmts(self, node, context=None, asspath=None):
<     if asspath is None:
<         asspath = []
<     node_idx = self.nodes.index(node)
<     asspath.insert(0, node_idx)
<     return self.parent.assigned_stmts(self, context, asspath)
< nodes.AssTuple.assigned_stmts = mulass_assigned_stmts
< nodes.AssList.assigned_stmts = mulass_assigned_stmts
< 
< def assign_assigned_stmts(self, node, context=None, asspath=None):
<     if not asspath:
<         yield self.expr 
<         return
<     found = False
<     for infered in _resolve_asspart(self.expr.infer(context), asspath, context):
<         found = True
<         yield infered
<     if not found:
<         raise InferenceError()
< 
< nodes.Assign.assigned_stmts = assign_assigned_stmts
< 
< def _resolve_asspart(parts, asspath, context):
<     """recursive function to resolve multiple assignments"""
<     asspath = asspath[:]
<     index = asspath.pop(0)
<     for part in parts:
<         try:
<             assigned = part.getitem(index)
<         except (AttributeError, IndexError):
<             return
<         if not asspath:
<             # we acheived to resolved the assigment path,
<             # don't infer the last part
<             found = True
<             yield assigned
<         elif assigned is YES:
<             return
<         else:
<             # we are not yet on the last part of the path
<             # search on each possibly infered value
<             try:
<                 for infered in _resolve_asspart(assigned.infer(context), asspath, context):
<                     yield infered
<             except InferenceError:
<                 return
<     
< def tryexcept_assigned_stmts(self, node, context=None, asspath=None):
<     found = False
<     for exc_type, exc_obj, body in self.handlers:
<         if node is exc_obj:
<             for assigned in unpack_infer(exc_type):
<                 if isinstance(assigned, nodes.Class):
<                     assigned = Instance(assigned)
<                 yield assigned
<                 found = True
<             break
<     if not found:
<         raise InferenceError()
< nodes.TryExcept.assigned_stmts = tryexcept_assigned_stmts
< 
< 
< def _resolve_looppart(parts, asspath, context):
<     """recursive function to resolve multiple assignments on loops"""
<     asspath = asspath[:]
<     index = asspath.pop(0)
<     for part in parts:
<         if part is YES:
<             continue
<         if not hasattr(part, 'iter_stmts'):
<             continue
<         for stmt in part.iter_stmts():
<             try:
<                 assigned = stmt.getitem(index)
<             except (AttributeError, IndexError):
<                 continue
<             if not asspath:
<                 # we acheived to resolved the assigment path,
<                 # don't infer the last part
<                 found = True
<                 yield assigned
<             elif assigned is YES:
<                 break
<             else:
<                 # we are not yet on the last part of the path
<                 # search on each possibly infered value
<                 try:
<                     for infered in _resolve_looppart(assigned.infer(context), asspath, context):
<                         yield infered
<                 except InferenceError:
<                     break
< 
< def for_assigned_stmts(self, node, context=None, asspath=None):
<     found = False
<     if asspath is None:
<         for lst in self.loop_node().infer(context):
<             if isinstance(lst, (nodes.Tuple, nodes.List)):
<                 for item in lst.nodes:
<                     found = True
<                     yield item
<     else:
<         for infered in _resolve_looppart(self.loop_node().infer(context), asspath, context):
<             found = True
<             yield infered
<     if not found:
<         raise InferenceError()
< nodes.For.assigned_stmts = for_assigned_stmts
< nodes.ListCompFor.assigned_stmts = for_assigned_stmts
< nodes.GenExprFor.assigned_stmts = for_assigned_stmts
< 
< def with_assigned_stmts(self, node, context=None, asspath=None):
<     found = False
<     if asspath is None:
<         for lst in self.vars.infer(context):
<             if isinstance(lst, (nodes.Tuple, nodes.List)):
<                 for item in lst.nodes:
<                     found = True
<                     yield item
<     else:
<         raise InferenceError()
<     if not found:
<         raise InferenceError()
< nodes.With.assigned_stmts = with_assigned_stmts
< 
<     
< def end_ass_type(self):
<     return self
< nodes.With.ass_type = end_ass_type
< nodes.For.ass_type = end_ass_type
< nodes.ListCompFor.ass_type = end_ass_type
< nodes.GenExprFor.ass_type = end_ass_type
< nodes.TryExcept.ass_type = end_ass_type
< nodes.Assign.ass_type = end_ass_type
< nodes.AugAssign.ass_type = end_ass_type
< def parent_ass_type(self):
<     return self.parent.ass_type()
< nodes.AssName.ass_type = parent_ass_type
< nodes.AssAttr.ass_type = parent_ass_type
< nodes.AssTuple.ass_type = parent_ass_type
< nodes.AssList.ass_type = parent_ass_type
< def assend_ass_type(self, context=None):
<     # only infer *real* assignments
<     if self.flags == 'OP_DELETE':
<         return self
<     return self.parent.ass_type()
< nodes.AssName.ass_type = assend_ass_type
< nodes.AssAttr.ass_type = assend_ass_type
< 
< # subscription protocol #######################################################
<         
< def tl_getitem(self, index):
<     return self.nodes[index]
< nodes.List.getitem = tl_getitem
< nodes.Tuple.getitem = tl_getitem
<         
< def tl_iter_stmts(self):
<     return self.nodes
< nodes.List.iter_stmts = tl_iter_stmts
< nodes.Tuple.iter_stmts = tl_iter_stmts
< 
< #Dict.getitem = getitem XXX
<         
< def dict_getitem(self, key):
<     for i in xrange(0, len(self.items), 2):
<         for inferedkey in self.items[i].infer():
<             if inferedkey is YES:
<                 continue
<             if inferedkey.eq(key):
<                 return self.items[i+1]
<     raise IndexError(key)
< 
< nodes.Dict.getitem = dict_getitem
<         
< def dict_iter_stmts(self):
<     return self.items[::2]
< nodes.Dict.iter_stmts = dict_iter_stmts
< 
< 
< def for_loop_node(self):
<     return self.list
< nodes.For.loop_node = for_loop_node
< nodes.ListCompFor.loop_node = for_loop_node
< 
< def gen_loop_nodes(self):
<     return self.iter
< nodes.GenExprFor.loop_node = gen_loop_nodes
diff -r -N code-worker/tasks/clonedigger/logilab/astng/__init__.py code-worker/code-worker/tasks/clonedigger/logilab/astng/__init__.py
1,294d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Python Abstract Syntax Tree New Generation
< 
< The aim of this module is to provide a common base representation of
< python source code for projects such as pychecker, pyreverse,
< pylint... Well, actually the development of this library is essentialy
< governed by pylint's needs.
< 
< It extends class defined in the compiler.ast [1] module with some
< additional methods and attributes. Instance attributes are added by a
< builder object, which can either generate extended ast (let's call
< them astng ;) by visiting an existant ast tree or by inspecting living
< object. Methods are added by monkey patching ast classes.
< 
< Main modules are:
< 
< * nodes and scoped_nodes for more information about methods and
<   attributes added to different node classes
< 
< * the manager contains a high level object to get astng trees from
<   source files and living objects. It maintains a cache of previously
<   constructed tree for quick access
< 
< * builder contains the class responsible to build astng trees
< 
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< from __future__ import generators
< 
< __doctype__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.compat import chain, imap
< 
< # WARNING: internal imports order matters !
< 
< from clonedigger.logilab.astng._exceptions import *
< 
< 
< class InferenceContext(object):
<     __slots__ = ('startingfrom', 'path', 'lookupname', 'callcontext', 'boundnode')
<     
<     def __init__(self, node=None, path=None):
<         self.startingfrom = node # XXX useful ?
<         if path is None:
<             self.path = []
<         else:
<             self.path = path
<         self.lookupname = None
<         self.callcontext = None
<         self.boundnode = None
< 
<     def push(self, node):
<         name = self.lookupname
<         if (node, name) in self.path:
<             raise StopIteration()
<         self.path.append( (node, name) )
< 
<     def pop(self):
<         return self.path.pop()
< 
<     def clone(self):
<         # XXX copy lookupname/callcontext ?
<         clone = InferenceContext(self.startingfrom, self.path)
<         clone.callcontext = self.callcontext
<         clone.boundnode = self.boundnode
<         return clone
< 
< 
< def unpack_infer(stmt, context=None):
<     """return an iterator on nodes infered by the given statement
<     if the infered value is a list or a tuple, recurse on it to
<     get values infered by its content
<     """
<     if isinstance(stmt, (List, Tuple)):
<         # XXX loosing context
<         return chain(*imap(unpack_infer, stmt.nodes))
<     infered = stmt.infer(context).next()
<     if infered is stmt:
<         return iter( (stmt,) )
<     return chain(*imap(unpack_infer, stmt.infer(context)))
< 
< def copy_context(context):
<     if context is not None:
<         return context.clone()
<     else:
<         return InferenceContext()
<     
< def _infer_stmts(stmts, context, frame=None):
<     """return an iterator on statements infered by each statement in <stmts>
<     """
<     stmt = None
<     infered = False
<     if context is not None:
<         name = context.lookupname
<         context = context.clone()
<     else:
<         name = None
<         context = InferenceContext()
<     for stmt in stmts:
<         if stmt is YES:
<             yield stmt
<             infered = True
<             continue
<         context.lookupname = stmt._infer_name(frame, name)
<         try:
<             for infered in stmt.infer(context):
<                 yield infered
<                 infered = True
<         except UnresolvableName:
<             continue
<         except InferenceError:
<             yield YES
<             infered = True
<     if not infered:
<         raise InferenceError(str(stmt))
< 
< # special inference objects ###################################################
< 
< class Yes(object):
<     """a yes object"""
<     def __repr__(self):
<         return 'YES'
<     def __getattribute__(self, name):
<         return self
<     def __call__(self, *args, **kwargs):
<         return self
< YES = Yes()
< 
< class Proxy:
<     """a simple proxy object"""
<     def __init__(self, proxied):
<         self._proxied = proxied
< 
<     def __getattr__(self, name):
<         return getattr(self._proxied, name)
< 
<     def infer(self, context=None):
<         yield self
< 
< 
< class InstanceMethod(Proxy):
<     """a special node representing a function bound to an instance"""
<     def __repr__(self):
<         instance = self._proxied.parent.frame()
<         return 'Bound method %s of %s.%s' % (self._proxied.name,
<                                              instance.root().name,
<                                              instance.name)
<     __str__ = __repr__
< 
<     def is_bound(self):
<         return True
< 
< 
< class Instance(Proxy):
<     """a special node representing a class instance"""
<     def getattr(self, name, context=None, lookupclass=True):
<         try:
<             return self._proxied.instance_attr(name, context)
<         except NotFoundError:
<             if name == '__class__':
<                 return [self._proxied]
<             if name == '__name__':
<                 # access to __name__ gives undefined member on class
<                 # instances but not on class objects
<                 raise NotFoundError(name)
<             if lookupclass:
<                 return self._proxied.getattr(name, context)
<         raise NotFoundError(name)
< 
<     def igetattr(self, name, context=None):
<         """infered getattr"""
<         try:
<             # XXX frame should be self._proxied, or not ?
<             return _infer_stmts(
<                 self._wrap_attr(self.getattr(name, context, lookupclass=False)),
<                                 context, frame=self)
<         except NotFoundError:
<             try:
<                 # fallback to class'igetattr since it has some logic to handle
<                 # descriptors
<                 return self._wrap_attr(self._proxied.igetattr(name, context))
<             except NotFoundError:
<                 raise InferenceError(name)
<             
<     def _wrap_attr(self, attrs):
<         """wrap bound methods of attrs in a InstanceMethod proxies"""
<         # Guess which attrs are used in inference.
<         def wrap(attr):
<             if isinstance(attr, Function) and attr.type == 'method':
<                 return InstanceMethod(attr)
<             else:
<                 return attr
<         return imap(wrap, attrs)
<         
<     def infer_call_result(self, caller, context=None):
<         """infer what's a class instance is returning when called"""
<         infered = False
<         for node in self._proxied.igetattr('__call__', context):
<             for res in node.infer_call_result(caller, context):
<                 infered = True
<                 yield res
<         if not infered:
<             raise InferenceError()
< 
<     def __repr__(self):
<         return 'Instance of %s.%s' % (self._proxied.root().name,
<                                       self._proxied.name)
<     __str__ = __repr__
<     
<     def callable(self):
<         try:
<             self._proxied.getattr('__call__')
<             return True
<         except NotFoundError:
<             return False
< 
<     def pytype(self):
<         return self._proxied.qname()
<     
< class Generator(Proxy): 
<     """a special node representing a generator"""
<     def callable(self):
<         return True
<     
<     def pytype(self):
<         return '__builtin__.generator'
< 
< # imports #####################################################################
< 
< from clonedigger.logilab.astng.manager import ASTNGManager, Project, Package
< MANAGER = ASTNGManager()
< 
< from clonedigger.logilab.astng.nodes import *
< from clonedigger.logilab.astng import nodes
< from clonedigger.logilab.astng.scoped_nodes import *
< from clonedigger.logilab.astng import inference
< from clonedigger.logilab.astng import lookup
< lookup._decorate(nodes)
< 
< List._proxied = MANAGER.astng_from_class(list)
< List.__bases__ += (inference.Instance,)
< List.pytype = lambda x: '__builtin__.list'
< 
< Tuple._proxied = MANAGER.astng_from_class(tuple)
< Tuple.__bases__ += (inference.Instance,)
< Tuple.pytype = lambda x: '__builtin__.tuple'
< 
< Dict.__bases__ += (inference.Instance,)
< Dict._proxied = MANAGER.astng_from_class(dict)
< Dict.pytype = lambda x: '__builtin__.dict'
< 
< builtin_astng = Dict._proxied.root()
< 
< Const.__bases__ += (inference.Instance,)
< Const._proxied = None
< def Const___getattr__(self, name):
<     if self.value is None:
<         raise AttributeError(name)
<     if self._proxied is None:
<         self._proxied = MANAGER.astng_from_class(self.value.__class__)
<     return getattr(self._proxied, name)
< Const.__getattr__ = Const___getattr__
< def Const_getattr(self, name, context=None, lookupclass=None):
<     if self.value is None:
<         raise NotFoundError(name)
<     if self._proxied is None:
<         self._proxied = MANAGER.astng_from_class(self.value.__class__)
<     return self._proxied.getattr(name, context)
< Const.getattr = Const_getattr
< Const.has_dynamic_getattr = lambda x: False
< 
< def Const_pytype(self):
<     if self.value is None:
<         return '__builtin__.NoneType'
<     if self._proxied is None:
<         self._proxied = MANAGER.astng_from_class(self.value.__class__)
<     return self._proxied.qname()
< Const.pytype = Const_pytype
diff -r -N code-worker/tasks/clonedigger/logilab/astng/inspector.py code-worker/code-worker/tasks/clonedigger/logilab/astng/inspector.py
1,266d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """visitor doing some postprocessing on the astng tree.
< Try to resolve definitions (namespace) dictionnary, relationship...
< 
< This module has been imported from pyreverse
< 
< 
< :version:   $Revision: 1.6 $  
< :author:    Sylvain Thenault
< :copyright: 2003-2005 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2005 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< from os.path import dirname
< 
< from clonedigger.logilab.common.modutils import get_module_part, is_relative, \
<      is_standard_module
< 
< from clonedigger.logilab import astng
< from clonedigger.logilab.astng.utils import LocalsVisitor
< 
< class IdGeneratorMixIn:
<     """
<     Mixin adding the ability to generate integer uid
<     """
<     def __init__(self, start_value=0):
<         self.id_count = start_value
<     
<     def init_counter(self, start_value=0):
<         """init the id counter
<         """
<         self.id_count = start_value
<         
<     def generate_id(self):
<         """generate a new identifer
<         """
<         self.id_count += 1
<         return self.id_count
< 
< 
< class Linker(IdGeneratorMixIn, LocalsVisitor):
<     """
<     walk on the project tree and resolve relationships.
<     
<     According to options the following attributes may be added to visited nodes:
<     
<     * uid,
<       a unique identifier for the node (on astng.Project, astng.Module,
<       astng.Class and astng.locals_type). Only if the linker has been instantiad
<       with tag=True parameter (False by default).
<             
<     * Function
<       a mapping from locals'names to their bounded value, which may be a
<       constant like a string or an integer, or an astng node (on astng.Module,
<       astng.Class and astng.Function).
< 
<     * instance_attrs_type
<       as locals_type but for klass member attributes (only on astng.Class)
<       
<     * implements,
<       list of implemented interfaces _objects_ (only on astng.Class nodes)
<     """
<     
<     def __init__(self, project, inherited_interfaces=0, tag=False):
<         IdGeneratorMixIn.__init__(self)
<         LocalsVisitor.__init__(self)
<         # take inherited interface in consideration or not
<         self.inherited_interfaces = inherited_interfaces
<         # tag nodes or not
<         self.tag = tag
<         # visited project
<         self.project = project
< 
<         
<     def visit_project(self, node):
<         """visit an astng.Project node
<         
<          * optionaly tag the node wth a unique id
<         """
<         if self.tag:
<             node.uid = self.generate_id()
<         for module in node.modules:
<             self.visit(module)
<             
<     def visit_package(self, node):
<         """visit an astng.Package node
<         
<          * optionaly tag the node wth a unique id
<         """
<         if self.tag:
<             node.uid = self.generate_id()
<         for subelmt in node.values():
<             self.visit(subelmt)
<             
<     def visit_module(self, node):
<         """visit an astng.Module node
<         
<          * set the locals_type mapping
<          * set the depends mapping
<          * optionaly tag the node wth a unique id
<         """
<         if hasattr(node, 'locals_type'):
<             return
<         node.locals_type = {}
<         node.depends = []
<         if self.tag:
<             node.uid = self.generate_id()
<     
<     def visit_class(self, node):
<         """visit an astng.Class node
<         
<          * set the locals_type and instance_attrs_type mappings
<          * set the implements list and build it
<          * optionaly tag the node wth a unique id
<         """
<         if hasattr(node, 'locals_type'):
<             return
<         node.locals_type = {}
<         if self.tag:
<             node.uid = self.generate_id()
<         # resolve ancestors
<         for baseobj in node.ancestors(recurs=False):
<             specializations = getattr(baseobj, 'specializations', [])
<             specializations.append(node)
<             baseobj.specializations = specializations
<         # resolve instance attributes
<         node.instance_attrs_type = {}
<         for assattrs in node.instance_attrs.values():
<             for assattr in assattrs:
<                 self.visit_assattr(assattr, node)
<         # resolve implemented interface
<         try:
<             node.implements = list(node.interfaces(self.inherited_interfaces))
<         except TypeError:
<             node.implements = ()
<             
<     def visit_function(self, node):
<         """visit an astng.Function node
<         
<          * set the locals_type mapping
<          * optionaly tag the node wth a unique id
<         """
<         if hasattr(node, 'locals_type'):
<             return
<         node.locals_type = {}
<         if self.tag:
<             node.uid = self.generate_id()
<             
<     link_project = visit_project
<     link_module = visit_module
<     link_class = visit_class
<     link_function = visit_function
<         
<     def visit_assname(self, node):
<         """visit an astng.AssName node
< 
<         handle locals_type
<         """
<         frame = node.frame()
<         try:
<             values = list(node.infer())
<             try:
<                 already_infered = frame.locals_type[node.name]
<                 for valnode in values:
<                     if not valnode in already_infered:
<                         already_infered.append(valnode)
<             except KeyError:
<                 frame.locals_type[node.name] = values
<         except astng.InferenceError:
<             pass
<         
<     def visit_assattr(self, node, parent):
<         """visit an astng.AssAttr node
< 
<         handle instance_attrs_type
<         """
<         try:
<             values = list(node.infer())
<             try:
<                 already_infered = parent.instance_attrs_type[node.attrname]
<                 for valnode in values:
<                     if not valnode in already_infered:
<                         already_infered.append(valnode)
<             except KeyError:
<                 parent.instance_attrs_type[node.attrname] = values
<         except astng.InferenceError:
<             pass
<             
<     def visit_import(self, node):
<         """visit an astng.Import node
<         
<         resolve module dependencies
<         """
<         context_file = node.root().file
<         for name in node.names:
<             relative = is_relative(name[0], context_file)
<             self._imported_module(node, name[0], relative)
<         
< 
<     def visit_from(self, node):
<         """visit an astng.From node
<         
<         resolve module dependencies
<         """
<         basename = node.modname
<         context_file = node.root().file
<         if context_file is not None:
<             relative = is_relative(basename, context_file)
<         else:
<             relative = False
<         for name in node.names:
<             if name[0] == '*':
<                 continue
<             # analyze dependancies
<             fullname = '%s.%s' % (basename, name[0])
<             if fullname.find('.') > -1:
<                 try:
<                     # XXX: don't use get_module_part, missing package precedence
<                     fullname = get_module_part(fullname)
<                 except ImportError:
<                     continue
<             if fullname != basename:
<                 self._imported_module(node, fullname, relative)
< 
<         
<     def compute_module(self, context_name, mod_path):
<         """return true if the module should be added to dependencies"""
<         package_dir = dirname(self.project.path)
<         if context_name == mod_path:
<             return 0
<         elif is_standard_module(mod_path, (package_dir,)):
<             return 1
<         return 0
<     
<     # protected methods ########################################################
< 
<     def _imported_module(self, node, mod_path, relative):
<         """notify an imported module, used to analyze dependancies
<         """
<         module = node.root()
<         context_name = module.name
<         if relative:
<             mod_path = '%s.%s' % ('.'.join(context_name.split('.')[:-1]),
<                                   mod_path)
<         if self.compute_module(context_name, mod_path):
<             # handle dependancies
<             if not hasattr(module, 'depends'):
<                 module.depends = []
<             mod_paths = module.depends
<             if not mod_path in mod_paths:
<                 mod_paths.append(mod_path)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/lookup.py code-worker/code-worker/tasks/clonedigger/logilab/astng/lookup.py
1,224d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """name lookup methods, available on Name ans scoped (Module, Class,
< Function...) nodes:
< 
< * .lookup(name)
< * .ilookup(name)
< 
< Be careful, lookup is kinda internal and return a tuple (scope, [stmts]), while
< ilookup return an iterator on infered values
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< from __future__ import generators
< 
< __docformat__ = "restructuredtext en"
< 
< import __builtin__
< 
< from clonedigger.logilab.astng.utils import are_exclusive
< from clonedigger.logilab.astng import nodes, MANAGER, _infer_stmts, copy_context
< 
< 
< def lookup(self, name):
<     """lookup a variable name
< 
<     return the scoope node and the list of assignments associated to the given
<     name according to the scope where it has been found (locals, globals or
<     builtin)
< 
<     The lookup is starting from self's scope. If self is not a frame itself and
<     the name is found in the inner frame locals, statements will be filtered
<     to remove ignorable statements according to self's location
<     """
<     #assert ID_RGX.match(name), '%r is not a valid identifier' % name
<     return self.scope().scope_lookup(self, name)
< 
< def scope_lookup(self, node, name, offset=0):
<     try:
<         stmts = node._filter_stmts(self.locals[name], self, offset)
<     except KeyError:
<         stmts = ()
<     if stmts:
<         return self, stmts
<     if self.parent:
<         # nested scope: if parent scope is a function, that's fine
<         # else jump to the module
<         pscope = self.parent.scope()
<         if not isinstance(pscope, nodes.Function):
<             pscope = pscope.root()
<         return pscope.scope_lookup(node, name)
<     return builtin_lookup(name)
< 
< def class_scope_lookup(self, node, name, offset=0):
<     if node in self.bases:
<         #print 'frame swaping'
<         frame = self.parent.frame()
<         # line offset to avoid that class A(A) resolve the ancestor to
<         # the defined class
<         offset = -1
<     else:
<         frame = self
<     return scope_lookup(frame, node, name, offset)
< 
< def function_scope_lookup(self, node, name, offset=0):
<     if node in self.defaults:
<         frame = self.parent.frame()
<         # line offset to avoid that def func(f=func) resolve the default
<         # value to the defined function
<         offset = -1
<     else:
<         # check this is not used in function decorators
<         frame = self
<     return scope_lookup(frame, node, name, offset)
<     
< def builtin_lookup(name):
<     """lookup a name into the builtin module
<     return the list of matching statements and the astng for the builtin
<     module
<     """
<     builtinastng = MANAGER.astng_from_module(__builtin__)
<     try:
<         stmts = builtinastng.locals[name]
<     except KeyError:
<         stmts = ()
<     return builtinastng, stmts
< 
< def ilookup(self, name, context=None):
<     """infered lookup
<     
<     return an iterator on infered values of the statements returned by
<     the lookup method
<     """
<     frame, stmts = self.lookup(name)
<     context = copy_context(context)
<     context.lookupname = name
<     return _infer_stmts(stmts, context, frame)
< 
< 
< def _filter_stmts(self, stmts, frame, offset):
<     """filter statements:
< 
<     If self is not a frame itself and the name is found in the inner
<     frame locals, statements will be filtered to remove ignorable
<     statements according to self's location
<     """
<     # if offset == -1, my actual frame is not the inner frame but its parent
<     #
<     # class A(B): pass
<     #
<     # we need this to resolve B correctly
<     if offset == -1:
<         myframe = self.frame().parent.frame()
<     else:
<         myframe = self.frame()
<     if not myframe is frame or self is frame:
<         return stmts
<     #print self.name, frame.name
<     mystmt = self.statement()
<     # line filtering if we are in the same frame
<     if myframe is frame:
<         mylineno = mystmt.source_line() + offset
<     else:
<         # disabling lineno filtering
<         print 'disabling lineno filtering'
<         mylineno = 0
<     _stmts = []
<     _stmt_parents = []
<     #print '-'*60
<     #print 'filtering', stmts, mylineno
<     for node in stmts:
<         stmt = node.statement()
<         # line filtering is on and we have reached our location, break
<         if mylineno > 0 and stmt.source_line() > mylineno:
<             #print 'break', mylineno, stmt.source_line()
<             break
<         if isinstance(node, Class) and self in node.bases:
<             #print 'breaking on', self, node.bases            
<             break
<         try:
<             ass_type = node.ass_type()
<             if ass_type is mystmt:
<                 if not isinstance(ass_type, (ListCompFor,  GenExprFor)):
<                     #print 'break now2', self, ass_type
<                     break
<                 if isinstance(self, (Const, Name)):
<                     _stmts = [self]
<                     #print 'break now', ass_type, self, node
<                     break
<         except AttributeError:
<             ass_type = None
<         # a loop assigment is hidding previous assigment
<         if isinstance(ass_type, (For, ListCompFor,  GenExprFor)) and \
<                ass_type.parent_of(self):
<             _stmts = [node]
<             _stmt_parents = [stmt.parent]
<             continue
<         try:
<             pindex = _stmt_parents.index(stmt.parent)
<         except ValueError:
<             pass
<         else:
<             try:
<                 if ass_type and _stmts[pindex].ass_type().parent_of(ass_type):
<                     # print 'skipping', node, node.source_line()
<                     continue
<             except AttributeError:
<                 pass # name from Import, Function, Class...
<             if not are_exclusive(self, node):
<                 ###print 'PARENT', stmt.parent
<                 #print 'removing', _stmts[pindex]
<                 del _stmt_parents[pindex]
<                 del _stmts[pindex]
<         if isinstance(node, AssName):
<             if stmt.parent is mystmt.parent:
<                 #print 'assign clear'
<                 _stmts = []
<                 _stmt_parents = []
<             if node.flags == 'OP_DELETE':
<                 #print 'delete clear'
<                 _stmts = []
<                 _stmt_parents = []
<                 continue
<                 
<         if not are_exclusive(self, node):
<             #print 'append', node, node.source_line()
<             _stmts.append(node)
<             _stmt_parents.append(stmt.parent)
<     #print '->', _stmts
<     stmts = _stmts
<     return stmts
< 
< 
< def _decorate(astmodule):
<     """add this module functionalities to necessary nodes"""
<     for klass in (astmodule.Name, astmodule.Module, astmodule.Class,
<                   astmodule.Function, astmodule.Lambda):
<         klass.ilookup = ilookup
<         klass.lookup = lookup
<         klass._filter_stmts = _filter_stmts
<     astmodule.Class.scope_lookup = class_scope_lookup
<     astmodule.Function.scope_lookup = function_scope_lookup
<     astmodule.Lambda.scope_lookup = function_scope_lookup
<     astmodule.Module.scope_lookup = scope_lookup
<     astmodule.GenExpr.scope_lookup = scope_lookup
<     for name in ('Class', 'Function', 'Lambda',
<                  'For', 'ListCompFor', 'GenExprFor',
<                  'AssName', 'Name', 'Const'):
<         globals()[name] = getattr(astmodule, name)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/manager.py code-worker/code-worker/tasks/clonedigger/logilab/astng/manager.py
1,382d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """astng manager: avoid multible astng build of a same module when
< possible by providing a class responsible to get astng representation
< from various source and using a cache of built modules)
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< import os
< from os.path import dirname, basename, abspath, join, isdir, exists
< 
< from clonedigger.logilab.common.cache import Cache
< from clonedigger.logilab.common.modutils import NoSourceFile, is_python_source, \
<      file_from_modpath, load_module_from_name, \
<      get_module_files, get_source_file
< from clonedigger.logilab.common.configuration import OptionsProviderMixIn
< 
< from clonedigger.logilab.astng import ASTNGBuildingException, Instance, nodes
< 
< def astng_wrapper(func, modname):
<     """wrapper to give to ASTNGManager.project_from_files"""
<     print 'parsing %s...' % modname
<     try:
<         return func(modname)
<     except ASTNGBuildingException, ex:
<         print ex
<     except KeyboardInterrupt:
<         raise
<     except Exception, ex:
<         import traceback
<         traceback.print_exc()
< 
< def safe_repr(obj):
<     try:
<         return repr(obj)
<     except:
<         return '???'
<     
< class ASTNGManager(OptionsProviderMixIn):
<     """the astng manager, responsible to build astng from files
<      or modules.
< 
<     Use the Borg pattern.
<     """
<     name = 'astng loader'
<     options = (("ignore",
<                 {'type' : "csv", 'metavar' : "<file>",
<                  'dest' : "black_list", "default" : ('CVS',),
<                  'help' : "add <file> (may be a directory) to the black list\
< . It should be a base name, not a path. You may set this option multiple times\
< ."}),
<                ("project",
<                 {'default': "No Name", 'type' : 'string', 'short': 'p',
<                  'metavar' : '<project name>',
<                  'help' : 'set the project name.'}),
<                )
<     brain = {}    
<     def __init__(self):
<         self.__dict__ = ASTNGManager.brain
<         if not self.__dict__:
<             OptionsProviderMixIn.__init__(self)
<             self._cache = None
<             self._mod_file_cache = None
<             self.set_cache_size(200)
<             self.load_defaults()
<             
<     def set_cache_size(self, cache_size):
<         """set the cache size (flush it as a side effect!)"""
<         self._cache = {} #Cache(cache_size)
<         self._mod_file_cache = {}
< 
<     def from_directory(self, directory, modname=None):
<         """given a module name, return the astng object"""
<         modname = modname or basename(directory)
<         directory = abspath(directory)
<         return Package(directory, modname, self)
< 
<     def astng_from_file(self, filepath, modname=None, fallback=True):
<         """given a module name, return the astng object"""
<         try:
<             filepath = get_source_file(filepath, include_no_ext=True)
<             source = True
<         except NoSourceFile:
<             source = False
<         try:
<             return self._cache[filepath]
<         except KeyError:
<             if source:
<                 try:
< 		    from clonedigger.logilab.astng.builder import ASTNGBuilder
<                     astng = ASTNGBuilder(self).file_build(filepath, modname)
<                 except SyntaxError:
<                     raise
<                 except Exception, ex:
<                     if __debug__:
<                         import traceback
<                         traceback.print_exc()
<                     msg = 'Unable to load module %s (%s)' % (modname, ex)
<                     raise ASTNGBuildingException(msg), None, sys.exc_info()[-1]
<             elif fallback and modname:
<                 return self.astng_from_module_name(modname)
<             else:
<                 raise ASTNGBuildingException('unable to get astng for file %s' %
<                                              filepath)
<         self._cache[filepath] = astng
<         return astng
<     
<     from_file = astng_from_file # backward compat
<     
<     def astng_from_module_name(self, modname, context_file=None):
<         """given a module name, return the astng object"""
<         old_cwd = os.getcwd()
<         if context_file:
<             os.chdir(dirname(context_file))
<         try:
<             filepath = self.file_from_module_name(modname, context_file)
<             if filepath is None or not is_python_source(filepath):
<                 try:
<                     module = load_module_from_name(modname) 
<                 except ImportError, ex:
<                     msg = 'Unable to load module %s (%s)' % (modname, ex)
<                     raise ASTNGBuildingException(msg)
<                 return self.astng_from_module(module, modname)
<             return self.astng_from_file(filepath, modname, fallback=False)
<         finally:
<             os.chdir(old_cwd)
<             
<     def file_from_module_name(self, modname, contextfile):
<         try:
<             value = self._mod_file_cache[(modname, contextfile)]
<         except KeyError:
<             try:
<                 value = file_from_modpath(modname.split('.'),
<                                           context_file=contextfile)
<             except ImportError, ex:
<                 msg = 'Unable to load module %s (%s)' % (modname, ex)
<                 value = ASTNGBuildingException(msg)
<             self._mod_file_cache[(modname, contextfile)] = value
<         if isinstance(value, ASTNGBuildingException):
<             raise value
<         return value
<         
<     def astng_from_module(self, module, modname=None):
<         """given an imported module, return the astng object"""
<         modname = modname or module.__name__
<         filepath = modname
<         try:
<             # some builtin modules don't have __file__ attribute
<             filepath = module.__file__
<             if is_python_source(filepath):
<                 return self.astng_from_file(filepath, modname)
<         except AttributeError:
<             pass
<         try:
<             return self._cache[filepath]
<         except KeyError:
<             from clonedigger.logilab.astng.builder import ASTNGBuilder
<             astng = ASTNGBuilder(self).module_build(module, modname)
<             # update caches (filepath and astng.file are not necessarily  the
<             # same (.pyc pb))
<             self._cache[filepath] = self._cache[astng.file] = astng
<             return astng
<             
<     def astng_from_class(self, klass, modname=None):
<         """get astng for the given class"""
<         if modname is None:
<             try:
<                 modname = klass.__module__
<             except AttributeError:
<                 raise ASTNGBuildingException(
<                     'Unable to get module for class %s' % safe_repr(klass))
<         modastng = self.astng_from_module_name(modname)
<         return modastng.getattr(klass.__name__)[0] # XXX
< 
<             
<     def infer_astng_from_something(self, obj, modname=None, context=None):
<         """infer astng for the given class"""
<         if hasattr(obj, '__class__') and not isinstance(obj, type):
<             klass = obj.__class__
<         else:
<             klass = obj
<         if modname is None:
<             try:
<                 modname = klass.__module__
<             except AttributeError:
<                 raise ASTNGBuildingException(
<                     'Unable to get module for %s' % safe_repr(klass))
<             except Exception, ex:
<                 raise ASTNGBuildingException(
<                     'Unexpected error while retreiving module for %s: %s'
<                     % (safe_repr(klass), ex))
<         try:
<             name = klass.__name__
<         except AttributeError:
<             raise ASTNGBuildingException(
<                 'Unable to get name for %s' % safe_repr(klass))
<         except Exception, ex:
<             raise ASTNGBuildingException(
<                 'Unexpected error while retreiving name for %s: %s'
<                 % (safe_repr(klass), ex))
<         # take care, on living object __module__ is regularly wrong :(
<         modastng = self.astng_from_module_name(modname)
<         for infered in modastng.igetattr(name, context):
<             if klass is not obj and isinstance(infered, nodes.Class):
<                 infered = Instance(infered)
<             yield infered
<             
<     def project_from_files(self, files, func_wrapper=astng_wrapper,
<                            project_name=None, black_list=None):
<         """return a Project from a list of files or modules"""
<         # insert current working directory to the python path to have a correct
<         # behaviour
<         sys.path.insert(0, os.getcwd())
<         try:
<             # build the project representation
<             project_name = project_name or self.config.project
<             black_list = black_list or self.config.black_list
<             project = Project(project_name)
<             for something in files:
<                 if not exists(something):
<                     fpath = file_from_modpath(something.split('.'))
<                 elif isdir(something):
<                     fpath = join(something, '__init__.py')
<                 else:
<                     fpath = something
<                 astng = func_wrapper(self.astng_from_file, fpath)
<                 if astng is None:
<                     continue
<                 project.path = project.path or astng.file
<                 project.add_module(astng)
<                 base_name = astng.name
<                 # recurse in package except if __init__ was explicitly given
<                 if astng.package and something.find('__init__') == -1:
<                     # recurse on others packages / modules if this is a package
<                     for fpath in get_module_files(dirname(astng.file),
<                                                   black_list):
<                         astng = func_wrapper(self.astng_from_file, fpath)
<                         if astng is None or astng.name == base_name:
<                             continue
<                         project.add_module(astng)
<             return project
<         finally:
<             sys.path.pop(0)
<     
< 
< 
< class Package:
<     """a package using a dictionary like interface
< 
<     load submodules lazily, as they are needed
<     """
<     
<     def __init__(self, path, name, manager):
<         self.name = name
<         self.path = abspath(path)
<         self.manager = manager
<         self.parent = None
<         self.lineno = 0
<         self.__keys = None
<         self.__subobjects = None
< 
<     def fullname(self):
<         """return the full name of the package (i.e. prefix by the full name
<         of the parent package if any
<         """
<         if self.parent is None:
<             return self.name
<         return '%s.%s' % (self.parent.fullname(), self.name)
<     
<     def get_subobject(self, name):
<         """method used to get sub-objects lazily : sub package or module are
<         only build once they are requested
<         """
<         if self.__subobjects is None:
<             try:
<                 self.__subobjects = dict.fromkeys(self.keys())
<             except AttributeError:
<                 # python <= 2.3
<                 self.__subobjects = dict([(k, None) for k in self.keys()])
<         obj = self.__subobjects[name]
<         if obj is None:
<             objpath = join(self.path, name)
<             if isdir(objpath):
<                 obj = Package(objpath, name, self.manager)
<                 obj.parent = self
<             else:
<                 modname = '%s.%s' % (self.fullname(), name)
<                 obj = self.manager.astng_from_file(objpath + '.py', modname)
<             self.__subobjects[name] = obj
<         return obj
<     
<     def get_module(self, modname):
<         """return the Module or Package object with the given name if any
<         """
<         path = modname.split('.')
<         if path[0] != self.name:
<             raise KeyError(modname)
<         obj = self
<         for part in path[1:]:
<             obj = obj.get_subobject(part)
<         return obj
<     
<     def keys(self):
<         if self.__keys is None:
<             self.__keys = []
<             for fname in os.listdir(self.path):
<                 if fname.endswith('.py'):
<                     self.__keys.append(fname[:-3])
<                     continue
<                 fpath = join(self.path, fname)
<                 if isdir(fpath) and exists(join(fpath, '__init__.py')):
<                     self.__keys.append(fname)
<             self.__keys.sort()
<         return self.__keys[:]
<     
<     def values(self):
<         return [self.get_subobject(name) for name in self.keys()]
<         
<     def items(self):
<         return zip(self.keys(), self.values())
<     
<     def has_key(self, name):
<         return bool(self.get(name))
<     
<     def get(self, name, default=None):
<         try:
<             return self.get_subobject(name)
<         except KeyError:
<             return default
<         
<     def __getitem__(self, name):
<         return self.get_subobject(name)        
<     def __contains__(self, name):
<         return self.has_key(name)
<     def __iter__(self):
<         return iter(self.keys())
<     
< 
< class Project:
<     """a project handle a set of modules / packages"""
<     def __init__(self, name=''):
<         self.name = name
<         self.path = None
<         self.modules = []
<         self.locals = {}
<         self.__getitem__ = self.locals.__getitem__
<         self.__iter__ = self.locals.__iter__
<         self.values = self.locals.values
<         self.keys = self.locals.keys
<         self.has_key = self.locals.has_key
<         
<     def add_module(self, node):
<         self.locals[node.name] = node
<         self.modules.append(node)
<         
<     def get_module(self, name):
<         return self.locals[name]
<     
<     def getChildNodes(self):
<         return self.modules
< 
<     def __repr__(self):
<         return '<Project %r at %s (%s modules)>' % (self.name, id(self),
<                                                     len(self.modules))
diff -r -N code-worker/tasks/clonedigger/logilab/astng/nodes.py code-worker/code-worker/tasks/clonedigger/logilab/astng/nodes.py
1,816d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< on all nodes :
<  .is_statement(), returning true if the node should be considered as a
<   statement node
<  .root(), returning the root node of the tree (i.e. a Module)
<  .previous_sibling(), returning previous sibling statement node
<  .next_sibling(), returning next sibling statement node
<  .statement(), returning the first parent node marked as statement node
<  .frame(), returning the first node defining a new local scope (i.e.
<   Module, Function or Class)
<  .set_local(name, node), define an identifier <name> on the first parent frame,
<   with the node defining it. This is used by the astng builder and should not
<   be used from out there.
<  .as_string(), returning a string representation of the code (should be
<   executable).
< 
< on From and Import :
<  .real_name(name),
< 
<  [1] http://docs.python.org/lib/module-compiler.ast.html
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< # This file have been modified by Anatoly Zapadinski to meet the Clone Digger's needs
< 
< from __future__ import generators
< 
< __docformat__ = "restructuredtext en"
< 
< from compiler.ast import Assign, Add, And, AssAttr, AssList, AssName, \
<      AssTuple, Assert, Assign, AugAssign, \
<      Backquote, Bitand, Bitor, Bitxor, Break, CallFunc, Class, \
<      Compare, Const, Continue, Dict, Discard, Div, FloorDiv, \
<      Ellipsis, EmptyNode, Exec, \
<      For, From, Function, Getattr, Global, \
<      If, Import, Invert, Keyword, Lambda, LeftShift, \
<      List, ListComp, ListCompFor, ListCompIf, Mod, Module, Mul, Name, Node, \
<      Not, Or, Pass, Power, Print, Printnl, Raise, Return, RightShift, Slice, \
<      Sliceobj, Stmt, Sub, Subscript, TryExcept, TryFinally, Tuple, UnaryAdd, \
<      UnarySub, While, Yield
< try:
<     # introduced in python 2.4
<     from compiler.ast import GenExpr, GenExprFor, GenExprIf, GenExprInner
< except:
<     class GenExpr:
<         """dummy GenExpr node, shouldn't be used since py < 2.4"""
<     class GenExprFor: 
<         """dummy GenExprFor node, shouldn't be used since py < 2.4"""
<     class GenExprIf: 
<         """dummy GenExprIf node, shouldn't be used since py < 2.4"""
<     class GenExprInner: 
<         """dummy GenExprInner node, shouldn't be used since py < 2.4"""
< 
< try:
<     # introduced in python 2.4
<     from compiler.ast import Decorators
< except:
<     class Decorators:
<         """dummy Decorators node, shouldn't be used since py < 2.4"""
< 
< try:
<     # introduced in python 2.5
<     from compiler.ast import With
< except:
<     class With:
<         """dummy With node, shouldn't be used since py < 2.5"""
< 
< from clonedigger.logilab.astng._exceptions import NotFoundError, InferenceError
< from clonedigger.logilab.astng.utils import extend_class
< from clonedigger.logilab.astng import InferenceContext
< 
< import re
< ID_RGX = re.compile('^[a-zA-Z_][a-zA-Z_0-9]*$')
< del re
< 
< INFER_NEED_NAME_STMTS = (From, Import, Global, TryExcept)
< 
< # Node  ######################################################################
< 
< class NodeNG:
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<     
<     # attributes below are set by the builder module or by raw factories
<     fromlineno = None
<     tolineno = None
<     # parent node in the tree
<     parent = None
< 
<     def __str__(self):
<         return '%s(%s)' % (self.__class__.__name__, getattr(self, 'name', ''))
<     
<     def parent_of(self, node):
<         """return true if i'm a parent of the given node"""
<         parent = node.parent
<         while parent is not None:
<             if self is parent:
<                 return True
<             parent = parent.parent
<         return False
< 
<     def is_statement(self):
<         """return true if the node should be considered as statement node
<         """
<         if isinstance(self.parent, Stmt):
<             return self
<         return None
< 
<     def statement(self):
<         """return the first parent node marked as statement node
<         """
<         if self.is_statement():
<             return self
<         return self.parent.statement()
< 
<     def frame(self):
<         """return the first parent frame node (i.e. Module, Function or Class)
<         """
<         return self.parent.frame()
< 
<     def scope(self):
<         """return the first node defining a new scope (i.e. Module,
<         Function, Class, Lambda but also GenExpr)
<         """
<         return self.parent.scope()
< 
<     def root(self):
<         """return the root node of the tree, (i.e. a Module)
<         """
<         if self.parent:
<             return self.parent.root()
<         return self
< 
<     def next_sibling(self):
<         """return the previous sibling statement 
<         """
<         while not self.is_statement(): 
<             self = self.parent
<         index = self.parent.nodes.index(self)
<         try:
<             return self.parent.nodes[index+1]
<         except IndexError:
<             return
< 
<     def previous_sibling(self):
<         """return the next sibling statement 
<         """
<         while not self.is_statement(): 
<             self = self.parent
<         index = self.parent.nodes.index(self)
<         if index > 0:
<             return self.parent.nodes[index-1]
<         return
< 
<     def nearest(self, nodes):
<         """return the node which is the nearest before this one in the
<         given list of nodes
<         """
<         myroot = self.root()
<         mylineno = self.source_line()
<         nearest = None, 0
<         for node in nodes:
<             assert node.root() is myroot, \
<                    'not from the same module %s' % (self, node)
<             lineno = node.source_line()
<             if node.source_line() > mylineno:
<                 break
<             if lineno > nearest[1]:
<                 nearest = node, lineno
<         # FIXME: raise an exception if nearest is None ?
<         return nearest[0]
<     
<     def source_line(self):
<         """return the line number where the given node appears
< 
<         we need this method since not all nodes as the lineno attribute
<         correctly set...
<         """
<         line = self.lineno
<         if line is None:
<             _node = self
<             try:
<                 while line is None:
<                     _node = _node.getChildNodes()[0]
<                     line = _node.lineno
<             except IndexError:
<                 _node = self.parent
<                 while _node and line is None:
<                     line = _node.lineno
<                     _node = _node.parent
<             self.lineno = line
<         return line
<     
<     def last_source_line(self):
<         """return the last block line number for this node (i.e. including
<         children)
<         """
<         try:
<             return self.__dict__['_cached_last_source_line']
<         except KeyError:
<             line = self.source_line()
<             for node in self.getChildNodes():
<                 line = max(line, node.last_source_line())
<             self._cached_last_source_line = line
<             return line
< 
<     def block_range(self, lineno):
<         """handle block line numbers range for non block opening statements
<         """
<         return lineno, self.last_source_line()
< 
< 
<     def set_local(self, name, stmt):
<         """delegate to a scoped parent handling a locals dictionary
<         """
<         self.parent.set_local(name, stmt)
< 
<     def nodes_of_class(self, klass, skip_klass=None):
<         """return an iterator on nodes which are instance of the given class(es)
< 
<         klass may be a class object or a tuple of class objects
<         """
<         if isinstance(self, klass):
<             yield self
<         for child_node in self.getChildNodes():
<             if skip_klass is not None and isinstance(child_node, skip_klass):
<                 continue
<             for matching in child_node.nodes_of_class(klass, skip_klass):
<                 yield matching
< 
<     def _infer_name(self, frame, name):
<         if isinstance(self, INFER_NEED_NAME_STMTS) or (
<                  isinstance(self, (Function, Lambda)) and self is frame):
<             return name
<         return None
< 
<     def eq(self, value):
<         return False
<     
< extend_class(Node, NodeNG)
< 
< Const.eq = lambda self, value: self.value == value
< 
< def decorators_scope(self):
<     # skip the function node to go directly to the upper level scope
<     return self.parent.parent.scope()
< Decorators.scope = decorators_scope
< 
< # block range overrides #######################################################
< 
< def object_block_range(node, lineno):
<     """handle block line numbers range for function/class statements:
< 
<     start from the "def" or "class" position whatever the given lineno
<     """
<     return node.source_line(), node.last_source_line()
< 
< Function.block_range = object_block_range
< Class.block_range = object_block_range
< Module.block_range = object_block_range
< 
< def if_block_range(node, lineno):
<     """handle block line numbers range for if/elif statements
<     """
<     last = None
<     for test, testbody in node.tests[1:]:
<         if lineno == testbody.source_line():
<             return lineno, lineno
<         if lineno <= testbody.last_source_line():
<             return lineno, testbody.last_source_line()
<         if last is None:
<             last = testbody.source_line() - 1
<     return elsed_block_range(node, lineno, last)
< 
< If.block_range = if_block_range
< 
< def try_except_block_range(node, lineno):
<     """handle block line numbers range for try/except statements
<     """
<     last = None
<     for excls, exinst, exbody in node.handlers:
<         if excls and lineno == excls.source_line():
<             return lineno, lineno
<         if exbody.source_line() <= lineno <= exbody.last_source_line():
<             return lineno, exbody.last_source_line()
<         if last is None:
<             last = exbody.source_line() - 1
<     return elsed_block_range(node, lineno, last)
< 
< TryExcept.block_range = try_except_block_range
< 
< def elsed_block_range(node, lineno, last=None):
<     """handle block line numbers range for try/finally, for and while
<     statements
<     """
<     if lineno == node.source_line():
<         return lineno, lineno
<     if node.else_:
<         if lineno >= node.else_.source_line():
<             return lineno, node.else_.last_source_line()
<         return lineno, node.else_.source_line() - 1
<     return lineno, last or node.last_source_line()
< 
< TryFinally.block_range = elsed_block_range
< While.block_range = elsed_block_range
< For.block_range = elsed_block_range
< 
< # From and Import #############################################################
< 
< def real_name(node, asname):
<     """get name from 'as' name
<     """
<     for index in range(len(node.names)):
<         name, _asname = node.names[index]
<         if name == '*':
<             return asname
<         if not _asname:
<             name = name.split('.', 1)[0]
<             _asname = name
<         if asname == _asname:
<             return name
<     raise NotFoundError(asname)
<     
< From.real_name = real_name
< Import.real_name = real_name
< 
< def infer_name_module(node, name):
<     context = InferenceContext(node)
<     context.lookupname = name
<     return node.infer(context, asname=False)
< Import.infer_name_module = infer_name_module
< 
< # as_string ###################################################################
< 
< def add_as_string(node):
<     """return an ast.Add node as string"""
<     return '(%s) + (%s)' % (node.left.as_string(), node.right.as_string())
< Add.as_string = add_as_string
< 
< def and_as_string(node):
<     """return an ast.And node as string"""
<     return ' and '.join(['(%s)' % n.as_string() for n in node.nodes])
< And.as_string = and_as_string
<     
< def assattr_as_string(node):
<     """return an ast.AssAttr node as string"""
<     if node.flags == 'OP_DELETE':
<         return 'del %s.%s' % (node.expr.as_string(), node.attrname.as_string())
<     return '%s.%s' % (node.expr.as_string(), node.attrname.as_string())
< AssAttr.as_string = assattr_as_string
< 
< def asslist_as_string(node):
<     """return an ast.AssList node as string"""
<     string = ', '.join([n.as_string() for n in node.nodes])
<     return '[%s]' % string
< AssList.as_string = asslist_as_string
< 
< def assname_as_string(node):
<     """return an ast.AssName node as string"""
<     if node.flags == 'OP_DELETE':
<         return 'del %s' % node.name.as_string()
<     return node.name.as_string()
< AssName.as_string = assname_as_string
<     
< def asstuple_as_string(node):
<     """return an ast.AssTuple node as string"""
<     string = ', '.join([n.as_string() for n in node.nodes])
<     # fix for del statement
<     return string.replace(', del ', ', ')
< AssTuple.as_string = asstuple_as_string
< 
< def assert_as_string(node):
<     """return an ast.Assert node as string"""
<     if node.fail:
<         return 'assert %s, %s' % (node.test.as_string(), node.fail.as_string())
<     return 'assert %s' % node.test.as_string()
< Assert.as_string = assert_as_string
< 
< def assign_as_string(node):
<     """return an ast.Assign node as string"""
<     lhs = ' = '.join([n.as_string() for n in node.nodes])
<     return '%s = %s' % (lhs, node.expr.as_string())
< Assign.as_string = assign_as_string
< 
< def augassign_as_string(node):
<     """return an ast.AugAssign node as string"""
<     return '%s %s %s' % (node.node.as_string(), node.op.as_string(), node.expr.as_string())
< AugAssign.as_string = augassign_as_string
< 
< def backquote_as_string(node):
<     """return an ast.Backquote node as string"""
<     return '`%s`' % node.expr.as_string()
< Backquote.as_string = backquote_as_string
< 
< def bitand_as_string(node):
<     """return an ast.Bitand node as string"""
<     return ' & '.join(['(%s)' % n.as_string() for n in node.nodes])
< Bitand.as_string = bitand_as_string
< 
< def bitor_as_string(node):
<     """return an ast.Bitor node as string"""
<     return ' | '.join(['(%s)' % n.as_string() for n in node.nodes])
< Bitor.as_string = bitor_as_string
< 
< def bitxor_as_string(node):
<     """return an ast.Bitxor node as string"""
<     return ' ^ '.join(['(%s)' % n.as_string() for n in node.nodes])
< Bitxor.as_string = bitxor_as_string
< 
< def break_as_string(node):
<     """return an ast.Break node as string"""
<     return 'break'
< Break.as_string = break_as_string
< 
< def callfunc_as_string(node):
<     """return an ast.CallFunc node as string"""
<     expr_str = node.node.as_string()
<     args = ', '.join([arg.as_string() for arg in node.args])
<     if node.star_args:
<         args += ', *%s' % node.star_args.as_string()
<     if node.dstar_args:
<         args += ', **%s' % node.dstar_args.as_string()
<     return '%s(%s)' % (expr_str, args)
< CallFunc.as_string = callfunc_as_string
< 
< def class_as_string(node):
<     """return an ast.Class node as string"""
<     bases =  ', '.join([n.as_string() for n in node.bases])
<     bases = bases and '(%s)' % bases or ''
<     docs = node.doc and '\n    """%s"""' % node.doc or ''
<     return 'class %s%s:%s\n    %s\n' % (node.name.as_string(), bases, docs,
<                                         node.code.as_string())
< Class.as_string = class_as_string
< 
< def compare_as_string(node):
<     """return an ast.Compare node as string"""
<     rhs_str = ' '.join(['%s %s' % (op.as_string(), expr.as_string())
<                         for op, expr in node.ops])
<     return '%s %s' % (node.expr.as_string(), rhs_str)
< Compare.as_string = compare_as_string
< 
< def const_as_string(node):
<     """return an ast.Const node as string"""
<     return node.value.as_string()
< Const.as_string = const_as_string
< 
< def continue_as_string(node):
<     """return an ast.Continue node as string"""
<     return 'continue'
< Continue.as_string = continue_as_string
< 
< def dict_as_string(node):
<     """return an ast.Dict node as string"""
<     return '{%s}' % ', '.join(['%s: %s' % (key.as_string(), value.as_string())
<                                for key, value in node.items])
< Dict.as_string = dict_as_string
< 
< def discard_as_string(node):
<     """return an ast.Discard node as string"""
<     return node.expr.as_string()
< Discard.as_string = discard_as_string
< 
< def div_as_string(node):
<     """return an ast.Div node as string"""
<     return '(%s) / (%s)' % (node.left.as_string(), node.right.as_string())
< Div.as_string = div_as_string
< 
< def floordiv_as_string(node):
<     """return an ast.Div node as string"""
<     return '(%s) // (%s)' % (node.left.as_string(), node.right.as_string())
< FloorDiv.as_string = floordiv_as_string
< 
< def ellipsis_as_string(node):
<     """return an ast.Ellipsis node as string"""
<     return '...'
< Ellipsis.as_string = ellipsis_as_string
< 
< def empty_as_string(node):
<     return ''
< EmptyNode.as_string = empty_as_string
< 
< def exec_as_string(node):
<     """return an ast.Exec node as string"""
<     if node.globals:
<         return 'exec %s in %s, %s' % (node.expr.as_string(),
<                                       node.locals.as_string(),
<                                       node.globals.as_string())
<     if node.locals:
<         return 'exec %s in %s' % (node.expr.as_string(),
<                                   node.locals.as_string())
<     return 'exec %s' % node.expr.as_string()
< Exec.as_string = exec_as_string
< 
< def for_as_string(node):
<     """return an ast.For node as string"""
<     fors = 'for %s in %s:\n    %s' % (node.assign.as_string(),
<                                       node.list.as_string(),
<                                       node.body.as_string())
<     if node.else_:
<         fors = '%s\nelse:\n    %s' % (fors, node.else_.as_string())
<     return fors
< For.as_string = for_as_string
< 
< def from_as_string(node):
<     """return an ast.From node as string"""
<     return 'from %s import %s' % (node.modname, _import_string(node.names))
< From.as_string = from_as_string
< 
< def function_as_string(node):
<     """return an ast.Function node as string"""
<     fargs = node.format_args()
<     docs = node.doc and '\n    """%s"""' % node.doc or ''
<     return 'def %s(%s):%s\n    %s' % (node.name, fargs, docs,
<                                       node.code.as_string())
< Function.as_string = function_as_string
< 
< def genexpr_as_string(node):
<     """return an ast.GenExpr node as string"""
<     return '(%s)' % node.code.as_string()
< GenExpr.as_string = genexpr_as_string
< 
< def genexprinner_as_string(node):
<     """return an ast.GenExpr node as string"""
<     return '%s %s' % (node.expr.as_string(), ' '.join([n.as_string()
<                                                        for n in node.quals]))
< GenExprInner.as_string = genexprinner_as_string
< 
< def genexprfor_as_string(node):
<     """return an ast.GenExprFor node as string"""
<     return 'for %s in %s %s' % (node.assign.as_string(),
<                                 node.iter.as_string(),
<                                 ' '.join([n.as_string() for n in node.ifs]))
< GenExprFor.as_string = genexprfor_as_string
< 
< def genexprif_as_string(node):
<     """return an ast.GenExprIf node as string"""
<     return 'if %s' % node.test.as_string()
< GenExprIf.as_string = genexprif_as_string
< 
< def getattr_as_string(node):
<     """return an ast.Getattr node as string"""
<     return '%s.%s' % (node.expr.as_string(), node.attrname.as_string())
< Getattr.as_string = getattr_as_string
< 
< def global_as_string(node):
<     """return an ast.Global node as string"""
<     return 'global %s' % ', '.join([name.as_string() for name in node.names])
< Global.as_string = global_as_string
< 
< def if_as_string(node):
<     """return an ast.If node as string"""
<     cond, body = node.tests[0]
<     ifs = ['if %s:\n    %s' % (cond.as_string(), body.as_string())]
<     for cond, body in node.tests[1:]:
<         ifs.append('elif %s:\n    %s' % (cond.as_string(), body.as_string()))
<     if node.else_:
<         ifs.append('else:\n    %s' % node.else_.as_string())
<     return '\n'.join(ifs)
< If.as_string = if_as_string
< 
< def import_as_string(node):
<     """return an ast.Import node as string"""
<     return 'import %s' % _import_string(node.names)
< Import.as_string = import_as_string
< 
< def invert_as_string(node):
<     """return an ast.Invert node as string"""
<     return '~%s' % node.expr.as_string()
< Invert.as_string = invert_as_string
< 
< def keyword_as_string(node):
<     """return an ast.Keyword node as string"""
<     return '%s=%s' % (node.name.as_string(), node.expr.as_string())
< Keyword.as_string = keyword_as_string
< 
< def lambda_as_string(node):
<     """return an ast.Lambda node as string"""
<     return 'lambda %s: %s' % (node.format_args(), node.code.as_string())
< Lambda.as_string = lambda_as_string
< 
< def leftshift_as_string(node):
<     """return an ast.LeftShift node as string"""
<     return '(%s) << (%s)' % (node.left.as_string(), node.right.as_string())
< LeftShift.as_string = leftshift_as_string
< 
< def list_as_string(node):
<     """return an ast.List node as string"""
<     return '[%s]' % ', '.join([child.as_string() for child in node.nodes])
< List.as_string = list_as_string
< 
< def listcomp_as_string(node):
<     """return an ast.ListComp node as string"""
<     return '[%s %s]' % (node.expr.as_string(), ' '.join([n.as_string()
<                                                          for n in node.quals]))
< ListComp.as_string = listcomp_as_string
< 
< def listcompfor_as_string(node):
<     """return an ast.ListCompFor node as string"""
<     return 'for %s in %s %s' % (node.assign.as_string(),
<                                 node.list.as_string(),
<                                 ' '.join([n.as_string() for n in node.ifs]))
< ListCompFor.as_string = listcompfor_as_string
< 
< def listcompif_as_string(node):
<     """return an ast.ListCompIf node as string"""
<     return 'if %s' % node.test.as_string()
< ListCompIf.as_string = listcompif_as_string
< 
< def mod_as_string(node):
<     """return an ast.Mod node as string"""
<     return '(%s) %% (%s)' % (node.left.as_string(), node.right.as_string())
< Mod.as_string = mod_as_string
< 
< def module_as_string(node):
<     """return an ast.Module node as string"""
<     docs = node.doc and '"""%s"""\n' % node.doc or ''
<     return '%s%s' % (docs, node.node.as_string())
< Module.as_string = module_as_string
< 
< def mul_as_string(node):
<     """return an ast.Mul node as string"""
<     return '(%s) * (%s)' % (node.left.as_string(), node.right.as_string())
< Mul.as_string = mul_as_string
< 
< def name_as_string(node):
<     """return an ast.Name node as string"""
<     return node.name.as_string()
< Name.as_string = name_as_string
< 
< def not_as_string(node):
<     """return an ast.Not node as string"""
<     return 'not %s' % node.expr.as_string()
< Not.as_string = not_as_string
< 
< def or_as_string(node):
<     """return an ast.Or node as string"""
<     return ' or '.join(['(%s)' % n.as_string() for n in node.nodes])
< Or.as_string = or_as_string
< 
< def pass_as_string(node):
<     """return an ast.Pass node as string"""
<     return 'pass'
< Pass.as_string = pass_as_string
< 
< def power_as_string(node):
<     """return an ast.Power node as string"""
<     return '(%s) ** (%s)' % (node.left.as_string(), node.right.as_string())
< Power.as_string = power_as_string
< 
< def print_as_string(node):
<     """return an ast.Print node as string"""
<     nodes = ', '.join([n.as_string() for n in node.nodes])
<     if node.dest:
<         return 'print >> %s, %s,' % (node.dest.as_string(), nodes)
<     return 'print %s,' % nodes
< Print.as_string = print_as_string
< 
< def printnl_as_string(node):
<     """return an ast.Printnl node as string"""
<     nodes = ', '.join([n.as_string() for n in node.nodes])
<     if node.dest:
<         return 'print >> %s, %s' % (node.dest.as_string(), nodes)
<     return 'print %s' % nodes
< Printnl.as_string = printnl_as_string
< 
< def raise_as_string(node):
<     """return an ast.Raise node as string"""
<     if node.expr1:
<         if node.expr2:
<             if node.expr3:
<                 return 'raise %s, %s, %s' % (node.expr1.as_string(),
<                                              node.expr2.as_string(),
<                                              node.expr3.as_string())
<             return 'raise %s, %s' % (node.expr1.as_string(),
<                                      node.expr2.as_string())
<         return 'raise %s' % node.expr1.as_string()
<     return 'raise'
< Raise.as_string = raise_as_string
< 
< def return_as_string(node):
<     """return an ast.Return node as string"""
<     return 'return %s' % node.value.as_string()
< Return.as_string = return_as_string
< 
< def rightshift_as_string(node):
<     """return an ast.RightShift node as string"""
<     return '(%s) >> (%s)' % (node.left.as_string(), node.right.as_string())
< RightShift.as_string = rightshift_as_string
< 
< def slice_as_string(node):
<     """return an ast.Slice node as string"""
<     # FIXME: use flags
<     lower = node.lower and node.lower.as_string() or ''
<     upper = node.upper and node.upper.as_string() or ''
<     return '%s[%s:%s]' % (node.expr.as_string(), lower, upper)
< Slice.as_string = slice_as_string
< 
< def sliceobj_as_string(node):
<     """return an ast.Sliceobj node as string"""
<     return ':'.join([n.as_string() for n in node.nodes])
< Sliceobj.as_string = sliceobj_as_string
< 
< def stmt_as_string(node):
<     """return an ast.Stmt node as string"""
<     stmts = '\n'.join([n.as_string() for n in node.nodes])
<     if isinstance(node.parent, Module):
<         return stmts
<     return stmts.replace('\n', '\n    ')
< Stmt.as_string = stmt_as_string
< 
< def sub_as_string(node):
<     """return an ast.Sub node as string"""
<     return '(%s) - (%s)' % (node.left.as_string(), node.right.as_string())
< Sub.as_string = sub_as_string
< 
< def subscript_as_string(node):
<     """return an ast.Subscript node as string"""
<     # FIXME: flags ?
<     return '%s[%s]' % (node.expr.as_string(), ','.join([n.as_string()
<                                                         for n in node.subs]))
< Subscript.as_string = subscript_as_string
< 
< def tryexcept_as_string(node):
<     """return an ast.TryExcept node as string"""
<     trys = ['try:\n    %s' % node.body.as_string()]
<     for exc_type, exc_obj, body in node.handlers:
<         if exc_type:
<             if exc_obj:
<                 excs = 'except %s, %s' % (exc_type.as_string(),
<                                           exc_obj.as_string())
<             else:
<                 excs = 'except %s' % exc_type.as_string()
<         else:
<             excs = 'except'
<         trys.append('%s:\n    %s' % (excs, body.as_string()))
<     return '\n'.join(trys)
< TryExcept.as_string = tryexcept_as_string
< 
< def tryfinally_as_string(node):
<     """return an ast.TryFinally node as string"""
<     return 'try:\n    %s\nfinally:\n    %s' % (node.body.as_string(),
<                                                node.final.as_string())
< TryFinally.as_string = tryfinally_as_string
< 
< def tuple_as_string(node):
<     """return an ast.Tuple node as string"""
<     return '(%s)' % ', '.join([child.as_string() for child in node.nodes])
< Tuple.as_string = tuple_as_string
< 
< def unaryadd_as_string(node):
<     """return an ast.UnaryAdd node as string"""
<     return '+%s' % node.expr.as_string()
< UnaryAdd.as_string = unaryadd_as_string
< 
< def unarysub_as_string(node):
<     """return an ast.UnarySub node as string"""
<     return '-%s' % node.expr.as_string()
< UnarySub.as_string = unarysub_as_string
< 
< def while_as_string(node):
<     """return an ast.While node as string"""
<     whiles = 'while %s:\n    %s' % (node.test.as_string(),
<                                     node.body.as_string())
<     if node.else_:
<         whiles = '%s\nelse:\n    %s' % (whiles, node.else_.as_string())
<     return whiles
< While.as_string = while_as_string
< 
< def with_as_string(node):
<     """return an ast.With node as string"""
<     withs = 'with (%s) as (%s):\n    %s' % (node.expr.as_string(),
<                                       node.vars.as_string(),
<                                       node.body.as_string())
<     return withs
< With.as_string = with_as_string
< 
< def yield_as_string(node):
<     """yield an ast.Yield node as string"""
<     return 'yield %s' % node.value.as_string()
< Yield.as_string = yield_as_string
< 
< 
< def _import_string(names):
<     """return a list of (name, asname) formatted as a string
<     """
<     _names = []
<     for name, asname in names:
<         if asname is not None:
<             _names.append('%s as %s' % (name, asname))
<         else:
<             _names.append(name)
<     return  ', '.join(_names)
< 
< # to backport into compiler ###################################################
< 
< EmptyNode.getChildNodes = lambda self: ()
diff -r -N code-worker/tasks/clonedigger/logilab/astng/__pkginfo__.py code-worker/code-worker/tasks/clonedigger/logilab/astng/__pkginfo__.py
1,60d0
< # pylint: disable-msg=W0622
< #
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< logilab.astng packaging information
< """
< 
< modname = 'astng'
< distname = 'logilab-astng'
< numversion = (0, 17, 2)
< version = '.'.join([str(num) for num in numversion])
< pyversions = ["2.3", "2.4", "2.5"]
< 
< license = 'GPL'
< copyright = '''Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr'''
< 
< author = 'Sylvain Thenault'
< author_email = 'sylvain.thenault@logilab.fr'
< 
< short_desc = "extend python's abstract syntax tree"
< 
< long_desc = """The aim of this module is to provide a common base \
< representation of
< python source code for projects such as pychecker, pyreverse,
< pylint... Well, actually the development of this library is essentialy
< governed by pylint's needs.
< 
< It extends class defined in the compiler.ast [1] module with some
< additional methods and attributes. Instance attributes are added by a
< builder object, which can either generate extended ast (let's call
< them astng ;) by visiting an existant ast tree or by inspecting living
< object. Methods are added by monkey patching ast classes."""
< 
< 
< web = "http://www.logilab.org/project/name/%s" % distname
< ftp = "ftp://ftp.logilab.org/pub/%s" % modname
< mailinglist = "mailto://python-projects@lists.logilab.org"
< 
< subpackage_of = 'logilab'
< 
< from os.path import join
< include_dirs = [join('test', 'regrtest_data'),
<                 join('test', 'data'), join('test', 'data2')]
< 
< debian_uploader = 'Alexandre Fayolle <afayolle@debian.org>'
diff -r -N code-worker/tasks/clonedigger/logilab/astng/raw_building.py code-worker/code-worker/tasks/clonedigger/logilab/astng/raw_building.py
1,234d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains a set of functions to create astng trees from scratch
< (build_* functions) or from living object (object_build_* functions)
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< from inspect import getargspec
< 
< from clonedigger.logilab.astng import nodes
< 
< def attach___dict__(node):
<     """attach the __dict__ attribute to Class and Module objects"""
<     dictn = nodes.Dict([])
<     dictn.parent = node
<     node.locals['__dict__'] = [dictn]
< 
< _marker = object()
< 
< def attach_dummy_node(node, name, object=_marker):
<     """create a dummy node and register it in the locals of the given
<     node with the specified name
<     """
<     enode = nodes.EmptyNode()
<     enode.object = object
<     _attach_local_node(node, enode, name)
< 
< nodes.EmptyNode.has_underlying_object = lambda self: self.object is not _marker
< 
< def attach_const_node(node, name, value):
<     """create a Const node and register it in the locals of the given
<     node with the specified name
<     """
<     _attach_local_node(node, nodes.Const(value), name)
< 
< if sys.version_info < (2, 5):
<     def attach_import_node(node, modname, membername):
<         """create a From node and register it in the locals of the given
<         node with the specified name
<         """
<         _attach_local_node(node,
<                            nodes.From(modname, ( (membername, None), ) ),
<                            membername)
< else:
<     def attach_import_node(node, modname, membername):
<         """create a From node and register it in the locals of the given
<         node with the specified name
<         """
<         _attach_local_node(node,
<                            nodes.From(modname, ( (membername, None), ), 0),
<                            membername)
<     
< def _attach_local_node(parent, node, name):
<     node.name = name # needed by add_local_node
<     node.parent = parent
<     node.lineno = 1
<     parent.add_local_node(node)
< 
< 
< def build_module(name, doc=None):
<     """create and initialize a astng Module node"""
<     node = nodes.Module(doc, nodes.Stmt([]))
<     node.node.parent = node
<     node.name = name
<     node.pure_python = False
<     node.package = False
<     node.parent = None
<     node.globals = node.locals = {}
<     return node
< 
< def build_class(name, basenames=None, doc=None):
<     """create and initialize a astng Class node"""
<     klass = nodes.Class(name, [], doc, nodes.Stmt([]))
<     bases = [nodes.Name(base) for base in basenames]
<     for base in bases:
<         base.parent = klass
<     klass.basenames = basenames
<     klass.bases = bases
<     klass.code.parent = klass
<     klass.locals = {}
<     klass.instance_attrs = {}
<     for name, value in ( ('__name__', name),
<                          #('__module__', node.root().name),
<                          ):
<         const = nodes.Const(value)
<         const.parent = klass
<         klass.locals[name] = [const]
<     return klass
< 
< # introduction of decorators has changed the Function initializer arguments
< if sys.version_info >= (2, 4):
<     try:
<         from compiler.ast import Decorators as BaseDecorators
<         class Decorators(BaseDecorators):
<             def __init__(self):
<                 BaseDecorators.__init__(self, [], 0)
<     except ImportError:
<         Decorators = list
<         
<     def build_function(name, args=None, defaults=None, flag=0, doc=None):
<         """create and initialize a astng Function node"""
<         args, defaults = args or [], defaults or []
<         # first argument is now a list of decorators
<         func = nodes.Function(Decorators(), name, args, defaults, flag, doc,
<                               nodes.Stmt([]))
<         func.code.parent = func
<         func.locals = {}
<         if args:
<             register_arguments(func, args)
<         return func
<     
< else:    
<     def build_function(name, args=None, defaults=None, flag=0, doc=None):
<         """create and initialize a astng Function node"""
<         args, defaults = args or [], defaults or []
<         func = nodes.Function(name, args, defaults, flag, doc, nodes.Stmt([]))
<         func.code.parent = func
<         func.locals = {}
<         if args:
<             register_arguments(func, args)
<         return func
< 
< 
< def build_name_assign(name, value):
<     """create and initialize an astng Assign for a name assignment"""
<     return nodes.Assign([nodes.AssName(name, 'OP_ASSIGN')], nodes.Const(value))
< 
< def build_attr_assign(name, value, attr='self'):
<     """create and initialize an astng Assign for an attribute assignment"""
<     return nodes.Assign([nodes.AssAttr(nodes.Name(attr), name, 'OP_ASSIGN')],
<                         nodes.Const(value))
< 
< if sys.version_info < (2, 5):
<     def build_from_import(fromname, names):
<         """create and intialize an astng From import statement"""
<         return nodes.From(fromname, [(name, None) for name in names])
< else:
<     def build_from_import(fromname, names):
<         """create and intialize an astng From import statement"""
<         return nodes.From(fromname, [(name, None) for name in names], 0)
< 
< def register_arguments(node, args):
<     """add given arguments to local
<     
<     args is a list that may contains nested lists
<     (i.e. def func(a, (b, c, d)): ...)
<     """
<     for arg in args:
<         if type(arg) is type(''):
<             node.set_local(arg, node)
<         else:
<             register_arguments(node, arg)
< 
< 
< def object_build_class(node, member):
<     """create astng for a living class object"""
<     basenames = [base.__name__ for base in member.__bases__]
<     return _base_class_object_build(node, member, basenames)
< 
< def object_build_function(node, member):
<     """create astng for a living function object"""
<     args, varargs, varkw, defaults = getargspec(member)
<     if varargs is not None:
<         args.append(varargs)
<     if varkw is not None:
<         args.append(varkw)
<     func = build_function(member.__name__, args, defaults,
<                           member.func_code.co_flags, member.__doc__)
<     node.add_local_node(func)
< 
< def object_build_datadescriptor(node, member, name):
<     """create astng for a living data descriptor object"""
<     return _base_class_object_build(node, member, [], name)
< 
< def object_build_methoddescriptor(node, member):
<     """create astng for a living method descriptor object"""
<     # FIXME get arguments ?
<     func = build_function(member.__name__, doc=member.__doc__)
<     # set argnames to None to notice that we have no information, not
<     # and empty argument list
<     func.argnames = None 
<     node.add_local_node(func)
< 
< def _base_class_object_build(node, member, basenames, name=None):
<     """create astng for a living class object, with a given set of base names
<     (e.g. ancestors)
<     """
<     klass = build_class(name or member.__name__, basenames, member.__doc__)
<     klass._newstyle = isinstance(member, type)
<     node.add_local_node(klass)
<     try:
<         # limit the instantiation trick since it's too dangerous
<         # (such as infinite test execution...)
<         # this at least resolves common case such as Exception.args,
<         # OSError.errno
<         if issubclass(member, Exception):
<             instdict = member().__dict__
<         else:
<             raise TypeError
<     except:
<         pass
<     else:
<         for name, obj in instdict.items():
<             valnode = nodes.EmptyNode()
<             valnode.object = obj
<             valnode.parent = klass
<             valnode.lineno = 1
<             klass.instance_attrs[name] = [valnode]
<     return klass
< 
< 
< __all__ = ('register_arguments',  'build_module', 
<            'object_build_class', 'object_build_function', 
<            'object_build_datadescriptor', 'object_build_methoddescriptor',
<            'attach___dict__', 'attach_dummy_node',
<            'attach_const_node', 'attach_import_node')
diff -r -N code-worker/tasks/clonedigger/logilab/astng/scoped_nodes.py code-worker/code-worker/tasks/clonedigger/logilab/astng/scoped_nodes.py
1,709d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """This module extends ast "scoped" node, i.e. which are opening a new
< local scope in the language definition : Module, Class, Function (and
< Lambda in some extends).
< 
< Each new methods and attributes added on each class are documented
< below.
< 
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< from __future__ import generators
< 
< __doctype__ = "restructuredtext en"
< 
< import sys
< 
< from clonedigger.logilab.common.compat import chain, set
< 
< from clonedigger.logilab.astng.utils import extend_class
< from clonedigger.logilab.astng import YES, MANAGER, Instance, InferenceContext, copy_context, \
<      unpack_infer, _infer_stmts, \
<      Class, Const, Dict, Function, GenExpr, Lambda, \
<      Module, Name, Pass, Raise, Tuple, Yield
< from clonedigger.logilab.astng import NotFoundError, NoDefault, \
<      ASTNGBuildingException, InferenceError
< 
< # module class dict/iterator interface ########################################
<     
< class LocalsDictMixIn(object):
<     """ this class provides locals handling common to Module, Function
<     and Class nodes, including a dict like interface for direct access
<     to locals information
<     
<     /!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<     
<     # attributes below are set by the builder module or by raw factories
<     
<     # dictionary of locals with name as key and node defining the local as
<     # value    
<     locals = None
< 
<     def qname(self):
<         """return the 'qualified' name of the node, eg module.name,
<         module.class.name ...
<         """
<         if self.parent is None:
<             return self.name
<         return '%s.%s' % (self.parent.frame().qname(), self.name)
<         
<     def frame(self):
<         """return the first parent frame node (i.e. Module, Function or Class)
<         """
<         return self
<     
<     def scope(self):
<         """return the first node defining a new scope (i.e. Module,
<         Function, Class, Lambda but also GenExpr)
<         """
<         return self
<     
<     def set_local(self, name, stmt):
<         """define <name> in locals (<stmt> is the node defining the name)
<         if the node is a Module node (i.e. has globals), add the name to
<         globals
< 
<         if the name is already defined, ignore it
<         """
<         self.locals.setdefault(name, []).append(stmt)
<         
<     __setitem__ = set_local
<     
<     def add_local_node(self, child_node, name=None):
<         """append a child which should alter locals to the given node"""
<         if name != '__class__':
<             # add __class__ node as a child will cause infinite recursion later!
<             self._append_node(child_node)
<         self.set_local(name or child_node.name, child_node)
< 
<     def _append_node(self, child_node):
<         """append a child, linking it in the tree"""
<         self.code.nodes.append(child_node)
<         child_node.parent = self
<     
<     def __getitem__(self, item):
<         """method from the `dict` interface returning the first node
<         associated with the given name in the locals dictionnary
< 
<         :type item: str
<         :param item: the name of the locally defined object
<         :raises KeyError: if the name is not defined
<         """
<         return self.locals[item][0]
<     
<     def __iter__(self):
<         """method from the `dict` interface returning an iterator on
<         `self.keys()`
<         """
<         return iter(self.keys())
<     
<     def keys(self):
<         """method from the `dict` interface returning a tuple containing
<         locally defined names
<         """
<         return self.locals.keys()
< ##         associated to nodes which are instance of `Function` or
< ##         `Class`
< ##         """
< ##         # FIXME: sort keys according to line number ?
< ##         try:
< ##             return self.__keys
< ##         except AttributeError:
< ##             keys = [member.name for member in self.locals.values()
< ##                     if (isinstance(member, Function)
< ##                         or isinstance(member, Class))
< ##                         and member.parent.frame() is self]
< ##             self.__keys = tuple(keys)
< ##             return keys
< 
<     def values(self):
<         """method from the `dict` interface returning a tuple containing
<         locally defined nodes which are instance of `Function` or `Class`
<         """
<         return [self[key] for key in self.keys()]
<     
<     def items(self):
<         """method from the `dict` interface returning a list of tuple
<         containing each locally defined name with its associated node,
<         which is an instance of `Function` or `Class`
<         """
<         return zip(self.keys(), self.values())
< 
<     def has_key(self, name):
<         """method from the `dict` interface returning True if the given
<         name is defined in the locals dictionary
<         """
<         return self.locals.has_key(name)
<     
<     __contains__ = has_key
<     
< extend_class(Module, LocalsDictMixIn)
< extend_class(Class, LocalsDictMixIn)
< extend_class(Function, LocalsDictMixIn)
< extend_class(Lambda, LocalsDictMixIn)
< # GenExpr has it's own locals but isn't a frame
< extend_class(GenExpr, LocalsDictMixIn)
< def frame(self):
<     return self.parent.frame()
< GenExpr.frame = frame
< 
< 
< class GetattrMixIn(object):
<     def getattr(self, name, context=None):
<         try:
<             return self.locals[name]
<         except KeyError:
<             raise NotFoundError(name)
<         
<     def igetattr(self, name, context=None):
<         """infered getattr"""
<         # set lookup name since this is necessary to infer on import nodes for
<         # instance
<         context = copy_context(context)
<         context.lookupname = name
<         try:
<             return _infer_stmts(self.getattr(name, context), context, frame=self)
<         except NotFoundError:
<             raise InferenceError(name)
< extend_class(Module, GetattrMixIn)
< extend_class(Class, GetattrMixIn)
< 
< # Module  #####################################################################
< 
< class ModuleNG(object):
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<         
<     # attributes below are set by the builder module or by raw factories
< 
<     # the file from which as been extracted the astng representation. It may
<     # be None if the representation has been built from a built-in module
<     file = None
<     # the module name
<     name = None
<     # boolean for astng built from source (i.e. ast)
<     pure_python = None
<     # boolean for package module
<     package = None
<     # dictionary of globals with name as key and node defining the global
<     # as value
<     globals = None
< 
<     def pytype(self):
<         return '__builtin__.module'
<     
<     def getattr(self, name, context=None):
<         try:
<             return self.locals[name]
<         except KeyError:
<             if self.package:
<                 try:
<                     return [self.import_module(name, relative_only=True)]
<                 except KeyboardInterrupt:
<                     raise
<                 except:
<                     pass
<             raise NotFoundError(name)
<         
<     def _append_node(self, child_node):
<         """append a child version specific to Module node"""
<         self.node.nodes.append(child_node)
<         child_node.parent = self
<         
<     def source_line(self):
<         """return the source line number, 0 on a module"""
<         return 0
< 
<     def fully_defined(self):
<         """return True if this module has been built from a .py file
<         and so contains a complete representation including the code
<         """
<         return self.file is not None and self.file.endswith('.py')
<     
<     def statement(self):
<         """return the first parent node marked as statement node
<         consider a module as a statement...
<         """
<         return self
< 
<     def import_module(self, modname, relative_only=False):
<         """import the given module considering self as context"""
<         try:
<             return MANAGER.astng_from_module_name(self.relative_name(modname))
<         except ASTNGBuildingException:
<             if relative_only:
<                 raise
<         module = MANAGER.astng_from_module_name(modname)
<         return module
< 
<     def relative_name(self, modname):
<         if self.package:
<             return '%s.%s' % (self.name, modname)
<         package_name = '.'.join(self.name.split('.')[:-1])
<         if package_name:
<             return '%s.%s' % (package_name, modname)
<         return modname
<         
<     def wildcard_import_names(self):
<         """return the list of imported names when this module is 'wildard
<         imported'
< 
<         It doesn't include the '__builtins__' name which is added by the
<         current CPython implementation of wildcard imports.
<         """
<         # take advantage of a living module if it exists
<         try:
<             living = sys.modules[self.name]
<         except KeyError:
<             pass
<         else:
<             try:
<                 return living.__all__
<             except AttributeError:
<                 return [name for name in living.__dict__.keys()
<                         if not name.startswith('_')]
<         # else lookup the astng
<         try:
<             explicit = self['__all__'].assigned_stmts().next()
<             # should be a tuple of constant string
<             return [const.value for const in explicit.nodes]
<         except (KeyError, AttributeError, InferenceError):
<             # XXX should admit we have lost if there is something like
<             # __all__ that we've not been able to analyse (such as
<             # dynamically constructed __all__)
<             return [name for name in self.keys()
<                     if not name.startswith('_')]
< 
< extend_class(Module, ModuleNG)
< 
< # Function  ###################################################################
< 
< class FunctionNG(object):
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
< 
<     # attributes below are set by the builder module or by raw factories
< 
<     # function's type, 'function' | 'method' | 'staticmethod' | 'classmethod'
<     type = 'function'
<     # list of argument names. MAY BE NONE on some builtin functions where
<     # arguments are unknown
<     argnames = None
< 
<     def pytype(self):
<         if 'method' in self.type:
<             return '__builtin__.instancemethod'
<         return '__builtin__.function'
< 
<     def is_method(self):
<         """return true if the function node should be considered as a method"""
<         return self.type != 'function'
<     
<     def is_bound(self):
<         """return true if the function is bound to an Instance or a class"""
<         return self.type == 'classmethod'
< 
<     def is_abstract(self, pass_is_abstract=True):
<         """return true if the method is abstract
<         It's considered as abstract if the only statement is a raise of
<         NotImplementError, or, if pass_is_abstract, a pass statement
<         """
<         for child_node in self.code.getChildNodes():
<             if isinstance(child_node, Raise) and child_node.expr1:
<                 try:
<                     name = child_node.expr1.nodes_of_class(Name).next()
<                     if name.name == 'NotImplementedError':
<                         return True
<                 except StopIteration:
<                     pass
<             if pass_is_abstract and isinstance(child_node, Pass):
<                 return True
<             return False
<         # empty function is the same as function with a single "pass" statement
<         if pass_is_abstract:
<             return True
< 
<     def is_generator(self):
<         """return true if this is a generator function"""
<         try:
<             return self.nodes_of_class(Yield, skip_klass=Function).next()
<         except StopIteration:
<             return False
<         
<     def format_args(self):
<         """return arguments formatted as string"""
<         if self.argnames is None: # information is missing
<             return ''
<         result = []
<         args, kwargs, last, default_idx = self._pos_information()
<         for i in range(len(self.argnames)):
<             name = self.argnames[i]
<             if type(name) is type(()):
<                 name = '(%s)' % ','.join([n.as_string() for n in name])
<             if i == last and kwargs:
<                 name = '**%s' % name.as_string()
<             elif args and i == last or (kwargs and i == last - 1):
<                 name = '*%s' % name.as_string()
<             elif i >= default_idx:
<                 default_str = self.defaults[i - default_idx].as_string()
<                 name = '%s=%s' % (name.as_string(), default_str)
< 	    else:
< 		name = name.as_string()
<             result.append(name)
<         return ', '.join(result)
< 
<     def default_value(self, argname):
<         """return the default value for an argument
< 
<         :raise `NoDefault`: if there is no default value defined
<         """
<         if self.argnames is None: # information is missing
<             raise NoDefault()
<         args, kwargs, last, defaultidx = self._pos_information()
<         try:
<             i = self.argnames.index(argname)
<         except ValueError:
<             raise NoDefault() # XXX
<         if i >= defaultidx and (i - defaultidx) < len(self.defaults):
<             return self.defaults[i - defaultidx]
<         raise NoDefault()
< 
<     def mularg_class(self, argname):
<         """if the given argument is a * or ** argument, return respectivly
<         a Tuple or Dict instance, else return None
<         """
<         args, kwargs, last, defaultidx = self._pos_information()
<         try:
<             i = self.argnames.index(argname)
<         except ValueError:
<             return None # XXX
<         if i == last and kwargs:
<             valnode = Dict([])
<             valnode.parent = self
<             return valnode
<         if args and (i == last or (kwargs and i == last - 1)):
<             valnode = Tuple([])
<             valnode.parent = self
<             return valnode
<         return None
< 
<     def _pos_information(self):
<         """return a 4-uple with positional information about arguments:
<         (true if * is used,
<          true if ** is used,
<          index of the last argument,
<          index of the first argument having a default value)
<         """
<         args = self.flags & 4
<         kwargs = self.flags & 8
<         last = len(self.argnames) - 1
<         defaultidx = len(self.argnames) - (len(self.defaults) +
<                                            (args and 1 or 0) +
<                                            (kwargs and 1 or 0))
<         return args, kwargs, last, defaultidx
< 
< extend_class(Function, FunctionNG)
< 
< # lambda nodes may also need some of the function members
< Lambda._pos_information = FunctionNG._pos_information.im_func
< Lambda.format_args = FunctionNG.format_args.im_func
< Lambda.default_value = FunctionNG.default_value.im_func
< Lambda.mularg_class = FunctionNG.mularg_class.im_func
< Lambda.type = 'function'
< Lambda.pytype = FunctionNG.pytype.im_func
< 
< # Class ######################################################################
< 
< def _class_type(klass):
<     """return a Class node type to differ metaclass, interface and exception
<     from 'regular' classes
<     """
<     if klass._type is not None:
<         return klass._type
<     if klass.name == 'type':
<         klass._type = 'metaclass'
<     elif klass.name.endswith('Interface'):
<         klass._type = 'interface'
<     elif klass.name.endswith('Exception'):
<         klass._type = 'exception'
<     else:
<         for base in klass.ancestors(recurs=False):
<             if base.type != 'class':
<                 klass._type = base.type
<                 break
<     if klass._type is None:
<         klass._type = 'class'
<     return klass._type
< 
< def _iface_hdlr(iface_node):
<     """a handler function used by interfaces to handle suspicious
<     interface nodes
<     """
<     return True
< 
< class ClassNG(object):
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<     
<     _type = None
<     type = property(_class_type,
<                     doc="class'type, possible values are 'class' | "
<                     "'metaclass' | 'interface' | 'exception'")
<     
<     def _newstyle_impl(self, context=None):
<         context = context or InferenceContext()
<         if self._newstyle is not None:
<             return self._newstyle
<         for base in self.ancestors(recurs=False, context=context):
<             if base._newstyle_impl(context):
<                 self._newstyle = True
<                 break
<         if self._newstyle is None:
<             self._newstyle = False
<         return self._newstyle
< 
<     _newstyle = None
<     newstyle = property(_newstyle_impl,
<                         doc="boolean indicating if it's a new style class"
<                         "or not")
< 
<     def pytype(self):
<         if self.newstyle:
<             return '__builtin__.type'
<         return '__builtin__.classobj'
<     
<     # attributes below are set by the builder module or by raw factories
<     
<     # a dictionary of class instances attributes
<     instance_attrs = None
<     # list of parent class as a list of string (ie names as they appears
<     # in the class definition)
<     basenames = None
< 
<     def ancestors(self, recurs=True, context=None):
<         """return an iterator on the node base classes in a prefixed
<         depth first order
<         
<         :param recurs:
<           boolean indicating if it should recurse or return direct
<           ancestors only
<         """
<         # FIXME: should be possible to choose the resolution order
<         # XXX inference make infinite loops possible here (see BaseTransformer
<         # manipulation in the builder module for instance !)
<         context = context or InferenceContext()
<         for stmt in self.bases:
<             try:
<                 for baseobj in stmt.infer(context):
<                     if not isinstance(baseobj, Class):
<                         # duh ?
<                         continue
<                     if baseobj is self:
<                         continue # cf xxx above
<                     yield baseobj
<                     if recurs:
<                         for grandpa in baseobj.ancestors(True, context):
<                             if grandpa is self:
<                                 continue # cf xxx above
<                             yield grandpa
<             except InferenceError:
<                 #import traceback
<                 #traceback.print_exc()
<                 # XXX log error ?
<                 continue
<             
<     def local_attr_ancestors(self, name, context=None):
<         """return an iterator on astng representation of parent classes
<         which have <name> defined in their locals
<         """
<         for astng in self.ancestors(context=context):
<             if astng.locals.has_key(name):
<                 yield astng
< 
<     def instance_attr_ancestors(self, name, context=None):
<         """return an iterator on astng representation of parent classes
<         which have <name> defined in their instance attribute dictionary
<         """
<         for astng in self.ancestors(context=context):
<             if astng.instance_attrs.has_key(name):
<                 yield astng
< 
<     def local_attr(self, name, context=None):
<         """return the astng associated to name in this class locals or
<         in its parents
< 
<         :raises `NotFoundError`:
<           if no attribute with this name has been find in this class or
<           its parent classes
<         """
<         try:
<             return self[name]
<         except KeyError:
<             # get if from the first parent implementing it if any
<             for class_node in self.local_attr_ancestors(name, context):
<                 return class_node[name]
<         raise NotFoundError(name)
<         
<     def instance_attr(self, name, context=None):
<         """return the astng nodes associated to name in this class instance
<         attributes dictionary or in its parents
< 
<         :raises `NotFoundError`:
<           if no attribute with this name has been find in this class or
<           its parent classes
<         """
<         try:
<             return self.instance_attrs[name]
<         except KeyError:
<             # get if from the first parent implementing it if any
<             for class_node in self.instance_attr_ancestors(name, context):
<                 return class_node.instance_attrs[name]
<         raise NotFoundError(name)
< 
<     def getattr(self, name, context=None):
<         """this method doesn't look in the instance_attrs dictionary since it's
<         done by an Instance proxy at inference time.
<         
<         It may return a YES object if the attribute has not been actually
<         found but a __getattr__ or __getattribute__ method is defined
<         """
<         if name in self.locals:
<             return self.locals[name]
<         if name == '__bases__':
<             return tuple(self.ancestors(recurs=False))
<         # XXX need proper meta class handling + MRO implementation
<         if name == '__mro__':
<             return tuple(self.ancestors(recurs=True))
<         for classnode in self.ancestors(recurs=False, context=context):
<             try:
<                 return classnode.getattr(name, context)
<             except NotFoundError:
<                 continue
<         raise NotFoundError(name)
< 
<     def igetattr(self, name, context=None):
<         """infered getattr, need special treatment in class to handle
<         descriptors
<         """
<         # set lookoup name since this is necessary to infer on import nodes for
<         # instance
<         context = copy_context(context)
<         context.lookupname = name
<         try:
<             for infered in _infer_stmts(self.getattr(name, context), context,
<                                         frame=self):
<                 # yield YES object instead of descriptors when necessary
<                 if not isinstance(infered, Const) and isinstance(infered, Instance):
<                     try:
<                         infered._proxied.getattr('__get__', context)
<                     except NotFoundError:
<                         yield infered
<                     else:
<                         yield YES
<                 else:
<                     yield infered
<         except NotFoundError:
<             if not name.startswith('__') and self.has_dynamic_getattr(context):
<                 # class handle some dynamic attributes, return a YES object
<                 yield YES
<             else:
<                 raise InferenceError(name)
<         
<     def has_dynamic_getattr(self, context=None):
<         """return True if the class has a custom __getattr__ or
<         __getattribute__ method
<         """
<         # need to explicitly handle optparse.Values (setattr is not detected)
<         if self.name == 'Values' and self.root().name == 'optparse':
<             return True
<         try:
<             self.getattr('__getattr__', context)
<             return True
<         except NotFoundError:
<             #if self.newstyle: XXX cause an infinite recursion error
<             try:
<                 getattribute = self.getattr('__getattribute__', context)[0]
<                 if getattribute.root().name != '__builtin__':
<                     # class has a custom __getattribute__ defined
<                     return True
<             except NotFoundError:
<                 pass
<         return False
<     
<     def methods(self):
<         """return an iterator on all methods defined in the class and
<         its ancestors
<         """
<         done = {}
<         for astng in chain(iter((self,)), self.ancestors()):
<             for meth in astng.mymethods():
<                 if done.has_key(meth.name):
<                     continue
<                 done[meth.name] = None
<                 yield meth
<                 
<     def mymethods(self):
<         """return an iterator on all methods defined in the class"""
<         for member in self.values():
<             if isinstance(member, Function):
<                 yield member
<                 
<     def interfaces(self, herited=True, handler_func=_iface_hdlr):
<         """return an iterator on interfaces implemented by the given
<         class node
<         """
<         # FIXME: what if __implements__ = (MyIFace, MyParent.__implements__)...
<         try:
<             implements = Instance(self).getattr('__implements__')[0]
<         except NotFoundError:
<             return
<         if not herited and not implements.frame() is self:
<             return
<         oneinf = False
<         for iface in unpack_infer(implements):
<             if iface is YES:
<                 continue
<             if handler_func(iface):
<                 oneinf = True
<                 yield iface
<         if not oneinf:
<             raise InferenceError()
< ##         if hasattr(implements, 'nodes'):
< ##             implements = implements.nodes
< ##         else:
< ##             implements = (implements,)
< ##         for iface in implements:
< ##             # let the handler function take care of this....
< ##             for iface in handler_func(iface):
< ##                 yield iface
< 
< extend_class(Class, ClassNG)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/all-wcprops
1,83d0
< K 25
< svn:wc:ra_dav:version-url
< V 65
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/logilab/astng
< END
< astutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/astng/astutils.py
< END
< nodes.py
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/170/trunk/clonedigger/logilab/astng/nodes.py
< END
< __pkginfo__.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/astng/__pkginfo__.py
< END
< lookup.py
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/astng/lookup.py
< END
< manager.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/170/trunk/clonedigger/logilab/astng/manager.py
< END
< inference.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/astng/inference.py
< END
< __init__.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/astng/__init__.py
< END
< _exceptions.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/astng/_exceptions.py
< END
< utils.py
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/astng/utils.py
< END
< scoped_nodes.py
< K 25
< svn:wc:ra_dav:version-url
< V 81
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/logilab/astng/scoped_nodes.py
< END
< builder.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/170/trunk/clonedigger/logilab/astng/builder.py
< END
< inspector.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/astng/inspector.py
< END
< raw_building.py
< K 25
< svn:wc:ra_dav:version-url
< V 80
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/astng/raw_building.py
< END
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/entries code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/entries
1,470d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/logilab/astng
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< astutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< d8c5ed53933dd4957fb0cf27fb4a7988
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2457
< 
< nodes.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< ad94b20b04dc6b9650806bdd82231406
< 2008-08-19T10:30:38.783594Z
< 170
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 28854
< 
< __pkginfo__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< ab5d2606df649f51988c8bd369f2adf4
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2283
< 
< lookup.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 5787b905309e80ad46de19347bd1840f
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 8071
< 
< manager.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< e5542f3d20e5f67c0ef6e36dd8a4aef6
< 2008-08-19T10:30:38.783594Z
< 170
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 14678
< 
< inference.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< a12219b7218062974957babb2d1cf33e
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 24873
< 
< __init__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 3a6530995dd1ae6e48d44e9d4acfeb28
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 9891
< 
< _exceptions.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< cb2e0ab34c5fc02e193b5f9c4ea18698
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 1877
< 
< utils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 0f41d2999f54a0d8579413f50e96ceb3
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 6441
< 
< scoped_nodes.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 6b6b3fad9c87932eacb4252921da477e
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 26367
< 
< builder.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< fa33d316cdeb3bbda7f79decbe771cf3
< 2008-08-19T10:30:38.783594Z
< 170
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 23497
< 
< inspector.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 22218823c55352afae0a99f026655be1
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 9044
< 
< raw_building.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 37f2d2fb72feba3aca582e1dd4aee5bc
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 8624
< 
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/astutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/astutils.py.svn-base
1,79d0
< # Copyright (c) 2003 Sylvain Thenault (thenault@nerim.net)
< # Copyright (c) 2003 Logilab
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some usefull functions to manipulate ast tuples
< """
< 
< __author__ = u"Sylvain Thenault"
< 
< import symbol
< import token
< from types import TupleType
< 
< def debuild(ast_tuple):
<     """
<     reverse ast_tuple to string
<     """
<     if type(ast_tuple[1]) is TupleType:
<         result = ''
<         for child in ast_tuple[1:]: 
<             result = '%s%s' % (result, debuild(child))
<         return result
<     else:
<         return ast_tuple[1]
< 
< def clean(ast_tuple):
<     """
<     reverse ast tuple to a list of tokens
<     merge sequences (token.NAME, token.DOT, token.NAME)
<     """
<     result = []
<     last = None
<     for couple in _clean(ast_tuple):
<         if couple[0] == token.NAME and last == token.DOT:
<             result[-1][1] += couple[1]
<         elif couple[0] == token.DOT and last == token.NAME:
<             result[-1][1] += couple[1]
<         else:
<             result.append(couple)
<         last = couple[0]
<     return result
< 
< def _clean(ast_tuple):
<     """ transform the ast into as list of tokens (i.e. final elements)
<     """
<     if type(ast_tuple[1]) is TupleType:
<         v = []
<         for c in ast_tuple[1:]:
<             v += _clean(c)
<         return v
<     else:
<         return [list(ast_tuple[:2])]
<     
< def cvrtr(tuple):
<     """debug method returning an ast string in a readable fashion"""
<     if type(tuple) is TupleType:
<         try:
<             try:
<                 txt = 'token.'+token.tok_name[tuple[0]]
<             except:
<                 txt = 'symbol.'+symbol.sym_name[tuple[0]]
<         except:
<             txt =  'Unknown token/symbol'
<         return [txt] + map(cvrtr, tuple[1:])
<     else:
<         return tuple
< 
< __all__ = ('debuild', 'clean', 'cvrtr')
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/builder.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/builder.py.svn-base
1,597d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """The ASTNGBuilder makes astng from living object and / or from compiler.ast
< 
< The builder is not thread safe and can't be used to parse different sources
< at the same time.
< 
< TODO:
<  - more complet representation on inspect build
<    (imported modules ? use dis.dis ?)
< 
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< from os.path import splitext, basename, dirname, exists, abspath
< from parser import ParserError
< from compiler import parse
< from inspect import isfunction, ismethod, ismethoddescriptor, isclass, \
<      isbuiltin
< from inspect import isdatadescriptor
< 
< from clonedigger.logilab.common.fileutils import norm_read
< from clonedigger.logilab.common.modutils import modpath_from_file
< 
< from clonedigger.logilab.astng import nodes, YES, Instance
< from clonedigger.logilab.astng.utils import ASTWalker
< from clonedigger.logilab.astng._exceptions import ASTNGBuildingException, InferenceError
< from clonedigger.logilab.astng.raw_building import *
< from clonedigger.logilab.astng.astutils import cvrtr
< 
< import token
< from compiler import transformer, consts
< from types import TupleType
< 
< def fromto_lineno(asttuple):
<     """return the minimum and maximum line number of the given ast tuple"""
<     return from_lineno(asttuple), to_lineno(asttuple)
< def from_lineno(asttuple):
<     """return the minimum line number of the given ast tuple"""
<     if type(asttuple[1]) is TupleType:
<         return from_lineno(asttuple[1])
<     return asttuple[2]
< def to_lineno(asttuple):
<     """return the maximum line number of the given ast tuple"""
<     if type(asttuple[-1]) is TupleType:
<         return to_lineno(asttuple[-1])
<     return asttuple[2]
< 
< def fix_lineno(node, fromast, toast=None):
<     if 'fromlineno' in node.__dict__:
<         return node    
<     #print 'fixing', id(node), id(node.__dict__), node.__dict__.keys(), repr(node)
<     if isinstance(node, nodes.Stmt):
<         node.fromlineno = from_lineno(fromast)#node.nodes[0].fromlineno
<         node.tolineno = node.nodes[-1].tolineno
<         return node
<     if toast is None:
<         node.fromlineno, node.tolineno = fromto_lineno(fromast)
<     else:
<         node.fromlineno, node.tolineno = from_lineno(fromast), to_lineno(toast)
<     #print 'fixed', id(node)
<     return node
< 
< BaseTransformer = transformer.Transformer
< 
< COORD_MAP = {
<     # if: test ':' suite ('elif' test ':' suite)* ['else' ':' suite]
<     'if': (0, 0),
<     # 'while' test ':' suite ['else' ':' suite]
<     'while': (0, 1),
<     # 'for' exprlist 'in' exprlist ':' suite ['else' ':' suite]
<     'for': (0, 3),
<     # 'try' ':' suite (except_clause ':' suite)+ ['else' ':' suite]
<     'try': (0, 0),
<     # | 'try' ':' suite 'finally' ':' suite
<     
<     }
< 
< def fixlineno_wrap(function, stype):
<     def fixlineno_wrapper(self, nodelist):
<         node = function(self, nodelist)            
<         idx1, idx2 = COORD_MAP.get(stype, (0, -1))
<         return fix_lineno(node, nodelist[idx1], nodelist[idx2])
<     return fixlineno_wrapper
< nodes.Module.fromlineno = 0
< nodes.Module.tolineno = 0
< class ASTNGTransformer(BaseTransformer):
<     """ovverides transformer for a better source line number handling"""
<     def com_NEWLINE(self, *args):
<         # A ';' at the end of a line can make a NEWLINE token appear
<         # here, Render it harmless. (genc discards ('discard',
<         # ('const', xxxx)) Nodes)
<         lineno = args[0][1]
<         # don't put fromlineno/tolineno on Const None to mark it as dynamically
<         # added, without "physical" reference in the source
<         n = nodes.Discard(nodes.Const(None))
<         n.fromlineno = n.tolineno = lineno
<         return n    
<     def com_node(self, node):
<         res = self._dispatch[node[0]](node[1:])
<         return fix_lineno(res, node)
<     def com_assign(self, node, assigning):
<         res = BaseTransformer.com_assign(self, node, assigning)
<         return fix_lineno(res, node)
<     def com_apply_trailer(self, primaryNode, nodelist):
<         node = BaseTransformer.com_apply_trailer(self, primaryNode, nodelist)
<         return fix_lineno(node, nodelist)
<     
< ##     def atom(self, nodelist):
< ##         node = BaseTransformer.atom(self, nodelist)
< ##         return fix_lineno(node, nodelist[0], nodelist[-1])
<     
<     def funcdef(self, nodelist):
<         node = BaseTransformer.funcdef(self, nodelist)
<         # XXX decorators
<         return fix_lineno(node, nodelist[-5], nodelist[-3])
<     def classdef(self, nodelist):
<         node = BaseTransformer.classdef(self, nodelist)
<         return fix_lineno(node, nodelist[0], nodelist[-2])
<             
< # wrap *_stmt methods
< for name in dir(BaseTransformer):
<     if name.endswith('_stmt') and not (name in ('com_stmt',
<                                                 'com_append_stmt')
<                                        or name in ASTNGTransformer.__dict__):
<         setattr(BaseTransformer, name,
<                 fixlineno_wrap(getattr(BaseTransformer, name), name[:-5]))
<             
< transformer.Transformer = ASTNGTransformer
< 
< # ast NG builder ##############################################################
< 
< class ASTNGBuilder:
<     """provide astng building methods
<     """
<     
<     def __init__(self, manager=None):
<         if manager is None:
<             from clonedigger.logilab.astng import MANAGER as manager
<         self._manager = manager
<         self._module = None
<         self._file = None
<         self._done = None
<         self._stack, self._par_stack = None, None
<         self._metaclass = None        
<         self._walker = ASTWalker(self)
<         self._dyn_modname_map = {'gtk': 'gtk._gtk'}
<         self._delayed = []
<         
<     def module_build(self, module, modname=None):
<         """build an astng from a living module instance
<         """
<         node = None
<         self._module = module
<         path = getattr(module, '__file__', None)
<         if path is not None:
<             path_, ext = splitext(module.__file__)
<             if ext in ('.py', '.pyc', '.pyo') and exists(path_ + '.py'):
<                 node = self.file_build(path_ + '.py', modname)
<         if node is None:
<             # this is a built-in module
<             # get a partial representation by introspection
<             node = self.inspect_build(module, modname=modname, path=path)
<         return node
< 
<     def inspect_build(self, module, modname=None, path=None):
<         """build astng from a living module (i.e. using inspect)
<         this is used when there is no python source code available (either
<         because it's a built-in module or because the .py is not available)
<         """
<         self._module = module
<         node = build_module(modname or module.__name__, module.__doc__)
<         node.file = node.path = path and abspath(path) or path
<         if self._manager is not None:
<             self._manager._cache[node.file] = self._manager._cache[node.name] = node
<         node.package = hasattr(module, '__path__')
<         attach___dict__(node)
<         self._done = {}
<         self.object_build(node, module)
<         return node
<     
<     def file_build(self, path, modname=None):
<         """build astng from a source code file (i.e. from an ast)
< 
<         path is expected to be a python source file
<         """
<         try:
<             data = norm_read(path)
<         except IOError, ex:
<             msg = 'Unable to load file %r (%s)' % (path, ex)
<             raise ASTNGBuildingException(msg)
<         self._file = path
<         # get module name if necessary, *before modifying sys.path*
<         if modname is None:
<             try:
<                 modname = '.'.join(modpath_from_file(path))
<             except ImportError:
<                 modname = splitext(basename(path))[0]
<         # build astng representation
<         try:
<             sys.path.insert(0, dirname(path))
<             node = self.string_build(data, modname, path)
<             node.file = abspath(path)
<         finally:
<             self._file = None
<             sys.path.pop(0)
<         
<         return node
<     
<     def string_build(self, data, modname='', path=None):
<         """build astng from a source code stream (i.e. from an ast)"""
<         return self.ast_build(parse(data + '\n'), modname, path)
<        
<     def ast_build(self, node, modname=None, path=None):
<         """recurse on the ast (soon ng) to add some arguments et method
<         """
<         if path is not None:
<             node.file = node.path = abspath(path)
<         else:
<             node.file = node.path = '<?>'
<         if modname.endswith('.__init__'):
<             modname = modname[:-9]
<             node.package = True
<         else:
<             node.package = path and path.find('__init__.py') > -1 or False
<         node.name = modname 
<         node.pure_python = True
<         if self._manager is not None:
<             self._manager._cache[node.file] = node
<             if self._file:
<                 self._manager._cache[abspath(self._file)] = node
<         self._walker.walk(node)
<         while self._delayed:
<             dnode = self._delayed.pop(0)
<             getattr(self, 'delayed_visit_%s' % dnode.__class__.__name__.lower())(dnode)
<         return node
< 
<     # callbacks to build from an existing compiler.ast tree ###################
< 
<     def visit_module(self, node):
<         """visit a stmt.Module node -> init node and push the corresponding
<         object or None on the top of the stack
<         """
<         self._stack = [self._module]
<         self._par_stack = [node]
<         self._metaclass = ['']
<         self._global_names = []
<         node.parent = None
<         node.globals = node.locals = {}
<         for name, value in ( ('__name__', node.name),
<                              ('__file__', node.path),
<                              ('__doc__', node.doc) ):
<             const = nodes.Const(value)
<             const.parent = node
<             node.locals[name] = [const]
<         attach___dict__(node)
<         if node.package:
<             # FIXME: List(Const())
<             const = nodes.Const(dirname(node.path))
<             const.parent = node
<             node.locals['__path__'] = [const]
<             
< 
<     def leave_module(self, _):
<         """leave a stmt.Module node -> pop the last item on the stack and check
<         the stack is empty
<         """
<         self._stack.pop()
<         assert not self._stack, 'Stack is not empty : %s' % self._stack
<         self._par_stack.pop()
<         assert not self._par_stack, \
<                'Parent stack is not empty : %s' % self._par_stack
<         
<     def visit_class(self, node):
<         """visit a stmt.Class node -> init node and push the corresponding
<         object or None on the top of the stack
<         """
<         self.visit_default(node)
<         node.instance_attrs = {}
<         node.basenames = [b_node for b_node in node.bases]
<         self._push(node)
<         for name, value in ( ('__name__', node.name),
<                              ('__module__', node.root().name),
<                              ('__doc__', node.doc) ):
<             const = nodes.Const(value)
<             const.parent = node
<             node.locals[name] = [const]
<         attach___dict__(node)
<         self._metaclass.append(self._metaclass[-1])
<         
<     def leave_class(self, node):
<         """leave a stmt.Class node -> pop the last item on the stack
<         """
<         self.leave_default(node)
<         self._stack.pop()
<         metaclass = self._metaclass.pop()
<         if not node.bases:
<             # no base classes, detect new / style old style according to
<             # current scope
<             node._newstyle = metaclass == 'type'
<         
<     def visit_function(self, node):
<         """visit a stmt.Function node -> init node and push the corresponding
<         object or None on the top of the stack
<         """
<         self.visit_default(node)
<         self._global_names.append({})
<         node.argnames = list(node.argnames)
<         if isinstance(node.parent.frame(), nodes.Class):
<             node.type = 'method'
<             if node.name == '__new__':
<                 node.type = 'classmethod'
<         self._push(node)
<         register_arguments(node, node.argnames)
<         
<     def leave_function(self, node):
<         """leave a stmt.Function node -> pop the last item on the stack
<         """
<         self.leave_default(node)
<         self._stack.pop()
<         self._global_names.pop()
<         
<     def visit_lambda(self, node):
<         """visit a stmt.Lambda node -> init node locals
<         """
<         self.visit_default(node)
<         node.argnames = list(node.argnames)
<         node.locals = {}
<         register_arguments(node, node.argnames)
<         
<     def visit_genexpr(self, node):
<         """visit a stmt.GenExpr node -> init node locals
<         """
<         self.visit_default(node)
<         node.locals = {}
<         
<     def visit_global(self, node):
<         """visit a stmt.Global node -> add declared names to locals
<         """
<         self.visit_default(node)
<         if not self._global_names: # global at the module level, no effect
<             return
<         for name in node.names:
<             self._global_names[-1].setdefault(name, []).append(node)
< #             node.parent.set_local(name, node)
< #         module = node.root()
< #         if module is not node.frame():
< #             for name in node.names:
< #                 module.set_local(name, node)
<             
<     def visit_import(self, node):
<         """visit a stmt.Import node -> add imported names to locals
<         """
<         self.visit_default(node)
<         for (name, asname) in node.names:
<             name = asname or name
<             node.parent.set_local(name.split('.')[0], node)
<             
<     def visit_from(self, node):
<         """visit a stmt.From node -> add imported names to locals
<         """
<         self.visit_default(node)
<         # add names imported by the import to locals
<         for (name, asname) in node.names:
<             if name == '*':
<                 try:
<                     imported = node.root().import_module(node.modname)
<                 except ASTNGBuildingException:
<                     #import traceback
<                     #traceback.print_exc()
<                     continue
<                     # FIXME: log error
<                     #print >> sys.stderr, \
<                     #      'Unable to get imported names for %r line %s"' % (
<                     #    node.modname, node.lineno)
<                 for name in imported.wildcard_import_names():
<                     node.parent.set_local(name, node)
<             else:
<                 node.parent.set_local(asname or name, node)
< 
<     def leave_decorators(self, node):
<         """python >= 2.4
<         visit a stmt.Decorator node -> check for classmethod and staticmethod
<         """
<         func = node.parent
<         for decorator_expr in node.nodes:
<             if isinstance(decorator_expr, nodes.Name) and \
<                    decorator_expr.name in ('classmethod', 'staticmethod'):
<                 func.type = decorator_expr.name
<         self.leave_default(node)
<         
<     def visit_assign(self, node):
<         """visit a stmt.Assign node -> check for classmethod and staticmethod
<         + __metaclass__
<         """
<         self.visit_default(node)
<         klass = node.parent.frame()
<         #print node
<         if isinstance(klass, nodes.Class) and \
<             isinstance(node.expr, nodes.CallFunc) and \
<             isinstance(node.expr.node, nodes.Name):
<             func_name = node.expr.node.name
<             if func_name in ('classmethod', 'staticmethod'):
<                 for ass_node in node.nodes:
<                     if isinstance(ass_node, nodes.AssName):
<                         try:
<                             meth = klass[ass_node.name]
<                             if isinstance(meth, nodes.Function):
<                                 meth.type = func_name
<                             #else:
<                             #    print >> sys.stderr, 'FIXME 1', meth
<                         except KeyError:
<                             #print >> sys.stderr, 'FIXME 2', ass_node.name
<                             continue
<         elif (isinstance(node.nodes[0], nodes.AssName)
<               and node.nodes[0].name == '__metaclass__'): # XXX check more...
<             self._metaclass[-1] = 'type' # XXX get the actual metaclass
< 
<     def visit_assname(self, node):
<         """visit a stmt.AssName node -> add name to locals
<         """
<         self.visit_default(node)
<         self._add_local(node, node.name)
< 
<     def visit_augassign(self, node):
<         """visit a stmt.AssName node -> add name to locals
<         """
<         self.visit_default(node)
<         if not isinstance(node.node, nodes.Name):
<             return  # XXX
<         self._add_local(node, node.node.name)
< 
<     def _add_local(self, node, name):
<         if self._global_names and name in self._global_names[-1]:
<             node.root().set_local(name, node)
<         else:
<             node.parent.set_local(name, node)
<         
<     def visit_assattr(self, node):
<         """visit a stmt.AssAttr node -> delay it to handle members
<         definition later
<         """
<         self.visit_default(node)
<         self._delayed.append(node)
<     
<     def delayed_visit_assattr(self, node):
<         """visit a stmt.AssAttr node -> add name to locals, handle members
<         definition
<         """
<         try:
<             frame = node.frame()
<             for infered in node.expr.infer():
<                 if infered is YES:
<                     continue
<                 try:
<                     if infered.__class__ is Instance:
<                         infered = infered._proxied
<                         iattrs = infered.instance_attrs
<                     else:
<                         iattrs = infered.locals
<                 except AttributeError:
<                     continue
<                 values = iattrs.setdefault(node.attrname, [])
<                 if node in values:
<                     continue
<                 # get assign in __init__ first XXX useful ?
<                 if frame.name == '__init__' and values and not \
<                        values[0].frame().name == '__init__':
<                     values.insert(0, node)
<                 else:
<                     values.append(node)
<                 #print node.attrname, infered, values
<         except InferenceError:
<             #print frame, node
<             pass
<         
<     def visit_default(self, node):
<         """default visit method, handle the parent attribute
<         """
<         node.parent = self._par_stack[-1]
<         assert node.parent is not node
<         self._par_stack.append(node)
< 
<     def leave_default(self, _):       
<         """default leave method, handle the parent attribute
<         """
<         self._par_stack.pop()             
< 
<     def _push(self, node):
<         """update the stack and init some parts of the Function or Class node
<         """
<         obj = getattr(self._stack[-1], node.name, None)
<         self._stack.append(obj)
<         node.locals = {}
<         node.parent.frame().set_local(node.name, node)
< 
<     # astng from living objects ###############################################
<     #
<     # this is actually a really minimal representation, including only Module,
<     # Function and Class nodes and some others as guessed
<     
<     def object_build(self, node, obj):
<         """recursive method which create a partial ast from real objects
<          (only function, class, and method are handled)
<         """
<         if self._done.has_key(obj):
<             return self._done[obj]
<         self._done[obj] = node
<         modname = self._module.__name__
<         modfile = getattr(self._module, '__file__', None)
<         for name in dir(obj):
<             try:
<                 member = getattr(obj, name)
<             except AttributeError:
<                 # damned ExtensionClass.Base, I know you're there !
<                 attach_dummy_node(node, name)
<                 continue
<             if ismethod(member):
<                 member = member.im_func
<             if isfunction(member):
<                 # verify this is not an imported function
<                 if member.func_code.co_filename != modfile:
<                     attach_dummy_node(node, name, member)
<                     continue
<                 object_build_function(node, member)
<             elif isbuiltin(member):
<                 # verify this is not an imported member
<                 if self._member_module(member) != modname:
<                     imported_member(node, member, name)
<                     continue
<                 object_build_methoddescriptor(node, member)                
<             elif isclass(member):
<                 # verify this is not an imported class
<                 if self._member_module(member) != modname:
<                     imported_member(node, member, name)
<                     continue
<                 if member in self._done:
<                     class_node = self._done[member]
<                     node.add_local_node(class_node, name)
<                 else:
<                     class_node = object_build_class(node, member)
<                 # recursion
<                 self.object_build(class_node, member)
<             elif ismethoddescriptor(member):
<                 assert isinstance(member, object)
<                 object_build_methoddescriptor(node, member)
<             elif isdatadescriptor(member):
<                 assert isinstance(member, object)
<                 object_build_datadescriptor(node, member, name)
<             elif isinstance(member, (int, long, float, str, unicode)) or member is None:
<                 attach_const_node(node, name, member)
<             else:
<                 # create an empty node so that the name is actually defined
<                 attach_dummy_node(node, name, member)
< 
<     def _member_module(self, member):
<         modname = getattr(member, '__module__', None)
<         return self._dyn_modname_map.get(modname, modname)
<         
< def imported_member(node, member, name):
<     """consider a class/builtin member where __module__ != current module name
< 
<     check if it's sound valid and then add an import node, else use a dummy node
<     """
<     # /!\ some classes like ExtensionClass doesn't have a 
<     # __module__ attribute !
<     member_module = getattr(member, '__module__', '__builtin__')
<     try:
<         getattr(sys.modules[member_module], name)
<     except (KeyError, AttributeError):
<         attach_dummy_node(node, name, member)
<     else:
<         attach_import_node(node, member_module, name)
<     
< # optimize the tokenize module
< #from logilab.common.bind import optimize_module
< #import tokenize
< #optimize_module(sys.modules['tokenize'], tokenize.__dict__)
< #optimize_module(sys.modules[__name__], sys.modules[__name__].__dict__)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/_exceptions.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/_exceptions.py.svn-base
1,52d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains exceptions used in the astng library
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __doctype__ = "restructuredtext en"
< 
< class ASTNGError(Exception):
<     """base exception class for all astng related exceptions
<     """
< 
< class ASTNGBuildingException(ASTNGError):
<     """exception class when we are not able to build an astng representation"""
< 
< class ResolveError(ASTNGError):
<     """base class of astng resolution/inference error"""
< 
< class NotFoundError(ResolveError):
<     """raised when we are unabled to resolve a name"""
< 
< class InferenceError(ResolveError):
<     """raised when we are unabled to infer a node"""
< 
< class UnresolvableName(InferenceError):
<     """raised when we are unabled to resolve a name"""
< 
< 
< class NoDefault(ASTNGError):
<     """raised by function's `default_value` method when an argument has
<     no default value
<     """
< 
< class IgnoreChild(Exception):
<     """exception that maybe raised by visit methods to avoid children traversal
<     """
<     
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/inference.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/inference.py.svn-base
1,723d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains a set of functions to handle inference on astng trees
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2008 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< from __future__ import generators
< 
< __doctype__ = "restructuredtext en"
< 
< from copy import copy
< 
< from clonedigger.logilab.common.compat import imap, chain, set
< 
< from clonedigger.logilab.astng import MANAGER, YES, InferenceContext, Instance, Generator, \
<      unpack_infer, _infer_stmts, nodes, copy_context
< from clonedigger.logilab.astng import ASTNGError, InferenceError, UnresolvableName, \
<      NoDefault, NotFoundError, ASTNGBuildingException
< 
<     
< def path_wrapper(func):
<     """return the given infer function wrapped to handle the path"""
<     def wrapped(node, context=None, _func=func, **kwargs):
<         """wrapper function handling context"""
<         if context is None:
<             context = InferenceContext(node)
<         context.push(node)
<         yielded = set()
<         try:
<             for res in _func(node, context, **kwargs):
<                 # unproxy only true instance, not const, tuple, dict...
<                 if res.__class__ is Instance:
<                     ares = res._proxied
<                 else:
<                     ares = res
<                 if not ares in yielded:
<                     yield res
<                     yielded.add(ares)
<             context.pop()
<         except:
<             context.pop()
<             raise
<     return wrapped
< 
< # .infer method ###############################################################
< 
< def infer_default(self, context=None):
<     """we don't know how to resolve a statement by default"""
<     #print 'inference error', self, name, path
<     raise InferenceError(self.__class__.__name__)
< 
< #infer_default = infer_default
< nodes.Node.infer = infer_default
< 
< 
< def infer_end(self, context=None):
<     """inference's end for node such as Module, Class, Function, Const...
<     """
<     yield self
< 
< #infer_end = path_wrapper(infer_end)
< nodes.Module.infer = nodes.Class.infer = infer_end
< nodes.List.infer = infer_end
< nodes.Tuple.infer = infer_end
< nodes.Dict.infer = infer_end
< nodes.Const.infer = infer_end
< 
< def infer_empty_node(self, context=None):
<     if not self.has_underlying_object():
<         yield YES
<     else:
<         try:
<             for infered in MANAGER.infer_astng_from_something(self.object,
<                                                               context=context):
<                 yield infered
<         except ASTNGError:
<             yield YES
< nodes.EmptyNode.infer = path_wrapper(infer_empty_node)
<     
< 
< 
< class CallContext:
<     """when infering a function call, this class is used to remember values
<     given as argument
<     """
<     def __init__(self, args, starargs, dstarargs):
<         self.args = []
<         self.nargs = {}
<         for arg in args:
<             if isinstance(arg, nodes.Keyword):
<                 self.nargs[arg.name] = arg.expr
<             else:
<                 self.args.append(arg)
<         self.starargs = starargs
<         self.dstarargs = dstarargs
< 
<     def infer_argument(self, funcnode, name, context):
<         """infer a function argument value according the the call context"""
<         # 1. search in named keywords
<         try:
<             return self.nargs[name].infer(context)
<         except KeyError:
<             # Function.argnames can be None in astng (means that we don't have
<             # information on argnames)
<             if funcnode.argnames is not None:
<                 try:
<                     argindex = funcnode.argnames.index(name)
<                 except ValueError:
<                     pass
<                 else:
<                     # 2. first argument of instance/class method
<                     if argindex == 0 and funcnode.type in ('method', 'classmethod'):
<                         if context.boundnode is not None:
<                             boundnode = context.boundnode
<                         else:
<                             # XXX can do better ?
<                             boundnode = funcnode.parent.frame()
<                         if funcnode.type == 'method':
<                             return iter((Instance(boundnode),))
<                         if funcnode.type == 'classmethod':
<                             return iter((boundnode,))                            
<                     # 2. search arg index
<                     try:
<                         return self.args[argindex].infer(context)
<                     except IndexError:
<                         pass
<                     # 3. search in *args (.starargs)
<                     if self.starargs is not None:
<                         its = []
<                         for infered in self.starargs.infer(context):
<                             if infered is YES:
<                                 its.append((YES,))
<                                 continue
<                             try:
<                                 its.append(infered.getitem(argindex).infer(context))
<                             except (InferenceError, AttributeError):
<                                 its.append((YES,))
<                             except IndexError:
<                                 continue
<                         if its:
<                             return chain(*its)
<         # 4. XXX search in **kwargs (.dstarargs)
<         if self.dstarargs is not None:
<             its = []
<             for infered in self.dstarargs.infer(context):
<                 if infered is YES:
<                     its.append((YES,))
<                     continue
<                 try:
<                     its.append(infered.getitem(name).infer(context))
<                 except (InferenceError, AttributeError):
<                     its.append((YES,))
<                 except IndexError:
<                     continue
<             if its:
<                 return chain(*its)
<         # 5. */** argument, (Tuple or Dict)
<         mularg = funcnode.mularg_class(name)
<         if mularg is not None: 
<             # XXX should be able to compute values inside
<             return iter((mularg,))
<         # 6. return default value if any
<         try:
<             return funcnode.default_value(name).infer(context)
<         except NoDefault:
<             raise InferenceError(name)
<         
<         
< def infer_function(self, context=None):
<     """infer on Function nodes must be take with care since it
<     may be called to infer one of it's argument (in which case <name>
<     should be given)
<     """
<     name = context.lookupname
<     # no name is given, we are infering the function itself
<     if name is None:
<         yield self
<         return
<     if context.callcontext:
<         # reset call context/name
<         callcontext = context.callcontext
<         context = copy_context(context)
<         context.callcontext = None
<         for infered in callcontext.infer_argument(self, name, context):
<             yield infered
<         return
<     # Function.argnames can be None in astng (means that we don't have
<     # information on argnames), in which case we can't do anything more
<     if self.argnames is None:
<         yield YES
<         return
<     if not name in self.argnames:
<         raise InferenceError()
<     # first argument of instance/class method
<     if name == self.argnames[0]:
<         if self.type == 'method':
<             yield Instance(self.parent.frame())
<             return
<         if self.type == 'classmethod':
<             yield self.parent.frame()
<             return
<     mularg = self.mularg_class(name)
<     if mularg is not None: # */** argument, no doubt it's a Tuple or Dict
<         yield mularg
<         return
<     # if there is a default value, yield it. And then yield YES to reflect
<     # we can't guess given argument value
<     try:
<         context = copy_context(context)
<         for infered in self.default_value(name).infer(context):
<             yield infered
<         yield YES
<     except NoDefault:
<         yield YES
< 
< nodes.Function.infer = path_wrapper(infer_function)
< nodes.Lambda.infer = path_wrapper(infer_function)
< 
< 
< def infer_name(self, context=None):
<     """infer a Name: use name lookup rules"""
<     context = context.clone()
<     context.lookupname = self.name
<     frame, stmts = self.lookup(self.name)
<     if not stmts:
<         raise UnresolvableName(self.name)
<     return _infer_stmts(stmts, context, frame)
< 
< nodes.Name.infer = path_wrapper(infer_name)
< 
< 
< def infer_assname(self, context=None):
<     """infer a AssName/AssAttr: need to inspect the RHS part of the
<     assign node
<     """
<     stmts = self.assigned_stmts(context=context)
<     return _infer_stmts(stmts, context)
<     
< nodes.AssName.infer = path_wrapper(infer_assname)
< 
< 
< def infer_assattr(self, context=None):
<     """infer a AssName/AssAttr: need to inspect the RHS part of the
<     assign node
<     """
<     stmts = self.assigned_stmts(context=context)
<     return _infer_stmts(stmts, context)
<     
< nodes.AssAttr.infer = path_wrapper(infer_assattr)
< 
<         
< def infer_callfunc(self, context=None):
<     """infer a CallFunc node by trying to guess what's the function is
<     returning
<     """
<     one_infered = False
<     context = context.clone()
<     context.callcontext = CallContext(self.args, self.star_args, self.dstar_args)
<     for callee in self.node.infer(context):
<         if callee is YES:
<             yield callee
<             one_infered = True
<             continue
<         try:
<             for infered in callee.infer_call_result(self, context):
<                 yield infered
<                 one_infered = True
<         except (AttributeError, InferenceError):
<             ## XXX log error ?
<             continue
<     if not one_infered:
<         raise InferenceError()
< 
< nodes.CallFunc.infer = path_wrapper(infer_callfunc)
< 
< 
< def infer_getattr(self, context=None):
<     """infer a Getattr node by using getattr on the associated object
<     """
<     one_infered = False
<     # XXX
<     #context = context.clone()
<     for owner in self.expr.infer(context):
<         if owner is YES:
<             yield owner
<             one_infered = True
<             continue
<         try:
<             context.boundnode = owner
<             for obj in owner.igetattr(self.attrname, context):
<                 yield obj
<                 one_infered = True
<             context.boundnode = None
<         except (NotFoundError, InferenceError):
<             continue
<         except AttributeError:
<             # XXX method / function
<             continue
<     if not one_infered:
<         raise InferenceError()
<                 
< nodes.Getattr.infer = path_wrapper(infer_getattr)
< 
< 
< def _imported_module_astng(node, modname):
<     """return the ast for a module whose name is <modname> imported by <node>
<     """
<     # handle special case where we are on a package node importing a module
<     # using the same name as the package, which may end in an infinite loop
<     # on relative imports
<     # XXX: no more needed ?
<     mymodule = node.root()
<     if mymodule.relative_name(modname) == mymodule.name:
<         # FIXME: I don't know what to do here...
<         raise InferenceError(modname)
<     try:
<         return mymodule.import_module(modname)
<     except (ASTNGBuildingException, SyntaxError):
<         raise InferenceError(modname)
<         
< def infer_import(self, context=None, asname=True):
<     """self resolve on From / Import nodes return the imported module/object"""
<     name = context.lookupname
<     if name is None:
<         raise InferenceError()
<     if asname:
<         yield _imported_module_astng(self, self.real_name(name))
<     else:
<         yield _imported_module_astng(self, name)
<     
< nodes.Import.infer = path_wrapper(infer_import)
< 
< def infer_from(self, context=None, asname=True):
<     """self resolve on From / Import nodes return the imported module/object"""
<     name = context.lookupname
<     if name is None:
<         raise InferenceError()
<     if asname:
<         name = self.real_name(name)
<     module = _imported_module_astng(self, self.modname)
<     try:
<         context = copy_context(context)
<         context.lookupname = name
<         return _infer_stmts(module.getattr(name), context)
<     except NotFoundError:
<         raise InferenceError(name)
< 
< nodes.From.infer = path_wrapper(infer_from)
< 
< 
< def infer_global(self, context=None):
<     if context.lookupname is None:
<         raise InferenceError()
<     try:
<         return _infer_stmts(self.root().getattr(context.lookupname), context)
<     except NotFoundError:
<         raise InferenceError()
< nodes.Global.infer = path_wrapper(infer_global)
< 
< 
< def infer_subscript(self, context=None):
<     """infer simple subscription such as [1,2,3][0] or (1,2,3)[-1]
<     """
<     if len(self.subs) == 1:
<         index = self.subs[0].infer(context).next()
<         if index is YES:
<             yield YES
<             return
<         try:
<             # suppose it's a Tuple/List node (attribute error else)
<             assigned = self.expr.getitem(index.value)
<         except AttributeError:
<             raise InferenceError()
<         except IndexError:
<             yield YES
<             return
<         for infered in assigned.infer(context):
<             yield infered
<     else:
<         raise InferenceError()
< nodes.Subscript.infer = path_wrapper(infer_subscript)
< 
< def infer_unarysub(self, context=None):
<     for infered in self.expr.infer(context):
<         try:
<             value = -infered.value
<         except (TypeError, AttributeError):
<             yield YES
<             continue
<         node = copy(self.expr)
<         node.value = value
<         yield node
< nodes.UnarySub.infer = path_wrapper(infer_unarysub)
< 
< def infer_unaryadd(self, context=None):
<     return self.expr.infer(context)
< nodes.UnaryAdd.infer = infer_unaryadd
< 
< def _py_value(node):
<     try:
<         return node.value
<     except AttributeError:
<         # not a constant
<         if isinstance(node, nodes.Dict):
<             return {}
<         if isinstance(node, nodes.List):
<             return []
<         if isinstance(node, nodes.Tuple):
<             return ()
<     raise ValueError()
< 
< def _infer_operator(self, context=None, impl=None, meth='__method__'):
<     for lhs in self.left.infer(context):
<         try:
<             lhsvalue = _py_value(lhs)
<         except ValueError:
<             # not a constant
<             try:
<                 # XXX just suppose if the type implement meth, returned type
<                 # will be the same
<                 lhs.getattr(meth)
<                 yield lhs
<             except:
<                 yield YES
<             continue
<         for rhs in self.right.infer(context):
<             try:
<                 rhsvalue = _py_value(rhs)
<             except ValueError:
<                 try:
<                     # XXX just suppose if the type implement meth, returned type
<                     # will be the same
<                     rhs.getattr(meth)
<                     yield rhs
<                 except:
<                     yield YES
<                 continue
<             try:
<                 value = impl(lhsvalue, rhsvalue)
<             except TypeError:
<                 yield YES
<                 continue
<             if type(value) is type(lhsvalue):
<                 node = copy(lhs)
<             else:
<                 node = copy(rhs)
<             # XXX may be dict, tuple...
<             node.value = value
<             yield node
< 
< def infer_sub(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a-b, meth='__sub__')
< nodes.Sub.infer = path_wrapper(infer_sub)
< 
< def infer_add(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a+b, meth='__add__')
< nodes.Add.infer = path_wrapper(infer_add)
< 
< def infer_mul(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a*b, meth='__mul__')
< nodes.Mul.infer = path_wrapper(infer_mul)
< 
< def infer_div(self, context=None):
<     return _infer_operator(self, context=context, impl=lambda a,b: a/b, meth='__div__')
< nodes.Div.infer = path_wrapper(infer_div)
<     
< # .infer_call_result method ###################################################
< def callable_default(self):
<     return False
< nodes.Node.callable = callable_default
< def callable_true(self):
<     return True
< nodes.Function.callable = callable_true
< nodes.Lambda.callable = callable_true
< nodes.Class.callable = callable_true
< 
< def infer_call_result_function(self, caller, context=None):
<     """infer what's a function is returning when called"""
<     if self.is_generator():
<         yield Generator(self)
<         return
<     returns = self.nodes_of_class(nodes.Return, skip_klass=nodes.Function)
<     for returnnode in returns:
<         try:
<             for infered in returnnode.value.infer(context):
<                 yield infered
<         except InferenceError:
<             yield YES
< nodes.Function.infer_call_result = infer_call_result_function
< 
< def infer_call_result_lambda(self, caller, context=None):
<     """infer what's a function is returning when called"""
<     return self.code.infer(context)
< nodes.Lambda.infer_call_result = infer_call_result_lambda
< 
< def infer_call_result_class(self, caller, context=None):
<     """infer what's a class is returning when called"""
<     yield Instance(self)
< 
< nodes.Class.infer_call_result = infer_call_result_class
< 
< 
< # Assignment related nodes ####################################################
< """the assigned_stmts method is responsible to return the assigned statement
< (eg not infered) according to the assignment type.
< 
< The `asspath` argument is used to record the lhs path of the original node.
< For instance if we want assigned statements for 'c' in 'a, (b,c)', asspath
< will be [1, 1] once arrived to the Assign node.
< 
< The `context` argument is the current inference context which should be given
< to any intermediary inference necessary.
< """
< def assend_assigned_stmts(self, context=None):
<     # only infer *real* assignments
<     if self.flags == 'OP_DELETE':
<         raise InferenceError()
<     return self.parent.assigned_stmts(self, context=context)
<     
< nodes.AssName.assigned_stmts = assend_assigned_stmts
< nodes.AssAttr.assigned_stmts = assend_assigned_stmts
< 
< def mulass_assigned_stmts(self, node, context=None, asspath=None):
<     if asspath is None:
<         asspath = []
<     node_idx = self.nodes.index(node)
<     asspath.insert(0, node_idx)
<     return self.parent.assigned_stmts(self, context, asspath)
< nodes.AssTuple.assigned_stmts = mulass_assigned_stmts
< nodes.AssList.assigned_stmts = mulass_assigned_stmts
< 
< def assign_assigned_stmts(self, node, context=None, asspath=None):
<     if not asspath:
<         yield self.expr 
<         return
<     found = False
<     for infered in _resolve_asspart(self.expr.infer(context), asspath, context):
<         found = True
<         yield infered
<     if not found:
<         raise InferenceError()
< 
< nodes.Assign.assigned_stmts = assign_assigned_stmts
< 
< def _resolve_asspart(parts, asspath, context):
<     """recursive function to resolve multiple assignments"""
<     asspath = asspath[:]
<     index = asspath.pop(0)
<     for part in parts:
<         try:
<             assigned = part.getitem(index)
<         except (AttributeError, IndexError):
<             return
<         if not asspath:
<             # we acheived to resolved the assigment path,
<             # don't infer the last part
<             found = True
<             yield assigned
<         elif assigned is YES:
<             return
<         else:
<             # we are not yet on the last part of the path
<             # search on each possibly infered value
<             try:
<                 for infered in _resolve_asspart(assigned.infer(context), asspath, context):
<                     yield infered
<             except InferenceError:
<                 return
<     
< def tryexcept_assigned_stmts(self, node, context=None, asspath=None):
<     found = False
<     for exc_type, exc_obj, body in self.handlers:
<         if node is exc_obj:
<             for assigned in unpack_infer(exc_type):
<                 if isinstance(assigned, nodes.Class):
<                     assigned = Instance(assigned)
<                 yield assigned
<                 found = True
<             break
<     if not found:
<         raise InferenceError()
< nodes.TryExcept.assigned_stmts = tryexcept_assigned_stmts
< 
< 
< def _resolve_looppart(parts, asspath, context):
<     """recursive function to resolve multiple assignments on loops"""
<     asspath = asspath[:]
<     index = asspath.pop(0)
<     for part in parts:
<         if part is YES:
<             continue
<         if not hasattr(part, 'iter_stmts'):
<             continue
<         for stmt in part.iter_stmts():
<             try:
<                 assigned = stmt.getitem(index)
<             except (AttributeError, IndexError):
<                 continue
<             if not asspath:
<                 # we acheived to resolved the assigment path,
<                 # don't infer the last part
<                 found = True
<                 yield assigned
<             elif assigned is YES:
<                 break
<             else:
<                 # we are not yet on the last part of the path
<                 # search on each possibly infered value
<                 try:
<                     for infered in _resolve_looppart(assigned.infer(context), asspath, context):
<                         yield infered
<                 except InferenceError:
<                     break
< 
< def for_assigned_stmts(self, node, context=None, asspath=None):
<     found = False
<     if asspath is None:
<         for lst in self.loop_node().infer(context):
<             if isinstance(lst, (nodes.Tuple, nodes.List)):
<                 for item in lst.nodes:
<                     found = True
<                     yield item
<     else:
<         for infered in _resolve_looppart(self.loop_node().infer(context), asspath, context):
<             found = True
<             yield infered
<     if not found:
<         raise InferenceError()
< nodes.For.assigned_stmts = for_assigned_stmts
< nodes.ListCompFor.assigned_stmts = for_assigned_stmts
< nodes.GenExprFor.assigned_stmts = for_assigned_stmts
< 
< def with_assigned_stmts(self, node, context=None, asspath=None):
<     found = False
<     if asspath is None:
<         for lst in self.vars.infer(context):
<             if isinstance(lst, (nodes.Tuple, nodes.List)):
<                 for item in lst.nodes:
<                     found = True
<                     yield item
<     else:
<         raise InferenceError()
<     if not found:
<         raise InferenceError()
< nodes.With.assigned_stmts = with_assigned_stmts
< 
<     
< def end_ass_type(self):
<     return self
< nodes.With.ass_type = end_ass_type
< nodes.For.ass_type = end_ass_type
< nodes.ListCompFor.ass_type = end_ass_type
< nodes.GenExprFor.ass_type = end_ass_type
< nodes.TryExcept.ass_type = end_ass_type
< nodes.Assign.ass_type = end_ass_type
< nodes.AugAssign.ass_type = end_ass_type
< def parent_ass_type(self):
<     return self.parent.ass_type()
< nodes.AssName.ass_type = parent_ass_type
< nodes.AssAttr.ass_type = parent_ass_type
< nodes.AssTuple.ass_type = parent_ass_type
< nodes.AssList.ass_type = parent_ass_type
< def assend_ass_type(self, context=None):
<     # only infer *real* assignments
<     if self.flags == 'OP_DELETE':
<         return self
<     return self.parent.ass_type()
< nodes.AssName.ass_type = assend_ass_type
< nodes.AssAttr.ass_type = assend_ass_type
< 
< # subscription protocol #######################################################
<         
< def tl_getitem(self, index):
<     return self.nodes[index]
< nodes.List.getitem = tl_getitem
< nodes.Tuple.getitem = tl_getitem
<         
< def tl_iter_stmts(self):
<     return self.nodes
< nodes.List.iter_stmts = tl_iter_stmts
< nodes.Tuple.iter_stmts = tl_iter_stmts
< 
< #Dict.getitem = getitem XXX
<         
< def dict_getitem(self, key):
<     for i in xrange(0, len(self.items), 2):
<         for inferedkey in self.items[i].infer():
<             if inferedkey is YES:
<                 continue
<             if inferedkey.eq(key):
<                 return self.items[i+1]
<     raise IndexError(key)
< 
< nodes.Dict.getitem = dict_getitem
<         
< def dict_iter_stmts(self):
<     return self.items[::2]
< nodes.Dict.iter_stmts = dict_iter_stmts
< 
< 
< def for_loop_node(self):
<     return self.list
< nodes.For.loop_node = for_loop_node
< nodes.ListCompFor.loop_node = for_loop_node
< 
< def gen_loop_nodes(self):
<     return self.iter
< nodes.GenExprFor.loop_node = gen_loop_nodes
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/__init__.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/__init__.py.svn-base
1,294d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Python Abstract Syntax Tree New Generation
< 
< The aim of this module is to provide a common base representation of
< python source code for projects such as pychecker, pyreverse,
< pylint... Well, actually the development of this library is essentialy
< governed by pylint's needs.
< 
< It extends class defined in the compiler.ast [1] module with some
< additional methods and attributes. Instance attributes are added by a
< builder object, which can either generate extended ast (let's call
< them astng ;) by visiting an existant ast tree or by inspecting living
< object. Methods are added by monkey patching ast classes.
< 
< Main modules are:
< 
< * nodes and scoped_nodes for more information about methods and
<   attributes added to different node classes
< 
< * the manager contains a high level object to get astng trees from
<   source files and living objects. It maintains a cache of previously
<   constructed tree for quick access
< 
< * builder contains the class responsible to build astng trees
< 
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< from __future__ import generators
< 
< __doctype__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.compat import chain, imap
< 
< # WARNING: internal imports order matters !
< 
< from clonedigger.logilab.astng._exceptions import *
< 
< 
< class InferenceContext(object):
<     __slots__ = ('startingfrom', 'path', 'lookupname', 'callcontext', 'boundnode')
<     
<     def __init__(self, node=None, path=None):
<         self.startingfrom = node # XXX useful ?
<         if path is None:
<             self.path = []
<         else:
<             self.path = path
<         self.lookupname = None
<         self.callcontext = None
<         self.boundnode = None
< 
<     def push(self, node):
<         name = self.lookupname
<         if (node, name) in self.path:
<             raise StopIteration()
<         self.path.append( (node, name) )
< 
<     def pop(self):
<         return self.path.pop()
< 
<     def clone(self):
<         # XXX copy lookupname/callcontext ?
<         clone = InferenceContext(self.startingfrom, self.path)
<         clone.callcontext = self.callcontext
<         clone.boundnode = self.boundnode
<         return clone
< 
< 
< def unpack_infer(stmt, context=None):
<     """return an iterator on nodes infered by the given statement
<     if the infered value is a list or a tuple, recurse on it to
<     get values infered by its content
<     """
<     if isinstance(stmt, (List, Tuple)):
<         # XXX loosing context
<         return chain(*imap(unpack_infer, stmt.nodes))
<     infered = stmt.infer(context).next()
<     if infered is stmt:
<         return iter( (stmt,) )
<     return chain(*imap(unpack_infer, stmt.infer(context)))
< 
< def copy_context(context):
<     if context is not None:
<         return context.clone()
<     else:
<         return InferenceContext()
<     
< def _infer_stmts(stmts, context, frame=None):
<     """return an iterator on statements infered by each statement in <stmts>
<     """
<     stmt = None
<     infered = False
<     if context is not None:
<         name = context.lookupname
<         context = context.clone()
<     else:
<         name = None
<         context = InferenceContext()
<     for stmt in stmts:
<         if stmt is YES:
<             yield stmt
<             infered = True
<             continue
<         context.lookupname = stmt._infer_name(frame, name)
<         try:
<             for infered in stmt.infer(context):
<                 yield infered
<                 infered = True
<         except UnresolvableName:
<             continue
<         except InferenceError:
<             yield YES
<             infered = True
<     if not infered:
<         raise InferenceError(str(stmt))
< 
< # special inference objects ###################################################
< 
< class Yes(object):
<     """a yes object"""
<     def __repr__(self):
<         return 'YES'
<     def __getattribute__(self, name):
<         return self
<     def __call__(self, *args, **kwargs):
<         return self
< YES = Yes()
< 
< class Proxy:
<     """a simple proxy object"""
<     def __init__(self, proxied):
<         self._proxied = proxied
< 
<     def __getattr__(self, name):
<         return getattr(self._proxied, name)
< 
<     def infer(self, context=None):
<         yield self
< 
< 
< class InstanceMethod(Proxy):
<     """a special node representing a function bound to an instance"""
<     def __repr__(self):
<         instance = self._proxied.parent.frame()
<         return 'Bound method %s of %s.%s' % (self._proxied.name,
<                                              instance.root().name,
<                                              instance.name)
<     __str__ = __repr__
< 
<     def is_bound(self):
<         return True
< 
< 
< class Instance(Proxy):
<     """a special node representing a class instance"""
<     def getattr(self, name, context=None, lookupclass=True):
<         try:
<             return self._proxied.instance_attr(name, context)
<         except NotFoundError:
<             if name == '__class__':
<                 return [self._proxied]
<             if name == '__name__':
<                 # access to __name__ gives undefined member on class
<                 # instances but not on class objects
<                 raise NotFoundError(name)
<             if lookupclass:
<                 return self._proxied.getattr(name, context)
<         raise NotFoundError(name)
< 
<     def igetattr(self, name, context=None):
<         """infered getattr"""
<         try:
<             # XXX frame should be self._proxied, or not ?
<             return _infer_stmts(
<                 self._wrap_attr(self.getattr(name, context, lookupclass=False)),
<                                 context, frame=self)
<         except NotFoundError:
<             try:
<                 # fallback to class'igetattr since it has some logic to handle
<                 # descriptors
<                 return self._wrap_attr(self._proxied.igetattr(name, context))
<             except NotFoundError:
<                 raise InferenceError(name)
<             
<     def _wrap_attr(self, attrs):
<         """wrap bound methods of attrs in a InstanceMethod proxies"""
<         # Guess which attrs are used in inference.
<         def wrap(attr):
<             if isinstance(attr, Function) and attr.type == 'method':
<                 return InstanceMethod(attr)
<             else:
<                 return attr
<         return imap(wrap, attrs)
<         
<     def infer_call_result(self, caller, context=None):
<         """infer what's a class instance is returning when called"""
<         infered = False
<         for node in self._proxied.igetattr('__call__', context):
<             for res in node.infer_call_result(caller, context):
<                 infered = True
<                 yield res
<         if not infered:
<             raise InferenceError()
< 
<     def __repr__(self):
<         return 'Instance of %s.%s' % (self._proxied.root().name,
<                                       self._proxied.name)
<     __str__ = __repr__
<     
<     def callable(self):
<         try:
<             self._proxied.getattr('__call__')
<             return True
<         except NotFoundError:
<             return False
< 
<     def pytype(self):
<         return self._proxied.qname()
<     
< class Generator(Proxy): 
<     """a special node representing a generator"""
<     def callable(self):
<         return True
<     
<     def pytype(self):
<         return '__builtin__.generator'
< 
< # imports #####################################################################
< 
< from clonedigger.logilab.astng.manager import ASTNGManager, Project, Package
< MANAGER = ASTNGManager()
< 
< from clonedigger.logilab.astng.nodes import *
< from clonedigger.logilab.astng import nodes
< from clonedigger.logilab.astng.scoped_nodes import *
< from clonedigger.logilab.astng import inference
< from clonedigger.logilab.astng import lookup
< lookup._decorate(nodes)
< 
< List._proxied = MANAGER.astng_from_class(list)
< List.__bases__ += (inference.Instance,)
< List.pytype = lambda x: '__builtin__.list'
< 
< Tuple._proxied = MANAGER.astng_from_class(tuple)
< Tuple.__bases__ += (inference.Instance,)
< Tuple.pytype = lambda x: '__builtin__.tuple'
< 
< Dict.__bases__ += (inference.Instance,)
< Dict._proxied = MANAGER.astng_from_class(dict)
< Dict.pytype = lambda x: '__builtin__.dict'
< 
< builtin_astng = Dict._proxied.root()
< 
< Const.__bases__ += (inference.Instance,)
< Const._proxied = None
< def Const___getattr__(self, name):
<     if self.value is None:
<         raise AttributeError(name)
<     if self._proxied is None:
<         self._proxied = MANAGER.astng_from_class(self.value.__class__)
<     return getattr(self._proxied, name)
< Const.__getattr__ = Const___getattr__
< def Const_getattr(self, name, context=None, lookupclass=None):
<     if self.value is None:
<         raise NotFoundError(name)
<     if self._proxied is None:
<         self._proxied = MANAGER.astng_from_class(self.value.__class__)
<     return self._proxied.getattr(name, context)
< Const.getattr = Const_getattr
< Const.has_dynamic_getattr = lambda x: False
< 
< def Const_pytype(self):
<     if self.value is None:
<         return '__builtin__.NoneType'
<     if self._proxied is None:
<         self._proxied = MANAGER.astng_from_class(self.value.__class__)
<     return self._proxied.qname()
< Const.pytype = Const_pytype
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/inspector.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/inspector.py.svn-base
1,266d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """visitor doing some postprocessing on the astng tree.
< Try to resolve definitions (namespace) dictionnary, relationship...
< 
< This module has been imported from pyreverse
< 
< 
< :version:   $Revision: 1.6 $  
< :author:    Sylvain Thenault
< :copyright: 2003-2005 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2005 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< from os.path import dirname
< 
< from clonedigger.logilab.common.modutils import get_module_part, is_relative, \
<      is_standard_module
< 
< from clonedigger.logilab import astng
< from clonedigger.logilab.astng.utils import LocalsVisitor
< 
< class IdGeneratorMixIn:
<     """
<     Mixin adding the ability to generate integer uid
<     """
<     def __init__(self, start_value=0):
<         self.id_count = start_value
<     
<     def init_counter(self, start_value=0):
<         """init the id counter
<         """
<         self.id_count = start_value
<         
<     def generate_id(self):
<         """generate a new identifer
<         """
<         self.id_count += 1
<         return self.id_count
< 
< 
< class Linker(IdGeneratorMixIn, LocalsVisitor):
<     """
<     walk on the project tree and resolve relationships.
<     
<     According to options the following attributes may be added to visited nodes:
<     
<     * uid,
<       a unique identifier for the node (on astng.Project, astng.Module,
<       astng.Class and astng.locals_type). Only if the linker has been instantiad
<       with tag=True parameter (False by default).
<             
<     * Function
<       a mapping from locals'names to their bounded value, which may be a
<       constant like a string or an integer, or an astng node (on astng.Module,
<       astng.Class and astng.Function).
< 
<     * instance_attrs_type
<       as locals_type but for klass member attributes (only on astng.Class)
<       
<     * implements,
<       list of implemented interfaces _objects_ (only on astng.Class nodes)
<     """
<     
<     def __init__(self, project, inherited_interfaces=0, tag=False):
<         IdGeneratorMixIn.__init__(self)
<         LocalsVisitor.__init__(self)
<         # take inherited interface in consideration or not
<         self.inherited_interfaces = inherited_interfaces
<         # tag nodes or not
<         self.tag = tag
<         # visited project
<         self.project = project
< 
<         
<     def visit_project(self, node):
<         """visit an astng.Project node
<         
<          * optionaly tag the node wth a unique id
<         """
<         if self.tag:
<             node.uid = self.generate_id()
<         for module in node.modules:
<             self.visit(module)
<             
<     def visit_package(self, node):
<         """visit an astng.Package node
<         
<          * optionaly tag the node wth a unique id
<         """
<         if self.tag:
<             node.uid = self.generate_id()
<         for subelmt in node.values():
<             self.visit(subelmt)
<             
<     def visit_module(self, node):
<         """visit an astng.Module node
<         
<          * set the locals_type mapping
<          * set the depends mapping
<          * optionaly tag the node wth a unique id
<         """
<         if hasattr(node, 'locals_type'):
<             return
<         node.locals_type = {}
<         node.depends = []
<         if self.tag:
<             node.uid = self.generate_id()
<     
<     def visit_class(self, node):
<         """visit an astng.Class node
<         
<          * set the locals_type and instance_attrs_type mappings
<          * set the implements list and build it
<          * optionaly tag the node wth a unique id
<         """
<         if hasattr(node, 'locals_type'):
<             return
<         node.locals_type = {}
<         if self.tag:
<             node.uid = self.generate_id()
<         # resolve ancestors
<         for baseobj in node.ancestors(recurs=False):
<             specializations = getattr(baseobj, 'specializations', [])
<             specializations.append(node)
<             baseobj.specializations = specializations
<         # resolve instance attributes
<         node.instance_attrs_type = {}
<         for assattrs in node.instance_attrs.values():
<             for assattr in assattrs:
<                 self.visit_assattr(assattr, node)
<         # resolve implemented interface
<         try:
<             node.implements = list(node.interfaces(self.inherited_interfaces))
<         except TypeError:
<             node.implements = ()
<             
<     def visit_function(self, node):
<         """visit an astng.Function node
<         
<          * set the locals_type mapping
<          * optionaly tag the node wth a unique id
<         """
<         if hasattr(node, 'locals_type'):
<             return
<         node.locals_type = {}
<         if self.tag:
<             node.uid = self.generate_id()
<             
<     link_project = visit_project
<     link_module = visit_module
<     link_class = visit_class
<     link_function = visit_function
<         
<     def visit_assname(self, node):
<         """visit an astng.AssName node
< 
<         handle locals_type
<         """
<         frame = node.frame()
<         try:
<             values = list(node.infer())
<             try:
<                 already_infered = frame.locals_type[node.name]
<                 for valnode in values:
<                     if not valnode in already_infered:
<                         already_infered.append(valnode)
<             except KeyError:
<                 frame.locals_type[node.name] = values
<         except astng.InferenceError:
<             pass
<         
<     def visit_assattr(self, node, parent):
<         """visit an astng.AssAttr node
< 
<         handle instance_attrs_type
<         """
<         try:
<             values = list(node.infer())
<             try:
<                 already_infered = parent.instance_attrs_type[node.attrname]
<                 for valnode in values:
<                     if not valnode in already_infered:
<                         already_infered.append(valnode)
<             except KeyError:
<                 parent.instance_attrs_type[node.attrname] = values
<         except astng.InferenceError:
<             pass
<             
<     def visit_import(self, node):
<         """visit an astng.Import node
<         
<         resolve module dependencies
<         """
<         context_file = node.root().file
<         for name in node.names:
<             relative = is_relative(name[0], context_file)
<             self._imported_module(node, name[0], relative)
<         
< 
<     def visit_from(self, node):
<         """visit an astng.From node
<         
<         resolve module dependencies
<         """
<         basename = node.modname
<         context_file = node.root().file
<         if context_file is not None:
<             relative = is_relative(basename, context_file)
<         else:
<             relative = False
<         for name in node.names:
<             if name[0] == '*':
<                 continue
<             # analyze dependancies
<             fullname = '%s.%s' % (basename, name[0])
<             if fullname.find('.') > -1:
<                 try:
<                     # XXX: don't use get_module_part, missing package precedence
<                     fullname = get_module_part(fullname)
<                 except ImportError:
<                     continue
<             if fullname != basename:
<                 self._imported_module(node, fullname, relative)
< 
<         
<     def compute_module(self, context_name, mod_path):
<         """return true if the module should be added to dependencies"""
<         package_dir = dirname(self.project.path)
<         if context_name == mod_path:
<             return 0
<         elif is_standard_module(mod_path, (package_dir,)):
<             return 1
<         return 0
<     
<     # protected methods ########################################################
< 
<     def _imported_module(self, node, mod_path, relative):
<         """notify an imported module, used to analyze dependancies
<         """
<         module = node.root()
<         context_name = module.name
<         if relative:
<             mod_path = '%s.%s' % ('.'.join(context_name.split('.')[:-1]),
<                                   mod_path)
<         if self.compute_module(context_name, mod_path):
<             # handle dependancies
<             if not hasattr(module, 'depends'):
<                 module.depends = []
<             mod_paths = module.depends
<             if not mod_path in mod_paths:
<                 mod_paths.append(mod_path)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/lookup.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/lookup.py.svn-base
1,224d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """name lookup methods, available on Name ans scoped (Module, Class,
< Function...) nodes:
< 
< * .lookup(name)
< * .ilookup(name)
< 
< Be careful, lookup is kinda internal and return a tuple (scope, [stmts]), while
< ilookup return an iterator on infered values
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< from __future__ import generators
< 
< __docformat__ = "restructuredtext en"
< 
< import __builtin__
< 
< from clonedigger.logilab.astng.utils import are_exclusive
< from clonedigger.logilab.astng import nodes, MANAGER, _infer_stmts, copy_context
< 
< 
< def lookup(self, name):
<     """lookup a variable name
< 
<     return the scoope node and the list of assignments associated to the given
<     name according to the scope where it has been found (locals, globals or
<     builtin)
< 
<     The lookup is starting from self's scope. If self is not a frame itself and
<     the name is found in the inner frame locals, statements will be filtered
<     to remove ignorable statements according to self's location
<     """
<     #assert ID_RGX.match(name), '%r is not a valid identifier' % name
<     return self.scope().scope_lookup(self, name)
< 
< def scope_lookup(self, node, name, offset=0):
<     try:
<         stmts = node._filter_stmts(self.locals[name], self, offset)
<     except KeyError:
<         stmts = ()
<     if stmts:
<         return self, stmts
<     if self.parent:
<         # nested scope: if parent scope is a function, that's fine
<         # else jump to the module
<         pscope = self.parent.scope()
<         if not isinstance(pscope, nodes.Function):
<             pscope = pscope.root()
<         return pscope.scope_lookup(node, name)
<     return builtin_lookup(name)
< 
< def class_scope_lookup(self, node, name, offset=0):
<     if node in self.bases:
<         #print 'frame swaping'
<         frame = self.parent.frame()
<         # line offset to avoid that class A(A) resolve the ancestor to
<         # the defined class
<         offset = -1
<     else:
<         frame = self
<     return scope_lookup(frame, node, name, offset)
< 
< def function_scope_lookup(self, node, name, offset=0):
<     if node in self.defaults:
<         frame = self.parent.frame()
<         # line offset to avoid that def func(f=func) resolve the default
<         # value to the defined function
<         offset = -1
<     else:
<         # check this is not used in function decorators
<         frame = self
<     return scope_lookup(frame, node, name, offset)
<     
< def builtin_lookup(name):
<     """lookup a name into the builtin module
<     return the list of matching statements and the astng for the builtin
<     module
<     """
<     builtinastng = MANAGER.astng_from_module(__builtin__)
<     try:
<         stmts = builtinastng.locals[name]
<     except KeyError:
<         stmts = ()
<     return builtinastng, stmts
< 
< def ilookup(self, name, context=None):
<     """infered lookup
<     
<     return an iterator on infered values of the statements returned by
<     the lookup method
<     """
<     frame, stmts = self.lookup(name)
<     context = copy_context(context)
<     context.lookupname = name
<     return _infer_stmts(stmts, context, frame)
< 
< 
< def _filter_stmts(self, stmts, frame, offset):
<     """filter statements:
< 
<     If self is not a frame itself and the name is found in the inner
<     frame locals, statements will be filtered to remove ignorable
<     statements according to self's location
<     """
<     # if offset == -1, my actual frame is not the inner frame but its parent
<     #
<     # class A(B): pass
<     #
<     # we need this to resolve B correctly
<     if offset == -1:
<         myframe = self.frame().parent.frame()
<     else:
<         myframe = self.frame()
<     if not myframe is frame or self is frame:
<         return stmts
<     #print self.name, frame.name
<     mystmt = self.statement()
<     # line filtering if we are in the same frame
<     if myframe is frame:
<         mylineno = mystmt.source_line() + offset
<     else:
<         # disabling lineno filtering
<         print 'disabling lineno filtering'
<         mylineno = 0
<     _stmts = []
<     _stmt_parents = []
<     #print '-'*60
<     #print 'filtering', stmts, mylineno
<     for node in stmts:
<         stmt = node.statement()
<         # line filtering is on and we have reached our location, break
<         if mylineno > 0 and stmt.source_line() > mylineno:
<             #print 'break', mylineno, stmt.source_line()
<             break
<         if isinstance(node, Class) and self in node.bases:
<             #print 'breaking on', self, node.bases            
<             break
<         try:
<             ass_type = node.ass_type()
<             if ass_type is mystmt:
<                 if not isinstance(ass_type, (ListCompFor,  GenExprFor)):
<                     #print 'break now2', self, ass_type
<                     break
<                 if isinstance(self, (Const, Name)):
<                     _stmts = [self]
<                     #print 'break now', ass_type, self, node
<                     break
<         except AttributeError:
<             ass_type = None
<         # a loop assigment is hidding previous assigment
<         if isinstance(ass_type, (For, ListCompFor,  GenExprFor)) and \
<                ass_type.parent_of(self):
<             _stmts = [node]
<             _stmt_parents = [stmt.parent]
<             continue
<         try:
<             pindex = _stmt_parents.index(stmt.parent)
<         except ValueError:
<             pass
<         else:
<             try:
<                 if ass_type and _stmts[pindex].ass_type().parent_of(ass_type):
<                     # print 'skipping', node, node.source_line()
<                     continue
<             except AttributeError:
<                 pass # name from Import, Function, Class...
<             if not are_exclusive(self, node):
<                 ###print 'PARENT', stmt.parent
<                 #print 'removing', _stmts[pindex]
<                 del _stmt_parents[pindex]
<                 del _stmts[pindex]
<         if isinstance(node, AssName):
<             if stmt.parent is mystmt.parent:
<                 #print 'assign clear'
<                 _stmts = []
<                 _stmt_parents = []
<             if node.flags == 'OP_DELETE':
<                 #print 'delete clear'
<                 _stmts = []
<                 _stmt_parents = []
<                 continue
<                 
<         if not are_exclusive(self, node):
<             #print 'append', node, node.source_line()
<             _stmts.append(node)
<             _stmt_parents.append(stmt.parent)
<     #print '->', _stmts
<     stmts = _stmts
<     return stmts
< 
< 
< def _decorate(astmodule):
<     """add this module functionalities to necessary nodes"""
<     for klass in (astmodule.Name, astmodule.Module, astmodule.Class,
<                   astmodule.Function, astmodule.Lambda):
<         klass.ilookup = ilookup
<         klass.lookup = lookup
<         klass._filter_stmts = _filter_stmts
<     astmodule.Class.scope_lookup = class_scope_lookup
<     astmodule.Function.scope_lookup = function_scope_lookup
<     astmodule.Lambda.scope_lookup = function_scope_lookup
<     astmodule.Module.scope_lookup = scope_lookup
<     astmodule.GenExpr.scope_lookup = scope_lookup
<     for name in ('Class', 'Function', 'Lambda',
<                  'For', 'ListCompFor', 'GenExprFor',
<                  'AssName', 'Name', 'Const'):
<         globals()[name] = getattr(astmodule, name)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/manager.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/manager.py.svn-base
1,382d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """astng manager: avoid multible astng build of a same module when
< possible by providing a class responsible to get astng representation
< from various source and using a cache of built modules)
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< import os
< from os.path import dirname, basename, abspath, join, isdir, exists
< 
< from clonedigger.logilab.common.cache import Cache
< from clonedigger.logilab.common.modutils import NoSourceFile, is_python_source, \
<      file_from_modpath, load_module_from_name, \
<      get_module_files, get_source_file
< from clonedigger.logilab.common.configuration import OptionsProviderMixIn
< 
< from clonedigger.logilab.astng import ASTNGBuildingException, Instance, nodes
< 
< def astng_wrapper(func, modname):
<     """wrapper to give to ASTNGManager.project_from_files"""
<     print 'parsing %s...' % modname
<     try:
<         return func(modname)
<     except ASTNGBuildingException, ex:
<         print ex
<     except KeyboardInterrupt:
<         raise
<     except Exception, ex:
<         import traceback
<         traceback.print_exc()
< 
< def safe_repr(obj):
<     try:
<         return repr(obj)
<     except:
<         return '???'
<     
< class ASTNGManager(OptionsProviderMixIn):
<     """the astng manager, responsible to build astng from files
<      or modules.
< 
<     Use the Borg pattern.
<     """
<     name = 'astng loader'
<     options = (("ignore",
<                 {'type' : "csv", 'metavar' : "<file>",
<                  'dest' : "black_list", "default" : ('CVS',),
<                  'help' : "add <file> (may be a directory) to the black list\
< . It should be a base name, not a path. You may set this option multiple times\
< ."}),
<                ("project",
<                 {'default': "No Name", 'type' : 'string', 'short': 'p',
<                  'metavar' : '<project name>',
<                  'help' : 'set the project name.'}),
<                )
<     brain = {}    
<     def __init__(self):
<         self.__dict__ = ASTNGManager.brain
<         if not self.__dict__:
<             OptionsProviderMixIn.__init__(self)
<             self._cache = None
<             self._mod_file_cache = None
<             self.set_cache_size(200)
<             self.load_defaults()
<             
<     def set_cache_size(self, cache_size):
<         """set the cache size (flush it as a side effect!)"""
<         self._cache = {} #Cache(cache_size)
<         self._mod_file_cache = {}
< 
<     def from_directory(self, directory, modname=None):
<         """given a module name, return the astng object"""
<         modname = modname or basename(directory)
<         directory = abspath(directory)
<         return Package(directory, modname, self)
< 
<     def astng_from_file(self, filepath, modname=None, fallback=True):
<         """given a module name, return the astng object"""
<         try:
<             filepath = get_source_file(filepath, include_no_ext=True)
<             source = True
<         except NoSourceFile:
<             source = False
<         try:
<             return self._cache[filepath]
<         except KeyError:
<             if source:
<                 try:
< 		    from clonedigger.logilab.astng.builder import ASTNGBuilder
<                     astng = ASTNGBuilder(self).file_build(filepath, modname)
<                 except SyntaxError:
<                     raise
<                 except Exception, ex:
<                     if __debug__:
<                         import traceback
<                         traceback.print_exc()
<                     msg = 'Unable to load module %s (%s)' % (modname, ex)
<                     raise ASTNGBuildingException(msg), None, sys.exc_info()[-1]
<             elif fallback and modname:
<                 return self.astng_from_module_name(modname)
<             else:
<                 raise ASTNGBuildingException('unable to get astng for file %s' %
<                                              filepath)
<         self._cache[filepath] = astng
<         return astng
<     
<     from_file = astng_from_file # backward compat
<     
<     def astng_from_module_name(self, modname, context_file=None):
<         """given a module name, return the astng object"""
<         old_cwd = os.getcwd()
<         if context_file:
<             os.chdir(dirname(context_file))
<         try:
<             filepath = self.file_from_module_name(modname, context_file)
<             if filepath is None or not is_python_source(filepath):
<                 try:
<                     module = load_module_from_name(modname) 
<                 except ImportError, ex:
<                     msg = 'Unable to load module %s (%s)' % (modname, ex)
<                     raise ASTNGBuildingException(msg)
<                 return self.astng_from_module(module, modname)
<             return self.astng_from_file(filepath, modname, fallback=False)
<         finally:
<             os.chdir(old_cwd)
<             
<     def file_from_module_name(self, modname, contextfile):
<         try:
<             value = self._mod_file_cache[(modname, contextfile)]
<         except KeyError:
<             try:
<                 value = file_from_modpath(modname.split('.'),
<                                           context_file=contextfile)
<             except ImportError, ex:
<                 msg = 'Unable to load module %s (%s)' % (modname, ex)
<                 value = ASTNGBuildingException(msg)
<             self._mod_file_cache[(modname, contextfile)] = value
<         if isinstance(value, ASTNGBuildingException):
<             raise value
<         return value
<         
<     def astng_from_module(self, module, modname=None):
<         """given an imported module, return the astng object"""
<         modname = modname or module.__name__
<         filepath = modname
<         try:
<             # some builtin modules don't have __file__ attribute
<             filepath = module.__file__
<             if is_python_source(filepath):
<                 return self.astng_from_file(filepath, modname)
<         except AttributeError:
<             pass
<         try:
<             return self._cache[filepath]
<         except KeyError:
<             from clonedigger.logilab.astng.builder import ASTNGBuilder
<             astng = ASTNGBuilder(self).module_build(module, modname)
<             # update caches (filepath and astng.file are not necessarily  the
<             # same (.pyc pb))
<             self._cache[filepath] = self._cache[astng.file] = astng
<             return astng
<             
<     def astng_from_class(self, klass, modname=None):
<         """get astng for the given class"""
<         if modname is None:
<             try:
<                 modname = klass.__module__
<             except AttributeError:
<                 raise ASTNGBuildingException(
<                     'Unable to get module for class %s' % safe_repr(klass))
<         modastng = self.astng_from_module_name(modname)
<         return modastng.getattr(klass.__name__)[0] # XXX
< 
<             
<     def infer_astng_from_something(self, obj, modname=None, context=None):
<         """infer astng for the given class"""
<         if hasattr(obj, '__class__') and not isinstance(obj, type):
<             klass = obj.__class__
<         else:
<             klass = obj
<         if modname is None:
<             try:
<                 modname = klass.__module__
<             except AttributeError:
<                 raise ASTNGBuildingException(
<                     'Unable to get module for %s' % safe_repr(klass))
<             except Exception, ex:
<                 raise ASTNGBuildingException(
<                     'Unexpected error while retreiving module for %s: %s'
<                     % (safe_repr(klass), ex))
<         try:
<             name = klass.__name__
<         except AttributeError:
<             raise ASTNGBuildingException(
<                 'Unable to get name for %s' % safe_repr(klass))
<         except Exception, ex:
<             raise ASTNGBuildingException(
<                 'Unexpected error while retreiving name for %s: %s'
<                 % (safe_repr(klass), ex))
<         # take care, on living object __module__ is regularly wrong :(
<         modastng = self.astng_from_module_name(modname)
<         for infered in modastng.igetattr(name, context):
<             if klass is not obj and isinstance(infered, nodes.Class):
<                 infered = Instance(infered)
<             yield infered
<             
<     def project_from_files(self, files, func_wrapper=astng_wrapper,
<                            project_name=None, black_list=None):
<         """return a Project from a list of files or modules"""
<         # insert current working directory to the python path to have a correct
<         # behaviour
<         sys.path.insert(0, os.getcwd())
<         try:
<             # build the project representation
<             project_name = project_name or self.config.project
<             black_list = black_list or self.config.black_list
<             project = Project(project_name)
<             for something in files:
<                 if not exists(something):
<                     fpath = file_from_modpath(something.split('.'))
<                 elif isdir(something):
<                     fpath = join(something, '__init__.py')
<                 else:
<                     fpath = something
<                 astng = func_wrapper(self.astng_from_file, fpath)
<                 if astng is None:
<                     continue
<                 project.path = project.path or astng.file
<                 project.add_module(astng)
<                 base_name = astng.name
<                 # recurse in package except if __init__ was explicitly given
<                 if astng.package and something.find('__init__') == -1:
<                     # recurse on others packages / modules if this is a package
<                     for fpath in get_module_files(dirname(astng.file),
<                                                   black_list):
<                         astng = func_wrapper(self.astng_from_file, fpath)
<                         if astng is None or astng.name == base_name:
<                             continue
<                         project.add_module(astng)
<             return project
<         finally:
<             sys.path.pop(0)
<     
< 
< 
< class Package:
<     """a package using a dictionary like interface
< 
<     load submodules lazily, as they are needed
<     """
<     
<     def __init__(self, path, name, manager):
<         self.name = name
<         self.path = abspath(path)
<         self.manager = manager
<         self.parent = None
<         self.lineno = 0
<         self.__keys = None
<         self.__subobjects = None
< 
<     def fullname(self):
<         """return the full name of the package (i.e. prefix by the full name
<         of the parent package if any
<         """
<         if self.parent is None:
<             return self.name
<         return '%s.%s' % (self.parent.fullname(), self.name)
<     
<     def get_subobject(self, name):
<         """method used to get sub-objects lazily : sub package or module are
<         only build once they are requested
<         """
<         if self.__subobjects is None:
<             try:
<                 self.__subobjects = dict.fromkeys(self.keys())
<             except AttributeError:
<                 # python <= 2.3
<                 self.__subobjects = dict([(k, None) for k in self.keys()])
<         obj = self.__subobjects[name]
<         if obj is None:
<             objpath = join(self.path, name)
<             if isdir(objpath):
<                 obj = Package(objpath, name, self.manager)
<                 obj.parent = self
<             else:
<                 modname = '%s.%s' % (self.fullname(), name)
<                 obj = self.manager.astng_from_file(objpath + '.py', modname)
<             self.__subobjects[name] = obj
<         return obj
<     
<     def get_module(self, modname):
<         """return the Module or Package object with the given name if any
<         """
<         path = modname.split('.')
<         if path[0] != self.name:
<             raise KeyError(modname)
<         obj = self
<         for part in path[1:]:
<             obj = obj.get_subobject(part)
<         return obj
<     
<     def keys(self):
<         if self.__keys is None:
<             self.__keys = []
<             for fname in os.listdir(self.path):
<                 if fname.endswith('.py'):
<                     self.__keys.append(fname[:-3])
<                     continue
<                 fpath = join(self.path, fname)
<                 if isdir(fpath) and exists(join(fpath, '__init__.py')):
<                     self.__keys.append(fname)
<             self.__keys.sort()
<         return self.__keys[:]
<     
<     def values(self):
<         return [self.get_subobject(name) for name in self.keys()]
<         
<     def items(self):
<         return zip(self.keys(), self.values())
<     
<     def has_key(self, name):
<         return bool(self.get(name))
<     
<     def get(self, name, default=None):
<         try:
<             return self.get_subobject(name)
<         except KeyError:
<             return default
<         
<     def __getitem__(self, name):
<         return self.get_subobject(name)        
<     def __contains__(self, name):
<         return self.has_key(name)
<     def __iter__(self):
<         return iter(self.keys())
<     
< 
< class Project:
<     """a project handle a set of modules / packages"""
<     def __init__(self, name=''):
<         self.name = name
<         self.path = None
<         self.modules = []
<         self.locals = {}
<         self.__getitem__ = self.locals.__getitem__
<         self.__iter__ = self.locals.__iter__
<         self.values = self.locals.values
<         self.keys = self.locals.keys
<         self.has_key = self.locals.has_key
<         
<     def add_module(self, node):
<         self.locals[node.name] = node
<         self.modules.append(node)
<         
<     def get_module(self, name):
<         return self.locals[name]
<     
<     def getChildNodes(self):
<         return self.modules
< 
<     def __repr__(self):
<         return '<Project %r at %s (%s modules)>' % (self.name, id(self),
<                                                     len(self.modules))
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/nodes.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/nodes.py.svn-base
1,816d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< on all nodes :
<  .is_statement(), returning true if the node should be considered as a
<   statement node
<  .root(), returning the root node of the tree (i.e. a Module)
<  .previous_sibling(), returning previous sibling statement node
<  .next_sibling(), returning next sibling statement node
<  .statement(), returning the first parent node marked as statement node
<  .frame(), returning the first node defining a new local scope (i.e.
<   Module, Function or Class)
<  .set_local(name, node), define an identifier <name> on the first parent frame,
<   with the node defining it. This is used by the astng builder and should not
<   be used from out there.
<  .as_string(), returning a string representation of the code (should be
<   executable).
< 
< on From and Import :
<  .real_name(name),
< 
<  [1] http://docs.python.org/lib/module-compiler.ast.html
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< # This file have been modified by Anatoly Zapadinski to meet the Clone Digger's needs
< 
< from __future__ import generators
< 
< __docformat__ = "restructuredtext en"
< 
< from compiler.ast import Assign, Add, And, AssAttr, AssList, AssName, \
<      AssTuple, Assert, Assign, AugAssign, \
<      Backquote, Bitand, Bitor, Bitxor, Break, CallFunc, Class, \
<      Compare, Const, Continue, Dict, Discard, Div, FloorDiv, \
<      Ellipsis, EmptyNode, Exec, \
<      For, From, Function, Getattr, Global, \
<      If, Import, Invert, Keyword, Lambda, LeftShift, \
<      List, ListComp, ListCompFor, ListCompIf, Mod, Module, Mul, Name, Node, \
<      Not, Or, Pass, Power, Print, Printnl, Raise, Return, RightShift, Slice, \
<      Sliceobj, Stmt, Sub, Subscript, TryExcept, TryFinally, Tuple, UnaryAdd, \
<      UnarySub, While, Yield
< try:
<     # introduced in python 2.4
<     from compiler.ast import GenExpr, GenExprFor, GenExprIf, GenExprInner
< except:
<     class GenExpr:
<         """dummy GenExpr node, shouldn't be used since py < 2.4"""
<     class GenExprFor: 
<         """dummy GenExprFor node, shouldn't be used since py < 2.4"""
<     class GenExprIf: 
<         """dummy GenExprIf node, shouldn't be used since py < 2.4"""
<     class GenExprInner: 
<         """dummy GenExprInner node, shouldn't be used since py < 2.4"""
< 
< try:
<     # introduced in python 2.4
<     from compiler.ast import Decorators
< except:
<     class Decorators:
<         """dummy Decorators node, shouldn't be used since py < 2.4"""
< 
< try:
<     # introduced in python 2.5
<     from compiler.ast import With
< except:
<     class With:
<         """dummy With node, shouldn't be used since py < 2.5"""
< 
< from clonedigger.logilab.astng._exceptions import NotFoundError, InferenceError
< from clonedigger.logilab.astng.utils import extend_class
< from clonedigger.logilab.astng import InferenceContext
< 
< import re
< ID_RGX = re.compile('^[a-zA-Z_][a-zA-Z_0-9]*$')
< del re
< 
< INFER_NEED_NAME_STMTS = (From, Import, Global, TryExcept)
< 
< # Node  ######################################################################
< 
< class NodeNG:
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<     
<     # attributes below are set by the builder module or by raw factories
<     fromlineno = None
<     tolineno = None
<     # parent node in the tree
<     parent = None
< 
<     def __str__(self):
<         return '%s(%s)' % (self.__class__.__name__, getattr(self, 'name', ''))
<     
<     def parent_of(self, node):
<         """return true if i'm a parent of the given node"""
<         parent = node.parent
<         while parent is not None:
<             if self is parent:
<                 return True
<             parent = parent.parent
<         return False
< 
<     def is_statement(self):
<         """return true if the node should be considered as statement node
<         """
<         if isinstance(self.parent, Stmt):
<             return self
<         return None
< 
<     def statement(self):
<         """return the first parent node marked as statement node
<         """
<         if self.is_statement():
<             return self
<         return self.parent.statement()
< 
<     def frame(self):
<         """return the first parent frame node (i.e. Module, Function or Class)
<         """
<         return self.parent.frame()
< 
<     def scope(self):
<         """return the first node defining a new scope (i.e. Module,
<         Function, Class, Lambda but also GenExpr)
<         """
<         return self.parent.scope()
< 
<     def root(self):
<         """return the root node of the tree, (i.e. a Module)
<         """
<         if self.parent:
<             return self.parent.root()
<         return self
< 
<     def next_sibling(self):
<         """return the previous sibling statement 
<         """
<         while not self.is_statement(): 
<             self = self.parent
<         index = self.parent.nodes.index(self)
<         try:
<             return self.parent.nodes[index+1]
<         except IndexError:
<             return
< 
<     def previous_sibling(self):
<         """return the next sibling statement 
<         """
<         while not self.is_statement(): 
<             self = self.parent
<         index = self.parent.nodes.index(self)
<         if index > 0:
<             return self.parent.nodes[index-1]
<         return
< 
<     def nearest(self, nodes):
<         """return the node which is the nearest before this one in the
<         given list of nodes
<         """
<         myroot = self.root()
<         mylineno = self.source_line()
<         nearest = None, 0
<         for node in nodes:
<             assert node.root() is myroot, \
<                    'not from the same module %s' % (self, node)
<             lineno = node.source_line()
<             if node.source_line() > mylineno:
<                 break
<             if lineno > nearest[1]:
<                 nearest = node, lineno
<         # FIXME: raise an exception if nearest is None ?
<         return nearest[0]
<     
<     def source_line(self):
<         """return the line number where the given node appears
< 
<         we need this method since not all nodes as the lineno attribute
<         correctly set...
<         """
<         line = self.lineno
<         if line is None:
<             _node = self
<             try:
<                 while line is None:
<                     _node = _node.getChildNodes()[0]
<                     line = _node.lineno
<             except IndexError:
<                 _node = self.parent
<                 while _node and line is None:
<                     line = _node.lineno
<                     _node = _node.parent
<             self.lineno = line
<         return line
<     
<     def last_source_line(self):
<         """return the last block line number for this node (i.e. including
<         children)
<         """
<         try:
<             return self.__dict__['_cached_last_source_line']
<         except KeyError:
<             line = self.source_line()
<             for node in self.getChildNodes():
<                 line = max(line, node.last_source_line())
<             self._cached_last_source_line = line
<             return line
< 
<     def block_range(self, lineno):
<         """handle block line numbers range for non block opening statements
<         """
<         return lineno, self.last_source_line()
< 
< 
<     def set_local(self, name, stmt):
<         """delegate to a scoped parent handling a locals dictionary
<         """
<         self.parent.set_local(name, stmt)
< 
<     def nodes_of_class(self, klass, skip_klass=None):
<         """return an iterator on nodes which are instance of the given class(es)
< 
<         klass may be a class object or a tuple of class objects
<         """
<         if isinstance(self, klass):
<             yield self
<         for child_node in self.getChildNodes():
<             if skip_klass is not None and isinstance(child_node, skip_klass):
<                 continue
<             for matching in child_node.nodes_of_class(klass, skip_klass):
<                 yield matching
< 
<     def _infer_name(self, frame, name):
<         if isinstance(self, INFER_NEED_NAME_STMTS) or (
<                  isinstance(self, (Function, Lambda)) and self is frame):
<             return name
<         return None
< 
<     def eq(self, value):
<         return False
<     
< extend_class(Node, NodeNG)
< 
< Const.eq = lambda self, value: self.value == value
< 
< def decorators_scope(self):
<     # skip the function node to go directly to the upper level scope
<     return self.parent.parent.scope()
< Decorators.scope = decorators_scope
< 
< # block range overrides #######################################################
< 
< def object_block_range(node, lineno):
<     """handle block line numbers range for function/class statements:
< 
<     start from the "def" or "class" position whatever the given lineno
<     """
<     return node.source_line(), node.last_source_line()
< 
< Function.block_range = object_block_range
< Class.block_range = object_block_range
< Module.block_range = object_block_range
< 
< def if_block_range(node, lineno):
<     """handle block line numbers range for if/elif statements
<     """
<     last = None
<     for test, testbody in node.tests[1:]:
<         if lineno == testbody.source_line():
<             return lineno, lineno
<         if lineno <= testbody.last_source_line():
<             return lineno, testbody.last_source_line()
<         if last is None:
<             last = testbody.source_line() - 1
<     return elsed_block_range(node, lineno, last)
< 
< If.block_range = if_block_range
< 
< def try_except_block_range(node, lineno):
<     """handle block line numbers range for try/except statements
<     """
<     last = None
<     for excls, exinst, exbody in node.handlers:
<         if excls and lineno == excls.source_line():
<             return lineno, lineno
<         if exbody.source_line() <= lineno <= exbody.last_source_line():
<             return lineno, exbody.last_source_line()
<         if last is None:
<             last = exbody.source_line() - 1
<     return elsed_block_range(node, lineno, last)
< 
< TryExcept.block_range = try_except_block_range
< 
< def elsed_block_range(node, lineno, last=None):
<     """handle block line numbers range for try/finally, for and while
<     statements
<     """
<     if lineno == node.source_line():
<         return lineno, lineno
<     if node.else_:
<         if lineno >= node.else_.source_line():
<             return lineno, node.else_.last_source_line()
<         return lineno, node.else_.source_line() - 1
<     return lineno, last or node.last_source_line()
< 
< TryFinally.block_range = elsed_block_range
< While.block_range = elsed_block_range
< For.block_range = elsed_block_range
< 
< # From and Import #############################################################
< 
< def real_name(node, asname):
<     """get name from 'as' name
<     """
<     for index in range(len(node.names)):
<         name, _asname = node.names[index]
<         if name == '*':
<             return asname
<         if not _asname:
<             name = name.split('.', 1)[0]
<             _asname = name
<         if asname == _asname:
<             return name
<     raise NotFoundError(asname)
<     
< From.real_name = real_name
< Import.real_name = real_name
< 
< def infer_name_module(node, name):
<     context = InferenceContext(node)
<     context.lookupname = name
<     return node.infer(context, asname=False)
< Import.infer_name_module = infer_name_module
< 
< # as_string ###################################################################
< 
< def add_as_string(node):
<     """return an ast.Add node as string"""
<     return '(%s) + (%s)' % (node.left.as_string(), node.right.as_string())
< Add.as_string = add_as_string
< 
< def and_as_string(node):
<     """return an ast.And node as string"""
<     return ' and '.join(['(%s)' % n.as_string() for n in node.nodes])
< And.as_string = and_as_string
<     
< def assattr_as_string(node):
<     """return an ast.AssAttr node as string"""
<     if node.flags == 'OP_DELETE':
<         return 'del %s.%s' % (node.expr.as_string(), node.attrname.as_string())
<     return '%s.%s' % (node.expr.as_string(), node.attrname.as_string())
< AssAttr.as_string = assattr_as_string
< 
< def asslist_as_string(node):
<     """return an ast.AssList node as string"""
<     string = ', '.join([n.as_string() for n in node.nodes])
<     return '[%s]' % string
< AssList.as_string = asslist_as_string
< 
< def assname_as_string(node):
<     """return an ast.AssName node as string"""
<     if node.flags == 'OP_DELETE':
<         return 'del %s' % node.name.as_string()
<     return node.name.as_string()
< AssName.as_string = assname_as_string
<     
< def asstuple_as_string(node):
<     """return an ast.AssTuple node as string"""
<     string = ', '.join([n.as_string() for n in node.nodes])
<     # fix for del statement
<     return string.replace(', del ', ', ')
< AssTuple.as_string = asstuple_as_string
< 
< def assert_as_string(node):
<     """return an ast.Assert node as string"""
<     if node.fail:
<         return 'assert %s, %s' % (node.test.as_string(), node.fail.as_string())
<     return 'assert %s' % node.test.as_string()
< Assert.as_string = assert_as_string
< 
< def assign_as_string(node):
<     """return an ast.Assign node as string"""
<     lhs = ' = '.join([n.as_string() for n in node.nodes])
<     return '%s = %s' % (lhs, node.expr.as_string())
< Assign.as_string = assign_as_string
< 
< def augassign_as_string(node):
<     """return an ast.AugAssign node as string"""
<     return '%s %s %s' % (node.node.as_string(), node.op.as_string(), node.expr.as_string())
< AugAssign.as_string = augassign_as_string
< 
< def backquote_as_string(node):
<     """return an ast.Backquote node as string"""
<     return '`%s`' % node.expr.as_string()
< Backquote.as_string = backquote_as_string
< 
< def bitand_as_string(node):
<     """return an ast.Bitand node as string"""
<     return ' & '.join(['(%s)' % n.as_string() for n in node.nodes])
< Bitand.as_string = bitand_as_string
< 
< def bitor_as_string(node):
<     """return an ast.Bitor node as string"""
<     return ' | '.join(['(%s)' % n.as_string() for n in node.nodes])
< Bitor.as_string = bitor_as_string
< 
< def bitxor_as_string(node):
<     """return an ast.Bitxor node as string"""
<     return ' ^ '.join(['(%s)' % n.as_string() for n in node.nodes])
< Bitxor.as_string = bitxor_as_string
< 
< def break_as_string(node):
<     """return an ast.Break node as string"""
<     return 'break'
< Break.as_string = break_as_string
< 
< def callfunc_as_string(node):
<     """return an ast.CallFunc node as string"""
<     expr_str = node.node.as_string()
<     args = ', '.join([arg.as_string() for arg in node.args])
<     if node.star_args:
<         args += ', *%s' % node.star_args.as_string()
<     if node.dstar_args:
<         args += ', **%s' % node.dstar_args.as_string()
<     return '%s(%s)' % (expr_str, args)
< CallFunc.as_string = callfunc_as_string
< 
< def class_as_string(node):
<     """return an ast.Class node as string"""
<     bases =  ', '.join([n.as_string() for n in node.bases])
<     bases = bases and '(%s)' % bases or ''
<     docs = node.doc and '\n    """%s"""' % node.doc or ''
<     return 'class %s%s:%s\n    %s\n' % (node.name.as_string(), bases, docs,
<                                         node.code.as_string())
< Class.as_string = class_as_string
< 
< def compare_as_string(node):
<     """return an ast.Compare node as string"""
<     rhs_str = ' '.join(['%s %s' % (op.as_string(), expr.as_string())
<                         for op, expr in node.ops])
<     return '%s %s' % (node.expr.as_string(), rhs_str)
< Compare.as_string = compare_as_string
< 
< def const_as_string(node):
<     """return an ast.Const node as string"""
<     return node.value.as_string()
< Const.as_string = const_as_string
< 
< def continue_as_string(node):
<     """return an ast.Continue node as string"""
<     return 'continue'
< Continue.as_string = continue_as_string
< 
< def dict_as_string(node):
<     """return an ast.Dict node as string"""
<     return '{%s}' % ', '.join(['%s: %s' % (key.as_string(), value.as_string())
<                                for key, value in node.items])
< Dict.as_string = dict_as_string
< 
< def discard_as_string(node):
<     """return an ast.Discard node as string"""
<     return node.expr.as_string()
< Discard.as_string = discard_as_string
< 
< def div_as_string(node):
<     """return an ast.Div node as string"""
<     return '(%s) / (%s)' % (node.left.as_string(), node.right.as_string())
< Div.as_string = div_as_string
< 
< def floordiv_as_string(node):
<     """return an ast.Div node as string"""
<     return '(%s) // (%s)' % (node.left.as_string(), node.right.as_string())
< FloorDiv.as_string = floordiv_as_string
< 
< def ellipsis_as_string(node):
<     """return an ast.Ellipsis node as string"""
<     return '...'
< Ellipsis.as_string = ellipsis_as_string
< 
< def empty_as_string(node):
<     return ''
< EmptyNode.as_string = empty_as_string
< 
< def exec_as_string(node):
<     """return an ast.Exec node as string"""
<     if node.globals:
<         return 'exec %s in %s, %s' % (node.expr.as_string(),
<                                       node.locals.as_string(),
<                                       node.globals.as_string())
<     if node.locals:
<         return 'exec %s in %s' % (node.expr.as_string(),
<                                   node.locals.as_string())
<     return 'exec %s' % node.expr.as_string()
< Exec.as_string = exec_as_string
< 
< def for_as_string(node):
<     """return an ast.For node as string"""
<     fors = 'for %s in %s:\n    %s' % (node.assign.as_string(),
<                                       node.list.as_string(),
<                                       node.body.as_string())
<     if node.else_:
<         fors = '%s\nelse:\n    %s' % (fors, node.else_.as_string())
<     return fors
< For.as_string = for_as_string
< 
< def from_as_string(node):
<     """return an ast.From node as string"""
<     return 'from %s import %s' % (node.modname, _import_string(node.names))
< From.as_string = from_as_string
< 
< def function_as_string(node):
<     """return an ast.Function node as string"""
<     fargs = node.format_args()
<     docs = node.doc and '\n    """%s"""' % node.doc or ''
<     return 'def %s(%s):%s\n    %s' % (node.name, fargs, docs,
<                                       node.code.as_string())
< Function.as_string = function_as_string
< 
< def genexpr_as_string(node):
<     """return an ast.GenExpr node as string"""
<     return '(%s)' % node.code.as_string()
< GenExpr.as_string = genexpr_as_string
< 
< def genexprinner_as_string(node):
<     """return an ast.GenExpr node as string"""
<     return '%s %s' % (node.expr.as_string(), ' '.join([n.as_string()
<                                                        for n in node.quals]))
< GenExprInner.as_string = genexprinner_as_string
< 
< def genexprfor_as_string(node):
<     """return an ast.GenExprFor node as string"""
<     return 'for %s in %s %s' % (node.assign.as_string(),
<                                 node.iter.as_string(),
<                                 ' '.join([n.as_string() for n in node.ifs]))
< GenExprFor.as_string = genexprfor_as_string
< 
< def genexprif_as_string(node):
<     """return an ast.GenExprIf node as string"""
<     return 'if %s' % node.test.as_string()
< GenExprIf.as_string = genexprif_as_string
< 
< def getattr_as_string(node):
<     """return an ast.Getattr node as string"""
<     return '%s.%s' % (node.expr.as_string(), node.attrname.as_string())
< Getattr.as_string = getattr_as_string
< 
< def global_as_string(node):
<     """return an ast.Global node as string"""
<     return 'global %s' % ', '.join([name.as_string() for name in node.names])
< Global.as_string = global_as_string
< 
< def if_as_string(node):
<     """return an ast.If node as string"""
<     cond, body = node.tests[0]
<     ifs = ['if %s:\n    %s' % (cond.as_string(), body.as_string())]
<     for cond, body in node.tests[1:]:
<         ifs.append('elif %s:\n    %s' % (cond.as_string(), body.as_string()))
<     if node.else_:
<         ifs.append('else:\n    %s' % node.else_.as_string())
<     return '\n'.join(ifs)
< If.as_string = if_as_string
< 
< def import_as_string(node):
<     """return an ast.Import node as string"""
<     return 'import %s' % _import_string(node.names)
< Import.as_string = import_as_string
< 
< def invert_as_string(node):
<     """return an ast.Invert node as string"""
<     return '~%s' % node.expr.as_string()
< Invert.as_string = invert_as_string
< 
< def keyword_as_string(node):
<     """return an ast.Keyword node as string"""
<     return '%s=%s' % (node.name.as_string(), node.expr.as_string())
< Keyword.as_string = keyword_as_string
< 
< def lambda_as_string(node):
<     """return an ast.Lambda node as string"""
<     return 'lambda %s: %s' % (node.format_args(), node.code.as_string())
< Lambda.as_string = lambda_as_string
< 
< def leftshift_as_string(node):
<     """return an ast.LeftShift node as string"""
<     return '(%s) << (%s)' % (node.left.as_string(), node.right.as_string())
< LeftShift.as_string = leftshift_as_string
< 
< def list_as_string(node):
<     """return an ast.List node as string"""
<     return '[%s]' % ', '.join([child.as_string() for child in node.nodes])
< List.as_string = list_as_string
< 
< def listcomp_as_string(node):
<     """return an ast.ListComp node as string"""
<     return '[%s %s]' % (node.expr.as_string(), ' '.join([n.as_string()
<                                                          for n in node.quals]))
< ListComp.as_string = listcomp_as_string
< 
< def listcompfor_as_string(node):
<     """return an ast.ListCompFor node as string"""
<     return 'for %s in %s %s' % (node.assign.as_string(),
<                                 node.list.as_string(),
<                                 ' '.join([n.as_string() for n in node.ifs]))
< ListCompFor.as_string = listcompfor_as_string
< 
< def listcompif_as_string(node):
<     """return an ast.ListCompIf node as string"""
<     return 'if %s' % node.test.as_string()
< ListCompIf.as_string = listcompif_as_string
< 
< def mod_as_string(node):
<     """return an ast.Mod node as string"""
<     return '(%s) %% (%s)' % (node.left.as_string(), node.right.as_string())
< Mod.as_string = mod_as_string
< 
< def module_as_string(node):
<     """return an ast.Module node as string"""
<     docs = node.doc and '"""%s"""\n' % node.doc or ''
<     return '%s%s' % (docs, node.node.as_string())
< Module.as_string = module_as_string
< 
< def mul_as_string(node):
<     """return an ast.Mul node as string"""
<     return '(%s) * (%s)' % (node.left.as_string(), node.right.as_string())
< Mul.as_string = mul_as_string
< 
< def name_as_string(node):
<     """return an ast.Name node as string"""
<     return node.name.as_string()
< Name.as_string = name_as_string
< 
< def not_as_string(node):
<     """return an ast.Not node as string"""
<     return 'not %s' % node.expr.as_string()
< Not.as_string = not_as_string
< 
< def or_as_string(node):
<     """return an ast.Or node as string"""
<     return ' or '.join(['(%s)' % n.as_string() for n in node.nodes])
< Or.as_string = or_as_string
< 
< def pass_as_string(node):
<     """return an ast.Pass node as string"""
<     return 'pass'
< Pass.as_string = pass_as_string
< 
< def power_as_string(node):
<     """return an ast.Power node as string"""
<     return '(%s) ** (%s)' % (node.left.as_string(), node.right.as_string())
< Power.as_string = power_as_string
< 
< def print_as_string(node):
<     """return an ast.Print node as string"""
<     nodes = ', '.join([n.as_string() for n in node.nodes])
<     if node.dest:
<         return 'print >> %s, %s,' % (node.dest.as_string(), nodes)
<     return 'print %s,' % nodes
< Print.as_string = print_as_string
< 
< def printnl_as_string(node):
<     """return an ast.Printnl node as string"""
<     nodes = ', '.join([n.as_string() for n in node.nodes])
<     if node.dest:
<         return 'print >> %s, %s' % (node.dest.as_string(), nodes)
<     return 'print %s' % nodes
< Printnl.as_string = printnl_as_string
< 
< def raise_as_string(node):
<     """return an ast.Raise node as string"""
<     if node.expr1:
<         if node.expr2:
<             if node.expr3:
<                 return 'raise %s, %s, %s' % (node.expr1.as_string(),
<                                              node.expr2.as_string(),
<                                              node.expr3.as_string())
<             return 'raise %s, %s' % (node.expr1.as_string(),
<                                      node.expr2.as_string())
<         return 'raise %s' % node.expr1.as_string()
<     return 'raise'
< Raise.as_string = raise_as_string
< 
< def return_as_string(node):
<     """return an ast.Return node as string"""
<     return 'return %s' % node.value.as_string()
< Return.as_string = return_as_string
< 
< def rightshift_as_string(node):
<     """return an ast.RightShift node as string"""
<     return '(%s) >> (%s)' % (node.left.as_string(), node.right.as_string())
< RightShift.as_string = rightshift_as_string
< 
< def slice_as_string(node):
<     """return an ast.Slice node as string"""
<     # FIXME: use flags
<     lower = node.lower and node.lower.as_string() or ''
<     upper = node.upper and node.upper.as_string() or ''
<     return '%s[%s:%s]' % (node.expr.as_string(), lower, upper)
< Slice.as_string = slice_as_string
< 
< def sliceobj_as_string(node):
<     """return an ast.Sliceobj node as string"""
<     return ':'.join([n.as_string() for n in node.nodes])
< Sliceobj.as_string = sliceobj_as_string
< 
< def stmt_as_string(node):
<     """return an ast.Stmt node as string"""
<     stmts = '\n'.join([n.as_string() for n in node.nodes])
<     if isinstance(node.parent, Module):
<         return stmts
<     return stmts.replace('\n', '\n    ')
< Stmt.as_string = stmt_as_string
< 
< def sub_as_string(node):
<     """return an ast.Sub node as string"""
<     return '(%s) - (%s)' % (node.left.as_string(), node.right.as_string())
< Sub.as_string = sub_as_string
< 
< def subscript_as_string(node):
<     """return an ast.Subscript node as string"""
<     # FIXME: flags ?
<     return '%s[%s]' % (node.expr.as_string(), ','.join([n.as_string()
<                                                         for n in node.subs]))
< Subscript.as_string = subscript_as_string
< 
< def tryexcept_as_string(node):
<     """return an ast.TryExcept node as string"""
<     trys = ['try:\n    %s' % node.body.as_string()]
<     for exc_type, exc_obj, body in node.handlers:
<         if exc_type:
<             if exc_obj:
<                 excs = 'except %s, %s' % (exc_type.as_string(),
<                                           exc_obj.as_string())
<             else:
<                 excs = 'except %s' % exc_type.as_string()
<         else:
<             excs = 'except'
<         trys.append('%s:\n    %s' % (excs, body.as_string()))
<     return '\n'.join(trys)
< TryExcept.as_string = tryexcept_as_string
< 
< def tryfinally_as_string(node):
<     """return an ast.TryFinally node as string"""
<     return 'try:\n    %s\nfinally:\n    %s' % (node.body.as_string(),
<                                                node.final.as_string())
< TryFinally.as_string = tryfinally_as_string
< 
< def tuple_as_string(node):
<     """return an ast.Tuple node as string"""
<     return '(%s)' % ', '.join([child.as_string() for child in node.nodes])
< Tuple.as_string = tuple_as_string
< 
< def unaryadd_as_string(node):
<     """return an ast.UnaryAdd node as string"""
<     return '+%s' % node.expr.as_string()
< UnaryAdd.as_string = unaryadd_as_string
< 
< def unarysub_as_string(node):
<     """return an ast.UnarySub node as string"""
<     return '-%s' % node.expr.as_string()
< UnarySub.as_string = unarysub_as_string
< 
< def while_as_string(node):
<     """return an ast.While node as string"""
<     whiles = 'while %s:\n    %s' % (node.test.as_string(),
<                                     node.body.as_string())
<     if node.else_:
<         whiles = '%s\nelse:\n    %s' % (whiles, node.else_.as_string())
<     return whiles
< While.as_string = while_as_string
< 
< def with_as_string(node):
<     """return an ast.With node as string"""
<     withs = 'with (%s) as (%s):\n    %s' % (node.expr.as_string(),
<                                       node.vars.as_string(),
<                                       node.body.as_string())
<     return withs
< With.as_string = with_as_string
< 
< def yield_as_string(node):
<     """yield an ast.Yield node as string"""
<     return 'yield %s' % node.value.as_string()
< Yield.as_string = yield_as_string
< 
< 
< def _import_string(names):
<     """return a list of (name, asname) formatted as a string
<     """
<     _names = []
<     for name, asname in names:
<         if asname is not None:
<             _names.append('%s as %s' % (name, asname))
<         else:
<             _names.append(name)
<     return  ', '.join(_names)
< 
< # to backport into compiler ###################################################
< 
< EmptyNode.getChildNodes = lambda self: ()
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/__pkginfo__.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/__pkginfo__.py.svn-base
1,60d0
< # pylint: disable-msg=W0622
< #
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< logilab.astng packaging information
< """
< 
< modname = 'astng'
< distname = 'logilab-astng'
< numversion = (0, 17, 2)
< version = '.'.join([str(num) for num in numversion])
< pyversions = ["2.3", "2.4", "2.5"]
< 
< license = 'GPL'
< copyright = '''Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr'''
< 
< author = 'Sylvain Thenault'
< author_email = 'sylvain.thenault@logilab.fr'
< 
< short_desc = "extend python's abstract syntax tree"
< 
< long_desc = """The aim of this module is to provide a common base \
< representation of
< python source code for projects such as pychecker, pyreverse,
< pylint... Well, actually the development of this library is essentialy
< governed by pylint's needs.
< 
< It extends class defined in the compiler.ast [1] module with some
< additional methods and attributes. Instance attributes are added by a
< builder object, which can either generate extended ast (let's call
< them astng ;) by visiting an existant ast tree or by inspecting living
< object. Methods are added by monkey patching ast classes."""
< 
< 
< web = "http://www.logilab.org/project/name/%s" % distname
< ftp = "ftp://ftp.logilab.org/pub/%s" % modname
< mailinglist = "mailto://python-projects@lists.logilab.org"
< 
< subpackage_of = 'logilab'
< 
< from os.path import join
< include_dirs = [join('test', 'regrtest_data'),
<                 join('test', 'data'), join('test', 'data2')]
< 
< debian_uploader = 'Alexandre Fayolle <afayolle@debian.org>'
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/raw_building.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/raw_building.py.svn-base
1,234d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains a set of functions to create astng trees from scratch
< (build_* functions) or from living object (object_build_* functions)
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< from inspect import getargspec
< 
< from clonedigger.logilab.astng import nodes
< 
< def attach___dict__(node):
<     """attach the __dict__ attribute to Class and Module objects"""
<     dictn = nodes.Dict([])
<     dictn.parent = node
<     node.locals['__dict__'] = [dictn]
< 
< _marker = object()
< 
< def attach_dummy_node(node, name, object=_marker):
<     """create a dummy node and register it in the locals of the given
<     node with the specified name
<     """
<     enode = nodes.EmptyNode()
<     enode.object = object
<     _attach_local_node(node, enode, name)
< 
< nodes.EmptyNode.has_underlying_object = lambda self: self.object is not _marker
< 
< def attach_const_node(node, name, value):
<     """create a Const node and register it in the locals of the given
<     node with the specified name
<     """
<     _attach_local_node(node, nodes.Const(value), name)
< 
< if sys.version_info < (2, 5):
<     def attach_import_node(node, modname, membername):
<         """create a From node and register it in the locals of the given
<         node with the specified name
<         """
<         _attach_local_node(node,
<                            nodes.From(modname, ( (membername, None), ) ),
<                            membername)
< else:
<     def attach_import_node(node, modname, membername):
<         """create a From node and register it in the locals of the given
<         node with the specified name
<         """
<         _attach_local_node(node,
<                            nodes.From(modname, ( (membername, None), ), 0),
<                            membername)
<     
< def _attach_local_node(parent, node, name):
<     node.name = name # needed by add_local_node
<     node.parent = parent
<     node.lineno = 1
<     parent.add_local_node(node)
< 
< 
< def build_module(name, doc=None):
<     """create and initialize a astng Module node"""
<     node = nodes.Module(doc, nodes.Stmt([]))
<     node.node.parent = node
<     node.name = name
<     node.pure_python = False
<     node.package = False
<     node.parent = None
<     node.globals = node.locals = {}
<     return node
< 
< def build_class(name, basenames=None, doc=None):
<     """create and initialize a astng Class node"""
<     klass = nodes.Class(name, [], doc, nodes.Stmt([]))
<     bases = [nodes.Name(base) for base in basenames]
<     for base in bases:
<         base.parent = klass
<     klass.basenames = basenames
<     klass.bases = bases
<     klass.code.parent = klass
<     klass.locals = {}
<     klass.instance_attrs = {}
<     for name, value in ( ('__name__', name),
<                          #('__module__', node.root().name),
<                          ):
<         const = nodes.Const(value)
<         const.parent = klass
<         klass.locals[name] = [const]
<     return klass
< 
< # introduction of decorators has changed the Function initializer arguments
< if sys.version_info >= (2, 4):
<     try:
<         from compiler.ast import Decorators as BaseDecorators
<         class Decorators(BaseDecorators):
<             def __init__(self):
<                 BaseDecorators.__init__(self, [], 0)
<     except ImportError:
<         Decorators = list
<         
<     def build_function(name, args=None, defaults=None, flag=0, doc=None):
<         """create and initialize a astng Function node"""
<         args, defaults = args or [], defaults or []
<         # first argument is now a list of decorators
<         func = nodes.Function(Decorators(), name, args, defaults, flag, doc,
<                               nodes.Stmt([]))
<         func.code.parent = func
<         func.locals = {}
<         if args:
<             register_arguments(func, args)
<         return func
<     
< else:    
<     def build_function(name, args=None, defaults=None, flag=0, doc=None):
<         """create and initialize a astng Function node"""
<         args, defaults = args or [], defaults or []
<         func = nodes.Function(name, args, defaults, flag, doc, nodes.Stmt([]))
<         func.code.parent = func
<         func.locals = {}
<         if args:
<             register_arguments(func, args)
<         return func
< 
< 
< def build_name_assign(name, value):
<     """create and initialize an astng Assign for a name assignment"""
<     return nodes.Assign([nodes.AssName(name, 'OP_ASSIGN')], nodes.Const(value))
< 
< def build_attr_assign(name, value, attr='self'):
<     """create and initialize an astng Assign for an attribute assignment"""
<     return nodes.Assign([nodes.AssAttr(nodes.Name(attr), name, 'OP_ASSIGN')],
<                         nodes.Const(value))
< 
< if sys.version_info < (2, 5):
<     def build_from_import(fromname, names):
<         """create and intialize an astng From import statement"""
<         return nodes.From(fromname, [(name, None) for name in names])
< else:
<     def build_from_import(fromname, names):
<         """create and intialize an astng From import statement"""
<         return nodes.From(fromname, [(name, None) for name in names], 0)
< 
< def register_arguments(node, args):
<     """add given arguments to local
<     
<     args is a list that may contains nested lists
<     (i.e. def func(a, (b, c, d)): ...)
<     """
<     for arg in args:
<         if type(arg) is type(''):
<             node.set_local(arg, node)
<         else:
<             register_arguments(node, arg)
< 
< 
< def object_build_class(node, member):
<     """create astng for a living class object"""
<     basenames = [base.__name__ for base in member.__bases__]
<     return _base_class_object_build(node, member, basenames)
< 
< def object_build_function(node, member):
<     """create astng for a living function object"""
<     args, varargs, varkw, defaults = getargspec(member)
<     if varargs is not None:
<         args.append(varargs)
<     if varkw is not None:
<         args.append(varkw)
<     func = build_function(member.__name__, args, defaults,
<                           member.func_code.co_flags, member.__doc__)
<     node.add_local_node(func)
< 
< def object_build_datadescriptor(node, member, name):
<     """create astng for a living data descriptor object"""
<     return _base_class_object_build(node, member, [], name)
< 
< def object_build_methoddescriptor(node, member):
<     """create astng for a living method descriptor object"""
<     # FIXME get arguments ?
<     func = build_function(member.__name__, doc=member.__doc__)
<     # set argnames to None to notice that we have no information, not
<     # and empty argument list
<     func.argnames = None 
<     node.add_local_node(func)
< 
< def _base_class_object_build(node, member, basenames, name=None):
<     """create astng for a living class object, with a given set of base names
<     (e.g. ancestors)
<     """
<     klass = build_class(name or member.__name__, basenames, member.__doc__)
<     klass._newstyle = isinstance(member, type)
<     node.add_local_node(klass)
<     try:
<         # limit the instantiation trick since it's too dangerous
<         # (such as infinite test execution...)
<         # this at least resolves common case such as Exception.args,
<         # OSError.errno
<         if issubclass(member, Exception):
<             instdict = member().__dict__
<         else:
<             raise TypeError
<     except:
<         pass
<     else:
<         for name, obj in instdict.items():
<             valnode = nodes.EmptyNode()
<             valnode.object = obj
<             valnode.parent = klass
<             valnode.lineno = 1
<             klass.instance_attrs[name] = [valnode]
<     return klass
< 
< 
< __all__ = ('register_arguments',  'build_module', 
<            'object_build_class', 'object_build_function', 
<            'object_build_datadescriptor', 'object_build_methoddescriptor',
<            'attach___dict__', 'attach_dummy_node',
<            'attach_const_node', 'attach_import_node')
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/scoped_nodes.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/scoped_nodes.py.svn-base
1,709d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """This module extends ast "scoped" node, i.e. which are opening a new
< local scope in the language definition : Module, Class, Function (and
< Lambda in some extends).
< 
< Each new methods and attributes added on each class are documented
< below.
< 
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< from __future__ import generators
< 
< __doctype__ = "restructuredtext en"
< 
< import sys
< 
< from clonedigger.logilab.common.compat import chain, set
< 
< from clonedigger.logilab.astng.utils import extend_class
< from clonedigger.logilab.astng import YES, MANAGER, Instance, InferenceContext, copy_context, \
<      unpack_infer, _infer_stmts, \
<      Class, Const, Dict, Function, GenExpr, Lambda, \
<      Module, Name, Pass, Raise, Tuple, Yield
< from clonedigger.logilab.astng import NotFoundError, NoDefault, \
<      ASTNGBuildingException, InferenceError
< 
< # module class dict/iterator interface ########################################
<     
< class LocalsDictMixIn(object):
<     """ this class provides locals handling common to Module, Function
<     and Class nodes, including a dict like interface for direct access
<     to locals information
<     
<     /!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<     
<     # attributes below are set by the builder module or by raw factories
<     
<     # dictionary of locals with name as key and node defining the local as
<     # value    
<     locals = None
< 
<     def qname(self):
<         """return the 'qualified' name of the node, eg module.name,
<         module.class.name ...
<         """
<         if self.parent is None:
<             return self.name
<         return '%s.%s' % (self.parent.frame().qname(), self.name)
<         
<     def frame(self):
<         """return the first parent frame node (i.e. Module, Function or Class)
<         """
<         return self
<     
<     def scope(self):
<         """return the first node defining a new scope (i.e. Module,
<         Function, Class, Lambda but also GenExpr)
<         """
<         return self
<     
<     def set_local(self, name, stmt):
<         """define <name> in locals (<stmt> is the node defining the name)
<         if the node is a Module node (i.e. has globals), add the name to
<         globals
< 
<         if the name is already defined, ignore it
<         """
<         self.locals.setdefault(name, []).append(stmt)
<         
<     __setitem__ = set_local
<     
<     def add_local_node(self, child_node, name=None):
<         """append a child which should alter locals to the given node"""
<         if name != '__class__':
<             # add __class__ node as a child will cause infinite recursion later!
<             self._append_node(child_node)
<         self.set_local(name or child_node.name, child_node)
< 
<     def _append_node(self, child_node):
<         """append a child, linking it in the tree"""
<         self.code.nodes.append(child_node)
<         child_node.parent = self
<     
<     def __getitem__(self, item):
<         """method from the `dict` interface returning the first node
<         associated with the given name in the locals dictionnary
< 
<         :type item: str
<         :param item: the name of the locally defined object
<         :raises KeyError: if the name is not defined
<         """
<         return self.locals[item][0]
<     
<     def __iter__(self):
<         """method from the `dict` interface returning an iterator on
<         `self.keys()`
<         """
<         return iter(self.keys())
<     
<     def keys(self):
<         """method from the `dict` interface returning a tuple containing
<         locally defined names
<         """
<         return self.locals.keys()
< ##         associated to nodes which are instance of `Function` or
< ##         `Class`
< ##         """
< ##         # FIXME: sort keys according to line number ?
< ##         try:
< ##             return self.__keys
< ##         except AttributeError:
< ##             keys = [member.name for member in self.locals.values()
< ##                     if (isinstance(member, Function)
< ##                         or isinstance(member, Class))
< ##                         and member.parent.frame() is self]
< ##             self.__keys = tuple(keys)
< ##             return keys
< 
<     def values(self):
<         """method from the `dict` interface returning a tuple containing
<         locally defined nodes which are instance of `Function` or `Class`
<         """
<         return [self[key] for key in self.keys()]
<     
<     def items(self):
<         """method from the `dict` interface returning a list of tuple
<         containing each locally defined name with its associated node,
<         which is an instance of `Function` or `Class`
<         """
<         return zip(self.keys(), self.values())
< 
<     def has_key(self, name):
<         """method from the `dict` interface returning True if the given
<         name is defined in the locals dictionary
<         """
<         return self.locals.has_key(name)
<     
<     __contains__ = has_key
<     
< extend_class(Module, LocalsDictMixIn)
< extend_class(Class, LocalsDictMixIn)
< extend_class(Function, LocalsDictMixIn)
< extend_class(Lambda, LocalsDictMixIn)
< # GenExpr has it's own locals but isn't a frame
< extend_class(GenExpr, LocalsDictMixIn)
< def frame(self):
<     return self.parent.frame()
< GenExpr.frame = frame
< 
< 
< class GetattrMixIn(object):
<     def getattr(self, name, context=None):
<         try:
<             return self.locals[name]
<         except KeyError:
<             raise NotFoundError(name)
<         
<     def igetattr(self, name, context=None):
<         """infered getattr"""
<         # set lookup name since this is necessary to infer on import nodes for
<         # instance
<         context = copy_context(context)
<         context.lookupname = name
<         try:
<             return _infer_stmts(self.getattr(name, context), context, frame=self)
<         except NotFoundError:
<             raise InferenceError(name)
< extend_class(Module, GetattrMixIn)
< extend_class(Class, GetattrMixIn)
< 
< # Module  #####################################################################
< 
< class ModuleNG(object):
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<         
<     # attributes below are set by the builder module or by raw factories
< 
<     # the file from which as been extracted the astng representation. It may
<     # be None if the representation has been built from a built-in module
<     file = None
<     # the module name
<     name = None
<     # boolean for astng built from source (i.e. ast)
<     pure_python = None
<     # boolean for package module
<     package = None
<     # dictionary of globals with name as key and node defining the global
<     # as value
<     globals = None
< 
<     def pytype(self):
<         return '__builtin__.module'
<     
<     def getattr(self, name, context=None):
<         try:
<             return self.locals[name]
<         except KeyError:
<             if self.package:
<                 try:
<                     return [self.import_module(name, relative_only=True)]
<                 except KeyboardInterrupt:
<                     raise
<                 except:
<                     pass
<             raise NotFoundError(name)
<         
<     def _append_node(self, child_node):
<         """append a child version specific to Module node"""
<         self.node.nodes.append(child_node)
<         child_node.parent = self
<         
<     def source_line(self):
<         """return the source line number, 0 on a module"""
<         return 0
< 
<     def fully_defined(self):
<         """return True if this module has been built from a .py file
<         and so contains a complete representation including the code
<         """
<         return self.file is not None and self.file.endswith('.py')
<     
<     def statement(self):
<         """return the first parent node marked as statement node
<         consider a module as a statement...
<         """
<         return self
< 
<     def import_module(self, modname, relative_only=False):
<         """import the given module considering self as context"""
<         try:
<             return MANAGER.astng_from_module_name(self.relative_name(modname))
<         except ASTNGBuildingException:
<             if relative_only:
<                 raise
<         module = MANAGER.astng_from_module_name(modname)
<         return module
< 
<     def relative_name(self, modname):
<         if self.package:
<             return '%s.%s' % (self.name, modname)
<         package_name = '.'.join(self.name.split('.')[:-1])
<         if package_name:
<             return '%s.%s' % (package_name, modname)
<         return modname
<         
<     def wildcard_import_names(self):
<         """return the list of imported names when this module is 'wildard
<         imported'
< 
<         It doesn't include the '__builtins__' name which is added by the
<         current CPython implementation of wildcard imports.
<         """
<         # take advantage of a living module if it exists
<         try:
<             living = sys.modules[self.name]
<         except KeyError:
<             pass
<         else:
<             try:
<                 return living.__all__
<             except AttributeError:
<                 return [name for name in living.__dict__.keys()
<                         if not name.startswith('_')]
<         # else lookup the astng
<         try:
<             explicit = self['__all__'].assigned_stmts().next()
<             # should be a tuple of constant string
<             return [const.value for const in explicit.nodes]
<         except (KeyError, AttributeError, InferenceError):
<             # XXX should admit we have lost if there is something like
<             # __all__ that we've not been able to analyse (such as
<             # dynamically constructed __all__)
<             return [name for name in self.keys()
<                     if not name.startswith('_')]
< 
< extend_class(Module, ModuleNG)
< 
< # Function  ###################################################################
< 
< class FunctionNG(object):
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
< 
<     # attributes below are set by the builder module or by raw factories
< 
<     # function's type, 'function' | 'method' | 'staticmethod' | 'classmethod'
<     type = 'function'
<     # list of argument names. MAY BE NONE on some builtin functions where
<     # arguments are unknown
<     argnames = None
< 
<     def pytype(self):
<         if 'method' in self.type:
<             return '__builtin__.instancemethod'
<         return '__builtin__.function'
< 
<     def is_method(self):
<         """return true if the function node should be considered as a method"""
<         return self.type != 'function'
<     
<     def is_bound(self):
<         """return true if the function is bound to an Instance or a class"""
<         return self.type == 'classmethod'
< 
<     def is_abstract(self, pass_is_abstract=True):
<         """return true if the method is abstract
<         It's considered as abstract if the only statement is a raise of
<         NotImplementError, or, if pass_is_abstract, a pass statement
<         """
<         for child_node in self.code.getChildNodes():
<             if isinstance(child_node, Raise) and child_node.expr1:
<                 try:
<                     name = child_node.expr1.nodes_of_class(Name).next()
<                     if name.name == 'NotImplementedError':
<                         return True
<                 except StopIteration:
<                     pass
<             if pass_is_abstract and isinstance(child_node, Pass):
<                 return True
<             return False
<         # empty function is the same as function with a single "pass" statement
<         if pass_is_abstract:
<             return True
< 
<     def is_generator(self):
<         """return true if this is a generator function"""
<         try:
<             return self.nodes_of_class(Yield, skip_klass=Function).next()
<         except StopIteration:
<             return False
<         
<     def format_args(self):
<         """return arguments formatted as string"""
<         if self.argnames is None: # information is missing
<             return ''
<         result = []
<         args, kwargs, last, default_idx = self._pos_information()
<         for i in range(len(self.argnames)):
<             name = self.argnames[i]
<             if type(name) is type(()):
<                 name = '(%s)' % ','.join([n.as_string() for n in name])
<             if i == last and kwargs:
<                 name = '**%s' % name.as_string()
<             elif args and i == last or (kwargs and i == last - 1):
<                 name = '*%s' % name.as_string()
<             elif i >= default_idx:
<                 default_str = self.defaults[i - default_idx].as_string()
<                 name = '%s=%s' % (name.as_string(), default_str)
< 	    else:
< 		name = name.as_string()
<             result.append(name)
<         return ', '.join(result)
< 
<     def default_value(self, argname):
<         """return the default value for an argument
< 
<         :raise `NoDefault`: if there is no default value defined
<         """
<         if self.argnames is None: # information is missing
<             raise NoDefault()
<         args, kwargs, last, defaultidx = self._pos_information()
<         try:
<             i = self.argnames.index(argname)
<         except ValueError:
<             raise NoDefault() # XXX
<         if i >= defaultidx and (i - defaultidx) < len(self.defaults):
<             return self.defaults[i - defaultidx]
<         raise NoDefault()
< 
<     def mularg_class(self, argname):
<         """if the given argument is a * or ** argument, return respectivly
<         a Tuple or Dict instance, else return None
<         """
<         args, kwargs, last, defaultidx = self._pos_information()
<         try:
<             i = self.argnames.index(argname)
<         except ValueError:
<             return None # XXX
<         if i == last and kwargs:
<             valnode = Dict([])
<             valnode.parent = self
<             return valnode
<         if args and (i == last or (kwargs and i == last - 1)):
<             valnode = Tuple([])
<             valnode.parent = self
<             return valnode
<         return None
< 
<     def _pos_information(self):
<         """return a 4-uple with positional information about arguments:
<         (true if * is used,
<          true if ** is used,
<          index of the last argument,
<          index of the first argument having a default value)
<         """
<         args = self.flags & 4
<         kwargs = self.flags & 8
<         last = len(self.argnames) - 1
<         defaultidx = len(self.argnames) - (len(self.defaults) +
<                                            (args and 1 or 0) +
<                                            (kwargs and 1 or 0))
<         return args, kwargs, last, defaultidx
< 
< extend_class(Function, FunctionNG)
< 
< # lambda nodes may also need some of the function members
< Lambda._pos_information = FunctionNG._pos_information.im_func
< Lambda.format_args = FunctionNG.format_args.im_func
< Lambda.default_value = FunctionNG.default_value.im_func
< Lambda.mularg_class = FunctionNG.mularg_class.im_func
< Lambda.type = 'function'
< Lambda.pytype = FunctionNG.pytype.im_func
< 
< # Class ######################################################################
< 
< def _class_type(klass):
<     """return a Class node type to differ metaclass, interface and exception
<     from 'regular' classes
<     """
<     if klass._type is not None:
<         return klass._type
<     if klass.name == 'type':
<         klass._type = 'metaclass'
<     elif klass.name.endswith('Interface'):
<         klass._type = 'interface'
<     elif klass.name.endswith('Exception'):
<         klass._type = 'exception'
<     else:
<         for base in klass.ancestors(recurs=False):
<             if base.type != 'class':
<                 klass._type = base.type
<                 break
<     if klass._type is None:
<         klass._type = 'class'
<     return klass._type
< 
< def _iface_hdlr(iface_node):
<     """a handler function used by interfaces to handle suspicious
<     interface nodes
<     """
<     return True
< 
< class ClassNG(object):
<     """/!\ this class should not be used directly /!\ it's
<     only used as a methods and attribute container, and update the
<     original class from the compiler.ast module using its dictionnary
<     (see below the class definition)
<     """
<     
<     _type = None
<     type = property(_class_type,
<                     doc="class'type, possible values are 'class' | "
<                     "'metaclass' | 'interface' | 'exception'")
<     
<     def _newstyle_impl(self, context=None):
<         context = context or InferenceContext()
<         if self._newstyle is not None:
<             return self._newstyle
<         for base in self.ancestors(recurs=False, context=context):
<             if base._newstyle_impl(context):
<                 self._newstyle = True
<                 break
<         if self._newstyle is None:
<             self._newstyle = False
<         return self._newstyle
< 
<     _newstyle = None
<     newstyle = property(_newstyle_impl,
<                         doc="boolean indicating if it's a new style class"
<                         "or not")
< 
<     def pytype(self):
<         if self.newstyle:
<             return '__builtin__.type'
<         return '__builtin__.classobj'
<     
<     # attributes below are set by the builder module or by raw factories
<     
<     # a dictionary of class instances attributes
<     instance_attrs = None
<     # list of parent class as a list of string (ie names as they appears
<     # in the class definition)
<     basenames = None
< 
<     def ancestors(self, recurs=True, context=None):
<         """return an iterator on the node base classes in a prefixed
<         depth first order
<         
<         :param recurs:
<           boolean indicating if it should recurse or return direct
<           ancestors only
<         """
<         # FIXME: should be possible to choose the resolution order
<         # XXX inference make infinite loops possible here (see BaseTransformer
<         # manipulation in the builder module for instance !)
<         context = context or InferenceContext()
<         for stmt in self.bases:
<             try:
<                 for baseobj in stmt.infer(context):
<                     if not isinstance(baseobj, Class):
<                         # duh ?
<                         continue
<                     if baseobj is self:
<                         continue # cf xxx above
<                     yield baseobj
<                     if recurs:
<                         for grandpa in baseobj.ancestors(True, context):
<                             if grandpa is self:
<                                 continue # cf xxx above
<                             yield grandpa
<             except InferenceError:
<                 #import traceback
<                 #traceback.print_exc()
<                 # XXX log error ?
<                 continue
<             
<     def local_attr_ancestors(self, name, context=None):
<         """return an iterator on astng representation of parent classes
<         which have <name> defined in their locals
<         """
<         for astng in self.ancestors(context=context):
<             if astng.locals.has_key(name):
<                 yield astng
< 
<     def instance_attr_ancestors(self, name, context=None):
<         """return an iterator on astng representation of parent classes
<         which have <name> defined in their instance attribute dictionary
<         """
<         for astng in self.ancestors(context=context):
<             if astng.instance_attrs.has_key(name):
<                 yield astng
< 
<     def local_attr(self, name, context=None):
<         """return the astng associated to name in this class locals or
<         in its parents
< 
<         :raises `NotFoundError`:
<           if no attribute with this name has been find in this class or
<           its parent classes
<         """
<         try:
<             return self[name]
<         except KeyError:
<             # get if from the first parent implementing it if any
<             for class_node in self.local_attr_ancestors(name, context):
<                 return class_node[name]
<         raise NotFoundError(name)
<         
<     def instance_attr(self, name, context=None):
<         """return the astng nodes associated to name in this class instance
<         attributes dictionary or in its parents
< 
<         :raises `NotFoundError`:
<           if no attribute with this name has been find in this class or
<           its parent classes
<         """
<         try:
<             return self.instance_attrs[name]
<         except KeyError:
<             # get if from the first parent implementing it if any
<             for class_node in self.instance_attr_ancestors(name, context):
<                 return class_node.instance_attrs[name]
<         raise NotFoundError(name)
< 
<     def getattr(self, name, context=None):
<         """this method doesn't look in the instance_attrs dictionary since it's
<         done by an Instance proxy at inference time.
<         
<         It may return a YES object if the attribute has not been actually
<         found but a __getattr__ or __getattribute__ method is defined
<         """
<         if name in self.locals:
<             return self.locals[name]
<         if name == '__bases__':
<             return tuple(self.ancestors(recurs=False))
<         # XXX need proper meta class handling + MRO implementation
<         if name == '__mro__':
<             return tuple(self.ancestors(recurs=True))
<         for classnode in self.ancestors(recurs=False, context=context):
<             try:
<                 return classnode.getattr(name, context)
<             except NotFoundError:
<                 continue
<         raise NotFoundError(name)
< 
<     def igetattr(self, name, context=None):
<         """infered getattr, need special treatment in class to handle
<         descriptors
<         """
<         # set lookoup name since this is necessary to infer on import nodes for
<         # instance
<         context = copy_context(context)
<         context.lookupname = name
<         try:
<             for infered in _infer_stmts(self.getattr(name, context), context,
<                                         frame=self):
<                 # yield YES object instead of descriptors when necessary
<                 if not isinstance(infered, Const) and isinstance(infered, Instance):
<                     try:
<                         infered._proxied.getattr('__get__', context)
<                     except NotFoundError:
<                         yield infered
<                     else:
<                         yield YES
<                 else:
<                     yield infered
<         except NotFoundError:
<             if not name.startswith('__') and self.has_dynamic_getattr(context):
<                 # class handle some dynamic attributes, return a YES object
<                 yield YES
<             else:
<                 raise InferenceError(name)
<         
<     def has_dynamic_getattr(self, context=None):
<         """return True if the class has a custom __getattr__ or
<         __getattribute__ method
<         """
<         # need to explicitly handle optparse.Values (setattr is not detected)
<         if self.name == 'Values' and self.root().name == 'optparse':
<             return True
<         try:
<             self.getattr('__getattr__', context)
<             return True
<         except NotFoundError:
<             #if self.newstyle: XXX cause an infinite recursion error
<             try:
<                 getattribute = self.getattr('__getattribute__', context)[0]
<                 if getattribute.root().name != '__builtin__':
<                     # class has a custom __getattribute__ defined
<                     return True
<             except NotFoundError:
<                 pass
<         return False
<     
<     def methods(self):
<         """return an iterator on all methods defined in the class and
<         its ancestors
<         """
<         done = {}
<         for astng in chain(iter((self,)), self.ancestors()):
<             for meth in astng.mymethods():
<                 if done.has_key(meth.name):
<                     continue
<                 done[meth.name] = None
<                 yield meth
<                 
<     def mymethods(self):
<         """return an iterator on all methods defined in the class"""
<         for member in self.values():
<             if isinstance(member, Function):
<                 yield member
<                 
<     def interfaces(self, herited=True, handler_func=_iface_hdlr):
<         """return an iterator on interfaces implemented by the given
<         class node
<         """
<         # FIXME: what if __implements__ = (MyIFace, MyParent.__implements__)...
<         try:
<             implements = Instance(self).getattr('__implements__')[0]
<         except NotFoundError:
<             return
<         if not herited and not implements.frame() is self:
<             return
<         oneinf = False
<         for iface in unpack_infer(implements):
<             if iface is YES:
<                 continue
<             if handler_func(iface):
<                 oneinf = True
<                 yield iface
<         if not oneinf:
<             raise InferenceError()
< ##         if hasattr(implements, 'nodes'):
< ##             implements = implements.nodes
< ##         else:
< ##             implements = (implements,)
< ##         for iface in implements:
< ##             # let the handler function take care of this....
< ##             for iface in handler_func(iface):
< ##                 yield iface
< 
< extend_class(Class, ClassNG)
diff -r -N code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/utils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/astng/.svn/text-base/utils.py.svn-base
1,173d0
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains some utilities to navigate in the tree or to
< extract information from it
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.compat import enumerate
< from clonedigger.logilab.astng._exceptions import IgnoreChild
< 
< def extend_class(original, addons):
<     """add methods and attribute defined in the addons class to the original
<     class
<     """
<     brain = addons.__dict__.copy()
<     for special_key in ('__doc__', '__module__'):
<         if special_key in addons.__dict__:
<             del brain[special_key]
<     original.__dict__.update(brain)
<         
< class ASTWalker:
<     """a walker visiting a tree in preorder, calling on the handler:
<     
<     * visit_<class name> on entering a node, where class name is the class of
<     the node in lower case
<     
<     * leave_<class name> on leaving a node, where class name is the class of
<     the node in lower case
<     """
<     def __init__(self, handler):
<         self.handler = handler
<         self._cache = {}
<         
<     def walk(self, node):
<         """walk on the tree from <node>, getting callbacks from handler
<         """
<         try:            
<             self.visit(node)
<         except IgnoreChild:
<             pass
<         else:
<             for child_node in node.getChildNodes():
<                 self.walk(child_node)
<         self.leave(node)
< 
<     def get_callbacks(self, node):
<         """get callbacks from handler for the visited node
<         """
<         klass = node.__class__
<         methods = self._cache.get(klass)
<         if methods is None:
<             handler = self.handler
<             kid = klass.__name__.lower()
<             e_method = getattr(handler, 'visit_%s' % kid,
<                                getattr(handler, 'visit_default', None))
<             l_method = getattr(handler, 'leave_%s' % kid, 
<                                getattr(handler, 'leave_default', None))
<             self._cache[klass] = (e_method, l_method)
<         else:
<             e_method, l_method = methods
<         return e_method, l_method
<     
<     def visit(self, node):
<         """walk on the tree from <node>, getting callbacks from handler"""
<         method = self.get_callbacks(node)[0]
<         if method is not None:
<             method(node)
<             
<     def leave(self, node):
<         """walk on the tree from <node>, getting callbacks from handler"""
<         method = self.get_callbacks(node)[1]
<         if method is not None:
<             method(node)
< 
< 
< class LocalsVisitor(ASTWalker):
<     """visit a project by traversing the locals dictionnary"""
<     def __init__(self):
<         ASTWalker.__init__(self, self)
<         self._visited = {}
<         
<     def visit(self, node):
<         """launch the visit starting from the given node"""
<         if self._visited.has_key(node):
<             return
<         self._visited[node] = 1
<         methods = self.get_callbacks(node)
<         recurse = 1
<         if methods[0] is not None:
<             try:
<                 methods[0](node)
<             except IgnoreChild:
<                 recurse = 0
<         if recurse:
<             if hasattr(node, 'locals'):
<                 for local_node in node.values():
<                     self.visit(local_node)
<         if methods[1] is not None:
<             return methods[1](node)
< 
< def are_exclusive(stmt1, stmt2):
<     """return true if the two given statement are mutually exclusive
< 
<     algorithm :
<      1) index stmt1's parents
<      2) climb among stmt2's parents until we find a common parent
<      3) if the common parent is a If or TryExcept statement, look if nodes are
<         in exclusive branchs
<     """
<     from clonedigger.logilab.astng.nodes import If, TryExcept
<     # index stmt1's parents
<     stmt1_parents = {}
<     children = {}
<     node = stmt1.parent
<     previous = stmt1
<     while node:
<         stmt1_parents[node] = 1
<         children[node] = previous
<         previous = node
<         node = node.parent
<     # climb among stmt2's parents until we find a common parent
<     node = stmt2.parent
<     previous = stmt2
<     while node:
<         if stmt1_parents.has_key(node):
<             # if the common parent is a If or TryExcept statement, look if
<             # nodes are in exclusive branchs
<             if isinstance(node, If):
<                 if previous != children[node]:
<                     return True
<             elif isinstance(node, TryExcept):
<                 stmt1_previous = children[node]
<                 if not previous is stmt1_previous:
<                     stmt1_branch, stmt1_num = _try_except_from_branch(node, stmt1_previous)
<                     stmt2_branch, stmt2_num = _try_except_from_branch(node, previous)
<                     if stmt1_branch != stmt1_branch:
<                         if not ((stmt2_branch == 'body' and stmt1_branch == 'else') or
<                                 (stmt1_branch == 'body' and stmt2_branch == 'else') or
<                                 (stmt2_branch == 'body' and stmt1_branch == 'except') or
<                                 (stmt1_branch == 'body' and stmt2_branch == 'except')):
<                             return True
<                     elif stmt1_num != stmt2_num:
<                         return True
<             return False
<         previous = node
<         node = node.parent
<     return False
< 
< def _try_except_from_branch(node, stmt):
<     if stmt is node.body:
<         return 'body', 1
<     if stmt is node.else_:
<         return 'else', 1
<     for i, block_nodes in enumerate(node.handlers):
<         if stmt in block_nodes:
<             return 'except', i
diff -r -N code-worker/tasks/clonedigger/logilab/astng/utils.py code-worker/code-worker/tasks/clonedigger/logilab/astng/utils.py
1,173d0
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains some utilities to navigate in the tree or to
< extract information from it
< 
< :author:    Sylvain Thenault
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< :copyright: 2003-2007 Sylvain Thenault
< :contact:   mailto:thenault@gmail.com
< """
< 
< __docformat__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.compat import enumerate
< from clonedigger.logilab.astng._exceptions import IgnoreChild
< 
< def extend_class(original, addons):
<     """add methods and attribute defined in the addons class to the original
<     class
<     """
<     brain = addons.__dict__.copy()
<     for special_key in ('__doc__', '__module__'):
<         if special_key in addons.__dict__:
<             del brain[special_key]
<     original.__dict__.update(brain)
<         
< class ASTWalker:
<     """a walker visiting a tree in preorder, calling on the handler:
<     
<     * visit_<class name> on entering a node, where class name is the class of
<     the node in lower case
<     
<     * leave_<class name> on leaving a node, where class name is the class of
<     the node in lower case
<     """
<     def __init__(self, handler):
<         self.handler = handler
<         self._cache = {}
<         
<     def walk(self, node):
<         """walk on the tree from <node>, getting callbacks from handler
<         """
<         try:            
<             self.visit(node)
<         except IgnoreChild:
<             pass
<         else:
<             for child_node in node.getChildNodes():
<                 self.walk(child_node)
<         self.leave(node)
< 
<     def get_callbacks(self, node):
<         """get callbacks from handler for the visited node
<         """
<         klass = node.__class__
<         methods = self._cache.get(klass)
<         if methods is None:
<             handler = self.handler
<             kid = klass.__name__.lower()
<             e_method = getattr(handler, 'visit_%s' % kid,
<                                getattr(handler, 'visit_default', None))
<             l_method = getattr(handler, 'leave_%s' % kid, 
<                                getattr(handler, 'leave_default', None))
<             self._cache[klass] = (e_method, l_method)
<         else:
<             e_method, l_method = methods
<         return e_method, l_method
<     
<     def visit(self, node):
<         """walk on the tree from <node>, getting callbacks from handler"""
<         method = self.get_callbacks(node)[0]
<         if method is not None:
<             method(node)
<             
<     def leave(self, node):
<         """walk on the tree from <node>, getting callbacks from handler"""
<         method = self.get_callbacks(node)[1]
<         if method is not None:
<             method(node)
< 
< 
< class LocalsVisitor(ASTWalker):
<     """visit a project by traversing the locals dictionnary"""
<     def __init__(self):
<         ASTWalker.__init__(self, self)
<         self._visited = {}
<         
<     def visit(self, node):
<         """launch the visit starting from the given node"""
<         if self._visited.has_key(node):
<             return
<         self._visited[node] = 1
<         methods = self.get_callbacks(node)
<         recurse = 1
<         if methods[0] is not None:
<             try:
<                 methods[0](node)
<             except IgnoreChild:
<                 recurse = 0
<         if recurse:
<             if hasattr(node, 'locals'):
<                 for local_node in node.values():
<                     self.visit(local_node)
<         if methods[1] is not None:
<             return methods[1](node)
< 
< def are_exclusive(stmt1, stmt2):
<     """return true if the two given statement are mutually exclusive
< 
<     algorithm :
<      1) index stmt1's parents
<      2) climb among stmt2's parents until we find a common parent
<      3) if the common parent is a If or TryExcept statement, look if nodes are
<         in exclusive branchs
<     """
<     from clonedigger.logilab.astng.nodes import If, TryExcept
<     # index stmt1's parents
<     stmt1_parents = {}
<     children = {}
<     node = stmt1.parent
<     previous = stmt1
<     while node:
<         stmt1_parents[node] = 1
<         children[node] = previous
<         previous = node
<         node = node.parent
<     # climb among stmt2's parents until we find a common parent
<     node = stmt2.parent
<     previous = stmt2
<     while node:
<         if stmt1_parents.has_key(node):
<             # if the common parent is a If or TryExcept statement, look if
<             # nodes are in exclusive branchs
<             if isinstance(node, If):
<                 if previous != children[node]:
<                     return True
<             elif isinstance(node, TryExcept):
<                 stmt1_previous = children[node]
<                 if not previous is stmt1_previous:
<                     stmt1_branch, stmt1_num = _try_except_from_branch(node, stmt1_previous)
<                     stmt2_branch, stmt2_num = _try_except_from_branch(node, previous)
<                     if stmt1_branch != stmt1_branch:
<                         if not ((stmt2_branch == 'body' and stmt1_branch == 'else') or
<                                 (stmt1_branch == 'body' and stmt2_branch == 'else') or
<                                 (stmt2_branch == 'body' and stmt1_branch == 'except') or
<                                 (stmt1_branch == 'body' and stmt2_branch == 'except')):
<                             return True
<                     elif stmt1_num != stmt2_num:
<                         return True
<             return False
<         previous = node
<         node = node.parent
<     return False
< 
< def _try_except_from_branch(node, stmt):
<     if stmt is node.body:
<         return 'body', 1
<     if stmt is node.else_:
<         return 'else', 1
<     for i, block_nodes in enumerate(node.handlers):
<         if stmt in block_nodes:
<             return 'except', i
diff -r -N code-worker/tasks/clonedigger/logilab/common/adbh.py code-worker/code-worker/tasks/clonedigger/logilab/common/adbh.py
1,525d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """This module contains helpers for DBMS specific (advanced or non standard)
< functionalities
< 
< Helpers are provided for postgresql, mysql and sqlite.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.deprecation import obsolete
< 
< class BadQuery(Exception): pass
< class UnsupportedFunction(BadQuery): pass
< 
< 
< class metafunc(type):
<     def __new__(mcs, name, bases, dict):
<         dict['name'] = name.upper()
<         return type.__new__(mcs, name, bases, dict)
< 
<     
< class FunctionDescr(object):
<     __metaclass__ = metafunc
< 
<     rtype = None # None <-> returned type should be the same as the first argument
<     aggregat = False
<     minargs = 1
<     maxargs = 1
< 
<     def __init__(self, name=None, rtype=rtype, aggregat=aggregat):
<         if name is not None:
<             name = name.upper()
<         self.name = name
<         self.rtype = rtype
<         self.aggregat = aggregat
< 
<     #@classmethod
<     def check_nbargs(cls, nbargs):
<         if cls.minargs is not None and \
<                nbargs < cls.minargs:
<             raise BadQuery('not enough argument for function %s' % cls.name)
<         if cls.maxargs is not None and \
<                nbargs < cls.maxargs:
<             raise BadQuery('too many arguments for function %s' % cls.name)
<     check_nbargs = classmethod(check_nbargs)
< 
< class AggrFunctionDescr(FunctionDescr):
<     aggregat = True
<     rtype = None 
< 
< class MAX(AggrFunctionDescr): pass
< class MIN(AggrFunctionDescr): pass
< class SUM(AggrFunctionDescr): pass
< class COUNT(AggrFunctionDescr): 
<     rtype = 'Int'
< class AVG(AggrFunctionDescr):
<     rtype = 'Float'
< 
< class UPPER(FunctionDescr):
<     rtype = 'String'
< class LOWER(FunctionDescr):
<     rtype = 'String'
< class IN(FunctionDescr):
<     """this is actually a 'keyword' function..."""
<     maxargs = None
< class LENGTH(FunctionDescr):
<     rtype = 'Int'
< 
< class _GenericAdvFuncHelper:
<     """Generic helper, trying to provide generic way to implement
<     specific functionnalities from others DBMS
< 
<     An exception is raised when the functionality is not emulatable
<     """    
<     # DBMS resources descriptors and accessors
<     
<     needs_from_clause = False
<     union_parentheses_support = True
<     users_support = True
<     groups_support = True
<     ilike_support = True
< 
<     FUNCTIONS = {
<         # aggregat functions
<         'MIN': MIN, 'MAX': MAX,
<         'SUM': SUM,
<         'COUNT': COUNT,
<         'AVG': AVG,
<         # transformation functions
<         'UPPER': UPPER, 'LOWER': LOWER,
<         'LENGTH': LENGTH,
<         # keyword function
<         'IN': IN
<         }
< 
<     TYPE_MAPPING = {
<         'String' :   'text',
<         'Int' :      'integer',
<         'Float' :    'float',
<         'Boolean' :  'boolean',
<         'Date' :     'date', 
<         'Time' :     'time', 
<         'Datetime' : 'timestamp',
<         'Interval' : 'interval',
<         'Password' : 'bytea',
<         'Bytes' :    'bytea',
<         # FIXME: still there for use from erudi, should be moved out
<         # XXX think it can be safely removed now
<         'COUNT' : 'integer',
<         'MIN' :   'integer',
<         'MAX' :   'integer',
<         'SUM' :   'integer',
<         'LOWER' : 'text',
<         'UPPER' : 'text',
<         'LENGTH' :'integer',
<         }
< 
< 
<     #@classmethod
<     def register_function(cls, funcdef):
<         if isinstance(funcdef, basestring) :
<             funcdef = FunctionDescr(funcdef.upper())
<         assert not funcdef.name in cls.FUNCTIONS, \
<                '%s is already registered' % funcdef.name
<         cls.FUNCTIONS[funcdef.name] = funcdef
<     register_function = classmethod(register_function)
<     
<     #@classmethod
<     def function_description(cls, funcname):
<         """return the description (`FunctionDescription`) for a RQL function"""
<         try:
<             return cls.FUNCTIONS[funcname.upper()]
<         except KeyError:
<             raise UnsupportedFunction(funcname)
<     function_description = classmethod(function_description)
<     
<     #@obsolete('use users_support attribute')
<     def support_users(self):
<         """return True if the DBMS support users (this is usually
<         not true for in memory DBMS)
<         """
<         return self.users_support
<     support_user = obsolete('use users_support attribute')(support_users)
<     
<     #@obsolete('use groups_support attribute')    
<     def support_groups(self):
<         """return True if the DBMS support groups"""
<         return self.groups_support
<     support_user = obsolete('use groups_support attribute')(support_groups)
< 
<     def system_database(self):
<         """return the system database for the given driver"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def backup_command(self, dbname, dbhost, dbuser, dbpassword, backupfile,
<                        keepownership=True):
<         """return a command to backup the given database"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def restore_commands(self, dbname, dbhost, dbuser, backupfile,
<                          encoding='utf-8', keepownership=True, drop=True):
<         """return a list of commands to restore a backup the given database"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     # helpers to standardize SQL according to the database
<     
<     def sql_current_date(self):
<         return 'CURRENT_DATE'
<     
<     def sql_current_time(self):
<         return 'CURRENT_TIME'
<     
<     def sql_current_timestamp(self):
<         return 'CURRENT_TIMESTAMP'
<     
<     def sql_create_sequence(self, seq_name):
<         return '''CREATE TABLE %s (last INTEGER);
< INSERT INTO %s VALUES (0);''' % (seq_name, seq_name)
<     
<     def sql_create_index(self, table, column, unique=False):
<         idx = self._index_name(table, column, unique)
<         if unique:
<             return 'CREATE UNIQUE INDEX %s ON %s(%s);' % (idx, table, column)
<         else:
<             return 'CREATE INDEX %s ON %s(%s);' % (idx, table, column)
<     
<     def sql_drop_sequence(self, seq_name):
<         return 'DROP TABLE %s;' % seq_name
<     
<     def sqls_increment_sequence(self, seq_name):
<         return ('UPDATE %s SET last=last+1;' % seq_name,
<                 'SELECT last FROM %s;' % seq_name)
< 
<     def sql_temporary_table(self, table_name, table_schema,
<                             drop_on_commit=True):
<         return "CREATE TEMPORARY TABLE %s (%s);" % (table_name, table_schema)
<     
<     def boolean_value(self, value):
<         if value:
<             return 'TRUE'
<         else:
<             return 'FALSE'
<         
<     def increment_sequence(self, cursor, seq_name):
<         for sql in self.sqls_increment_sequence(seq_name):
<             cursor.execute(sql)
<         return cursor.fetchone()[0]
< 
<     def create_user(self, cursor, user, password):
<         """create a new database user"""
<         if not self.users_support:
<             raise NotImplementedError('not supported by this DBMS')
<         cursor.execute("CREATE USER %(user)s "
<                        "WITH PASSWORD '%(password)s'" % locals())
< 
<     def _index_name(self, table, column, unique=False):
<         if unique:
<             # note: this naming is consistent with indices automatically
<             # created by postgres when UNIQUE appears in a table schema
<             return '%s_%s_key' % (table.lower(), column.lower())
<         else:
<             return '%s_%s_idx' % (table.lower(), column.lower())
<     
<     def create_index(self, cursor, table, column, unique=False):
<         if not self.index_exists(cursor, table, column, unique):
<             cursor.execute(self.sql_create_index(table, column, unique))
<             
<     def drop_index(self, cursor, table, column, unique=False):
<         if self.index_exists(cursor, table, column, unique):
<             idx = self._index_name(table, column, unique)
<             cursor.execute('DROP INDEX %s' % idx)
<         
<     def index_exists(self, cursor, table, column, unique=False):
<         idx = self._index_name(table, column, unique)
<         return idx in self.list_indices(cursor, table)
< 
<     def user_exists(self, cursor, username):
<         """return True if a user with the given username exists"""
<         return username in self.list_users(cursor)
<     
<     def list_users(self, cursor):
<         """return the list of existing database users"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def create_database(self, cursor, dbname, owner=None, encoding='utf-8'):
<         """create a new database"""
<         raise NotImplementedError('not supported by this DBMS')
<         
<     def list_databases(self):
<         """return the list of existing databases"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         raise NotImplementedError('not supported by this DBMS')
<     
< 
< 
< def pgdbcmd(cmd, dbhost, dbuser):
<     cmd = [cmd]
<     if dbhost:
<         cmd.append('--host=%s' % dbhost)
<     if dbuser:
<         cmd.append('--username=%s' % dbuser)
<     return cmd
< 
< 
< class _PGAdvFuncHelper(_GenericAdvFuncHelper):
<     """Postgres helper, taking advantage of postgres SEQUENCE support
<     """
<     # modifiable but should not be shared
<     FUNCTIONS = _GenericAdvFuncHelper.FUNCTIONS.copy()
<     
<     def system_database(self):
<         """return the system database for the given driver"""
<         return 'template1'
<     
<     def backup_command(self, dbname, dbhost, dbuser, backupfile,
<                        keepownership=True):
<         """return a command to backup the given database"""
<         cmd = ['pg_dump -Fc']
<         if dbhost:
<             cmd.append('--host=%s' % dbhost)
<         if dbuser:
<             cmd.append('--username=%s' % dbuser)
<         if not keepownership:
<             cmd.append('--no-owner')
<         cmd.append('--file=%s' % backupfile)
<         cmd.append(dbname)
<         return ' '.join(cmd)
<     
<     def restore_commands(self, dbname, dbhost, dbuser, backupfile,
<                          encoding='utf-8', keepownership=True, drop=True):
<         """return a list of commands to restore a backup the given database"""
<         cmds = []
<         if drop:
<             cmd = pgdbcmd('dropdb', dbhost, dbuser)
<             cmd.append(dbname)
<             cmds.append(' '.join(cmd))
<         cmd = pgdbcmd('createdb -T template0 -E %s' % encoding, dbhost, dbuser)
<         cmd.append(dbname)
<         cmds.append(' '.join(cmd))
<         cmd = pgdbcmd('pg_restore -Fc', dbhost, dbuser)
<         cmd.append('--dbname %s' % dbname)
<         if not keepownership:
<             cmd.append('--no-owner')
<         cmd.append(backupfile)
<         cmds.append(' '.join(cmd))
<         return cmds
<                 
<     def sql_create_sequence(self, seq_name):
<         return 'CREATE SEQUENCE %s;' % seq_name
<     
<     def sql_drop_sequence(self, seq_name):
<         return 'DROP SEQUENCE %s;' % seq_name
<     
<     def sqls_increment_sequence(self, seq_name):
<         return ("SELECT nextval('%s');" % seq_name,)
<     
<     def sql_temporary_table(self, table_name, table_schema,
<                             drop_on_commit=True):
<         if not drop_on_commit:
<             return "CREATE TEMPORARY TABLE %s (%s);" % (table_name,
<                                                         table_schema)    
<         return "CREATE TEMPORARY TABLE %s (%s) ON COMMIT DROP;" % (table_name,
<                                                                    table_schema)
<     
<     def create_database(self, cursor, dbname, owner=None, encoding='utf-8'):
<         """create a new database"""
<         sql = "CREATE DATABASE %(dbname)s"
<         if owner:
<             sql += " WITH OWNER=%(owner)s"
<         if encoding:
<             sql += " ENCODING='%(encoding)s'"
<         cursor.execute(sql % locals())
< 
<     def create_language(self, cursor, extlang):
<         """postgres specific method to install a procedural language on a database"""
<         # make sure plpythonu is not directly in template1
<         cursor.execute("SELECT * FROM pg_language WHERE lanname='%s';" % extlang)
<         if cursor.fetchall():
<             print '%s language already installed' % extlang
<         else:
<             cursor.execute('CREATE LANGUAGE %s' % extlang)
<             print '%s language installed' % extlang
< 
<     def list_users(self, cursor, username=None):
<         """return the list of existing database users"""
<         if username:
<             warn('username argument is deprecated, use user_exists method',
<                  DeprecationWarning, stacklevel=2)
<             return self.user_exists(cursor, username)
<         cursor.execute("SELECT usename FROM pg_user")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_databases(self, cursor):
<         """return the list of existing databases"""
<         cursor.execute('SELECT datname FROM pg_database')
<         return [r[0] for r in cursor.fetchall()]
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         cursor.execute("SELECT tablename FROM pg_tables")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         sql = "SELECT indexname FROM pg_indexes"
<         if table:
<             sql += " WHERE LOWER(tablename)='%s'" % table.lower()
<         cursor.execute(sql)
<         return [r[0] for r in cursor.fetchall()]
< 
<             
< class _SqliteAdvFuncHelper(_GenericAdvFuncHelper):
<     """Generic helper, trying to provide generic way to implement
<     specific functionnalities from others DBMS
< 
<     An exception is raised when the functionality is not emulatable
<     """
<     # modifiable but should not be shared
<     FUNCTIONS = _GenericAdvFuncHelper.FUNCTIONS.copy()
<     
<     users_support = groups_support = False
<     ilike_support = False
<     union_parentheses_support = False
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         # filter type='table' else we get indices as well
<         cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         sql = "SELECT name FROM sqlite_master WHERE type='index'"
<         if table:
<             sql += " AND LOWER(tbl_name)='%s'" % table.lower()
<         cursor.execute(sql)
<         return [r[0] for r in cursor.fetchall()]
< 
<     
< class _MyAdvFuncHelper(_GenericAdvFuncHelper):
<     """MySQL helper, taking advantage of postgres SEQUENCE support
<     """
<     needs_from_clause = True
<     ilike_support = False # insensitive search by default
< 
<     # modifiable but should not be shared
<     FUNCTIONS = _GenericAdvFuncHelper.FUNCTIONS.copy() 
<     TYPE_MAPPING = _GenericAdvFuncHelper.TYPE_MAPPING.copy()
<     TYPE_MAPPING['Password'] = 'tinyblob'
<     TYPE_MAPPING['String'] = 'mediumtext'
<     TYPE_MAPPING['Bytes'] = 'longblob'
<     
<     def system_database(self):
<         """return the system database for the given driver"""
<         return ''
<     
<     def backup_command(self, dbname, dbhost, dbuser, backupfile,
<                        keepownership=True):
<         """return a command to backup the given database"""
<         # XXX compress
<         return 'mysqldump -h %s -u %s -p -r %s %s' % (dbhost, dbuser, backupfile, dbname)
<     
<     def restore_commands(self, dbname, dbhost, dbuser, backupfile,
<                          encoding='utf-8', keepownership=True, drop=True):
<         """return a list of commands to restore a backup the given database"""
<         cmds = []
<         if drop:
<             cmd = 'echo "DROP DATABASE %s;" | mysql -h %s -u %s -p' % (dbname, dbhost, dbuser)
<             cmds.append(cmd)
<         cmd = 'echo "%s;" | mysql -h %s -u %s -p' % (self.sql_create_database(dbname, encoding),
<                                                   dbhost, dbuser)
<         cmds.append(cmd)
<         cmd = pgdbcmd('mysql -h %s -u %s -p < %s' % (dbname, dbhost, dbuser, backupfile))
<         cmds.append(cmd)
<         return cmds
<                 
<     def sql_temporary_table(self, table_name, table_schema,
<                             drop_on_commit=True):
<         if not drop_on_commit:
<             return "CREATE TEMPORARY TABLE %s (%s);" % (table_name,
<                                                         table_schema)    
<         return "CREATE TEMPORARY TABLE %s (%s) ON COMMIT DROP;" % (table_name,
<                                                                    table_schema)
<     
<     def sql_create_database(self, dbname, encoding='utf-8'):
<         sql = "CREATE DATABASE %(dbname)s"
<         if encoding:
<             sql += " CHARACTER SET %(encoding)s"
<         return sql % locals()
<     
<     def create_database(self, cursor, dbname, owner=None, encoding='utf-8'):
<         """create a new database"""
<         cursor.execute(self.sql_create_database(dbname, encoding))
<         if owner:
<             cursor.execute('GRANT ALL ON `%s`.* to %s' % (dbname, owner))
< 
<     def boolean_value(self, value):
<         if value:
<             return True
<         else:
<             return False
<         
<     def list_users(self, cursor):
<         """return the list of existing database users"""
<         # Host, Password
<         cursor.execute("SELECT User FROM mysql.user")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_databases(self, cursor):
<         """return the list of existing databases"""
<         cursor.execute('SHOW DATABASES')
<         return [r[0] for r in cursor.fetchall()]
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         cursor.execute("SHOW TABLES")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         if table:
<             cursor.execute("SHOW INDEX FROM %s" % table)
<             return [r[2] for r in cursor.fetchall()]
<         allindices = []
<         for table in self.list_tables(cursor):
<             allindices += self.list_indices(cursor, table)
<         return allindices
< 
< 
<     
< ADV_FUNC_HELPER_DIRECTORY = {'postgres': _PGAdvFuncHelper(),
<                              'sqlite': _SqliteAdvFuncHelper(),
<                              'mysql': _MyAdvFuncHelper(),
<                              }
< 
< 
< 
< def get_adv_func_helper(driver):
<     """returns an advanced function helper for the given driver"""
<     return ADV_FUNC_HELPER_DIRECTORY[driver]
< 
< def register_function(driver, funcdef):
<     ADV_FUNC_HELPER_DIRECTORY[driver].register_function(funcdef)    
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/astutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/astutils.py
1,84d0
< # Copyright (c) 2003 Sylvain Thenault (thenault@nerim.net)
< # Copyright (c) 2003 Logilab
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some usefull functions to manipulate ast tuples
< """
< 
< from warnings import warn
< warn('this module has been moved into logilab.astng and will disappear from \
< logilab.common in a future release',
<      DeprecationWarning, stacklevel=1)
< 
< __author__ = u"Sylvain Thenault"
< 
< import symbol
< import token
< from types import TupleType
< 
< def debuild(ast_tuple):
<     """
<     reverse ast_tuple to string
<     """
<     if type(ast_tuple[1]) is TupleType:
<         result = ''
<         for child in ast_tuple[1:]: 
<             result = '%s%s' % (result, debuild(child))
<         return result
<     else:
<         return ast_tuple[1]
< 
< def clean(ast_tuple):
<     """
<     reverse ast tuple to a list of tokens
<     merge sequences (token.NAME, token.DOT, token.NAME)
<     """
<     result = []
<     last = None
<     for couple in _clean(ast_tuple):
<         if couple[0] == token.NAME and last == token.DOT:
<             result[-1][1] += couple[1]
<         elif couple[0] == token.DOT and last == token.NAME:
<             result[-1][1] += couple[1]
<         else:
<             result.append(couple)
<         last = couple[0]
<     return result
< 
< def _clean(ast_tuple):
<     """ transform the ast into as list of tokens (i.e. final elements)
<     """
<     if type(ast_tuple[1]) is TupleType:
<         v = []
<         for c in ast_tuple[1:]:
<             v += _clean(c)
<         return v
<     else:
<         return [list(ast_tuple[:2])]
<     
< def cvrtr(tuple):
<     """debug method returning an ast string in a readable fashion"""
<     if type(tuple) is TupleType:
<         try:
<             try:
<                 txt = 'token.'+token.tok_name[tuple[0]]
<             except:
<                 txt = 'symbol.'+symbol.sym_name[tuple[0]]
<         except:
<             txt =  'Unknown token/symbol'
<         return [txt] + map(cvrtr, tuple[1:])
<     else:
<         return tuple
< 
< __all__ = ('debuild', 'clean', 'cvrtr')
diff -r -N code-worker/tasks/clonedigger/logilab/common/bind.py code-worker/code-worker/tasks/clonedigger/logilab/common/bind.py
1,276d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< 
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
<  This module provides a way to optimize globals in certain functions by binding
<  their names to values provided in a dictionnary
< """
< 
< from warnings import warn
< warn('bind module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = '$Id: bind.py,v 1.8 2005-11-22 13:12:59 syt Exp $'
< 
< # TODO: unit tests
< # * this module provide a function bind(func,vars) which replaces every
< #   global variable 'm' by the value vars['m'] if such value exists in dict
< 
< from dis import HAVE_ARGUMENT
< from new import code as make_code, function as make_function
< import inspect
< 
< LOAD_GLOBAL = 116
< LOAD_CONST = 100
< EXTENDED_ARG = 143
< STORE_GLOBAL = 97
< 
< def bind_code(co, globals):
<     """
<     Take a code object and a dictionnary and returns a new code object where
<     the opcodes LOAD_GLOBAL are replaced by LOAD_CONST whenever the global's
<     name appear in the dictionnary
<     """
<     consts = list(co.co_consts)
<     assigned = {}
<     
<     code = co.co_code
<     new_code = ""
<     n = len(code)
<     i = 0
<     while i < n:
<         c = code[i]
<         op = ord(c)
<         i += 1
<         if op >= HAVE_ARGUMENT:
<             oparg = ord(code[i]) + ord(code[i+1]) * 256
<             i += 2
<         else:
<             oparg = None
<         if op == LOAD_GLOBAL:
<             name = co.co_names[oparg]
<             if globals.has_key(name):
<                 k = assigned.get(name, None)
<                 if k == None:
<                     k = len(consts)
<                     assigned[name] = len(consts)
<                     consts.append(globals[name])
<                 op = LOAD_CONST
<                 oparg = k
<         new_code += chr(op)
<         if oparg is not None:
<             new_code += chr(oparg & 255)
<             new_code += chr( (oparg>>8) & 255 )
<             
<     return make_code(co.co_argcount,
<                      co.co_nlocals,
<                      co.co_stacksize,
<                      co.co_flags,
<                      new_code,
<                      tuple(consts),
<                      co.co_names,
<                      co.co_varnames,
<                      co.co_filename,
<                      co.co_name,
<                      co.co_firstlineno,
<                      co.co_lnotab )
< 
< 
< def bind(f, globals):
<     """Returns a new function whose code object has been
<     bound by bind_code()"""
<     newcode = bind_code(f.func_code, globals)
<     defaults = f.func_defaults or ()
<     return make_function(newcode, f.func_globals, f.func_name, defaults)
< 
< if type(__builtins__) == dict:
<     builtins = __builtins__
< else:
<     builtins = __builtins__.__dict__
<     
< bind_code_opt = bind(bind_code, builtins )
< bind_code_opt = bind(bind_code_opt, globals() )
< 
< 
< def optimize_module(m, global_consts):
<     if not inspect.ismodule(m):
<         raise TypeError
<     d = {}
<     for i in global_consts:
<         v = m.__dict__.get(i)
<         d[i] = v
<     builtins = m.__builtins__
<     for name, f in m.__dict__.items():
<         if inspect.isfunction(f):
<             f = bind(f, builtins)
<             if d:
<                 f = bind(f, d)
<             m.__dict__[name] = f
<             
< 
< 
< 
< def analyze_code(co, globals, consts_dict, consts_list):
<     """Take a code object and a dictionnary and returns a
<     new code object where the opcodes LOAD_GLOBAL are replaced
<     by LOAD_CONST whenever the global's name appear in the
<     dictionnary"""
<     modified_globals = []
<     for c in co.co_consts:
<         if c not in consts_list:
<             consts_list.append(c)
<     modified = []
<     code = co.co_code
<     new_code = ""
<     n = len(code)
<     i = 0
<     extended_arg = 0
<     while i < n:
<         c = code[i]
<         op = ord(c)
<         i += 1
<         if op >= HAVE_ARGUMENT:
<             oparg = ord(code[i]) + ord(code[i+1])*256 + extended_arg
<             extended_arg = 0
<             i += 2
<         else:
<             oparg = None
<         if op == EXTENDED_ARG:
<             extended_arg = oparg*65536L
< 
<         if op == LOAD_GLOBAL:
<             name = co.co_names[oparg]
<             if globals.has_key(name):
<                 k = consts_dict.get(name, None)
<                 if k == None:
<                     k = len(consts_list)
<                     consts_dict[name] = k
<                     consts_list.append(globals[name])
<         if op == STORE_GLOBAL:
<             name = co.co_names[oparg]
<             if globals.has_key(name):
<                 modified_globals.append(name)
<     return modified_globals
< 
< def rewrite_code(co, consts_dict, consts_tuple):
<     """Take a code object and a dictionnary and returns a
<     new code object where the opcodes LOAD_GLOBAL are replaced
<     by LOAD_CONST whenever the global's name appear in the
<     dictionnary"""
<     code = co.co_code
<     new_code = ""
<     n = len(code)
<     i = 0
<     consts_list = list(consts_tuple)
<     while i < n:
<         c = code[i]
<         op = ord(c)
<         i += 1
<         extended_arg = 0
<         if op >= HAVE_ARGUMENT:
<             oparg = ord(code[i]) + ord(code[i+1])*256+extended_arg
<             extended_arg = 0
<             i += 2
<         else:
<             oparg = None
<         if op == EXTENDED_ARG:
<             extended_arg = oparg*65536L
<         elif op == LOAD_GLOBAL:
<             name = co.co_names[oparg]
<             k = consts_dict.get(name)
<             if k is not None:
<                 op = LOAD_CONST
<                 oparg = k
<         elif op == LOAD_CONST:
<             val = co.co_consts[oparg]
<             oparg = consts_list.index(val)
<         new_code += chr(op)
<         if oparg is not None:
<             new_code += chr(oparg & 255)
<             new_code += chr( (oparg>>8) & 255 )
<             
<     return make_code(co.co_argcount,
<                      co.co_nlocals,
<                      co.co_stacksize,
<                      co.co_flags,
<                      new_code,
<                      consts_tuple,
<                      co.co_names,
<                      co.co_varnames,
<                      co.co_filename,
<                      co.co_name,
<                      co.co_firstlineno,
<                      co.co_lnotab )
< 
< def optimize_module_2(m, globals_consts, bind_builtins=1):
<     if not inspect.ismodule(m):
<         raise TypeError
<     consts_dict = {}
<     consts_list = []
<     if type(globals_consts) == list or type(globals_consts) == tuple:
<         globals = {}
<         for i in globals_consts:
<             v = m.__dict__.get(i)
<             globals[i] = v
<     else:
<         globals = globals_consts
<     if bind_builtins:
<         for builtin_name, builtin_value in m.__builtins__.items():
<             # this way it is possible to redefine a builtin in globals_consts
<             globals.setdefault(builtin_name, builtin_value)
<     functions = {}
<     for name, f in m.__dict__.items():
<         if inspect.isfunction(f):
<             functions[name] = f
<             analyze_code(f.func_code, globals, consts_dict, consts_list)
<     consts_list = tuple(consts_list)
<     for name, f in functions.items():
<         newcode = rewrite_code(f.func_code, consts_dict, consts_list)
<         defaults = f.func_defaults or ()
<         m.__dict__[name] = make_function(newcode, f.func_globals, f.func_name,
<                                          defaults)
<         
< 
< def run_bench(n):
<     from time import time
<     t = time()
<     g = globals()
<     for i in range(n):
<         test = bind(bind_code, g)
<     t1 = time()-t
<     bind2 = bind(bind, {'bind_code':bind_code_opt})
<     t = time()
<     for i in range(n):
<         test=bind2(bind_code, g)
<     t2 = time()-t
<     print "1 regular version", t1
<     print "2 optimized version", t2
<     print "ratio (1-2)/1 : %f %%" % (100.*(t1-t2)/t1)
<     
< 
< def test_pystone():
<     from test import pystone
<     for _ in range(5):
<         pystone.main()
<     optimize_module(pystone, ('TRUE','FALSE','Proc0','Proc1','Proc2','Proc3',
<                               'Proc4','Proc5','Proc6','Proc7','Proc8','Func1',
<                              ' Func2','Func3'))
<     optimize_module(pystone, builtins.keys())
<     for _ in range(5):
<         pystone.main()
< 
< 
< if __name__ == "__main__":
<     run_bench(1000)
diff -r -N code-worker/tasks/clonedigger/logilab/common/cache.py code-worker/code-worker/tasks/clonedigger/logilab/common/cache.py
1,104d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
<  Cache module, with a least recently used algorithm for the management of the
<  deletion of entries.
< """
< 
< _marker = object()
< 
< class Cache:
<     """ a dictionnary like cache
< 
<     inv:
<         len(self._usage) <= self.size
<         len(self.data) <= self.size
<     """
<     
<     def __init__(self, size=100):
<         self.data = {}
<         self.size = size
<         self._usage = []
< 
<     def __repr__(self):
<         return repr(self.data)
< 
<     def __len__(self):
<         return len(self.data)
< 
<     def _update_usage(self, key):
<         # Special case : cache's size = 0 !
<         if self.size <= 0:
<             return
<         
<         if not self._usage:
<             self._usage.append(key)
<         
<         elif self._usage[-1] != key:
<             try:
<                 self._usage.remove(key)
<             except ValueError:
<                 # we are inserting a new key
<                 # check the size of the dictionnary
<                 # and remove the oldest item in the cache
<                 if self.size and len(self._usage) >= self.size:
<                     del self.data[self._usage[0]]
<                     del self._usage[0]
<             self._usage.append(key)
<         else:
<             pass # key is already the most recently used key
< 
<             
<     def __getitem__(self, key):
<         value = self.data[key]
<         self._update_usage(key)
<         return value
<     
<     def __setitem__(self, key, item):
<         # Just make sure that size > 0 before inserting a new item in the cache
<         if self.size > 0:
<             self.data[key] = item
<         self._update_usage(key)
<         
<     def __delitem__(self, key):
<         # If size <= 0, then we don't have anything to do
<         # XXX FIXME : Should we let the 'del' raise a KeyError ?
<         if self.size > 0:
<             del self.data[key]
<             self._usage.remove(key)
<         
<     def pop(self, value, default=_marker):
<         if value in self.data:
<             self._usage.remove(value)
<         if default is _marker:
<             return self.data.pop(value)
<         return self.data.pop(value, default)
<     
<     def clear(self):
<         self.data.clear()
<         self._usage = []
< 
<     def keys(self):
<         return self.data.keys()
< 
<     def items(self):
<         return self.data.items()
< 
<     def values(self):
<         return self.data.values()
< 
<     def has_key(self, key):
<         return self.data.has_key(key)
<     
diff -r -N code-worker/tasks/clonedigger/logilab/common/changelog.py code-worker/code-worker/tasks/clonedigger/logilab/common/changelog.py
1,194d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Manipulation of upstream change log files
< 
< The upstream change log files format handled is simpler than the one
< often used such as those generated by the default Emacs changelog mode.
< 
< Sample ChangeLog format:
< ------------------------------------------------------------
< Change log for project Yoo
< ==========================
< 
<  --
<     * add a new functionnality
< 
< 2002-02-01 -- 0.1.1
<     * fix bug #435454
<     * fix bug #434356
<     
< 2002-01-01 -- 0.1
<     * initial release
<     
< ------------------------------------------------------------
< 
< There is 3 entries in this change log, one for each released version and one
< for the next version (i.e. the current entry).
< Each entry contains a set of messages corresponding to changes done in this
< release.
< All the non empty lines before the first entry are considered as the change
< log title.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< import sys
< from stat import S_IWRITE
< 
< from clonedigger.logilab.common.fileutils import ensure_fs_mode
< 
< BULLET = '*'
< INDENT = '    '
< 
< class NoEntry(Exception):
<     """raised when we are unable to find an entry"""
< 
< class EntryNotFound(Exception):
<     """raised when we are unable to find a given entry"""
< 
< class Version(tuple):
<     """simple class to handle soft version number has a tuple while
<     correctly printing it as X.Y.Z
<     """
<     def __new__(klass, versionstr):
<         if isinstance(versionstr, basestring):
<             parsed = [int(i) for i in versionstr.split('.')]
<         else:
<             parsed = versionstr
<         return tuple.__new__(klass, parsed)
<         
<     def __str__(self):
<         return '.'.join([str(i) for i in self])
< 
< # upstream change log #########################################################
< 
< class ChangeLogEntry(object):
<     """a change log entry, ie a set of messages associated to a version and
<     its release date
<     """
<     version_class = Version
<     
<     def __init__(self, date=None, version=None, **kwargs):
<         self.__dict__.update(kwargs)
<         if version:
<             self.version = self.version_class(version)
<         else:
<             self.version = None
<         self.date = date
<         self.messages = []
<         
<     def add_message(self, msg):
<         """add a new message"""
<         self.messages.append([msg])
< 
<     def complete_latest_message(self, msg_suite):
<         """complete the latest added message
<         """
<         if not self.messages:
<             print >> sys.stderr, 'Ignoring %r (unexpected format)' % msg_suite
<         self.messages[-1].append(msg_suite)
< 
<     def write(self, stream=sys.stdout):
<         """write the entry to file """
<         stream.write('%s  --  %s\n' % (self.date or '', self.version or ''))
<         for msg in self.messages:
<             stream.write('%s%s %s\n' % (INDENT, BULLET, msg[0]))
<             stream.write(''.join(msg[1:]))
< 
< 
< class ChangeLog(object):
<     """object representation of a whole ChangeLog file"""
<     
<     entry_class = ChangeLogEntry
<     
<     def __init__(self, changelog_file, title=''):
<         self.file = changelog_file
<         self.title = title
<         self.additional_content = ''
<         self.entries = []
<         self.load()
< 
<     def __repr__(self):
<         return '<ChangeLog %s at %s (%s entries)>' % (self.file, id(self),
<                                                       len(self.entries))
<     
<     def add_entry(self, entry):
<         """add a new entry to the change log"""
<         self.entries.append(entry)
< 
<     def get_entry(self, version='', create=None):
<         """ return a given changelog entry
<         if version is omited, return the current entry 
<         """
<         if not self.entries:
<             if version or not create:
<                 raise NoEntry()
<             self.entries.append(self.entry_class())
<         if not version:
<             if self.entries[0].version and create is not None:
<                 self.entries.insert(0, self.entry_class())
<             return self.entries[0]
<         version = self.version_class(version)
<         for entry in self.entries:
<             if entry.version == version:
<                 return entry
<         raise EntryNotFound()
< 
<     def add(self, msg, create=None):
<         """add a new message to the latest opened entry"""
<         entry = self.get_entry(create=create)
<         entry.add_message(msg)
<     
<     def load(self):
<         """ read a logilab's ChangeLog from file """
<         try:
<             stream = open(self.file)
<         except IOError:
<             return
<         last = None
<         for line in stream.readlines():
<             sline = line.strip()
<             words = sline.split()
<             if len(words) == 1 and words[0] == '--':
<                 last = self.entry_class()
<                 self.add_entry(last)
<             elif len(words) == 3 and words[1] == '--':
<                 last = self.entry_class(words[0], words[2])
<                 self.add_entry(last)
<             elif last is None:
<                 if not sline:
<                     continue
<                 self.title = '%s%s' % (self.title, line)
<             elif sline and sline[0] == BULLET:
<                 last.add_message(sline[1:].strip())
<             elif last.messages:
<                 last.complete_latest_message(line)
<             else:
<                 self.additional_content += line
<         stream.close()
<         
<     def format_title(self):
<         return '%s\n\n' % self.title.strip()
<     
<     def save(self):
<         """write back change log"""
<         ensure_fs_mode(self.file, S_IWRITE)
<         self.write(open(self.file, 'w'))
<             
<     def write(self, stream=sys.stdout):
<         """write changelog to stream"""
<         stream.write(self.format_title())
<         for entry in self.entries:
<             entry.write(stream)
diff -r -N code-worker/tasks/clonedigger/logilab/common/clcommands.py code-worker/code-worker/tasks/clonedigger/logilab/common/clcommands.py
1,165d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """provides helper functions to handle a command line tool providing more than
< one command
< e.g called as "tool command [options] args..." where <options> and <args> are
< command'specific
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< # XXX : merge with optparser ? 
< import sys
< from os.path import basename
< 
< from clonedigger.logilab.common.configuration import Configuration
< 
< 
< DEFAULT_COPYRIGHT = '''\
< Copyright (c) 2004-2008 LOGILAB S.A. (Paris, FRANCE), all rights reserved.
< http://www.logilab.fr/ -- mailto:contact@logilab.fr'''
< 
< 
< class BadCommandUsage(Exception):
<     """Raised when an unknown command is used or when a command is not
<     correctly used
<     """
< 
< 
< class Command(Configuration):
<     """base class for command line commands"""
<     arguments = ''
<     name = ''
<     # hidden from help ?
<     hidden = False
<     # max/min args, None meaning unspecified
<     min_args = None
<     max_args = None
<     def __init__(self, __doc__=None, version=None):
<         if __doc__:
<             usage = __doc__ % (self.name, self.arguments,
<                                self.__doc__.replace('    ', ''))
<         else:
<             usage = self.__doc__.replace('    ', '')
<         Configuration.__init__(self, usage=usage, version=version)
< 
<     def check_args(self, args):
<         """check command's arguments are provided"""
<         if self.min_args is not None and len(args) < self.min_args:
<             raise BadCommandUsage('missing argument')
<         if self.max_args is not None and len(args) > self.max_args:
<             raise BadCommandUsage('too many arguments')
<         
<     def run(self, args):
<         """run the command with its specific arguments"""
<         raise NotImplementedError()
< 
< 
< def pop_arg(args_list, expected_size_after=0, msg="Missing argument"):
<     """helper function to get and check command line arguments"""
<     try:
<         value = args_list.pop(0)
<     except IndexError:
<         raise BadCommandUsage(msg)
<     if expected_size_after is not None and len(args_list) > expected_size_after:
<         raise BadCommandUsage('Too much arguments')
<     return value
< 
< 
< _COMMANDS = {}
< 
< def register_commands(commands):
<     """register existing commands"""
<     for command_klass in commands:
<         _COMMANDS[command_klass.name] = command_klass
< 
< 
< def main_usage(status=0, __doc__=None, copyright=DEFAULT_COPYRIGHT):
<     """display usage for the main program (ie when no command supplied)
<     and exit
<     """
<     commands = _COMMANDS.keys()
<     commands.sort()
<     doc = __doc__ % ('<command>', '<command arguments>',
<                      '''\
< Type "%prog <command> --help" for more information about a specific
< command. Available commands are :\n''')
<     doc = doc.replace('%prog', basename(sys.argv[0]))
<     print 'usage:', doc
<     max_len = max([len(cmd) for cmd in commands]) # list comprehension for py 2.3 support
<     padding = ' '*max_len
<     for command in commands:
<         cmd = _COMMANDS[command]
<         if not cmd.hidden:
<             title = cmd.__doc__.split('.')[0]
<             print ' ', (command+padding)[:max_len], title
<     print '\n', copyright
<     sys.exit(status)
< 
< 
< def cmd_run(cmdname, *args):
<     try:
<         command = _COMMANDS[cmdname](__doc__='%%prog %s %s\n\n%s')
<     except KeyError:
<         raise BadCommandUsage('no %s command' % cmdname)
<     args = command.load_command_line_configuration(args)
<     command.check_args(args)
<     try:
<         command.run(args)
<     except KeyboardInterrupt:
<         print 'interrupted'
<     except BadCommandUsage, err:
<         print 'ERROR: ', err
<         print command.help()
< 
<         
< def main_run(args, doc):
<     """command line tool"""
<     try:
<         arg = args.pop(0)
<     except IndexError:
<         main_usage(status=1, __doc__=doc)
<     if arg in ('-h', '--help'):
<         main_usage(__doc__=doc)
<     try:
<         cmd_run(arg, *args)
<     except BadCommandUsage, err:
<         print 'ERROR: ', err
<         main_usage(1, doc)
< 
< 
< class ListCommandsCommand(Command):
<     """list available commands, useful for bash completion."""
<     name = 'listcommands'
<     arguments = '[command]'    
<     hidden = True
<     
<     def run(self, args):
<         """run the command with its specific arguments"""
<         if args:
<             command = pop_arg(args)
<             cmd = _COMMANDS[command]
<             for optname, optdict in cmd.options:
<                 print '--help'
<                 print '--' + optname
<         else:
<             commands = _COMMANDS.keys()
<             commands.sort()
<             for command in commands:
<                 cmd = _COMMANDS[command]
<                 if not cmd.hidden:
<                     print command
<                 
< register_commands([ListCommandsCommand])
diff -r -N code-worker/tasks/clonedigger/logilab/common/cli.py code-worker/code-worker/tasks/clonedigger/logilab/common/cli.py
1,211d0
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Command line interface helper classes.
<  
<  It provides some default commands, a help system, a default readline
<  configuration with completion and persistent history
< 
< Exemple usage:
< 
<     class BookShell(CLIHelper):
< 
<         def __init__(self):
<             # quit and help are builtins
<             # CMD_MAP keys are commands, values are topics
<             self.CMD_MAP['pionce'] = _("Sommeil")
<             self.CMD_MAP['ronfle'] = _("Sommeil")
<             CLIHelper.__init__(self)
< 
<         help_do_pionce = ("pionce", "pionce duree", _("met ton corps en veille"))
<         def do_pionce(self):
<             print 'nap is good'
< 
<         help_do_ronfle = ("ronfle", "ronfle volume", _("met les autres en veille"))
<         def do_ronfle(self):
<             print 'fuuuuuuuuuuuu rhhhhhrhrhrrh'
< 
<     cl = BookShell()
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< 
< import __builtin__
< if not hasattr(__builtin__, '_'):
<     __builtin__._ = str
<     
< 
< def init_readline(complete_method, histfile=None):
<     """init the readline library if available"""
<     try:
<         import readline
<         readline.parse_and_bind("tab: complete")
<         readline.set_completer(complete_method)
<         string = readline.get_completer_delims().replace(':', '')
<         readline.set_completer_delims(string)
<         if histfile is not None:
<             try:
<                 readline.read_history_file(histfile)
<             except IOError:
<                 pass
<             import atexit
<             atexit.register(readline.write_history_file, histfile)
<     except:
<         print 'readline si not available :-('
< 
< 
< class Completer :
<     """readline completer"""
<     
<     def __init__(self, commands):
<         self.list = commands
<         
<     def complete(self, text, state):
<         """hook called by readline when <tab> is pressed"""
<         n = len(text)
<         matches = []
<         for cmd in self.list :
<             if cmd[:n] == text :
<                 matches.append(cmd)
<         try:
<             return matches[state]
<         except IndexError:
<             return None
< 
< 
< class CLIHelper:
<     """ an abstract command line interface client which recognize commands
<     and provide an help system
<     """
<     
<     CMD_MAP = {'help' : _("Others"),
<                'quit' : _("Others"),
<                }
<     CMD_PREFIX = ''
<     
<     def __init__(self, histfile=None) :
<         self._topics = {}
<         self.commands = None
<         self._completer = Completer(self._register_commands())
<         init_readline(self._completer.complete, histfile)
< 
<     def run(self):
<         """loop on user input, exit on EOF"""
<         while 1:
<             try:
<                 line = raw_input('>>> ')
<             except EOFError:
<                 print 
<                 break
<             s_line = line.strip()
<             if not s_line:
<                 continue
<             args = s_line.split()
<             if self.commands.has_key(args[0]):
<                 try:
<                     cmd = 'do_%s' % self.commands[args[0]]
<                     getattr(self, cmd)(*args[1:])
<                 except EOFError:
<                     break
<                 except:
<                     import traceback
<                     traceback.print_exc()
<             else:
<                 try:
<                     self.handle_line(s_line)
<                 except:
<                     import traceback
<                     traceback.print_exc()
< 
<     def handle_line(self, stripped_line):
<         """method to overload in the concrete class
<         
<         should handle lines wich are not command
<         """
<         raise NotImplementedError()
< 
< 
<     # private methods #########################################################
<     
<     def _register_commands(self):
<         """ register available commands method and return the list of
<         commands name
<         """
<         self.commands = {}
<         self._command_help = {}
<         commands = [attr[3:] for attr in dir(self) if attr[:3] == 'do_']
<         for command in commands:
<             topic = self.CMD_MAP[command]
<             help_method = getattr(self, 'help_do_%s' % command)
<             self._topics.setdefault(topic, []).append(help_method)
<             self.commands[self.CMD_PREFIX + command] = command
<             self._command_help[command] = help_method
<         return self.commands.keys()
< 
<     def _print_help(self, cmd, syntax, explanation):
<         print _('Command %s') % cmd
<         print _('Syntax: %s') % syntax
<         print '\t', explanation
<         print
< 
< 
<     # predefined commands #####################################################
<     
<     def do_help(self, command=None) :
<         """base input of the help system"""
<         if self._command_help.has_key(command):
<             self._print_help(*self._command_help[command])
<         elif command is None or not self._topics.has_key(command):
<             print _("Use help <topic> or help <command>.")
<             print _("Available topics are:")
<             topics = self._topics.keys()
<             topics.sort()
<             for topic in topics:
<                 print '\t', topic
<             print
<             print _("Available commands are:")
<             commands = self.commands.keys()
<             commands.sort()
<             for command in commands:
<                 print '\t', command[len(self.CMD_PREFIX):]
<                 
<         else:
<             print _('Available commands about %s:') % command
<             print
<             for command_help_method in self._topics[command]:
<                 try:
<                     if callable(command_help_method):
<                         self._print_help(*command_help_method())
<                     else:
<                         self._print_help(*command_help_method)
<                 except:
<                     import traceback
<                     traceback.print_exc()
<                     print 'ERROR in help method %s'% (
<                         command_help_method.func_name)
<                 
<     help_do_help = ("help", "help [topic|command]",
<                     _("print help message for the given topic/command or \
< available topics when no argument"))
< 
<     def do_quit(self):
<         """quit the CLI"""
<         raise EOFError()
<     
<     def help_do_quit(self):
<         return ("quit", "quit", _("quit the application"))
diff -r -N code-worker/tasks/clonedigger/logilab/common/compat.py code-worker/code-worker/tasks/clonedigger/logilab/common/compat.py
1,214d0
< # pylint: disable-msg=E0601,W0622,W0611
< #
< # Copyright (c) 2004-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """some wrapper around some builtins introduced in python 2.3, 2.4 and
< 2.5, making them available in for earlier versions of python.
< """
< from __future__ import generators
< 
< from warnings import warn
< 
< from clonedigger.logilab.common.deprecation import class_renamed
< 
< try:
<     set = set
<     frozenset = frozenset
< except NameError:
<     try:
<         from sets import Set as set, ImmutableSet as frozenset
<     except ImportError:
<         class _baseset(object):
<             def __init__(self, values=()):
<                 self._data = {}
<                 warn("This implementation of Set is not complete !",
<                      stacklevel=2)
<                 for v in values:
<                     self._data[v] = 1
< 
<             def __or__(self, other):
<                 result = self.__class__(self._data.keys())
<                 for val in other:
<                     result.add(val)
<                 return result
<             __add__ = __or__
<             
<             def __and__(self, other):
<                 result = self.__class__()
<                 for val in other:
<                     if val in self._data:
<                         result.add(val)
<                 return result
<             
<             def __sub__(self, other):
<                 result = self.__class__(self._data.keys())
<                 for val in other:
<                     if val in self._data:
<                         result.remove(val)
<                 return result
<             
<             def __cmp__(self, other):
<                 keys = self._data.keys()
<                 okeys = other._data.keys()
<                 keys.sort()
<                 okeys.sort()
<                 return cmp(keys, okeys)
<             
<             def __len__(self):
<                 return len(self._data)
< 
<             def __repr__(self):
<                 elements = self._data.keys()
<                 return 'lcc.%s(%r)' % (self.__class__.__name__, elements)
<             __str__ = __repr__
< 
<             def __iter__(self):
<                 return iter(self._data)
< 
<         class frozenset(_baseset):
<             """immutable set (can be set in dictionnaries)"""
<             def __init__(self, values=()):
<                 super(frozenset, self).__init__(values)
<                 self._hashcode = None
<                 
<             def _compute_hash(self):
<                 """taken from python stdlib (sets.py)"""
<                 # Calculate hash code for a set by xor'ing the hash codes of
<                 # the elements.  This ensures that the hash code does not depend
<                 # on the order in which elements are added to the set.  This is
<                 # not called __hash__ because a BaseSet should not be hashable;
<                 # only an ImmutableSet is hashable.
<                 result = 0
<                 for elt in self:
<                     result ^= hash(elt)
<                 return result
<             
<             def __hash__(self):
<                 """taken from python stdlib (sets.py)"""
<                 if self._hashcode is None:
<                     self._hashcode = self._compute_hash()
<                 return self._hashcode
< 
<             
<         class set(_baseset):
<             """mutable set"""
<             def add(self, value):
<                 self._data[value] = 1
< 
<             def remove(self, element):
<                 """removes <element> from set"""
<                 del self._data[element]
< 
<             def pop(self):
<                 """pops an arbitrary element from set"""
<                 return self._data.popitem()[0]
< 
<             def __hash__(self):
<                 """mutable et cannot be hashed."""
<                 raise TypeError("set objects are not hashable")
< 
<         del _baseset # don't explicity provide this class
< 
< Set = class_renamed('Set', set, 'logilab.common.compat.Set is deprecated, '
<                     'use logilab.common.compat.set instead')
< 
< try:
<     from itertools import izip, chain, imap
< except ImportError:
<     # from itertools documentation ###
<     def izip(*iterables):
<         iterables = map(iter, iterables)
<         while iterables:
<             result = [i.next() for i in iterables]
<             yield tuple(result)
< 
<     def chain(*iterables):
<         for it in iterables:
<             for element in it:
<                 yield element
<                 
<     def imap(function, *iterables):
<         iterables = map(iter, iterables)
<         while True:
<             args = [i.next() for i in iterables]
<             if function is None:
<                 yield tuple(args)
<             else:
<                 yield function(*args)                
< try:
<     sum = sum
<     enumerate = enumerate
< except NameError:
<     # define the sum and enumerate functions (builtins introduced in py 2.3)
<     import operator
<     def sum(seq, start=0):
<         """Returns the sum of all elements in the sequence"""
<         return reduce(operator.add, seq, start)
< 
<     def enumerate(iterable):
<         """emulates the python2.3 enumerate() function"""
<         i = 0
<         for val in iterable:
<             yield i, val
<             i += 1
<         #return zip(range(len(iterable)), iterable)
< try:
<     sorted = sorted
<     reversed = reversed
< except NameError:
<     
<     def sorted(iterable, cmp=None, key=None, reverse=False):
<         original = list(iterable)
<         if key:
<             l2 = [(key(elt), index) for index, elt in enumerate(original)]
<         else:
<             l2 = original
<         l2.sort(cmp)
<         if reverse:
<             l2.reverse()
<         if key:
<             return [original[index] for elt, index in l2]
<         return l2
<     
<     def reversed(l):
<         l2 = list(l)
<         l2.reverse()
<         return l2
< 
< # Python2.5 builtins
< try:
<     any = any
<     all = all
< except NameError:
<     def any(iterable):
<         """any(iterable) -> bool
< 
<         Return True if bool(x) is True for any x in the iterable.
<         """
<         for elt in iterable:
<             if elt:
<                 return True
<         return False
<     
<     def all(iterable):
<         """all(iterable) -> bool
< 
<         Return True if bool(x) is True for all values x in the iterable.
<         """
<         for elt in iterable:
<             if not elt:
<                 return False
<         return True
diff -r -N code-worker/tasks/clonedigger/logilab/common/configuration.py code-worker/code-worker/tasks/clonedigger/logilab/common/configuration.py
1,888d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some classes used to handle advanced configuration in simple to
< complex applications.
< 
< It's able to load the configuration from a file and or command line
< options, to generate a sample configuration file or to display program's
< usage. It basically fill the gap between optik/optparse and ConfigParser,
< with some additional data types (available as standalone optik extension
< in the `optik_ext` module)
< 
< 
< Quick start: simplest usage
< ```````````````````````````
< 
< import sys
< from clonedigger.logilab.common.configuration import Configuration
< 
< options = [('dothis', {'type':'yn', 'default': True, 'metavar': '<y or n>'}),
<            ('value', {'type': 'string', 'metavar': '<string>'}),
<            ('multiple', {'type': 'csv', 'default': ('yop',),
<                          'metavar': '<comma separated values>',
<                          'help': 'you can also document the option'}),
<            ('number', {'type': 'int', 'default':2, 'metavar':'<int>'}),
<            ]
< config = Configuration(options=options, name='My config')
< print config['dothis']
< print config['value']
< print config['multiple']
< print config['number']
< 
< print config.help()
< 
< f = open('myconfig.ini', 'w')
< f.write('''[MY CONFIG]
< number = 3
< dothis = no
< multiple = 1,2,3
< ''')
< f.close()
< config.load_file_configuration('myconfig.ini')
< print config['dothis']
< print config['value']
< print config['multiple']
< print config['number']
< 
< sys.argv = ['mon prog', '--value', 'bacon', '--multiple', '4,5,6',
<             'nonoptionargument']
< print config.load_command_line_configuration()
< print config['value']
< 
< config.generate_config()
< 
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< from __future__ import generators 
< 
< __docformat__ = "restructuredtext en"
< __all__ = ('OptionsManagerMixIn', 'OptionsProviderMixIn',
<            'ConfigurationMixIn', 'Configuration',
<            'OptionsManager2ConfigurationAdapter')
< 
< import os
< import sys
< import re
< from os.path import exists
< from copy import copy
< from ConfigParser import ConfigParser, NoOptionError, NoSectionError
< 
< from clonedigger.logilab.common.compat import set
< from clonedigger.logilab.common.textutils import normalize_text, unquote
< from clonedigger.logilab.common.optik_ext import OptionParser, OptionGroup, Values, \
<      OptionValueError, OptionError, HelpFormatter, generate_manpage, check_date, \
<      check_yn, check_csv, check_file, check_color, check_named, check_password,\
<      NO_DEFAULT, OPTPARSE_FORMAT_DEFAULT
< 
< REQUIRED = []
< 
< class UnsupportedAction(Exception):
<     """raised by set_option when it doesn't know what to do for an action"""
< 
< # validation functions ########################################################
< 
< def choice_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'choice'
<     """
<     if not value in opt_dict['choices']:
<         msg = "option %s: invalid value: %r, should be in %s"
<         raise OptionValueError(msg % (name, value, opt_dict['choices']))
<     return value
< 
< def multiple_choice_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'choice'
<     """
<     choices = opt_dict['choices']
<     values = check_csv(None, name, value)
<     for value in values:
<         if not value in choices:
<             msg = "option %s: invalid value: %r, should be in %s"
<             raise OptionValueError(msg % (name, value, choices))
<     return values
< 
< def csv_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'csv'
<     """
<     return check_csv(None, name, value)
< 
< def yn_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'yn'
<     """
<     return check_yn(None, name, value)
< 
< def named_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'named'
<     """
<     return check_named(None, name, value)
< 
< def file_validator(opt_dict, name, value):
<     """validate and return a filepath for option of type 'file'"""
<     return check_file(None, name, value)
< 
< def color_validator(opt_dict, name, value):
<     """validate and return a valid color for option of type 'color'"""
<     return check_color(None, name, value)
< 
< def password_validator(opt_dict, name, value):
<     """validate and return a string for option of type 'password'"""
<     return check_password(None, name, value)
< 
< def date_validator(opt_dict, name, value):
<     """validate and return a mx DateTime object for option of type 'date'"""
<     return check_password(None, name, value)
< 
< 
< VALIDATORS = {'string' : unquote,
<               'int' : int,
<               'float': float,
<               'file': file_validator,
<               'font': unquote,
<               'color': color_validator,
<               'regexp': re.compile,
<               'csv': csv_validator,
<               'yn': yn_validator,
<               'bool': yn_validator,
<               'named': named_validator,
<               'password': password_validator,
<               'date': date_validator,
<               'choice': choice_validator,
<               'multiple_choice': multiple_choice_validator,
<               }
< 
< def _call_validator(opttype, optdict, option, value):
<     if not VALIDATORS.has_key(opttype):
<         raise Exception('Unsupported type "%s"' % opttype)
<     try:
<         return VALIDATORS[opttype](optdict, option, value)
<     except TypeError:
<         try:
<             return VALIDATORS[opttype](value)
<         except OptionValueError:
<             raise
<         except:
<             raise OptionValueError('%s value (%r) should be of type %s' %
<                                    (option, value, opttype))
< 
< # user input functions ########################################################
< 
< def input_password(optdict, question='password:'):
<     from getpass import getpass
<     while True:
<         value = getpass(question)
<         value2 = getpass('confirm: ')
<         if value == value2:
<             return value
<         print 'password mismatch, try again'
< 
< def input_string(optdict, question):
<     value = raw_input(question).strip()
<     return value or None
< 
< def _make_input_function(opttype):
<     def input_validator(optdict, question):
<         while True:
<             value = raw_input(question)
<             if not value.strip():
<                 return None
<             try:
<                 return _call_validator(opttype, optdict, None, value)
<             except OptionValueError, ex:
<                 msg = str(ex).split(':', 1)[-1].strip()
<                 print 'bad value: %s' % msg
<     return input_validator
< 
< INPUT_FUNCTIONS = {
<     'string': input_string,
<     'password': input_password,
<     }
< 
< for opttype in VALIDATORS.keys():
<     INPUT_FUNCTIONS.setdefault(opttype, _make_input_function(opttype))
<     
< def expand_default(self, option):
<     """monkey patch OptionParser.expand_default since we have a particular
<     way to handle defaults to avoid overriding values in the configuration
<     file
<     """
<     if self.parser is None or not self.default_tag:
<         return option.help
<     optname = option._long_opts[0][2:]
<     try:
<         provider = self.parser.options_manager._all_options[optname]
<     except KeyError:
<         value = None
<     else:
<         optdict = provider.get_option_def(optname)
<         optname = provider.option_name(optname, optdict)
<         value = getattr(provider.config, optname, optdict)
<         value = format_option_value(optdict, value)
<     if value is NO_DEFAULT or not value:
<         value = self.NO_DEFAULT_VALUE
<     return option.help.replace(self.default_tag, str(value))
< 
<     
< def convert(value, opt_dict, name=''):
<     """return a validated value for an option according to its type
<     
<     optional argument name is only used for error message formatting
<     """
<     try:
<         _type = opt_dict['type']
<     except KeyError:
<         # FIXME
<         return value
<     return _call_validator(_type, opt_dict, name, value)
< 
< def comment(string):
<     """return string as a comment"""
<     lines = [line.strip() for line in string.splitlines()]
<     return '# ' + ('%s# ' % os.linesep).join(lines)
< 
< def format_option_value(optdict, value):
<     """return the user input's value from a 'compiled' value"""
<     if isinstance(value, (list, tuple)):
<         value = ','.join(value)
<     elif isinstance(value, dict):
<         value = ','.join(['%s:%s' % (k,v) for k,v in value.items()])    
<     elif hasattr(value, 'match'): # optdict.get('type') == 'regexp'
<         # compiled regexp
<         value = value.pattern
<     elif optdict.get('type') == 'yn':
<         value = value and 'yes' or 'no'
<     elif isinstance(value, (str, unicode)) and value.isspace():
<         value = "'%s'" % value
<     return value
< 
< def ini_format_section(stream, section, options, doc=None):
<     """format an options section using the INI format"""
<     if doc:
<         print >> stream, comment(doc)
<     print >> stream, '[%s]' % section
<     for optname, optdict, value in options:
<         value = format_option_value(optdict, value)
<         help = optdict.get('help')
<         if help:
<             print >> stream
<             print >> stream, normalize_text(help, line_len=79, indent='# ')
<         else:
<             print >> stream
<         if value is None:
<             print >> stream, '#%s=' % optname
<         else:
<             print >> stream, '%s=%s' % (optname, str(value).strip())
<         
< format_section = ini_format_section
< 
< def rest_format_section(stream, section, options, doc=None):
<     """format an options section using the INI format"""
<     if section:
<         print >> stream, '%s\n%s' % (section, "'"*len(section))
<     if doc:
<         print >> stream, normalize_text(doc, line_len=79, indent='')
<         print >> stream
<     for optname, optdict, value in options:
<         help = optdict.get('help')
<         print >> stream, ':%s:' % optname
<         if help:
<             print >> stream, normalize_text(help, line_len=79, indent='  ')
<         if value:
<             print >> stream, '  Default: %s' % format_option_value(optdict, value)
< 
< 
< class OptionsManagerMixIn(object):
<     """MixIn to handle a configuration from both a configuration file and
<     command line options
<     """
<     
<     def __init__(self, usage, config_file=None, version=None, quiet=0):
<         self.config_file = config_file
<         self.reset_parsers(usage, version=version)
<         # list of registered options providers
<         self.options_providers = []
<         # dictionary assocating option name to checker
<         self._all_options = {}
<         self._short_options = {}
<         self._nocallback_options = {}
<         # verbosity
<         self.quiet = quiet
< 
<     def reset_parsers(self, usage='', version=None):
<         # configuration file parser
<         self._config_parser = ConfigParser()
<         # command line parser
<         self._optik_parser = OptionParser(usage=usage, version=version)
<         self._optik_parser.options_manager = self
<         
<     def register_options_provider(self, provider, own_group=True):
<         """register an options provider"""
<         assert provider.priority <= 0, "provider's priority can't be >= 0"
<         for i in range(len(self.options_providers)):
<             if provider.priority > self.options_providers[i].priority:
<                 self.options_providers.insert(i, provider)
<                 break
<         else:
<             self.options_providers.append(provider)
<         non_group_spec_options = [option for option in provider.options
<                                   if not option[1].has_key('group')]
<         groups = getattr(provider, 'option_groups', ())
<         if own_group:
<             self.add_option_group(provider.name.upper(), provider.__doc__,
<                                   non_group_spec_options, provider)
<         else:
<             for opt_name, opt_dict in non_group_spec_options:
<                 args, opt_dict = self.optik_option(provider, opt_name, opt_dict)
<                 self._optik_parser.add_option(*args, **opt_dict)
<                 self._all_options[opt_name] = provider                
<         for gname, gdoc in groups:
<             goptions = [option for option in provider.options
<                         if option[1].get('group') == gname]
<             self.add_option_group(gname, gdoc, goptions, provider)
<         
<     def add_option_group(self, group_name, doc, options, provider):
<         """add an option group including the listed options
<         """
<         # add section to the config file
<         self._config_parser.add_section(group_name)
<         # add option group to the command line parser
<         if options:
<             group = OptionGroup(self._optik_parser,
<                                 title=group_name.capitalize())
<             self._optik_parser.add_option_group(group)
<         # add provider's specific options
<         for opt_name, opt_dict in options:
<             args, opt_dict = self.optik_option(provider, opt_name, opt_dict)
<             group.add_option(*args, **opt_dict)
<             self._all_options[opt_name] = provider
<             
<     def optik_option(self, provider, opt_name, opt_dict):
<         """get our personal option definition and return a suitable form for
<         use with optik/optparse
<         """
<         opt_dict = copy(opt_dict)
<         if opt_dict.has_key('action'):
<             self._nocallback_options[provider] = opt_name
<         else:
<             opt_dict['action'] = 'callback'
<             opt_dict['callback'] = self.cb_set_provider_option
<         for specific in ('default', 'group', 'inputlevel'):
<             if opt_dict.has_key(specific):
<                 del opt_dict[specific]
<                 if (OPTPARSE_FORMAT_DEFAULT
<                     and specific == 'default' and opt_dict.has_key('help')):
<                     opt_dict['help'] += ' [current: %default]'
<         args = ['--' + opt_name]
<         if opt_dict.has_key('short'):
<             self._short_options[opt_dict['short']] = opt_name
<             args.append('-' + opt_dict['short'])
<             del opt_dict['short']
<         available_keys = set(self._optik_parser.option_class.ATTRS)
<         for key in opt_dict.keys():
<             if not key in available_keys:
<                 opt_dict.pop(key)
<         return args, opt_dict
<             
<     def cb_set_provider_option(self, option, opt_name, value, parser):
<         """optik callback for option setting"""
<         if opt_name.startswith('--'):
<             # remove -- on long option
<             opt_name = opt_name[2:]
<         else:
<             # short option, get its long equivalent
<             opt_name = self._short_options[opt_name[1:]]
<         # trick since we can't set action='store_true' on options
<         if value is None:
<             value = 1
<         self.global_set_option(opt_name, value)
<         
<     def global_set_option(self, opt_name, value):
<         """set option on the correct option provider"""
<         self._all_options[opt_name].set_option(opt_name, value)
< 
<     def generate_config(self, stream=None, skipsections=()):
<         """write a configuration file according to the current configuration
<         into the given stream or stdout
<         """
<         stream = stream or sys.stdout
<         printed = False
<         for provider in self.options_providers:
<             default_options = []
<             sections = {}
<             for section, options in provider.options_by_section():
<                 if section in skipsections:
<                     continue
<                 options = [(n, d, v) for (n, d, v) in options
<                            if d.get('type') is not None]
<                 if not options:
<                     continue
<                 if section is None:
<                     section = provider.name
<                     doc = provider.__doc__
<                 else:
<                     doc = None
<                 if printed:
<                     print >> stream, '\n'
<                 format_section(stream, section.upper(), options, doc)
<                 printed = True
< 
<     def generate_manpage(self, pkginfo, section=1, stream=None):
<         """write a man page for the current configuration into the given
<         stream or stdout
<         """
<         generate_manpage(self._optik_parser, pkginfo,
<                          section, stream=stream or sys.stdout)
<         
<     # initialization methods ##################################################
< 
<     def load_provider_defaults(self):
<         """initialize configuration using default values"""
<         for provider in self.options_providers:
<             provider.load_defaults()
<             
<     def load_file_configuration(self, config_file=None):
<         """load the configuration from file"""
<         self.read_config_file(config_file)
<         self.load_config_file()
<         
<     def read_config_file(self, config_file=None):
<         """read the configuration file but do not load it (ie dispatching
<         values to each options provider)
<         """
<         if config_file is None:
<             config_file = self.config_file
<         if config_file and exists(config_file):
<             self._config_parser.read([config_file])
<         elif not self.quiet:
<             msg = 'No config file found, using default configuration'
<             print >> sys.stderr, msg
<             return
<     
<     def input_config(self, onlysection=None, inputlevel=0, stream=None):
<         """interactivly get configuration values by asking to the user and generate
<         a configuration file
<         """
<         if onlysection is not None:
<             onlysection = onlysection.upper()
<         for provider in self.options_providers:
<             for section, option, optdict in provider.all_options():
<                 if onlysection is not None and section != onlysection:
<                     continue
<                 provider.input_option(option, optdict, inputlevel)
<         # now we can generate the configuration file
<         if stream is not None:
<             self.generate_config(stream)
< 
<     def load_config_file(self):
<         """dispatch values previously read from a configuration file to each
<         options provider)
<         """
<         parser = self._config_parser        
<         for provider in self.options_providers:
<             for section, option, optdict in provider.all_options():
<                 try:
<                     value = parser.get(section, option)
<                     provider.set_option(option, value, opt_dict=optdict)
<                 except (NoSectionError, NoOptionError), ex:
<                     continue
< 
<     def load_configuration(self, **kwargs):
<         """override configuration according to given parameters
<         """
<         for opt_name, opt_value in kwargs.items():
<             opt_name = opt_name.replace('_', '-')
<             provider = self._all_options[opt_name]
<             provider.set_option(opt_name, opt_value)
<             
<     def load_command_line_configuration(self, args=None):
<         """override configuration according to command line parameters
< 
<         return additional arguments
<         """
<         # monkey patch optparse to deal with our default values
<         try:
<             expand_default_backup = HelpFormatter.expand_default
<             HelpFormatter.expand_default = expand_default
<         except AttributeError:
<             # python < 2.4: nothing to be done
<             pass
<         try:
<             if args is None:
<                 args = sys.argv[1:]
<             else:
<                 args = list(args)
<             (options, args) = self._optik_parser.parse_args(args=args)
<             for provider in self._nocallback_options.keys():
<                 config = provider.config
<                 for attr in config.__dict__.keys():
<                     value = getattr(options, attr, None)
<                     if value is None:
<                         continue
<                     setattr(config, attr, value)
<             return args
<         finally:
<             if hasattr(HelpFormatter, 'expand_default'):
<                 # unpatch optparse to avoid side effects
<                 HelpFormatter.expand_default = expand_default_backup
< 
< 
<     # help methods ############################################################
< 
<     def add_help_section(self, title, description):
<         """add a dummy option section for help purpose """
<         group = OptionGroup(self._optik_parser,
<                             title=title.capitalize(),
<                             description=description)
<         self._optik_parser.add_option_group(group)
<         
<     def help(self):
<         """return the usage string for available options """
<         return self._optik_parser.format_help()
<     
< 
< class Method(object):
<     """used to ease late binding of default method (so you can define options
<     on the class using default methods on the configuration instance)
<     """
<     def __init__(self, methname):
<         self.method = methname
<         self._inst = None
<         
<     def bind(self, instance):
<         """bind the method to its instance"""
<         if self._inst is None:
<             self._inst = instance
<         
<     def __call__(self):
<         assert self._inst, 'unbound method'
<         return getattr(self._inst, self.method)()
< 
<         
< class OptionsProviderMixIn(object):
<     """Mixin to provide options to an OptionsManager"""
<     
<     # those attributes should be overridden
<     priority = -1
<     name = 'default'
<     options = ()
< 
<     def __init__(self):
<         self.config = Values()
<         for option in self.options:
<             try:
<                 option, optdict = option
<             except ValueError:
<                 raise Exception('Bad option: %r' % option)
<             if isinstance(optdict.get('default'), Method):
<                 optdict['default'].bind(self)
<         self.load_defaults()
<                 
<     def load_defaults(self):
<         """initialize the provider using default values"""
<         for opt_name, opt_dict in self.options:
<             action = opt_dict.get('action')
<             if action != 'callback':
<                 # callback action have no default
<                 default = self.option_default(opt_name, opt_dict)
<                 if default is REQUIRED:
<                     continue
<                 self.set_option(opt_name, default, action, opt_dict)
< 
<     def option_default(self, opt_name, opt_dict=None):
<         """return the default value for an option"""
<         if opt_dict is None:
<             opt_dict = self.get_option_def(opt_name)
<         default = opt_dict.get('default')
<         if callable(default):
<             default = default()
<         return default
<         
<     def option_name(self, opt_name, opt_dict=None):
<         """get the config attribute corresponding to opt_name
<         """
<         if opt_dict is None:
<             opt_dict = self.get_option_def(opt_name)
<         return opt_dict.get('dest', opt_name.replace('-', '_'))
<     
<     def option_value(self, opt_name):
<         """get the current value for the given option"""
<         return getattr(self.config, self.option_name(opt_name), None)
<         
<     def set_option(self, opt_name, value, action=None, opt_dict=None):
<         """method called to set an option (registered in the options list)
<         """
<         # print "************ setting option", opt_name," to value", value
<         if opt_dict is None:
<             opt_dict = self.get_option_def(opt_name)
<         if value is not None:
<             value = convert(value, opt_dict, opt_name)
<         if action is None:
<             action = opt_dict.get('action', 'store')
<         if opt_dict.get('type') == 'named': # XXX need specific handling
<             optname = self.option_name(opt_name, opt_dict)
<             currentvalue = getattr(self.config, optname, None)
<             if currentvalue:
<                 currentvalue.update(value)
<                 value = currentvalue
<         if action == 'store':
<             setattr(self.config, self.option_name(opt_name, opt_dict), value)
<         elif action in ('store_true', 'count'):
<             setattr(self.config, self.option_name(opt_name, opt_dict), 0)
<         elif action == 'store_false':
<             setattr(self.config, self.option_name(opt_name, opt_dict), 1)
<         elif action == 'append':
<             opt_name = self.option_name(opt_name, opt_dict)
<             _list = getattr(self.config, opt_name, None)
<             if _list is None:
<                 if type(value) in (type(()), type([])):
<                     _list = value
<                 elif value is not None:
<                     _list = []
<                     _list.append(value)
<                 setattr(self.config, opt_name, _list)
<             elif type(_list) is type(()):
<                 setattr(self.config, opt_name, _list + (value,))
<             else:
<                 _list.append(value)
<         else:
<             raise UnsupportedAction(action)
< 
<     def input_option(self, option, optdict, inputlevel=99):
<         default = self.option_default(option, optdict)
<         if default is REQUIRED:
<             defaultstr = '(required): '
<         elif optdict.get('inputlevel', 0) > inputlevel:
<             self.set_option(option, default, opt_dict=optdict)
<             return
<         elif optdict['type'] == 'password' or default is None:
<             defaultstr = ': '
<         else:
<             defaultstr = '(default: %s): ' % format_option_value(optdict, default)
<         print ':%s:' % option
<         print optdict.get('help') or option
<         inputfunc = INPUT_FUNCTIONS[optdict['type']]
<         value = inputfunc(optdict, defaultstr)
<         while default is REQUIRED and not value:
<             print 'please specify a value'
<             value = inputfunc(optdict, '%s: ' % option)
<         if value is None and default is not None:
<             value = default
<         self.set_option(option, value, opt_dict=optdict)
<             
<     def get_option_def(self, opt_name):
<         """return the dictionary defining an option given it's name"""
<         assert self.options
<         for opt in self.options:
<             if opt[0] == opt_name:
<                 return opt[1]
<         raise OptionError('no such option in section %r' % self.name, opt_name)
< 
< 
<     def all_options(self):
<         """return an iterator on available options for this provider
<         option are actually described by a 3-uple:
<         (section, option name, option dictionary)
<         """        
<         for section, options in self.options_by_section():
<             if section is None:
<                 section = self.name.upper()
<             for option, optiondict, value in options:
<                 yield section, option, optiondict
<                 
<     def options_by_section(self):
<         """return an iterator on options grouped by section
<         
<         (section, [list of (optname, optdict, optvalue)])
<         """
<         sections = {}
<         for optname, optdict in self.options:
<             sections.setdefault(optdict.get('group'), []).append(
<                 (optname, optdict, self.option_value(optname)))
<         if None in sections:
<             yield None, sections.pop(None)
<         for section, options in sections.items():
<             yield section.upper(), options
<        
< 
< class ConfigurationMixIn(OptionsManagerMixIn, OptionsProviderMixIn):
<     """basic mixin for simple configurations which don't need the
<     manager / providers model
<     """
<     def __init__(self, *args, **kwargs):
<         if not args:
<             kwargs.setdefault('usage', '')
<         kwargs.setdefault('quiet', 1)
<         OptionsManagerMixIn.__init__(self, *args, **kwargs)
<         OptionsProviderMixIn.__init__(self)
<         if not getattr(self, 'option_groups', None):
<             self.option_groups = []
<             for option, optdict in self.options:
<                 try:
<                     gdef = (optdict['group'], '')
<                 except KeyError:
<                     continue
<                 if not gdef in self.option_groups:
<                     self.option_groups.append(gdef)
<         self.register_options_provider(self, own_group=0)
< 
<     def register_options(self, options):
<         """add some options to the configuration"""
<         options_by_group = {}
<         for optname, optdict in options:
<             options_by_group.setdefault(optdict.get('group', self.name.upper()), []).append((optname, optdict))
<         for group, options in options_by_group.items():
<             self.add_option_group(group, None, options, self)
<         self.options += tuple(options)
<         
<     def load_defaults(self):
<         OptionsProviderMixIn.load_defaults(self)
< 
<     def __getitem__(self, key):
<         try:
<             return getattr(self.config, self.option_name(key))
<         except (OptionValueError, AttributeError):
<             raise KeyError(key)
< 
<     def __setitem__(self, key, value):
<         self.set_option(self.option_name(key), value)
<         
<     def get(self, key, default=None):
<         try:
<             return getattr(self.config, self.option_name(key))
<         except (OptionError, AttributeError):
<             return default
<         
< 
< class Configuration(ConfigurationMixIn):
<     """class for simple configurations which don't need the
<     manager / providers model and prefer delegation to inheritance
< 
<     configuration values are accessible through a dict like interface
<     """
< 
<     def __init__(self, config_file=None, options=None, name=None,
<                  usage=None, doc=None, version=None):
<         if options is not None:
<             self.options = options
<         if name is not None:
<             self.name = name
<         if doc is not None:
<             self.__doc__ = doc
<         super(Configuration, self).__init__(config_file=config_file, usage=usage, version=version)
< 
< 
< class OptionsManager2ConfigurationAdapter(object):
<     """Adapt an option manager to behave like a
<     `logilab.common.configuration.Configuration` instance
<     """
<     def __init__(self, provider):
<         self.config = provider
<         
<     def __getattr__(self, key):
<         return getattr(self.config, key)
<         
<     def __getitem__(self, key):
<         provider = self.config._all_options[key]
<         try:
<             return getattr(provider.config, provider.option_name(key))
<         except AttributeError:
<             raise KeyError(key)
< 
<     def __setitem__(self, key, value):
<         self.config.global_set_option(self.config.option_name(key), value)
< 
<     def get(self, key, default=None):
<         provider = self.config._all_options[key]
<         try:
<             return getattr(provider.config, provider.option_name(key))
<         except AttributeError:
<             return default
< 
< 
< def read_old_config(newconfig, changes, configfile):
<     """initialize newconfig from a deprecated configuration file
<     
<     possible changes:
<     * ('renamed', oldname, newname)
<     * ('moved', option, oldgroup, newgroup)
<     * ('typechanged', option, oldtype, newvalue)
<     """
<     # build an index of changes
<     changesindex = {}
<     for action in changes:
<         if action[0] == 'moved':
<             option, oldgroup, newgroup = action[1:]
<             changesindex.setdefault(option, []).append((action[0], oldgroup, newgroup))
<             continue
<         if action[0] == 'renamed':
<             oldname, newname = action[1:]
<             changesindex.setdefault(newname, []).append((action[0], oldname))
<             continue
<         if action[0] == 'typechanged':
<             option, oldtype, newvalue = action[1:]
<             changesindex.setdefault(option, []).append((action[0], oldtype, newvalue))
<             continue        
<         if action[1] in ('added', 'removed'):
<             continue # nothing to do here
<         raise Exception('unknown change %s' % action[0])    
<     # build a config object able to read the old config
<     options = []
<     for optname, optdef in newconfig.options:
<         for action in changesindex.pop(optname, ()):
<             if action[0] == 'moved':
<                 oldgroup, newgroup = action[1:]
<                 optdef = optdef.copy()
<                 optdef['group'] = oldgroup
<             elif action[0] == 'renamed':
<                 optname = action[1]
<             elif action[0] == 'typechanged':
<                 oldtype = action[1]
<                 optdef = optdef.copy()
<                 optdef['type'] = oldtype
<         options.append((optname, optdef))
<     if changesindex:
<         raise Exception('unapplied changes: %s' % changesindex)
<     oldconfig = Configuration(options=options, name=newconfig.name)
<     # read the old config
<     oldconfig.load_file_configuration(configfile)
<     # apply values reverting changes
<     changes.reverse()
<     done = set()
<     for action in changes:
<         if action[0] == 'renamed':
<             oldname, newname = action[1:]
<             newconfig[newname] = oldconfig[oldname]
<             done.add(newname)
<         elif action[0] == 'typechanged':
<             optname, oldtype, newvalue = action[1:]
<             newconfig[optname] = newvalue
<             done.add(optname)
<     for optname, optdef in newconfig.options:
<         if not optname in done:
<             newconfig.set_option(optname, oldconfig[optname], opt_dict=optdef)
< 
< 
< def merge_options(options):
<     """preprocess options to remove duplicate"""
<     alloptions = {}
<     options = list(options)
<     for i in range(len(options)-1, -1, -1):
<         optname, optdict = options[i]
<         if optname in alloptions:
<             options.pop(i)
<             alloptions[optname].update(optdict)
<         else:
<             alloptions[optname] = optdict
<     return tuple(options)
diff -r -N code-worker/tasks/clonedigger/logilab/common/corbautils.py code-worker/code-worker/tasks/clonedigger/logilab/common/corbautils.py
1,96d0
< """A set of utility function to ease the use of OmniORBpy."""
< 
< __revision__ = '$Id: corbautils.py,v 1.2 2005-11-22 13:13:00 syt Exp $'
< 
< from omniORB import CORBA, PortableServer
< import CosNaming
< 
< orb = None
< 
< def get_orb():
<     """
<     returns a reference to the ORB.
<     The first call to the method initialized the ORB
<     This method is mainly used internally in the module.
<     """
<     
<     global orb
<     if orb is None:
<         import sys
<         orb = CORBA.ORB_init(sys.argv, CORBA.ORB_ID)
<     return orb
< 
< def get_root_context():
<     """
<     returns a reference to the NameService object.
<     This method is mainly used internally in the module.
<     """
<     
<     orb = get_orb()
<     nss = orb.resolve_initial_references("NameService")
<     rootContext = nss._narrow(CosNaming.NamingContext)
<     assert rootContext is not None,"Failed to narrow root naming context"
<     return rootContext
< 
< def register_object_name(object, namepath):
<     """
<     Registers a object in the NamingService.
<     The name path is a list of 2-uples (id,kind) giving the path.
< 
<     For instance if the path of an object is [('foo',''),('bar','')],
<     it is possible to get a reference to the object using the URL
<     'corbaname::hostname#foo/bar'.
<     [('logilab','rootmodule'),('chatbot','application'),('chatter','server')]
<     is mapped to
<     'corbaname::hostname#logilab.rootmodule/chatbot.application/chatter.server'
<     
<     The get_object_reference() function can be used to resolve such a URL.
<     """
<     context = get_root_context()
<     for id, kind in namepath[:-1]:
<         name = [CosNaming.NameComponent(id, kind)]
<         try:
<             context = context.bind_new_context(name)
<         except CosNaming.NamingContext.AlreadyBound, ex:
<             context = context.resolve(name)._narrow(CosNaming.NamingContext)
<             assert context is not None, \
<                    'test context exists but is not a NamingContext'
< 
<     id,kind = namepath[-1]
<     name = [CosNaming.NameComponent(id, kind)]
<     try:
<         context.bind(name, object._this())
<     except CosNaming.NamingContext.AlreadyBound, ex:
<         context.rebind(name, object._this())
< 
< def activate_POA():
<     """
<     This methods activates the Portable Object Adapter.
<     You need to call it to enable the reception of messages in your code,
<     on both the client and the server.
<     """
<     orb = get_orb()
<     poa = orb.resolve_initial_references('RootPOA')
<     poaManager = poa._get_the_POAManager()
<     poaManager.activate()
< 
< def run_orb():
<     """
<     Enters the ORB mainloop on the server.
<     You should not call this method on the client.
<     """
<     get_orb().run()
< 
< def get_object_reference(url):
<     """
<     Resolves a corbaname URL to an object proxy.
<     See register_object_name() for examples URLs
<     """
<     return get_orb().string_to_object(url)
< 
< def get_object_string(host, namepath):
<     """given an host name and a name path as described in register_object_name,
<     return a corba string identifier
<     """
<     strname = '/'.join(['.'.join(path_elt) for path_elt in namepath])
<     return 'corbaname::%s#%s' % (host, strname)
diff -r -N code-worker/tasks/clonedigger/logilab/common/daemon.py code-worker/code-worker/tasks/clonedigger/logilab/common/daemon.py
1,144d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< a daemon mix-in class
< """
< 
< __revision__ = '$Id: daemon.py,v 1.10 2005-11-22 13:13:01 syt Exp $'
< 
< import os, signal, sys, time
< from clonedigger.logilab.common.logger import make_logger, LOG_ALERT, LOG_NOTICE
< 
< class DaemonMixIn:
<     """ mixin to make a daemon from watchers/queriers
<     """
< 
<     def __init__(self, configmod) :
<         self.delay = configmod.DELAY
<         self.name = str(self.__class__).split('.')[-1]
<         self._pid_file = os.path.join('/tmp', '%s.pid'%self.name)
<         if os.path.exists(self._pid_file):
<             raise Exception('''Another instance of %s must be running.
< If it i not the case, remove the file %s''' % (self.name, self._pid_file))
<         self._alive = 1
<         self._sleeping = 0
<         treshold = configmod.LOG_TRESHOLD
<         if configmod.NODETACH:
<             configmod.log = make_logger('print', treshold, self.name).log
<         else:
<             configmod.log = make_logger('syslog', treshold, self.name).log
<         self.config = configmod
< 
<     def _daemonize(self):
<         if not self.config.NODETACH:
<             # fork so the parent can exist
<             if (os.fork()):
<                 return -1
<             # deconnect from tty and create a new session
<             os.setsid()
<             # fork again so the parent, (the session group leader), can exit.
<             # as a non-session group leader, we can never regain a controlling
<             # terminal.
<             if (os.fork()):
<                 return -1
<             # move to the root to avoit mount pb
<             os.chdir('/')
<             # set paranoid umask
<             os.umask(077)
<             # write pid in a file
<             f = open(self._pid_file, 'w')
<             f.write(str(os.getpid()))
<             f.close()
<             # close standard descriptors
<             sys.stdin.close()
<             sys.stdout.close()
<             sys.stderr.close()
<             # put signal handler
<             signal.signal(signal.SIGTERM, self.signal_handler)
<             signal.signal(signal.SIGHUP, self.signal_handler)
< 		
<         
<     def run(self):
<         """ optionaly go in daemon mode and
<         do what concrete classe has to do and pauses for delay between runs
<         If self.delay is negative, do a pause before starting
<         """
<         if self._daemonize() == -1:
<             return
<         self.config.log(LOG_NOTICE, '%s instance started' % self.name)
<         if self.delay < 0:
<             self.delay = -self.delay
<             time.sleep(self.delay)
<         while 1:
<             try:
<                 self._run()
<             except Exception, e:
<                 # display for info, sleep, and hope the problem will be solved
<                 # later.
<                 self.config.log(LOG_ALERT, 'Internal error: %s'%(e))
<             if not self._alive:
<                 break
<             try:
<                 self._sleeping = 1
<                 time.sleep(self.delay)
<                 self._sleeping = 0
<             except SystemExit:
<                 break
<         self.config.log(LOG_NOTICE, '%s instance exited'%self.name)
<         # remove pid file
<         os.remove(self._pid_file)
<         
<     def signal_handler(self, sig_num, stack_frame):
<         if sig_num == signal.SIGTERM:
<             if self._sleeping:
<                 # we are sleeping so we can exit without fear
<                 self.config.log(LOG_NOTICE, 'exit on SIGTERM')
<                 sys.exit(0)
<             else:
<                 self.config.log(LOG_NOTICE, 'exit on SIGTERM (on next turn)')
<                 self._alive = 0
<         elif sig_num == signal.SIGHUP:
<             self.config.log(LOG_NOTICE, 'reloading configuration on SIGHUP')
<             reload(self.config)
< 
<     def _run(self):
<         """should be overidden in the mixed class"""
<         raise NotImplementedError()
<     
< ## command line utilities ######################################################
< 
< L_OPTIONS = ["help", "log=", "delay=", 'no-detach']
< S_OPTIONS = 'hl:d:n'
< 
< def print_help(modconfig):
<     print """  --help or -h
<     displays this message
<   --log <log_level>
<     log treshold (7 record everything, 0 record only emergency.)
<     Defaults to %s
<   --delay <delay>
<     the number of seconds between two runs.
<     Defaults to %s""" % (modconfig.LOG_TRESHOLD, modconfig.DELAY)
< 
< def handle_option(modconfig, opt_name, opt_value, help_meth):
<     if opt_name in ('-h','--help'):            
<         help_meth()
<         sys.exit(0)
<     elif opt_name in ('-l','--log'):
<         modconfig.LOG_TRESHOLD = int(opt_value)
<     elif opt_name in ('-d', '--delay'):
<         modconfig.DELAY = int(opt_value)
<     elif opt_name in ('-n', '--no-detach'):
<         modconfig.NODETACH = 1
diff -r -N code-worker/tasks/clonedigger/logilab/common/date.py code-worker/code-worker/tasks/clonedigger/logilab/common/date.py
1,117d0
< # Copyright (c) 2006-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< 
< """date manipulation helper functions"""
< 
< import math
< 
< try:
<     from mx.DateTime import RelativeDateTime, strptime, Date
<     STEP = 1
< except ImportError:
<     from warnings import warn
<     warn("mxDateTime not found, holiday management won't be available")
<     from datetime import timedelta
<     STEP = timedelta(days=1)
< else:
<     endOfMonth = RelativeDateTime(months=1, day=-1)
< 
<     FRENCH_FIXED_HOLIDAYS = {
<         'jour_an'        : '%s-01-01',
<         'fete_travail'   : '%s-05-01',
<         'armistice1945'  : '%s-05-08',
<         'fete_nat'       : '%s-07-14',
<         'assomption'     : '%s-08-15',
<         'toussaint'      : '%s-11-01',
<         'armistice1918'  : '%s-11-11',
<         'noel'           : '%s-12-25',
<         }
< 
< 
<     FRENCH_MOBILE_HOLIDAYS = {
<         'paques2004'    : '2004-04-12',
<         'ascension2004' : '2004-05-20',
<         'pentecote2004' : '2004-05-31',
< 
<         'paques2005'    : '2005-03-28',
<         'ascension2005' : '2005-05-05',
<         'pentecote2005' : '2005-05-16',
< 
<         'paques2006'    : '2006-04-17',
<         'ascension2006' : '2006-05-25',
<         'pentecote2006' : '2006-06-05',
< 
<         'paques2007'    : '2007-04-09',
<         'ascension2007' : '2007-05-17',
<         'pentecote2007' : '2007-05-28',
< 
<         'paques2008'    : '2008-03-24',
<         'ascension2008' : '2008-05-01',
<         'pentecote2008' : '2008-05-12',
<         }
< 
<     def get_national_holidays(begin, end):
<         """return french national days off between begin and end"""
<         begin = Date(begin.year, begin.month, begin.day)
<         end = Date(end.year, end.month, end.day)
<         holidays = [strptime(datestr, '%Y-%m-%d')
<                     for datestr in FRENCH_MOBILE_HOLIDAYS.values()]
<         for year in xrange(begin.year, end.year+1):
<             for datestr in FRENCH_FIXED_HOLIDAYS.values():
<                 date = strptime(datestr % year, '%Y-%m-%d')
<                 if date not in holidays:
<                     holidays.append(date)
<         return [day for day in holidays if begin <= day < end]
< 
< 
<     def add_days_worked(start, days):
<         """adds date but try to only take days worked into account"""
<         weeks, plus = divmod(days, 5)
<         end = start+(weeks * 7) + plus
<         if end.day_of_week >= 5: # saturday or sunday
<             end += 2
<         end += len([x for x in get_national_holidays(start, end+1)
<                     if x.day_of_week < 5])
<         if end.day_of_week >= 5: # saturday or sunday
<             end += 2
<         return end
< 
<     def nb_open_days(start, end):
<         assert start <= end
<         days = int(math.ceil((end - start).days))
<         weeks, plus = divmod(days, 7)
<         if start.day_of_week > end.day_of_week:
<             plus -= 2
<         elif end.day_of_week == 6:
<             plus -= 1
<         open_days = weeks * 5 + plus
<         nb_week_holidays = len([x for x in get_national_holidays(start, end+1)
<                                 if x.day_of_week < 5 and x < end])
<         return open_days  - nb_week_holidays
< 
< 
< def date_range(begin, end, step=STEP):
<     """
<     enumerate dates between begin and end dates.
< 
<     step can either be oneDay, oneHour, oneMinute, oneSecond, oneWeek
<     use endOfMonth to enumerate months
<     """
<     date = begin
<     while date < end :
<         yield date
<         date += step
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/db.py code-worker/code-worker/tasks/clonedigger/logilab/common/db.py
1,650d0
< # Copyright (c) 2002-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """This modules contains wrappers to get actually replaceable DBAPI2 compliant
< modules and database connection whatever the database and client lib used.
< 
< Currently support:
< 
< - postgresql (pgdb, psycopg, psycopg2, pyPgSQL)
< - mysql (MySQLdb)
< - sqlite (pysqlite2, sqlite, sqlite3)
< 
< just use the `get_connection` function from this module to get a
< wrapped connection.  If multiple drivers for a database are available,
< you can control which one you want to use using the
< `set_prefered_driver` function.
< 
< Additional helpers are also provided for advanced functionalities such
< as listing existing users or databases, creating database... Get the
< helper for your database using the `get_adv_func_helper` function.
< """
< 
< import sys
< import re
< from warnings import warn
< 
< from clonedigger.logilab.common.deprecation import obsolete
< try:
<     from mx.DateTime import DateTimeType, DateTimeDeltaType, strptime
<     HAS_MX_DATETIME = True
< except:
<     HAS_MX_DATETIME = False
<     
< __all__ = ['get_dbapi_compliant_module', 
<            'get_connection', 'set_prefered_driver',
<            'PyConnection', 'PyCursor',
<            'UnknownDriver', 'NoAdapterFound',
<            ]
< 
< class UnknownDriver(Exception):
<     """raised when a unknown driver is given to get connexion"""
< 
< class NoAdapterFound(Exception):
<     """Raised when no Adpater to DBAPI was found"""
<     def __init__(self, obj, objname=None, protocol='DBAPI'):
<         if objname is None:
<             objname = obj.__name__
<         Exception.__init__(self, "Could not adapt %s to protocol %s" %
<                            (objname, protocol))
<         self.adapted_obj = obj
<         self.objname = objname
<         self._protocol = protocol
< 
< 
< def _import_driver_module(driver, drivers, imported_elements=None, quiet=True):
<     """Imports the first module found in 'drivers' for 'driver'
< 
<     :rtype: tuple
<     :returns: the tuple module_object, module_name where module_object
<               is the dbapi module, and modname the module's name
<     """
<     if not driver in drivers:
<         raise UnknownDriver(driver)
<     imported_elements = imported_elements or []
<     for modname in drivers[driver]:
<         try:
<             if not quiet:
<                 print >> sys.stderr, 'Trying %s' % modname
<             module = __import__(modname, globals(), locals(), imported_elements)
<             break
<         except ImportError:
<             if not quiet:
<                 print >> sys.stderr, '%s is not available' % modname
<             continue
<     else:
<         raise ImportError('Unable to import a %s module' % driver)
<     if not imported_elements:
<         for part in modname.split('.')[1:]:
<             module = getattr(module, part)
<     return module, modname
< 
< 
< ## Connection and cursor wrappers #############################################
<         
< class SimpleConnectionWrapper:
<     """A simple connection wrapper in python to decorated C-level connections
<     with additional attributes
<     """
<     def __init__(self, cnx):
<         """Wraps the original connection object"""
<         self._cnx = cnx
< 
<     # XXX : Would it work if only __getattr__ was defined 
<     def cursor(self):
<         """Wraps cursor()"""
<         return self._cnx.cursor()
< 
<     def commit(self):
<         """Wraps commit()"""
<         return self._cnx.commit()
< 
<     def rollback(self):
<         """Wraps rollback()"""
<         return self._cnx.rollback()
< 
<     def close(self):
<         """Wraps close()"""
<         return self._cnx.close()
< 
<     def __getattr__(self, attrname):
<         return getattr(self._cnx, attrname)    
< 
< class PyConnection(SimpleConnectionWrapper):
<     """A simple connection wrapper in python, generating wrapper for cursors as
<     well (useful for profiling)
<     """
<     def __init__(self, cnx):
<         """Wraps the original connection object"""
<         self._cnx = cnx
<         
<     def cursor(self):
<         """Wraps cursor()"""
<         return PyCursor(self._cnx.cursor())
< 
< 
< 
< class PyCursor:
<     """A simple cursor wrapper in python (useful for profiling)"""
<     def __init__(self, cursor):
<         self._cursor = cursor
< 
<     def close(self):
<         """Wraps close()"""
<         return self._cursor.close()
<         
<     def execute(self, *args, **kwargs):
<         """Wraps execute()"""
<         return self._cursor.execute(*args, **kwargs)
< 
<     def executemany(self, *args, **kwargs):
<         """Wraps executemany()"""
<         return self._cursor.executemany(*args, **kwargs)
< 
<     def fetchone(self, *args, **kwargs):
<         """Wraps fetchone()"""
<         return self._cursor.fetchone(*args, **kwargs)
< 
<     def fetchmany(self, *args, **kwargs):
<         """Wraps execute()"""
<         return self._cursor.fetchmany(*args, **kwargs)
< 
<     def fetchall(self, *args, **kwargs):
<         """Wraps fetchall()"""
<         return self._cursor.fetchall(*args, **kwargs)
< 
<     def __getattr__(self, attrname):
<         return getattr(self._cursor, attrname)
<     
< 
< ## Adapters list ##############################################################
<     
< class DBAPIAdapter:
<     """Base class for all DBAPI adpaters"""
< 
<     def __init__(self, native_module, pywrap=False):
<         """
<         :type native_module: module
<         :param native_module: the database's driver adapted module
<         """
<         self._native_module = native_module
<         self._pywrap = pywrap
< 
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Wraps the native module connect method"""
<         kwargs = {'host' : host, 'port' : port, 'database' : database,
<                   'user' : user, 'password' : password}
<         cnx = self._native_module.connect(**kwargs)
<         return self._wrap_if_needed(cnx, user)
< 
<     def _wrap_if_needed(self, cnx, user):
<         """Wraps the connection object if self._pywrap is True, and returns it
<         If false, returns the original cnx object
<         """
<         if self._pywrap:
<             cnx = PyConnection(cnx)
<         try:
<             cnx.logged_user = user
<         except AttributeError:
<             # C or __slots__ object
<             cnx = SimpleConnectionWrapper(cnx)
<             cnx.logged_user = user            
<         return cnx
<     
<     def __getattr__(self, attrname):
<         return getattr(self._native_module, attrname)
< 
<     def process_value(self, value, description, encoding='utf-8', binarywrap=None):
<         typecode = description[1]
<         assert typecode is not None, self # dbapi module isn't supporting type codes, override to return value directly
<         if typecode == self.STRING:
<             if isinstance(value, str):
<                 return unicode(value, encoding, 'replace')
<         elif typecode == self.BOOLEAN:
<             return bool(value)
<         elif typecode == self.BINARY and not binarywrap is None:
<             return binarywrap(value)
< ##                 elif typecode == dbapimod.DATETIME:
< ##                     pass
< ##                 elif typecode == dbapimod.NUMBER:
< ##                     pass
< ##                 else:
< ##                     self.warning("type -%s- unknown for %r (%s) ",
< ##                         typecode, value, type(value))
<         return value
<         
<     
< # Postgresql #########################################################
< 
< class _PgdbAdapter(DBAPIAdapter):
<     """Simple PGDB Adapter to DBAPI (pgdb modules lacks Binary() and NUMBER)
<     """
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self.NUMBER = native_module.pgdbType('int2', 'int4', 'serial',
<                                              'int8', 'float4', 'float8',
<                                              'numeric', 'bool', 'money')
<         
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Wraps the native module connect method"""
<         if port:
<             warn("pgdb doesn't support 'port' parameter in connect()", UserWarning)
<         kwargs = {'host' : host, 'database' : database,
<                   'user' : user, 'password' : password}
<         cnx = self._native_module.connect(**kwargs)
<         return self._wrap_if_needed(cnx, user)
< 
< 
< class _PsycopgAdapter(DBAPIAdapter):
<     """Simple Psycopg Adapter to DBAPI (cnx_string differs from classical ones)
<     """
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Handles psycopg connexion format"""
<         if host:
<             cnx_string = 'host=%s  dbname=%s  user=%s' % (host, database, user)
<         else:
<             cnx_string = 'dbname=%s  user=%s' % (database, user)
<         if port:
<             cnx_string += ' port=%s' % port
<         if password:
<             cnx_string = '%s password=%s' % (cnx_string, password)
<         cnx = self._native_module.connect(cnx_string)
<         cnx.set_isolation_level(1)
<         return self._wrap_if_needed(cnx, user)
<     
< class _Psycopg2Adapter(_PsycopgAdapter):
<     """Simple Psycopg2 Adapter to DBAPI (cnx_string differs from classical ones)
<     """
<     BOOLEAN = 16 # XXX see additional types in psycopg2.extensions
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self._init_psycopg2()
< 
<     def _init_psycopg2(self):
<         """initialize psycopg2 to use mx.DateTime for date and timestamps
<         instead for datetime.datetime"""
<         psycopg2 = self._native_module
<         if hasattr(psycopg2, '_lc_initialized'):
<             return
<         psycopg2._lc_initialized = 1
<         # use mxDateTime instead of datetime if available
<         if HAS_MX_DATETIME:
<             from psycopg2 import extensions
<             extensions.register_type(psycopg2._psycopg.MXDATETIME)
<             extensions.register_type(psycopg2._psycopg.MXINTERVAL)
<             extensions.register_type(psycopg2._psycopg.MXDATE)
<             extensions.register_type(psycopg2._psycopg.MXTIME)
<             # StringIO/cStringIO adaptation
<             # XXX (syt) todo, see my december discussion on the psycopg2 list
<             # for a working solution
<             #def adapt_stringio(stringio):
<             #    print 'ADAPTING', stringio
<             #    return psycopg2.Binary(stringio.getvalue())
<             #import StringIO
<             #extensions.register_adapter(StringIO.StringIO, adapt_stringio)
<             #import cStringIO
<             #extensions.register_adapter(cStringIO.StringIO, adapt_stringio)
<         
< 
< class _PgsqlAdapter(DBAPIAdapter):
<     """Simple pyPgSQL Adapter to DBAPI
<     """
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Handles psycopg connexion format"""
<         kwargs = {'host' : host, 'port': port or None,
<                   'database' : database,
<                   'user' : user, 'password' : password or None}
<         cnx = self._native_module.connect(**kwargs)
<         return self._wrap_if_needed(cnx, user)
< 
< 
<     def Binary(self, string):
<         """Emulates the Binary (cf. DB-API) function"""
<         return str
<     
<     def __getattr__(self, attrname):
<         # __import__('pyPgSQL.PgSQL', ...) imports the toplevel package
<         return getattr(self._native_module, attrname)
< 
< 
< # Sqlite #############################################################
< 
< class _PySqlite2Adapter(DBAPIAdapter):
<     """Simple pysqlite2 Adapter to DBAPI
<     """
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self._init_pysqlite2()
<         # no type code in pysqlite2
<         self.BINARY = 'XXX'
<         self.STRING = 'XXX'
<         self.DATETIME = 'XXX'
<         self.NUMBER = 'XXX'
< 
<     def _init_pysqlite2(self):
<         """initialize pysqlite2 to use mx.DateTime for date and timestamps"""
<         sqlite = self._native_module
<         if hasattr(sqlite, '_lc_initialized'):
<             return
<         sqlite._lc_initialized = 1
< 
<         # bytea type handling
<         from StringIO import StringIO
<         def adapt_bytea(data):
<             return data.getvalue()
<         sqlite.register_adapter(StringIO, adapt_bytea)
<         def convert_bytea(data):
<             return StringIO(data)
<         sqlite.register_converter('bytea', convert_bytea)
< 
<         # boolean type handling
<         def convert_boolean(ustr):
<             if ustr.upper() in ('F', 'FALSE'):
<                 return False
<             return True
<         sqlite.register_converter('boolean', convert_boolean)
<         def adapt_boolean(bval):
<             return str(bval).upper()
<         sqlite.register_adapter(bool, adapt_boolean)
< 
<         # date/time types handling
<         if HAS_MX_DATETIME:
<             def adapt_mxdatetime(mxd):
<                 return mxd.strftime('%Y-%m-%d %H:%M:%S')
<             sqlite.register_adapter(DateTimeType, adapt_mxdatetime)
<             def adapt_mxdatetimedelta(mxd):
<                 return mxd.strftime('%H:%M:%S')
<             sqlite.register_adapter(DateTimeDeltaType, adapt_mxdatetimedelta)
<             
<             def convert_mxdate(ustr):
<                 return strptime(ustr, '%Y-%m-%d %H:%M:%S')
<             sqlite.register_converter('date', convert_mxdate)
<             def convert_mxdatetime(ustr):
<                 return strptime(ustr, '%Y-%m-%d %H:%M:%S')
<             sqlite.register_converter('timestamp', convert_mxdatetime)
<             def convert_mxtime(ustr):
<                 try:
<                     return strptime(ustr, '%H:%M:%S')
<                 except:
<                     # DateTime used as Time?
<                     return strptime(ustr, '%Y-%m-%d %H:%M:%S')
<             sqlite.register_converter('time', convert_mxtime)
<         # XXX else use datetime.datetime
<     
<             
<     def connect(self, host='', database='', user='', password='', port=None):
<         """Handles sqlite connexion format"""
<         sqlite = self._native_module
<         
<         class PySqlite2Cursor(sqlite.Cursor):
<             """cursor adapting usual dict format to pysqlite named format
<             in SQL queries
<             """
<             def _replace_parameters(self, sql, kwargs):
<                 if isinstance(kwargs, dict):
<                     return re.sub(r'%\(([^\)]+)\)s', r':\1', sql)
<                 # XXX dumb
<                 return re.sub(r'%s', r'?', sql)
<                     
<             def execute(self, sql, kwargs=None):
<                 if kwargs is None:
<                     self.__class__.__bases__[0].execute(self, sql)
<                 else:
<                     self.__class__.__bases__[0].execute(self, self._replace_parameters(sql, kwargs), kwargs)
<             def executemany(self, sql, kwargss):
<                 if not isinstance(kwargss, (list, tuple)):
<                     kwargss = tuple(kwargss)
<                 self.__class__.__bases__[0].executemany(self, self._replace_parameters(sql, kwargss[0]), kwargss)
<                     
<         class PySqlite2CnxWrapper:
<             def __init__(self, cnx):
<                 self._cnx = cnx
<                 
<             def cursor(self):
<                 return self._cnx.cursor(PySqlite2Cursor)
<             def __getattr__(self, attrname):
<                 return getattr(self._cnx, attrname)
<         cnx = sqlite.connect(database, detect_types=sqlite.PARSE_DECLTYPES)
<         return self._wrap_if_needed(PySqlite2CnxWrapper(cnx), user)
<     
<     def process_value(self, value, description, encoding='utf-8', binarywrap=None):
<         if not binarywrap is None and isinstance(value, self._native_module.Binary):
<             return binarywrap(value)
<         return value # no type code support, can't do anything
< 
<     
< class _SqliteAdapter(DBAPIAdapter):
<     """Simple sqlite Adapter to DBAPI
<     """
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self.DATETIME = native_module.TIMESTAMP
<         
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Handles sqlite connexion format"""
<         cnx = self._native_module.connect(database)
<         return self._wrap_if_needed(cnx, user)
< 
< 
< # Mysql ##############################################################
< 
< class _MySqlDBAdapter(DBAPIAdapter):
<     """Simple mysql Adapter to DBAPI
<     """
<     BOOLEAN = 'XXX' # no specific type code for boolean
< 
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self._init_module()
< 
<     def _init_module(self):
<         """initialize mysqldb to use mx.DateTime for date and timestamps"""
<         natmod = self._native_module
<         if hasattr(natmod, '_lc_initialized'):
<             return
<         natmod._lc_initialized = 1
<         # date/time types handling
<         if HAS_MX_DATETIME:
<             from MySQLdb import times
<             from mx import DateTime as mxdt
<             times.Date = times.date = mxdt.Date
<             times.Time = times.time = mxdt.Time
<             times.Timestamp = times.datetime = mxdt.DateTime
<             times.TimeDelta = times.timedelta = mxdt.TimeDelta
<             times.DateTimeType = mxdt.DateTimeType
<             times.DateTimeDeltaType = mxdt.DateTimeDeltaType
<             
<     def connect(self, host='', database='', user='', password='', port=None,
<                 unicode=True, charset='utf8'):
<         """Handles mysqldb connexion format
<         the unicode named argument asks to use Unicode objects for strings
<         in result sets and query parameters
<         """
<         kwargs = {'host' : host or '', 'db' : database,
<                   'user' : user, 'passwd' : password,
<                   'use_unicode' : unicode}
<         # MySQLdb doesn't support None port
<         if port:
<             kwargs['port'] = int(port)
<         cnx = self._native_module.connect(**kwargs)
<         if unicode:
<             if charset.lower() == 'utf-8':
<                 charset = 'utf8'
<             cnx.set_character_set(charset)
<         return self._wrap_if_needed(cnx, user)
< 
<     def process_value(self, value, description, encoding='utf-8', binarywrap=None):
<         typecode = description[1]
<         # hack to differentiate mediumtext (String) and tinyblob/longblog
<         # (Password/Bytes) which are all sharing the same type code :(
<         if typecode == self.BINARY:
<             if hasattr(value, 'tostring'): # may be an array
<                 value = value.tostring()
<             maxsize = description[3]
<             # mediumtext can hold up to (2**24 - 1) characters (16777215)
<             # but if utf8 is set, each character is stored on 3 bytes words,
<             # so we have to test for 3 * (2**24 - 1)  (i.e. 50331645)
<             # XXX: what about other encodings ??
<             if maxsize in (16777215, 50331645): # mediumtext (2**24 - 1)
<                 if isinstance(value, str):
<                     return unicode(value, encoding)
<                 return value
<             #if maxsize == 255: # tinyblob (2**8 - 1)
<             #    return value
<             if binarywrap is None:
<                 return value
<             return binarywrap(value)
<         return DBAPIAdapter.process_value(self, value, description, encoding, binarywrap)
< 
<     def type_code_test(self, cursor):
<         print '*'*80
<         print 'module type codes'
<         for typename in ('STRING', 'BOOLEAN', 'BINARY', 'DATETIME', 'NUMBER'):
<             print typename, getattr(self, typename)
<         try:
<             cursor.execute("""CREATE TABLE _type_code_test(
<             varchar_field varchar(50),
<             text_field text unicode, 
<             mtext_field mediumtext,
<             binary_field tinyblob,
<             blob_field blob,
<             lblob_field longblob
<             )""")
<             cursor.execute("INSERT INTO _type_code_test VALUES ('1','2','3','4', '5', '6')")
<             cursor.execute("SELECT * FROM _type_code_test")
<             descr = cursor.description
<             print 'db fields type codes'
<             for i, name in enumerate(('varchar', 'text', 'mediumtext',
<                                       'binary', 'blob', 'longblob')):
<                 print name, descr[i]
<         finally:
<             cursor.execute("DROP TABLE _type_code_test")
<             
< 
< 
< ## Drivers, Adapters and helpers registries ###################################
< 
< 
< PREFERED_DRIVERS = {
<     "postgres" : [ 'psycopg2', 'psycopg', 'pgdb', 'pyPgSQL.PgSQL', ],
<     "mysql" : [ 'MySQLdb', ], # 'pyMySQL.MySQL, ],
<     "sqlite" : ['pysqlite2.dbapi2', 'sqlite', 'sqlite3',],
<     }
< 
< _ADAPTERS = {
<     'postgres' : { 'pgdb' : _PgdbAdapter,
<                    'psycopg' : _PsycopgAdapter,
<                    'psycopg2' : _Psycopg2Adapter,
<                    'pyPgSQL.PgSQL' : _PgsqlAdapter,
<                    },
<     'mysql' : { 'MySQLdb' : _MySqlDBAdapter, },
<     'sqlite' : { 'pysqlite2.dbapi2' : _PySqlite2Adapter,
<                  'sqlite' : _SqliteAdapter,
<                  'sqlite3' : _PySqlite2Adapter, },
<     }
< 
< # _AdapterDirectory could be more generic by adding a 'protocol' parameter
< # This one would become an adapter for 'DBAPI' protocol
< class _AdapterDirectory(dict):
<     """A simple dict that registers all adapters"""
<     def register_adapter(self, adapter, driver, modname):
<         """Registers 'adapter' in directory as adapting 'mod'"""
<         try:
<             driver_dict = self[driver]
<         except KeyError:
<             self[driver] = {}
<             
<         # XXX Should we have a list of adapters ?
<         driver_dict[modname] = adapter
<     
<     def adapt(self, database, prefered_drivers = None, pywrap = False):
<         """Returns an dbapi-compliant object based for database"""
<         prefered_drivers = prefered_drivers or PREFERED_DRIVERS
<         module, modname = _import_driver_module(database, prefered_drivers)
<         try:
<             return self[database][modname](module, pywrap=pywrap)
<         except KeyError:
<             raise NoAdapterFound(obj=module)        
< 
<     def get_adapter(self, database, modname):
<         try:
<             return self[database][modname]
<         except KeyError:
<             raise NoAdapterFound(None, modname)
< 
< ADAPTER_DIRECTORY = _AdapterDirectory(_ADAPTERS)
< del _AdapterDirectory
< 
< 
< ## Main functions #############################################################
<     
< def set_prefered_driver(database, module, _drivers=PREFERED_DRIVERS):
<     """sets the prefered driver module for database
<     database is the name of the db engine (postgresql, mysql...)
<     module is the name of the module providing the connect function
<     syntax is (params_func, post_process_func_or_None)
<     _drivers is a optionnal dictionnary of drivers
<     """
<     try:
<         modules = _drivers[database]
<     except KeyError:
<         raise UnknownDriver('Unknown database %s' % database)
<     # Remove module from modules list, and re-insert it in first position
<     try:
<         modules.remove(module)
<     except ValueError:
<         raise UnknownDriver('Unknown module %s for %s' % (module, database))
<     modules.insert(0, module)
<     
< def get_dbapi_compliant_module(driver, prefered_drivers = None, quiet = False,
<                                pywrap = False):
<     """returns a fully dbapi compliant module"""
<     try:
<         mod = ADAPTER_DIRECTORY.adapt(driver, prefered_drivers, pywrap=pywrap)
<     except NoAdapterFound, err:
<         if not quiet:
<             msg = 'No Adapter found for %s, returning native module'
<             print >> sys.stderr, msg % err.objname
<         mod = err.adapted_obj
<     from clonedigger.logilab.common.adbh import get_adv_func_helper
<     mod.adv_func_helper = get_adv_func_helper(driver)
<     return mod
< 
< def get_connection(driver='postgres', host='', database='', user='', 
<                   password='', port='', quiet=False, drivers=PREFERED_DRIVERS,
<                   pywrap=False):
<     """return a db connexion according to given arguments"""
<     module, modname = _import_driver_module(driver, drivers, ['connect'])
<     try:
<         adapter = ADAPTER_DIRECTORY.get_adapter(driver, modname)
<     except NoAdapterFound, err:
<         if not quiet:
<             msg = 'No Adapter found for %s, using default one' % err.objname
<             print >> sys.stderr, msg
<         adapted_module = DBAPIAdapter(module, pywrap)
<     else:
<         adapted_module = adapter(module, pywrap)
<     if host and not port:
<         try:
<             host, port = host.split(':', 1)
<         except ValueError:
<             pass
<     if port:
<         port = int(port)
<     return adapted_module.connect(host, database, user, password, port=port)
< 
< 
< from clonedigger.logilab.common.deprecation import moved
< get_adv_func_helper = moved('logilab.common.adbh', 'get_adv_func_helper')
diff -r -N code-worker/tasks/clonedigger/logilab/common/debugger.py code-worker/code-worker/tasks/clonedigger/logilab/common/debugger.py
1,172d0
< """customized version of pdb's default debugger.
< 
< - sets up a history file
< - uses ipython if available to colorize lines of code
< - overrides list command to search for current block instead
<   of using 5 lines of context
< """
< 
< try:
<     import readline
< except ImportError:
<     readline = None
< import os
< import os.path as osp
< import sys
< from pdb import Pdb
< from cStringIO import StringIO
< import inspect
< 
< try:
<     from IPython import PyColorize
< except ImportError:
<     def colorize(source, *args):
<         """fallback colorize function"""
<         return source
< else:
<     def colorize(source, start_lineno, curlineno):
<         """"""
<         parser = PyColorize.Parser()
<         output = StringIO()
<         parser.format(source, output)
<         annotated = []
<         for index, line in enumerate(output.getvalue().splitlines()):
<             lineno = index + start_lineno
<             if lineno == curlineno:
<                 annotated.append('%4s\t->\t%s' % (lineno, line))
<             else:
<                 annotated.append('%4s\t\t%s' % (lineno, line))                
<         return '\n'.join(annotated)
< 
< def getsource(obj):
<     """Return the text of the source code for an object.
< 
<     The argument may be a module, class, method, function, traceback, frame,
<     or code object.  The source code is returned as a single string.  An
<     IOError is raised if the source code cannot be retrieved."""
<     lines, lnum = inspect.getsourcelines(obj)
<     return ''.join(lines), lnum
< 
< 
< ################################################################
< class Debugger(Pdb):
<     """custom debugger
<     
<     - sets up a history file
<     - uses ipython if available to colorize lines of code
<     - overrides list command to search for current block instead
<       of using 5 lines of context
<     """
<     def __init__(self, tcbk):
<         Pdb.__init__(self)
<         self.reset()
<         while tcbk.tb_next is not None:
<             tcbk = tcbk.tb_next
<         self._tcbk = tcbk
<         self._histfile = osp.join(os.environ["HOME"], ".pdbhist")
<         
<     def setup_history_file(self):
<         """if readline is available, read pdb history file
<         """
<         if readline is not None:
<             try:
<                 readline.read_history_file(self._histfile)
<             except IOError:
<                 pass
< 
<     def start(self):
<         """starts the interactive mode"""
<         self.interaction(self._tcbk.tb_frame, self._tcbk)
< 
<     def setup(self, frame, tcbk):
<         """setup hook: set up history file"""
<         self.setup_history_file()
<         Pdb.setup(self, frame, tcbk)
< 
<     def set_quit(self):
<         """quit hook: save commands in the history file"""
<         if readline is not None:
<             readline.write_history_file(self._histfile)
<         Pdb.set_quit(self)
< 
<     def complete_p(self, text, line, begin_idx, end_idx):
<         """provide variable names completion for the ``p`` command"""
<         namespace = dict(self.curframe.f_globals)
<         namespace.update(self.curframe.f_locals)
<         if '.' in text:
<             return self.attr_matches(text, namespace)
<         return [varname for varname in namespace if varname.startswith(text)]
< 
< 
<     def attr_matches(self, text, namespace):
<         """implementation coming from rlcompleter.Completer.attr_matches
<         Compute matches when text contains a dot.
< 
<         Assuming the text is of the form NAME.NAME....[NAME], and is
<         evaluatable in self.namespace, it will be evaluated and its attributes
<         (as revealed by dir()) are used as possible completions.  (For class
<         instances, class members are also considered.)
< 
<         WARNING: this can still invoke arbitrary C code, if an object
<         with a __getattr__ hook is evaluated.
< 
<         """
<         import re
<         m = re.match(r"(\w+(\.\w+)*)\.(\w*)", text)
<         if not m:
<             return
<         expr, attr = m.group(1, 3)
<         object = eval(expr, namespace)
<         words = dir(object)
<         if hasattr(object,'__class__'):
<             words.append('__class__')
<             words = words + self.get_class_members(object.__class__)
<         matches = []
<         n = len(attr)
<         for word in words:
<             if word[:n] == attr and word != "__builtins__":
<                 matches.append("%s.%s" % (expr, word))
<         return matches
<     
<     def get_class_members(self, klass):
<         """implementation coming from rlcompleter.get_class_members"""
<         ret = dir(klass)
<         if hasattr(klass,'__bases__'):
<             for base in klass.__bases__:
<                 ret = ret + self.get_class_members(base)
<         return ret
<         
<     ## specific / overidden commands 
<     def do_list(self, arg):
<         """overrides default list command to display the surrounding block
<         instead of 5 lines of context
<         """
<         self.lastcmd = 'list'
<         if not arg:
<             try:
<                 source, start_lineno = getsource(self.curframe)
<                 print colorize(''.join(source), start_lineno,
<                                self.curframe.f_lineno)
<             except KeyboardInterrupt:
<                 pass
<             except IOError:
<                 Pdb.do_list(self, arg)
<         else:
<             Pdb.do_list(self, arg)
<     do_l = do_list
< 
<     def do_open(self, arg):
<         """opens source file corresponding to the current stack level"""
<         filename = self.curframe.f_code.co_filename
<         lineno = self.curframe.f_lineno
<         cmd = 'emacsclient --no-wait +%s %s' % (lineno, filename)
<         os.system(cmd)
<         
<     do_o = do_open
< 
< 
< def pm():
<     """use our custom debugger"""
<     dbg = Debugger(sys.last_traceback)
<     dbg.start()
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/decorators.py code-worker/code-worker/tasks/clonedigger/logilab/common/decorators.py
1,124d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains some function/method decorators
< 
< :author:    Logilab
< :copyright: 2006-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< # XXX rewrite so we can use the decorator syntax when keyarg has to be specified
< 
< def cached(callableobj, keyarg=None):
<     """simple decorator to cache result of method call"""
<     #print callableobj, keyarg, callableobj.func_code.co_argcount
<     if callableobj.func_code.co_argcount == 1 or keyarg == 0:
<         
<         def cache_wrapper1(self, *args):
<             cache = '_%s_cache_' % callableobj.__name__
<             #print 'cache1?', cache
<             try:
<                 return self.__dict__[cache]
<             except KeyError:
<                 #print 'miss'
<                 value = callableobj(self, *args)
<                 setattr(self, cache, value)
<                 return value
<         return cache_wrapper1
<     
<     elif keyarg:
<         
<         def cache_wrapper2(self, *args, **kwargs):
<             cache = '_%s_cache_' % callableobj.__name__
<             key = args[keyarg-1]
<             #print 'cache2?', cache, self, key
<             try:
<                 _cache = self.__dict__[cache]
<             except KeyError:
<                 #print 'init'
<                 _cache = {}
<                 setattr(self, cache, _cache)
<             try:
<                 return _cache[key]
<             except KeyError:
<                 #print 'miss', self, cache, key
<                 _cache[key] = callableobj(self, *args, **kwargs)
<             return _cache[key]
<         return cache_wrapper2
< 
<     def cache_wrapper3(self, *args):
<         cache = '_%s_cache_' % callableobj.__name__
<         #print 'cache3?', cache, self, args
<         try:
<             _cache = self.__dict__[cache]
<         except KeyError:
<             #print 'init'
<             _cache = {}
<             setattr(self, cache, _cache)
<         try:
<             return _cache[args]
<         except KeyError:
<             #print 'miss'
<             _cache[args] = callableobj(self, *args)
<         return _cache[args]
<     return cache_wrapper3
< 
< def clear_cache(obj, funcname):
<     """function to clear a cache handled by the cached decorator"""
<     try:
<         del obj.__dict__['_%s_cache_' % funcname]
<     except KeyError:
<         pass
< 
< def copy_cache(obj, funcname, cacheobj):
<     """copy cache for <funcname> from cacheobj to obj"""
<     cache = '_%s_cache_' % funcname
<     try:
<         setattr(obj, cache, cacheobj.__dict__[cache])
<     except KeyError:
<         pass
< 
< 
< class wproperty(object):
<     """simple descriptor expecting to take a modifier function as first argument
<     and looking for a _<function name> to retrieve the attribute
<     """
<     def __init__(self, setfunc):
<         self.setfunc = setfunc
<         self.attrname = '_%s' % setfunc.__name__
<         
<     def __set__(self, obj, value):
<         self.setfunc(obj, value)
<         
<     def __get__(self, obj, cls):
<         assert obj is not None
<         return getattr(obj, self.attrname)
< 
< 
< class classproperty(object):
<     def __init__(self, get):
<         self.get = get
<     def __get__(self, inst, cls):
<         return self.get(cls)
< 
< from time import clock
< def timed(f):
<     def wrap(*args, **kwargs):
<         t = clock()
<         #for i in range(100):
<         res = f(*args, **kwargs)
<         print '%s time: %.9f' % (f.__name__, clock() - t)
<         return res
<     return wrap
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/deprecation.py code-worker/code-worker/tasks/clonedigger/logilab/common/deprecation.py
1,144d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Deprecation utilities
< 
< :author:    Logilab
< :copyright: 2006-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< import sys
< from warnings import warn
< 
< from clonedigger.logilab.common.modutils import LazyObject, load_module_from_name
< 
< 
< class deprecated(type):
<     """metaclass to print a warning on instantiation of a deprecated class"""
<     
<     def __call__(cls, *args, **kwargs):
<         msg = getattr(cls, "__deprecation_warning__",
<                       "%s is deprecated" % cls.__name__)
<         warn(msg, DeprecationWarning, stacklevel=2)
<         return type.__call__(cls, *args, **kwargs)
< 
< 
< def class_renamed(old_name, new_class, message=None):
<     """automatically creates a class which fires a DeprecationWarning
<     when instantiated.
<     
<     >>> Set = class_renamed('Set', set, 'Set is now replaced by set')
<     >>> s = Set()
<     sample.py:57: DeprecationWarning: Set is now replaced by set
<       s = Set()
<     >>>
<     """
<     clsdict = {}
<     if message is None:
<         message = '%s is deprecated' % old_name
<     clsdict['__deprecation_warning__'] = message
<     try:
<         # new-style class
<         return deprecated(old_name, (new_class,), clsdict)
<     except (NameError, TypeError):
<         # old-style class
<         class DeprecatedClass(new_class):
<             """FIXME: There might be a better way to handle old/new-style class
<             """
<             def __init__(self, *args, **kwargs):
<                 warn(message, DeprecationWarning, stacklevel=2)
<                 new_class.__init__(self, *args, **kwargs)
<         return DeprecatedClass
< 
< 
< def class_moved(new_class, old_name=None, message=None):
<     """nice wrapper around class_renamed when a class has been moved into
<     another module
<     """
<     if old_name is None:
<         old_name = new_class.__name__
<     if message is None:
<         message = 'class %s is now available as %s.%s' % (
<             old_name, new_class.__module__, new_class.__name__)
<     return class_renamed(old_name, new_class, message)
< 
< 
< def deprecated_function(new_func, message=None):
<     """creates a function which fires a DeprecationWarning when used
< 
<     For example, if <bar> is deprecated in favour of <foo> :
<     >>> bar = deprecated_function(foo, 'bar is deprecated')
<     >>> bar()
<     sample.py:57: DeprecationWarning: bar is deprecated
<       bar()
<     >>>
<     """
<     if message is None:
<         message = "this function is deprecated, use %s instead" % (
<             new_func.func_name)
<     def deprecated(*args, **kwargs):
<         warn(message, DeprecationWarning, stacklevel=2)
<         return new_func(*args, **kwargs)
<     return deprecated
< 
< 
< def moved(modpath, objname):
<     """use to tell that a callable has been moved to a new module.
< 
<     It returns a callable wrapper, so that when its called a warning is printed
<     telling where the object can be found, import is done (and not before) and
<     the actual object is called.
< 
<     NOTE: the usage is somewhat limited on classes since it will fail if the
<     wrapper is use in a class ancestors list, use the `class_moved` function
<     instead (which has no lazy import feature though).
<     """
<     def callnew(*args, **kwargs):
<         message = "object %s has been moved to module %s" % (objname, modpath)
<         warn(message, DeprecationWarning, stacklevel=2)
<         m = load_module_from_name(modpath)
<         return getattr(m, objname)(*args, **kwargs)
<     return callnew
< 
< 
< class WarnLazyObject(LazyObject):
<     def __init__(self, oldname, newname):
<         # XXX doesn't work if module isn't in a package
<         package, module = newname.rsplit('.', 1)
<         super(WarnLazyObject, self).__init__(package, module)
<         self.oldname = oldname
<         self.newname = newname
<         print 'hop', oldname, newname
<         sys.modules[oldname] = self
< 
<     def __getobj(self):
<         if self._imported is None:
<             message = "module %s has moved, it's now %s" % (
<                 self.oldname, self.newname)
<             warn(message, DeprecationWarning, stacklevel=2)
<         return super(WarnLazyObject, self).__getobj()
< 
< module_moved = WarnLazyObject
< 
< def obsolete(reason="This function is obsolete"):
<     """this function is an alternative to `deprecated_function`
<     when there's no real replacement for the deprecated function
<     """
<     def newdecorator(func):
<         def wrapped(*args, **kwargs):
<             warn(reason, DeprecationWarning, stacklevel=2)
<             return func(*args, **kwargs)
<         return wrapped
<     return newdecorator
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/fileutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/fileutils.py
1,480d0
< # Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some file / file path manipulation utilities.
< 
< :group path manipulation: first_level_directory, relative_path, is_binary,\
< get_by_ext, remove_dead_links
< :group file manipulation: norm_read, norm_open, lines, stream_lines, lines,\
< write_open_mode, ensure_fs_mode, export
< :sort: path manipulation, file manipulation
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< import shutil
< import mimetypes
< from os.path import isabs, isdir, islink, split, exists, walk, normpath, join
< from os.path import abspath
< from os import sep, mkdir, remove, listdir, stat, chmod
< from stat import ST_MODE, S_IWRITE
< from cStringIO import StringIO
< 
< from clonedigger.logilab.common import STD_BLACKLIST as BASE_BLACKLIST, IGNORED_EXTENSIONS
< from clonedigger.logilab.common.shellutils import find
< 
< def first_level_directory(path):
<     """return the first level directory of a path
<     
<     >>> first_level_directory('home/syt/work')
<     'home'
<     >>> first_level_directory('/home/syt/work')
<     '/'
<     >>> first_level_directory('work')
<     'work'
<     >>>
< 
<     :type path: str
<     :param path: the path for which we want the first level directory
< 
<     :rtype: str
<     :return: the first level directory appearing in `path`
<     """
<     head, tail = split(path)
<     while head and tail:
<         head, tail = split(head)
<     if tail:
<         return tail
<     # path was absolute, head is the fs root
<     return head
< 
< def abspath_listdir(path):
<     """lists path's content using absolute paths
< 
<     >>> os.listdir('/home')
<     ['adim', 'alf', 'arthur', 'auc']    
<     >>> abspath_listdir('/home')
<     ['/home/adim', '/home/alf', '/home/arthur', '/home/auc']
<     """
<     path = abspath(path)
<     return [join(path, filename) for filename in listdir(path)]
< 
<     
< def is_binary(filename):
<     """return true if filename may be a binary file, according to it's
<     extension
< 
<     :type filename: str
<     :param filename: the name of the file
< 
<     :rtype: bool
<     :return:
<       true if the file is a binary file (actually if it's mime type
<       isn't begining by text/)
<     """
<     try:
<         return not mimetypes.guess_type(filename)[0].startswith('text')
<     except AttributeError:
<         return 1
< 
< 
< def write_open_mode(filename):
<     """return the write mode that should used to open file
< 
<     :type filename: str
<     :param filename: the name of the file
< 
<     :rtype: str
<     :return: the mode that should be use to open the file ('w' or 'wb') 
<     """
<     if is_binary(filename):
<         return 'wb'
<     return 'w'
< 
< 
< def ensure_fs_mode(filepath, desired_mode=S_IWRITE):
<     """check that the given file has the given mode(s) set, else try to
<     set it
< 
<     :type filepath: str
<     :param filepath: path of the file
< 
<     :type desired_mode: int
<     :param desired_mode:
<       ORed flags describing the desired mode. Use constants from the
<       `stat` module for file permission's modes
<     """
<     mode = stat(filepath)[ST_MODE]
<     if not mode & desired_mode:
<         chmod(filepath, mode | desired_mode)
<         
< 
< class ProtectedFile(file):
<     """a special file-object class that automatically that automatically
<     does a 'chmod +w' when needed
< 
<     XXX: for now, the way it is done allows 'normal file-objects' to be
<     created during the ProtectedFile object lifetime.
<     One way to circumvent this would be to chmod / unchmod on each
<     write operation.
<     
<     One other way would be to :
<     
<     - catch the IOError in the __init__
<     
<     - if IOError, then create a StringIO object
<     
<     - each write operation writes in this StringIO obejct
<     
<     - on close()/del(), write/append the StringIO content to the file and
<       do the chmod only once
<     """
<     def __init__(self, filepath, mode):
<         self.original_mode = stat(filepath)[ST_MODE]
<         self.mode_changed = False
<         if mode in ('w', 'a', 'wb', 'ab'):
<             if not self.original_mode & S_IWRITE:
<                 chmod(filepath, self.original_mode | S_IWRITE)
<                 self.mode_changed = True
<         file.__init__(self, filepath, mode)
< 
<     def _restore_mode(self):
<         """restores the original mode if needed"""
<         if self.mode_changed:
<             chmod(self.name, self.original_mode)
<             # Don't re-chmod in case of several restore
<             self.mode_changed = False
<     
<     def close(self):
<         """restore mode before closing"""
<         self._restore_mode()
<         file.close(self)
< 
<     def __del__(self):
<         if not self.closed:
<             self.close()
< 
< 
< class UnresolvableError(Exception):
<     """exception raised by relative path when it's unable to compute relative
<     path between two paths
<     """
< 
< def relative_path(from_file, to_file):
<     """try to get a relative path from from `from_file` to `to_file`
<     (path will be absolute if to_file is an absolute file). This function
<     is useful to create link in `from_file` to `to_file`. This typical use
<     case is used in this function description.
<     
<     If both files are relative, they're expected to be relative to the same
<     directory.
<     
<     >>> relative_path( from_file='toto/index.html', to_file='index.html')
<     '../index.html'
<     >>> relative_path( from_file='index.html', to_file='toto/index.html')
<     'toto/index.html'
<     >>> relative_path( from_file='tutu/index.html', to_file='toto/index.html')
<     '../toto/index.html'
<     >>> relative_path( from_file='toto/index.html', to_file='/index.html')
<     '/index.html'
<     >>> relative_path( from_file='/toto/index.html', to_file='/index.html')
<     '../index.html'
<     >>> relative_path( from_file='/toto/index.html', to_file='/toto/summary.html')
<     'summary.html'
<     >>> relative_path( from_file='index.html', to_file='index.html')
<     ''
<     >>> relative_path( from_file='/index.html', to_file='toto/index.html')
<     Traceback (most recent call last):
<       File "<string>", line 1, in ?
<       File "<stdin>", line 37, in relative_path
<     UnresolvableError
<     >>> relative_path( from_file='/index.html', to_file='/index.html')
<     ''
<     >>>
< 
<     :type from_file: str
<     :param from_file: source file (where links will be inserted)
<     
<     :type to_file: str
<     :param to_file: target file (on which links point)
< 
<     :raise UnresolvableError: if it has been unable to guess a correct path
<     
<     :rtype: str
<     :return: the relative path of `to_file` from `from_file`
<     """
<     from_file = normpath(from_file)
<     to_file = normpath(to_file)
<     if from_file == to_file:
<         return ''
<     if isabs(to_file):
<         if not isabs(from_file):
<             return to_file
<     elif isabs(from_file):
<         raise UnresolvableError()
<     from_parts = from_file.split(sep)
<     to_parts = to_file.split(sep)
<     idem = 1
<     result = []
<     while len(from_parts) > 1:
<         dirname = from_parts.pop(0)
<         if idem and len(to_parts) > 1 and dirname == to_parts[0]:
<             to_parts.pop(0)
<         else:
<             idem = 0
<             result.append('..')
<     result += to_parts
<     return sep.join(result)
< 
< 
< from clonedigger.logilab.common.textutils import _LINE_RGX
< from sys import version_info
< _HAS_UNIV_OPEN = version_info[:2] >= (2, 3)
< del version_info
< 
< def norm_read(path):
<     """return the content of the file with normalized line feeds
< 
<     :type path: str
<     :param path: path to the file to read
< 
<     :rtype: str
<     :return: the content of the file with normalized line feeds
<     """
<     if _HAS_UNIV_OPEN:
<         return open(path, 'U').read()
<     return _LINE_RGX.sub('\n', open(path).read())
< 
< 
< def norm_open(path):
<     """return a stream for a file with content with normalized line feeds
< 
<     :type path: str
<     :param path: path to the file to open
< 
<     :rtype: file or StringIO
<     :return: the opened file with normalized line feeds
<     """
<     if _HAS_UNIV_OPEN:
<         return open(path, 'U')
<     return StringIO(_LINE_RGX.sub('\n', open(path).read()))
< 
<       
< def lines(path, comments=None):
<     """return a list of non empty lines in the file located at `path`
< 
<     :type path: str
<     :param path: path to the file
< 
<     :type comments: str or None
<     :param comments:
<       optional string which can be used to comment a line in the file
<       (ie lines starting with this string won't be returned)
< 
<     :rtype: list
<     :return:
<       a list of stripped line in the file, without empty and commented
<       lines
< 
<     :warning: at some point this function will probably return an iterator
<     """
<     stream = norm_open(path)
<     result = stream_lines(stream, comments)
<     stream.close()
<     return result
< 
< 
< def stream_lines(stream, comments=None):
<     """return a list of non empty lines in the given `stream`
< 
<     :type stream: object implementing 'xreadlines' or 'readlines'
<     :param stream: file like object
< 
<     :type comments: str or None
<     :param comments:
<       optional string which can be used to comment a line in the file
<       (ie lines starting with this string won't be returned)
< 
<     :rtype: list
<     :return:
<       a list of stripped line in the file, without empty and commented
<       lines
< 
<     :warning: at some point this function will probably return an iterator
<     """
<     try:
<         readlines = stream.xreadlines
<     except AttributeError:
<         readlines = stream.readlines
<     result = []
<     for line in readlines():
<         line = line.strip()
<         if line and (comments is None or not line.startswith(comments)):
<             result.append(line)
<     return result
< 
< 
< def export(from_dir, to_dir,
<            blacklist=BASE_BLACKLIST, ignore_ext=IGNORED_EXTENSIONS,
<            verbose=0):
<     """make a mirror of `from_dir` in `to_dir`, omitting directories and
<     files listed in the black list or ending with one of the given
<     extensions
< 
<     :type from_dir: str
<     :param from_dir: directory to export
<     
<     :type to_dir: str
<     :param to_dir: destination directory
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       list of files or directories to ignore, default to the content of
<       `BASE_BLACKLIST`
< 
<     :type ignore_ext: list or tuple
<     :param ignore_ext:
<       list of extensions to ignore, default to  the content of
<       `IGNORED_EXTENSIONS`
< 
<     :type verbose: bool
<     :param verbose:
<       flag indicating wether information about exported files should be
<       printed to stderr, default to False
<     """
<     def make_mirror(_, directory, fnames):
<         """walk handler"""
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         for filename in fnames:
<             # don't include binary files
<             for ext in ignore_ext:
<                 if filename.endswith(ext):
<                     break
<             else:
<                 src = join(directory, filename)
<                 dest = to_dir + src[len(from_dir):]
<                 if verbose:
<                     print >> sys.stderr, src, '->', dest
<                 if isdir(src):
<                     if not exists(dest):
<                         mkdir(dest)
<                 else:
<                     if exists(dest):
<                         remove(dest)
<                     shutil.copy2(src, dest)
<     try:
<         mkdir(to_dir)
<     except OSError:
<         pass
<     walk(from_dir, make_mirror, None)
< 
< 
< def remove_dead_links(directory, verbose=0):
<     """recursivly traverse directory and remove all dead links
< 
<     :type directory: str
<     :param directory: directory to cleanup
< 
<     :type verbose: bool
<     :param verbose:
<       flag indicating wether information about deleted links should be
<       printed to stderr, default to False
<     """
<     def _remove_dead_link(_, directory, fnames):
<         """walk handler"""
<         for filename in fnames:
<             src = join(directory, filename)
<             if islink(src) and not exists(src):
<                 if verbose:
<                     print 'remove dead link', src
<                 remove(src)
<     walk(directory, _remove_dead_link, None)
< 
< 
< from warnings import warn
< 
< def files_by_ext(directory, include_exts=None, exclude_exts=None,
<                  exclude_dirs=BASE_BLACKLIST):
<     """return a list of files in a directory matching (or not) some
<     extensions: you should either give the `include_exts` argument (and
<     only files ending with one of the listed extensions will be
<     considered) or the `exclude_exts` argument (and only files not
<     ending by one of the listed extensions will be considered).
<     Subdirectories are processed recursivly.
< 
<     :type directory: str
<     :param directory: directory where files should be searched
< 
<     :type include_exts: list or tuple or None
<     :param include_exts: list of file extensions to consider
<     
<     :type exclude_exts: list or tuple or None
<     :param exclude_exts: list of file extensions to ignore
< 
<     :type exclude_dirs: list or tuple or None
<     :param exclude_dirs: list of directory where we should not recurse
< 
<     :rtype: list
<     :return: the list of files matching input criteria
<     """
<     assert not (include_exts and exclude_exts)
<     warn("files_by_ext is deprecated, use shellutils.find instead" ,
<          DeprecationWarning, stacklevel=2)
<     if include_exts:
<         return find(directory, include_exts, blacklist=exclude_dirs)
<     return find(directory, exclude_exts, exclude=True, blacklist=exclude_dirs)
< 
< def include_files_by_ext(directory, include_exts, exclude_dirs=BASE_BLACKLIST):
<     """return a list of files in a directory matching some extensions
< 
<     :type directory: str
<     :param directory: directory where files should be searched
< 
<     :type include_exts: list or tuple or None
<     :param include_exts: list of file extensions to consider
< 
<     :type exclude_dirs: list or tuple or None
<     :param exclude_dirs: list of directory where we should not recurse
< 
<     :rtype: list
<     :return: the list of files matching input criterias
<     """
<     warn("include_files_by_ext is deprecated, use shellutils.find instead" ,
<          DeprecationWarning, stacklevel=2)
<     return find(directory, include_exts, blacklist=exclude_dirs)
< 
< def exclude_files_by_ext(directory, exclude_exts, exclude_dirs=BASE_BLACKLIST):
<     """return a list of files in a directory not matching some extensions
< 
<     :type directory: str
<     :param directory: directory where files should be searched
< 
<     :type exclude_exts: list or tuple or None
<     :param exclude_exts: list of file extensions to ignore
< 
<     :type exclude_dirs: list or tuple or None
<     :param exclude_dirs: list of directory where we should not recurse
< 
<     :rtype: list
<     :return: the list of files matching input criterias
<     """
<     warn("exclude_files_by_ext is deprecated, use shellutils.find instead" ,
<          DeprecationWarning, stacklevel=2)
<     return find(directory, exclude_exts, exclude=True, blacklist=exclude_dirs)
diff -r -N code-worker/tasks/clonedigger/logilab/common/graph.py code-worker/code-worker/tasks/clonedigger/logilab/common/graph.py
1,165d0
< """some various graph manipuliation utilities
< 
< (dot generation adapted from pypy/translator/tool/make_dot.py)
< 
< :organization: Logilab
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE), all rights reserved.
< :contact: http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< __docformat__ = "restructuredtext en"
< __metaclass__ = type
< 
< import os.path as osp
< import os
< 
< def escape(value):
<     """make <value> usable in a dot file"""
<     lines = [line.replace('"', '\\"') for line in value.split('\n')]
<     data = '\\l'.join(lines)
<     return '\\n' + data
< 
< def target_info_from_filename(filename):
<     """transforms /some/path/foo.png into ('/some/path', 'foo.png', 'png')"""
<     abspath = osp.abspath(filename)
<     basename = osp.basename(filename)
<     storedir = osp.dirname(abspath)
<     target = filename.split('.')[-1]
<     return storedir, basename, target
< 
< 
< class DotBackend:
<     """Dot File backend"""
<     def __init__(self, graphname, rankdir=None, size=None, ratio=None, charset='utf-8'):
<         self.graphname = graphname
<         self.lines = []
<         self._source = None
<         self.emit("digraph %s {" % normalize_node_id(graphname))
<         if rankdir:
<             self.emit('rankdir=%s' % rankdir)
<         if ratio:
<             self.emit('ratio=%s' % ratio)
<         if size:
<             self.emit('size="%s"' % size)
<         if charset:
<             assert charset.lower() in ('utf-8', 'iso-8859-1', 'latin1'), \
<                    'unsupported charset %s' % charset
<             self.emit('charset="%s"' % charset)
< 
<     def get_source(self):
<         """returns self._source"""
<         if self._source is None:
<             self.emit("}")
<             self._source = '\n'.join(self.lines)
<             del self.lines
<         return self._source
< 
<     source = property(get_source)
<     
<     def generate(self, outputfile=None, dotfile=None):
<         """generates a graph file
<         :param target: output format ('png', 'ps', etc.). If None,
<                        the raw dot source will be returned
<         :return: a path to the generated file
<         """
<         if outputfile is not None:
<             storedir, basename, target = target_info_from_filename(outputfile)
<         else:
<             storedir = '/tmp'
<             basename = '%s.png' % (self.graphname)
<             target = 'png'
<             outputfile = osp.join(storedir, basename)
<         dotfile = dotfile or ('%s.dot' % self.graphname)
<         dot_sourcepath = osp.join(storedir, dotfile)
<         pdot = file(dot_sourcepath, 'w')
<         if isinstance(self.source, unicode):
<             pdot.write(self.source.encode('UTF8'))
<         else:
<             pdot.write(self.source)
<         pdot.close()
<         if target != 'dot':
<             os.system('dot -T%s %s -o%s' % (target, dot_sourcepath, outputfile))
<             os.unlink(dot_sourcepath)
<         return outputfile
< 
<     def emit(self, line):
<         """adds <line> to final output"""
<         self.lines.append(line)
< 
<     def emit_edge(self, name1, name2, **props):
<         """emits edge from <name1> to <name2>
<         
<         authorized props: see http://www.graphviz.org/doc/info/attrs.html
<         """
<         attrs = ['%s="%s"' % (prop, value) for prop, value in props.items()]
<         self.emit('edge [%s];' % ", ".join(attrs))
<         self.emit('%s -> %s' % (normalize_node_id(name1), normalize_node_id(name2)))
< 
<     def emit_node(self, name, **props):
<         """authorized props: see http://www.graphviz.org/doc/info/attrs.html
<         """
<         attrs = ['%s="%s"' % (prop, value) for prop, value in props.items()]
<         self.emit('%s [%s];' % (normalize_node_id(name), ", ".join(attrs)))
< 
< def normalize_node_id(nid):
<     """returns a suitable DOT node id for `nid`"""
<     return '"%s"' % nid
< 
< class GraphGenerator:
<     def __init__(self, backend):
<         # the backend is responsible to output the graph is a particular format
<         self.backend = backend
< 
<     def generate(self, visitor, propshdlr, outputfile=None):
<         # the visitor 
<         # the properties handler is used to get nodes and edges properties
<         # according to the graph and to the backend
<         self.propshdlr = propshdlr
<         for nodeid, node in visitor.nodes():
<             props = propshdlr.node_properties(node)
<             self.backend.emit_node(nodeid, **props)
<         for subjnode, objnode, edge in visitor.edges():
<             props = propshdlr.edge_properties(edge, subjnode, objnode)
<             self.backend.emit_edge(subjnode, objnode, **props)
<         return self.backend.generate(outputfile)
< 
< 
< 
< def get_cycles(graph_dict, vertices=None):
<     '''given a dictionnary representing an ordered graph (i.e. key are vertices
<     and values is a list of destination vertices representing edges), return a
<     list of detected cycles
<     '''
<     if not graph_dict:
<         return ()
<     result = []
<     if vertices is None:
<         vertices = graph_dict.keys()
<     for vertice in vertices:
<         _get_cycles(graph_dict, vertice, [], result)
<     return result
< 
< def _get_cycles(graph_dict, vertice=None, path=None, result=None):
<     """recursive function doing the real work for get_cycles"""
<     if vertice in path:
<         cycle = [vertice]
<         for i in range(len(path)-1, 0, -1):
<             node = path[i]
<             if node == vertice:
<                 break
<             cycle.insert(0, node)
<         # make a canonical representation
<         start_from = min(cycle)
<         index = cycle.index(start_from)
<         cycle = cycle[index:] + cycle[0:index]
<         # append it to result if not already in
<         if not cycle in result:
<             result.append(cycle)
<         return
<     path.append(vertice)
<     try:
<         for node in graph_dict[vertice]:
<             _get_cycles(graph_dict, node, path, result)
<     except KeyError:
<         pass
<     path.pop()
diff -r -N code-worker/tasks/clonedigger/logilab/common/html.py code-worker/code-worker/tasks/clonedigger/logilab/common/html.py
1,52d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2006 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< from warnings import warn
< warn('html module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=2)
< 
< __revision__ = "$Id: html.py,v 1.5 2003-09-12 11:54:47 syt Exp $"
< 
< import traceback
< from xml.sax.saxutils import escape  
< 
< # mk html traceback error #####################################################
< 
< def html_traceback(info, exception,
<                    title='', encoding='ISO-8859-1', body=''):
<     """ return an html formatted traceback from python exception infos.
<     """
<     #typ, value, tbck = info
<     stacktb = traceback.extract_tb(info[2]) #tbck)
<     strings = []
<     if body:
<         strings.append('<div class="error_body">')
<         strings.append(body)
<         strings.append('</div>')
<     if title:
<         strings.append('<h1 class="error">%s</h1>'% escape(title))
<     strings.append('<p class="error">%s</p>' % escape(str(exception)))
<     strings.append('<div class="error_traceback">')
<     for stackentry in stacktb :
<         strings.append('<b>File</b> <b class="file">%s</b>, <b>line</b> '
<                       '<b class="line">%s</b>, <b>function</b> '
<                       '<b class="function">%s</b>:<br/>'%(
<             escape(stackentry[0]), stackentry[1], stackentry[2]))
<         if stackentry[3]:
<             string = escape(repr(stackentry[3])[1:-1])#.encode(encoding)
<             strings.append('&nbsp;&nbsp;%s<br/>\n' % string)
<     strings.append('</div>')
<     return '\n'.join(strings)
diff -r -N code-worker/tasks/clonedigger/logilab/common/__init__.py code-worker/code-worker/tasks/clonedigger/logilab/common/__init__.py
1,165d0
< # Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Logilab common libraries:
< 
< a set of common functionnalities shared among logilab projects
< 
< 
< :type STD_BLACKLIST: tuple
< :var STD_BLACKLIST:
<   directories ignored by default by the functions in this package which have
<   to recurse into directories
< 
< :type IGNORED_EXTENSIONS: tuple
< :var IGNORED_EXTENSIONS:
<   file extensions that may usually be ignored
< """
< 
< STD_BLACKLIST = ('CVS', '.svn', '.hg', 'debian', 'dist', 'build')
< 
< IGNORED_EXTENSIONS = ('.pyc', '.pyo', '.elc', '~')
< 
< 
< 
< from clonedigger.logilab.common.deprecation import moved
< 
< get_cycles = moved('logilab.common.graph', 'get_cycles')
< cached = moved('logilab.common.decorators', 'cached')
< ProgressBar = moved('logilab.common.shellutils', 'ProgressBar')
< Execute = moved('logilab.common.shellutils', 'Execute')
< acquire_lock = moved('logilab.common.shellutils', 'acquire_lock')
< release_lock = moved('logilab.common.shellutils', 'release_lock')
< deprecated_function = moved('logilab.common.deprecation', 'deprecated_function')
< class_renamed = moved('logilab.common.deprecation', 'class_renamed')
< 
< def intersection(list1, list2):
<     """return the intersection of list1 and list2"""
<     warn('this function is deprecated, use a set instead', DeprecationWarning,
<          stacklevel=2)
<     intersect_dict, result = {}, []
<     for item in list1:
<         intersect_dict[item] = 1
<     for item in list2:
<         if intersect_dict.has_key(item):
<             result.append(item)
<     return result
< 
< def difference(list1, list2):
<     """return elements of list1 not in list2"""
<     warn('this function is deprecated, use a set instead', DeprecationWarning,
<          stacklevel=2)
<     tmp, result = {}, []
<     for i in list2:
<         tmp[i] = 1
<     for i in list1:
<         if not tmp.has_key(i):
<             result.append(i)
<     return result
< 
< def union(list1, list2):
<     """return list1 union list2"""
<     warn('this function is deprecated, use a set instead', DeprecationWarning,
<          stacklevel=2)
<     tmp = {}
<     for i in list1:
<         tmp[i] = 1
<     for i in list2:
<         tmp[i] = 1
<     return tmp.keys()
< 
< 
< class attrdict(dict):
<     """a dictionary whose keys are also accessible as attributes"""
<     def __getattr__(self, attr):
<         try:
<             return self[attr]
<         except KeyError:
<             raise AttributeError(attr)
<         
< class nullobject(object):
<     def __nonzero__(self):
<         return False
< 
< # flatten -----
< # XXX move in a specific module and use yield instead
< # do not mix flatten and translate
< #
< # def iterable(obj):
< #    try: iter(obj)
< #    except: return False
< #    return True
< #
< # def is_string_like(obj):
< #    try: obj +''
< #    except (TypeError, ValueError): return False
< #    return True
< #
< #def is_scalar(obj):
< #    return is_string_like(obj) or not iterable(obj)
< #
< #def flatten(seq):
< #    for item in seq:
< #        if is_scalar(item): 
< #            yield item
< #        else:
< #            for subitem in flatten(item):
< #               yield subitem
< 
< def flatten(iterable, tr_func=None, results=None):
<     """flatten a list of list with any level
< 
<     if tr_func is not None, it should be a one argument function that'll be called
<     on each final element
<     """
<     if results is None:
<         results = []
<     for val in iterable:
<         if isinstance(val, (list, tuple)):
<             flatten(val, tr_func, results)
<         elif tr_func is None:
<             results.append(val)
<         else:
<             results.append(tr_func(val))
<     return results
< 
< 
< # XXX is function below still used ?
< 
< def make_domains(lists):
<     """
<     given a list of lists, return a list of domain for each list to produce all
<     combinaisons of possibles values
< 
<     ex: (['a', 'b'], ['c','d', 'e'])
<        -> (['a', 'b', 'a', 'b', 'a', 'b'],
<            ['c', 'c', 'd', 'd', 'e', 'e'])
<     """
<     domains = []
<     for iterable in lists:
<         new_domain = iterable[:]
<         for i in range(len(domains)):
<             domains[i] = domains[i]*len(iterable)
<         if domains:
<             missing = (len(domains[0]) - len(iterable)) / len(iterable)
<             i = 0
<             for j in range(len(iterable)):
<                 value = iterable[j]
<                 for dummy in range(missing):
<                     new_domain.insert(i, value)
<                     i += 1
<                 i += 1
<         domains.append(new_domain)
<     return domains
diff -r -N code-worker/tasks/clonedigger/logilab/common/interface.py code-worker/code-worker/tasks/clonedigger/logilab/common/interface.py
1,70d0
< # Copyright (c) 2002-2007 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
<  bases class for interfaces to provide "light" interface handling.
< 
<  TODO:
<   _ implements a check method which check that an object implements the
<     interface
<   _ Attribute objects
< 
<   This module requires at least python 2.2
< """
< 
< from types import ListType, TupleType
< 
< class Interface:
<     """base class for interfaces"""
<     def is_implemented_by(cls, instance):
<         return implements(instance, cls)
<     is_implemented_by = classmethod(is_implemented_by)
< 
<     
< def implements(obj, interface):
<     """return true if the give object (maybe an instance or class) implements
<     the interface
<     """
<     kimplements = getattr(obj, '__implements__', ())
<     if not isinstance(kimplements, (list, tuple)):
<         kimplements = (kimplements,)
<     for implementedinterface in kimplements:
<         if issubclass(implementedinterface, interface):
<             return True
<     return False
< 
< 
< def extend(klass, interface, _recurs=False):
<     """add interface to klass'__implements__ if not already implemented in.
< 
<     if klass is subclassed, ensure subclasses __implements__ it as well.
<     
<     NOTE: klass should be e new class.
<     """
<     if not implements(klass, interface):
<         try:
<             kimplements = klass.__implements__
<             kimplementsklass = type(kimplements)
<             kimplements = list(kimplements)
<         except AttributeError:
<             kimplementsklass = tuple
<             kimplements = []
<         kimplements.append(interface)
<         klass.__implements__ = kimplementsklass(kimplements)
<         for subklass in klass.__subclasses__():
<             extend(subklass, interface, _recurs=True)
<     elif _recurs:
<         for subklass in klass.__subclasses__():
<             extend(subklass, interface, _recurs=True)
diff -r -N code-worker/tasks/clonedigger/logilab/common/logger.py code-worker/code-worker/tasks/clonedigger/logilab/common/logger.py
1,161d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< Define a logger interface and two concrete loggers : one which prints
< everything on stdout, the other using syslog.
< """
< 
< from warnings import warn
< warn('logger module is deprecated and will disappear in a future release. \
< use logging module instead.',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = "$Id: logger.py,v 1.18 2006-02-03 14:17:42 adim Exp $"
< 
< 
< import sys
< import traceback
< import time
< 
< 
< LOG_EMERG   = 0
< LOG_ALERT   = 1
< LOG_CRIT    = 2
< LOG_ERR     = 3
< LOG_WARN    = 4
< LOG_NOTICE  = 5
< LOG_INFO    = 6
< LOG_DEBUG   = 7
< 
< INDICATORS = ['emergency', 'alert', 'critical', 'error',
<               'warning', 'notice', 'info', 'debug']
< 
< 
< def make_logger(method='print', threshold=LOG_DEBUG, sid=None, output=None):
<     """return a logger for the given method
<     
<     known methods are 'print', 'eprint' and syslog'
<     """
<     if method == 'print':
<         if output is None:
<             output = sys.stdout
<         return PrintLogger(threshold, output, sid=sid)
<     elif method == 'eprint':
<         return PrintLogger(threshold, sys.stderr, sid=sid)
<     elif method == 'syslog':
<         return SysLogger(threshold, sid)
<     elif method == 'file':
<         if not output:
<             raise ValueError('No logfile specified')
<         else:
<             logfile = open(output, 'a')
<             return PrintLogger(threshold, logfile, sid=sid)
<     else:
<         raise ValueError('Unknown logger method: %r' % method)
< 
< 
< class AbstractLogger:
<     """logger interface.
<     Priorities allow to filter on the importance of events
<     An event gets logged if it's priority is lower than the threshold"""
< 
<     def __init__(self, threshold=LOG_DEBUG, priority_indicator=1):
<         self.threshold = threshold
<         self.priority_indicator = priority_indicator
<         
<     def log(self, priority=LOG_DEBUG, message='', substs=None):
<         """log a message with priority <priority>
<         substs are optional substrings
<         """
<         #print 'LOG', self, priority, self.threshold, message
<         if priority <= self.threshold :
<             if substs is not None:
<                 message = message % substs
<             if self.priority_indicator:
<                 message = '[%s] %s' % (INDICATORS[priority], message)
<             self._writelog(priority, message)
< 
<     def _writelog(self, priority, message):
<         """Override this method in concrete class """
<         raise NotImplementedError()
< 
<     def log_traceback(self, priority=LOG_ERR, tb_info=None):
<         """log traceback information with priority <priority>
<         """
<         assert tb_info is not None
<         e_type, value, tbck = tb_info
<         stacktb = traceback.extract_tb(tbck)
<         l = ['Traceback (most recent call last):']
<         for stackentry in stacktb :
<             if stackentry[3]:
<                 plus = '\n    %s' % stackentry[3]
<             else:
<                 plus = ''
<             l.append('filename="%s" line_number="%s" function_name="%s"%s' %
<                      (stackentry[0], stackentry[1], stackentry[2], plus))
<         try:
<             l.append(str(e_type) + ': ' + value.__str__())
<         except UnicodeError:
<             l.append(str(e_type) + ' (message can\'t be displayed)')
<             
<         self.log(priority, '\n'.join(l))
< 
< 
< class PrintLogger(AbstractLogger):
<     """logger implementation
< 
<     log everything to a file, using the standard output by default
<     """
<     
<     def __init__(self, threshold, output=sys.stdout, sid=None,
<                  encoding='UTF-8'):
<         AbstractLogger.__init__(self, threshold)
<         self.output = output
<         self.sid = sid
<         self.encoding = encoding
<         
<     def _writelog(self, priority, message):
<         """overridden from AbstractLogger"""
<         if isinstance(message, unicode):
<             message = message.encode(self.encoding, 'replace')
<         if self.sid is not None:
<             self.output.write('[%s] [%s] %s\n' % (time.asctime(), self.sid,
<                                                   message))
<         else:
<             self.output.write('[%s] %s\n' % (time.asctime(), message))
<         self.output.flush()
< 
< class SysLogger(AbstractLogger):
<     """ logger implementation
< 
<     log everything to syslog daemon
<     use the LOCAL_7 facility
<     """
< 
<     def __init__(self, threshold, sid=None, encoding='UTF-8'):
<         import syslog
<         AbstractLogger.__init__(self, threshold)
<         if sid is None:
<             sid = 'syslog'
<         self.encoding = encoding
<         syslog.openlog(sid, syslog.LOG_PID)
<         
<     def _writelog(self, priority, message):
<         """overridden from AbstractLogger"""
<         import syslog
<         if isinstance(message, unicode):
<             message = message.encode(self.encoding, 'replace')
<         syslog.syslog(priority | syslog.LOG_LOCAL7, message)
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/logging_ext.py code-worker/code-worker/tasks/clonedigger/logilab/common/logging_ext.py
1,83d0
< # -*- coding: iso-8859-1 -*-
< # Copyright (c) 2007 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2007 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< This module provides extensions to the logging module from the standard library.
< """
< 
< import logging
< 
< from clonedigger.logilab.common.textutils import colorize_ansi
< 
< def xxx_cyan(record):
<     if 'XXX' in record.message:
<         return 'cyan'
< 
< class ColorFormatter(logging.Formatter):
<     """
<     A color Formatter for the logging standard module.
< 
<     By default, colorize CRITICAL and ERROR in red, WARNING in orange
<     and INFO in yellow.
< 
<     self.colors is customizable via the 'color' constructor argument (dictionnary).
< 
<     self.colorfilters is a list of functions that get the LogRecord
<     and return a color name or None.
<     """
< 
<     def __init__(self, fmt=None, datefmt=None, colors=None):
<         logging.Formatter.__init__(self, fmt, datefmt)
<         self.colorfilters = []
<         self.colors = {'CRITICAL': 'red',
<                        'ERROR': 'red',
<                        'WARNING': 'magenta',
<                        'INFO': 'yellow',
<                        }
<         if colors is not None:
<             assert isinstance(colors, dict)
<             self.colors.update(colors)            
<                                
<     def format(self, record):
<         msg = logging.Formatter.format(self, record)
<         if record.levelname in self.colors:
<             color = self.colors[record.levelname]
<             return colorize_ansi(msg, color)
<         else:
<             for cf in self.colorfilters:
<                 color = cf(record)
<                 if color: 
<                     return colorize_ansi(msg, color)
<         return msg
< 
< def set_color_formatter(logger=None, **kw):
<     """
<     Install a color formatter on the 'logger'. If not given, it will
<     defaults to the default logger.
< 
<     Any additional keyword will be passed as-is to the ColorFormatter
<     constructor.
<     """
<     if logger is None:
<         logger = logging.getLogger()
<         if not logger.handlers:
<             logging.basicConfig()
<     format_msg = logger.handlers[0].formatter._fmt
<     fmt = ColorFormatter(format_msg, **kw)
<     fmt.colorfilters.append(xxx_cyan)
<     logger.handlers[0].setFormatter(fmt)
diff -r -N code-worker/tasks/clonedigger/logilab/common/logservice.py code-worker/code-worker/tasks/clonedigger/logilab/common/logservice.py
1,35d0
< """log utilities
< 
< Copyright (c) 2003-2004 LOGILAB S.A. (Paris, FRANCE), all rights reserved.
< http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< from warnings import warn
< warn('logservice module is deprecated and will disappear in a near release. \
< use logging module instead.',
<      DeprecationWarning, stacklevel=2)
< 
< __revision__ = "$Id: logservice.py,v 1.5 2006-03-05 16:13:28 syt Exp $"
< 
< from clonedigger.logilab.common.logger import make_logger, LOG_ERR, LOG_WARN, LOG_NOTICE, \
<      LOG_INFO, LOG_CRIT, LOG_DEBUG
< 
< def init_log(treshold, method='eprint', sid='common-log-service',
<              logger=None, output=None):
<     """init the logging system and and log methods to builtins"""
<     if logger is None:
<         logger = make_logger(method, treshold, sid, output=output)
<     # add log functions and constants to builtins
<     __builtins__.update({'log': logger.log,
<                          'log_traceback' : logger.log_traceback,
<                          'LOG_CRIT':   LOG_CRIT,
<                          'LOG_ERR':    LOG_ERR,
<                          'LOG_WARN':   LOG_WARN,
<                          'LOG_NOTICE': LOG_NOTICE,
<                          'LOG_INFO' :  LOG_INFO,
<                          'LOG_DEBUG':  LOG_DEBUG,
<                          })
< 
< init_log(LOG_ERR)
< 
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/modutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/modutils.py
1,596d0
< # -*- coding: iso-8859-1 -*-
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Python modules manipulation utility functions.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< 
< 
< 
< :type PY_SOURCE_EXTS: tuple(str)
< :var PY_SOURCE_EXTS: list of possible python source file extension
< 
< :type STD_LIB_DIR: str
< :var STD_LIB_DIR: directory where standard modules are located
< 
< :type BUILTIN_MODULES: dict
< :var BUILTIN_MODULES: dictionary with builtin module names has key
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< import os
< from os.path import walk, splitext, join, abspath, isdir, dirname, exists
< from imp import find_module, load_module, C_BUILTIN, PY_COMPILED, PKG_DIRECTORY
< 
< from clonedigger.logilab.common import STD_BLACKLIST
< 
< if sys.platform.startswith('win'):
<     PY_SOURCE_EXTS = ('py', 'pyw')
<     PY_COMPILED_EXTS = ('dll', 'pyd')
<     STD_LIB_DIR = join(sys.prefix, 'lib')
< else:
<     PY_SOURCE_EXTS = ('py',)
<     PY_COMPILED_EXTS = ('so',)
<     STD_LIB_DIR = join(sys.prefix, 'lib', 'python%s' % sys.version[:3])
<     
< BUILTIN_MODULES = dict(zip(sys.builtin_module_names,
<                            [1]*len(sys.builtin_module_names)))
< 
< 
< class NoSourceFile(Exception):
<     """exception raised when we are not able to get a python
<     source file for a precompiled file
<     """
< 
< class LazyObject(object):
<     def __init__(self, module, obj):
<         self.module = module
<         self.obj = obj
<         self._imported = None
<         
<     def __getobj(self):
<         if self._imported is None:
<            self._imported = getattr(load_module_from_name(self.module),
<                                     self.obj)
<         return self._imported
<     
<     def __getattribute__(self, attr):
<         try:
<             return super(LazyObject, self).__getattribute__(attr)
<         except AttributeError, ex:
<             return getattr(self.__getobj(), attr)
<         
<     def __call__(self, *args, **kwargs):
<         return self.__getobj()(*args, **kwargs)
< 
< 
< def load_module_from_name(dotted_name, path=None, use_sys=1):
<     """load a Python module from it's name
< 
<     :type dotted_name: str
<     :param dotted_name: python name of a module or package
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type use_sys: bool
<     :param use_sys:
<       boolean indicating whether the sys.modules dictionary should be
<       used or not
< 
< 
<     :raise ImportError: if the module or package is not found
<     
<     :rtype: module
<     :return: the loaded module
<     """
<     return load_module_from_modpath(dotted_name.split('.'), path, use_sys)
< 
< 
< def load_module_from_modpath(parts, path=None, use_sys=1):
<     """load a python module from it's splitted name
< 
<     :type parts: list(str) or tuple(str)
<     :param parts:
<       python name of a module or package splitted on '.'
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type use_sys: bool
<     :param use_sys:
<       boolean indicating whether the sys.modules dictionary should be used or not
< 
<     :param _prefix: used internally, should not be specified
< 
< 
<     :raise ImportError: if the module or package is not found
<     
<     :rtype: module
<     :return: the loaded module
<     """
<     if use_sys:
<         try:
<             return sys.modules['.'.join(parts)]
<         except KeyError:
<             pass
<     modpath = []
<     prevmodule = None
<     for part in parts:
<         modpath.append(part)
<         curname = ".".join(modpath)
<         module = None
<         if len(modpath) != len(parts):
<             # even with use_sys=False, should try to get outer packages from sys.modules
<             module = sys.modules.get(curname)
<         if module is None:
<             mp_file, mp_filename, mp_desc = find_module(part, path)
<             module = load_module(curname, mp_file, mp_filename, mp_desc)
<         if prevmodule:
<             setattr(prevmodule, part, module)
<         _file = getattr(module, "__file__", "")
<         if not _file and len(modpath) != len(parts):
<             raise ImportError("no module in %s" % ".".join(parts[len(modpath):]) )
<         path = [dirname( _file )]
<         prevmodule = module
<     return module
< 
< 
< def load_module_from_file(filepath, path=None, use_sys=1):
<     """load a Python module from it's path
< 
<     :type filepath: str
<     :param dotted_name: path to the python module or package
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type use_sys: bool
<     :param use_sys:
<       boolean indicating whether the sys.modules dictionary should be
<       used or not
< 
< 
<     :raise ImportError: if the module or package is not found
<     
<     :rtype: module
<     :return: the loaded module
<     """
<     return load_module_from_modpath(modpath_from_file(filepath), path, use_sys)
< 
< 
< def modpath_from_file(filename):
<     """given a file path return the corresponding splitted module's name
<     (i.e name of a module or package splitted on '.')
< 
<     :type filename: str
<     :param filename: file's path for which we want the module's name
< 
< 
<     :raise ImportError:
<       if the corresponding module's name has not been found
< 
<     :rtype: list(str)
<     :return: the corresponding splitted module's name
<     """
<     base = splitext(abspath(filename))[0]
<     for path in sys.path:
<         path = abspath(path)
<         if path and base[:len(path)] == path:
<             if filename.find('site-packages') != -1 and \
<                    path.find('site-packages') == -1:
<                 continue
<             mod_path = [module for module in base[len(path):].split(os.sep)
<                         if module]
<             for part in mod_path[:-1]:
<                 path = join(path, part)
<                 if not _has_init(path):
<                     break
<             else:
<                 break
<     else:
<         raise ImportError('Unable to find module for %s in %s' % (
<             filename, ', \n'.join(sys.path)))
<     return mod_path
< 
< 
< 
< def file_from_modpath(modpath, path=None, context_file=None):
<     """given a mod path (ie splited module / package name), return the
<     corresponding file, giving priority to source file over precompiled
<     file if it exists
< 
<     :type modpath: list or tuple
<     :param modpath:
<       splitted module's name (i.e name of a module or package splitted
<       on '.')
<       (this means explicit relative imports that start with dots have
<       empty strings in this list!)
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type context_file: str or None
<     :param context_file:
<       context file to consider, necessary if the identifier has been
<       introduced using a relative import unresolvable in the actual
<       context (i.e. modutils)
<       
<     :raise ImportError: if there is no such module in the directory
< 
<     :rtype: str or None
<     :return:
<       the path to the module's file or None if it's an integrated
<       builtin module such as 'sys'
<     """
<     if context_file is not None:
<         context = dirname(context_file)
<     else:
<         context = context_file
<     if modpath[0] == 'xml':
<         # handle _xmlplus
<         try:
<             return _file_from_modpath(['_xmlplus'] + modpath[1:], path, context)
<         except ImportError:
<             return _file_from_modpath(modpath, path, context)
<     elif modpath == ['os', 'path']:
<         # FIXME: currently ignoring search_path...
<         return os.path.__file__
<     return _file_from_modpath(modpath, path, context)
< 
< 
<     
< def get_module_part(dotted_name, context_file=None):
<     """given a dotted name return the module part of the name :
<     
<     >>> get_module_part('logilab.common.modutils.get_module_part')
<     'logilab.common.modutils'
< 
<     
<     :type dotted_name: str
<     :param dotted_name: full name of the identifier we are interested in
< 
<     :type context_file: str or None
<     :param context_file:
<       context file to consider, necessary if the identifier has been
<       introduced using a relative import unresolvable in the actual
<       context (i.e. modutils)
< 
<     
<     :raise ImportError: if there is no such module in the directory
<     
<     :rtype: str or None
<     :return:
<       the module part of the name or None if we have not been able at
<       all to import the given name
< 
<     XXX: deprecated, since it doesn't handle package precedence over module
<     (see #10066)
<     """
<     # os.path trick
<     if dotted_name.startswith('os.path'):
<         return 'os.path'
<     parts = dotted_name.split('.')
<     if context_file is not None:
<         # first check for builtin module which won't be considered latter
<         # in that case (path != None)
<         if parts[0] in BUILTIN_MODULES:
<             if len(parts) > 2:
<                 raise ImportError(dotted_name)
<             return parts[0]
<         # don't use += or insert, we want a new list to be created !
<     path = None
<     starti = 0
<     if parts[0] == '':
<         assert context_file is not None, \
<                 'explicit relative import, but no context_file?'
<         path = [] # prevent resolving the import non-relatively
<         starti = 1
<     while parts[starti] == '': # for all further dots: change context
<         starti += 1
<         context_file = dirname(context_file)
<     for i in range(starti, len(parts)):
<         try:
<             file_from_modpath(parts[starti:i+1],
<                     path=path, context_file=context_file)
<         except ImportError:
<             if not i >= max(1, len(parts) - 2):
<                 raise
<             return '.'.join(parts[:i])
<     return dotted_name
< 
< 
<     
< def get_modules(package, src_directory, blacklist=STD_BLACKLIST):
<     """given a package directory return a list of all available python
<     modules in the package and its subpackages
< 
<     :type package: str
<     :param package: the python name for the package
< 
<     :type src_directory: str
<     :param src_directory:
<       path of the directory corresponding to the package
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       optional list of files or directory to ignore, default to
<       the value of `logilab.common.STD_BLACKLIST`
< 
<     :rtype: list
<     :return:
<       the list of all available python modules in the package and its
<       subpackages
<     """
<     def func(modules, directory, fnames):
<         """walk handler"""
<         # remove files/directories in the black list
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         # check for __init__.py
<         if not '__init__.py' in fnames:
<             while fnames:
<                 fnames.pop()
<         elif directory != src_directory:
<             #src = join(directory, file)
<             dir_package = directory[len(src_directory):].replace(os.sep, '.')
<             modules.append(package + dir_package)
<         for filename in fnames:
<             src = join(directory, filename)
<             if isdir(src):
<                 continue
<             if _is_python_file(filename) and filename != '__init__.py':
<                 module = package + src[len(src_directory):-3]
<                 modules.append(module.replace(os.sep, '.'))
<     modules = []
<     walk(src_directory, func, modules)
<     return modules
< 
< 
< 
< def get_module_files(src_directory, blacklist=STD_BLACKLIST):
<     """given a package directory return a list of all available python
<     module's files in the package and its subpackages
< 
<     :type src_directory: str
<     :param src_directory:
<       path of the directory corresponding to the package
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       optional list of files or directory to ignore, default to the value of
<       `logilab.common.STD_BLACKLIST`
< 
<     :rtype: list
<     :return:
<       the list of all available python module's files in the package and
<       its subpackages
<     """
<     def func(files, directory, fnames):
<         """walk handler"""
<         # remove files/directories in the black list
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         # check for __init__.py
<         if not '__init__.py' in fnames:
<             while fnames:
<                 fnames.pop()            
<         for filename in fnames:
<             src = join(directory, filename)
<             if isdir(src):
<                 continue
<             if _is_python_file(filename):
<                 files.append(src)
<     files = []
<     walk(src_directory, func, files)
<     return files
< 
< 
< def get_source_file(filename, include_no_ext=False):
<     """given a python module's file name return the matching source file
<     name (the filename will be returned identically if it's a already an
<     absolute path to a python source file...)
< 
<     :type filename: str
<     :param filename: python module's file name
< 
< 
<     :raise NoSourceFile: if no source file exists on the file system
<     
<     :rtype: str
<     :return: the absolute path of the source file if it exists
<     """
<     base, orig_ext = splitext(abspath(filename))
<     for ext in PY_SOURCE_EXTS:
<         source_path = '%s.%s' % (base, ext)
<         if exists(source_path):
<             return source_path
<     if include_no_ext and not orig_ext and exists(base):
<         return base
<     raise NoSourceFile(filename)
< 
< 
< 
< def is_python_source(filename):
<     """
<     rtype: bool
<     return: True if the filename is a python source file
<     """
<     return splitext(filename)[1][1:] in PY_SOURCE_EXTS
< 
< 
<     
< def is_standard_module(modname, std_path=(STD_LIB_DIR,)):
<     """try to guess if a module is a standard python module (by default,
<     see `std_path` parameter's description)
<     
<     :type modname: str
<     :param modname: name of the module we are interested in
< 
<     :type std_path: list(str) or tuple(str)
<     :param std_path: list of path considered has standard
< 
< 
<     :rtype: bool
<     :return:
<       true if the module:
<       - is located on the path listed in one of the directory in `std_path`
<       - is a built-in module
<     """
<     modpath = modname.split('.')
<     modname = modpath[0]
<     try:
<         filename = file_from_modpath(modpath)
<     except ImportError:
<         # import failed, i'm probably not so wrong by supposing it's
<         # not standard...
<         return 0
<     # modules which are not living in a file are considered standard
<     # (sys and __builtin__ for instance)
<     if filename is None:
<         return 1
<     filename = abspath(filename)
<     for path in std_path:
<         path = abspath(path)
<         if filename.startswith(path):
<             pfx_len = len(path)
<             if filename[pfx_len+1:pfx_len+14] != 'site-packages':
<                 return 1
<             return 0
<     return False
< 
<     
< 
< def is_relative(modname, from_file):
<     """return true if the given module name is relative to the given
<     file name
<     
<     :type modname: str
<     :param modname: name of the module we are interested in
< 
<     :type from_file: str
<     :param from_file:
<       path of the module from which modname has been imported
<     
<     :rtype: bool
<     :return:
<       true if the module has been imported relativly to `from_file`
<     """
<     if not isdir(from_file):
<         from_file = dirname(from_file)
<     if from_file in sys.path:
<         return False
<     try:
<         find_module(modname.split('.')[0], [from_file])
<         return True
<     except ImportError:
<         return False
< 
< 
< # internal only functions #####################################################
< 
< def _file_from_modpath(modpath, path=None, context=None):
<     """given a mod path (ie splited module / package name), return the
<     corresponding file
< 
<     this function is used internally, see `file_from_modpath`'s
<     documentation for more information
<     """
<     assert len(modpath) > 0
<     if context is not None:
<         try:
<             mtype, mp_filename = _module_file(modpath, [context])
<         except ImportError:
<             mtype, mp_filename = _module_file(modpath, path)
<     else:
<         mtype, mp_filename = _module_file(modpath, path)
<     if mtype == PY_COMPILED:
<         try:
<             return get_source_file(mp_filename)
<         except NoSourceFile:
<             return mp_filename
<     elif mtype == C_BUILTIN:
<         # integrated builtin module
<         return None
<     elif mtype == PKG_DIRECTORY:
<         mp_filename = _has_init(mp_filename)
<     return mp_filename
< 
< def _module_file(modpath, path=None):
<     """get a module type / file path
< 
<     :type modpath: list or tuple
<     :param modpath:
<       splitted module's name (i.e name of a module or package splitted
<       on '.'), with leading empty strings for explicit relative import
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<       
<     :rtype: tuple(int, str)
<     :return: the module type flag and the file path for a module
<     """
<     while modpath:
<         _, mp_filename, mp_desc = find_module(modpath[0], path)
<         modpath.pop(0)
<         mtype = mp_desc[2]
<         if modpath:
<             if mtype != PKG_DIRECTORY:
<                 raise ImportError('No module %r' % '.'.join(modpath))
<             path = [mp_filename]
<     return mtype, mp_filename
< 
< def _is_python_file(filename):
<     """return true if the given filename should be considered as a python file
< 
<     .pyc and .pyo are ignored
<     """
<     for ext in ('.py', '.so', '.pyd', '.pyw'):
<         if filename.endswith(ext):
<             return True
<     return False
< 
< 
< def _has_init(directory):
<     """if the given directory has a valid __init__ file, return its path,
<     else return None
<     """
<     mod_or_pack = join(directory, '__init__')
<     for ext in ('.py', '.pyw', '.pyc', '.pyo'):
<         if exists(mod_or_pack + ext):
<             return mod_or_pack + ext
<     return None
diff -r -N code-worker/tasks/clonedigger/logilab/common/monclient.py code-worker/code-worker/tasks/clonedigger/logilab/common/monclient.py
1,64d0
< """Simple interpreter client for monserver
< provides a simple readline interface.
< """
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< from socket import socket, SOCK_STREAM, AF_INET
< from select import select
< import sys
< import readline
< import threading
< 
< class SocketPrinter(threading.Thread):
<     """A thread that reads from a socket and output
<     to stdout as data are received"""
<     def __init__(self, sock):
<         threading.Thread.__init__(self)
<         self.socket = sock
<         self.stop = False
<         
<     def run(self):
<         """prints socket input indefinitely"""
<         fd = self.socket.fileno()
<         self.socket.setblocking(0)
<         while not self.stop:
<             iwl, _, _ = select([fd], [], [], 2)
<             if fd in iwl:
<                 data = self.socket.recv(100)
<                 if data:
<                     sys.stdout.write(data)
<                     sys.stdout.flush()
<             
< 
< 
< def client( host, port ):
<     """simple client that just sends input to the server"""
<     sock = socket( AF_INET, SOCK_STREAM )
<     sock.connect( (host, port) )
<     sp_thread = SocketPrinter(sock)
<     sp_thread.start()
<     while 1:
<         try:
<             line = raw_input() + "\n"
<             sock.send( line )
<         except EOFError:
<             print "Bye"
<             break
<         except:
<             sp_thread.stop = True
<             sp_thread.join()
<             raise
<     sp_thread.stop = True
<     sp_thread.join()
< 
< 
< if __name__ == "__main__":
<     server_host = sys.argv[1]
<     server_port = int(sys.argv[2])
<     client(server_host, server_port)
< 
<         
<         
diff -r -N code-worker/tasks/clonedigger/logilab/common/monserver.py code-worker/code-worker/tasks/clonedigger/logilab/common/monserver.py
1,121d0
< # -*- coding: iso-8859-1 -*-
< """This module implements a TCP server in a separate thread that
< allows *one* client to connect and provides a command line interpreter
< allowing the remote client to explore the process on the fly
< """
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = '$Id: monserver.py,v 1.2 2005-11-22 13:13:02 syt Exp $'
< 
< import threading
< import SocketServer
< import traceback
< import code
< import sys
< import time
< 
< 
< # NOTES: ce module tant utilis pour l'introspection, il peut
< # tre utile de fournir dans les locales de l'interpreteur des
< # objets dj initialiss (par exemple le module __main__ ou
< # bien __main__.*) ou encore des objets servant  l'introspection
< # comme on en trouve dans pymonitor (qui prend la liste des objets
< # maintenus par le garbage collector) ou a des statistiques
< # pour faire des oprations du style:
< # inspector.count_types( MyClass )
< # inspector.list_types( MyClass ) etc...
< 
< class MonitorInterpreter(code.InteractiveConsole):
<     """Subclasses InteractiveConsole so that all inputs
<     and outputs are done through a socket"""
<     def __init__(self, rfile, wfile ):
<         code.InteractiveConsole.__init__(self)
<         self.wfile = wfile
<         self.rfile = rfile
<         sys.stdout = self.wfile
<         sys.stderr = self.wfile
< 
<     def write(self, data):
<         """replace stderr output by writing to wfile"""
<         self.wfile.write( data )
<         self.wfile.flush()
< 
<     def raw_input( self, prompt = None ):
<         """Provides reading lines through the network"""
<         if prompt is not None:
<             self.wfile.write(prompt)
<             self.wfile.flush()
<         line = self.rfile.readline()
<         if line.endswith("\r\n"):
<             line = line[:-2]
<         elif line.endswith("\n"):
<             line = line[:-1]
<         return line
<         
< 
< class MonitorRequestHandler(SocketServer.BaseRequestHandler):
<     """Request handler for remote interpreter"""
<     def __init__(self, request, clientaddress, server ):
<         self.locals = {}
<         self.globals = globals().copy()
<         self.wfile = request.makefile("w")
<         self.rfile = request.makefile("r")
<         SocketServer.BaseRequestHandler.__init__(self, request, clientaddress,
<                                                  server )
<         
<     def handle(self):
<         """handle on request, through MonitorInterpreter"""
<         saved_stdout = sys.stdout
<         saved_stderr = sys.stderr
<         interpreter = MonitorInterpreter(self.rfile, self.wfile)
<         try:
<             interpreter.interact()
<         except KeyboardInterrupt:
<             self.server.exit = True
<         except:
<             sys.stdout = saved_stdout
<             sys.stderr = saved_stderr
<             traceback.print_exc()
<         print "Monitor handler exited"
< 
< class Monitor(threading.Thread):
<     """Monitor server. monothreaded we only
<     allow one client at a time"""
<     def __init__(self, host, port):
<         threading.Thread.__init__(self)
<         self.host = host
<         self.port = port
<         self.exit = False
< 
< 
<     def run(self):
<         """run the server loop"""
<         server = SocketServer.TCPServer( (self.host, self.port),
<                                          MonitorRequestHandler )
<         while not self.exit:
<             server.handle_request()
< 
< 
< 
< def demo_forever():
<     """sample demo server that outputs
<     numbers on screen"""
<     cnt = 1
<     while 1:
<         print cnt
<         time.sleep(2)
<         cnt += 1
< 
< if __name__ == "__main__":
<     listen_port = int(sys.argv[1])
<     mon = Monitor( "", listen_port )
<     mon.start()
<     try:
<         demo_forever()
<     except Exception:
<         traceback.print_exc()
<     mon.exit = True
<     mon.join()
diff -r -N code-worker/tasks/clonedigger/logilab/common/optik_ext.py code-worker/code-worker/tasks/clonedigger/logilab/common/optik_ext.py
1,331d0
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< add an abstraction level to transparently import optik classes from optparse
< (python >= 2.3) or the optik package.
< It also defines three new types for optik/optparse command line parser :
< 
<   * regexp
<     argument of this type will be converted using re.compile
<   * csv
<     argument of this type will be converted using split(',')
<   * yn
<     argument of this type will be true if 'y' or 'yes', false if 'n' or 'no'
<   * named
<     argument of this type are in the form <NAME>=<VALUE> or <NAME>:<VALUE>
< 
< """
< 
< import re
< import sys
< import time
< from copy import copy
< from os.path import exists
< 
< try:
<     # python >= 2.3
<     from optparse import OptionParser as BaseParser, Option as BaseOption, \
<          OptionGroup, OptionValueError, OptionError, Values, HelpFormatter, \
<          NO_DEFAULT
< except ImportError:
<     # python < 2.3
<     from optik import OptionParser as BaseParser, Option as BaseOption, \
<          OptionGroup, OptionValueError, OptionError, Values, HelpFormatter
<     try:
<         from optik import NO_DEFAULT
<     except:
<         NO_DEFAULT = []
< 
< try:
<     from mx import DateTime
<     HAS_MX_DATETIME = True
< except ImportError:
<     HAS_MX_DATETIME = False
< 
< 
< OPTPARSE_FORMAT_DEFAULT = sys.version_info >= (2, 4)
< 
< from clonedigger.logilab.common.textutils import get_csv
< 
< def check_regexp(option, opt, value):
<     """check a regexp value by trying to compile it
<     return the compiled regexp
<     """
<     if hasattr(value, 'pattern'):
<         return value
<     try:
<         return re.compile(value)
<     except ValueError:
<         raise OptionValueError(
<             "option %s: invalid regexp value: %r" % (opt, value))
<     
< def check_csv(option, opt, value):
<     """check a csv value by trying to split it
<     return the list of separated values
<     """
<     if isinstance(value, (list, tuple)):
<         return value
<     try:
<         return get_csv(value)
<     except ValueError:
<         raise OptionValueError(
<             "option %s: invalid csv value: %r" % (opt, value))
< 
< def check_yn(option, opt, value):
<     """check a yn value
<     return true for yes and false for no
<     """
<     if isinstance(value, int):
<         return bool(value)
<     if value in ('y', 'yes'):
<         return True
<     if value in ('n', 'no'):
<         return False
<     msg = "option %s: invalid yn value %r, should be in (y, yes, n, no)"
<     raise OptionValueError(msg % (opt, value))
< 
< def check_named(option, opt, value):
<     """check a named value
<     return a dictionnary containing (name, value) associations
<     """
<     if isinstance(value, dict):
<         return value
<     values = []
<     for value in check_csv(option, opt, value):
<         if value.find('=') != -1:
<             values.append(value.split('=', 1))
<         elif value.find(':') != -1:
<             values.append(value.split(':', 1))
<     if values:
<         return dict(values)
<     msg = "option %s: invalid named value %r, should be <NAME>=<VALUE> or \
< <NAME>:<VALUE>"
<     raise OptionValueError(msg % (opt, value))
< 
< def check_password(option, opt, value):
<     """check a password value (can't be empty)
<     """
<     # no actual checking, monkey patch if you want more
<     return value
< 
< def check_file(option, opt, value):
<     """check a file value
<     return the filepath
<     """
<     if exists(value):
<         return value
<     msg = "option %s: file %r does not exist"
<     raise OptionValueError(msg % (opt, value))
< 
< def check_date(option, opt, value):
<     """check a file value
<     return the filepath
<     """
<     try:
<         return DateTime.strptime(value, "%Y/%m/%d")
<     except DateTime.Error :
<         raise OptionValueError(
<             "expected format of %s is yyyy/mm/dd" % opt)
< 
< def check_color(option, opt, value):
<     """check a color value and returns it
<     /!\ does *not* check color labels (like 'red', 'green'), only
<     checks hexadecimal forms
<     """
<     # Case (1) : color label, we trust the end-user
<     if re.match('[a-z0-9 ]+$', value, re.I):
<         return value
<     # Case (2) : only accepts hexadecimal forms
<     if re.match('#[a-f0-9]{6}', value, re.I):
<         return value
<     # Else : not a color label neither a valid hexadecimal form => error
<     msg = "option %s: invalid color : %r, should be either hexadecimal \
<     value or predefinied color"
<     raise OptionValueError(msg % (opt, value))
< 
< import types
< 
< class Option(BaseOption):
<     """override optik.Option to add some new option types
<     """
<     TYPES = BaseOption.TYPES + ('regexp', 'csv', 'yn', 'named', 'password',
<                                 'multiple_choice', 'file', 'font', 'color')
<     TYPE_CHECKER = copy(BaseOption.TYPE_CHECKER)
<     TYPE_CHECKER['regexp'] = check_regexp
<     TYPE_CHECKER['csv'] = check_csv
<     TYPE_CHECKER['yn'] = check_yn
<     TYPE_CHECKER['named'] = check_named
<     TYPE_CHECKER['multiple_choice'] = check_csv
<     TYPE_CHECKER['file'] = check_file
<     TYPE_CHECKER['color'] = check_color
<     TYPE_CHECKER['password'] = check_password
<     if HAS_MX_DATETIME:
<         TYPES += ('date',)
<         TYPE_CHECKER['date'] = check_date
< 
<     def _check_choice(self):
<         """FIXME: need to override this due to optik misdesign"""
<         if self.type in ("choice", "multiple_choice"):
<             if self.choices is None:
<                 raise OptionError(
<                     "must supply a list of choices for type 'choice'", self)
<             elif type(self.choices) not in (types.TupleType, types.ListType):
<                 raise OptionError(
<                     "choices must be a list of strings ('%s' supplied)"
<                     % str(type(self.choices)).split("'")[1], self)
<         elif self.choices is not None:
<             raise OptionError(
<                 "must not supply choices for type %r" % self.type, self)
<     BaseOption.CHECK_METHODS[2] = _check_choice
< 
< 
<     def process(self, opt, value, values, parser):
<         # First, convert the value(s) to the right type.  Howl if any
<         # value(s) are bogus.
<         try:
<             value = self.convert_value(opt, value)
<         except AttributeError: # py < 2.4
<             value = self.check_value(opt, value)
<         if self.type == 'named': 
<             existant = getattr(values, self.dest)
<             if existant:
<                 existant.update(value)
<                 value = existant
<        # And then take whatever action is expected of us.
<         # This is a separate method to make life easier for
<         # subclasses to add new actions.
<         return self.take_action(
<             self.action, self.dest, opt, value, values, parser)
<     
< class OptionParser(BaseParser):
<     """override optik.OptionParser to use our Option class
<     """
<     def __init__(self, option_class=Option, *args, **kwargs):
<         BaseParser.__init__(self, option_class=Option, *args, **kwargs)
< 
< 
< class ManHelpFormatter(HelpFormatter):
<     """Format help using man pages ROFF format"""
< 
<     def __init__ (self,
<                   indent_increment=0,
<                   max_help_position=24,
<                   width=79,
<                   short_first=0):
<         HelpFormatter.__init__ (
<             self, indent_increment, max_help_position, width, short_first)
< 
<     def format_heading(self, heading):
<         return '.SH %s\n' % heading.upper()
< 
<     def format_description(self, description):
<         return description
< 
<     def format_option(self, option):
<         try:
<             optstring = option.option_strings
<         except AttributeError:
<             optstring = self.format_option_strings(option)
<         if option.help:
<             help = ' '.join([l.strip() for l in option.help.splitlines()])
<         else:
<             help = ''
<         return '''.IP "%s"
< %s
< ''' % (optstring, help)
< 
<     def format_head(self, optparser, pkginfo, section=1):
<         try:
<             pgm = optparser._get_prog_name()
<         except AttributeError:
<             # py >= 2.4.X (dunno which X exactly, at least 2)
<             pgm = optparser.get_prog_name()
<         short_desc = self.format_short_description(pgm, pkginfo.short_desc)
<         long_desc = self.format_long_description(pgm, pkginfo.long_desc)
<         return '%s\n%s\n%s\n%s' % (self.format_title(pgm, section), short_desc,
<                                    self.format_synopsis(pgm), long_desc)
< 
<     def format_title(self, pgm, section):
<         date = '-'.join([str(num) for num in time.localtime()[:3]])
<         return '.TH %s %s "%s" %s' % (pgm, section, date, pgm)
< 
<     def format_short_description(self, pgm, short_desc):
<         return '''.SH NAME
< .B %s 
< \- %s
< ''' % (pgm, short_desc.strip())
<         
<     def format_synopsis(self, pgm):
<         return '''.SH SYNOPSIS
< .B  %s
< [
< .I OPTIONS
< ] [
< .I <arguments>
< ]
< ''' % pgm
<         
<     def format_long_description(self, pgm, long_desc):
<         long_desc = '\n'.join([line.lstrip()
<                                for line in long_desc.splitlines()])
<         long_desc = long_desc.replace('\n.\n', '\n\n')
<         if long_desc.lower().startswith(pgm):
<             long_desc = long_desc[len(pgm):]
<         return '''.SH DESCRIPTION
< .B %s 
< %s
< ''' % (pgm, long_desc.strip())
<         
<     def format_tail(self, pkginfo):
<         return '''.SH SEE ALSO
< /usr/share/doc/pythonX.Y-%s/
< 
< .SH COPYRIGHT 
< %s
< 
< This program is free software; you can redistribute it and/or modify 
< it under the terms of the GNU General Public License as published 
< by the Free Software Foundation; either version 2 of the License, 
< or (at your option) any later version.
< 
< This program is distributed in the hope that it will be useful, 
< but WITHOUT ANY WARRANTY; without even the implied warranty of 
< MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the 
< GNU General Public License for more details.
< 
< You should have received a copy of the GNU General Public License 
< along with this program; if not, write to the Free Software 
< Foundation, Inc., 59 Temple Place, Suite 330, Boston, 
< MA 02111-1307 USA.
< .SH BUGS 
< Please report bugs on the project\'s mailing list:
< %s
< 
< .SH AUTHOR
< %s <%s>
< ''' % (getattr(pkginfo, 'debian_name', pkginfo.modname), pkginfo.copyright,
<        pkginfo.mailinglist, pkginfo.author, pkginfo.author_email)
< 
< 
< def generate_manpage(optparser, pkginfo, section=1, stream=sys.stdout):
<     """generate a man page from an optik parser"""
<     formatter = ManHelpFormatter()
<     print >> stream, formatter.format_head(optparser, pkginfo, section)
<     print >> stream, optparser.format_option_help(formatter)
<     print >> stream, formatter.format_tail(pkginfo)
< 
<     
< __all__ = ('OptionParser', 'Option', 'OptionGroup', 'OptionValueError',
<            'Values')
diff -r -N code-worker/tasks/clonedigger/logilab/common/optparser.py code-worker/code-worker/tasks/clonedigger/logilab/common/optparser.py
1,85d0
< # -*- coding: iso-8859-15 -*-
< # Copyright (c) 2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Extend OptionParser with commands.
< 
< Example:
< 
< >>> parser = OptionParser()
< >>> parser.usage = '%prog COMMAND [options] <arg> ...'
< >>> parser.add_command('build', 'mymod.build')
< >>> parser.add_command('clean', run_clean, add_opt_clean)
< >>> run, options, args = parser.parse_command(sys.argv[1:])
< >>> return run(options, args[1:])
< 
< With mymod.build that defines two functions run and add_options
< """
< 
< # XXX merge with optik_ext ? merge with clcommands ? 
< 
< import sys
< import optparse
< 
< class OptionParser(optparse.OptionParser):
< 
<     def __init__(self, *args, **kwargs):
<         optparse.OptionParser.__init__(self, *args, **kwargs)
<         self._commands = {}
<         self.min_args, self.max_args = 0, 1
<         
<     def add_command(self, name, mod_or_funcs, help=''):
<         """name of the command
< 	name of module or tuple of functions (run, add_options)
< 	"""
<         assert isinstance(mod_or_funcs, str) or isinstance(mod_or_funcs, tuple), \
< 	       "mod_or_funcs has to be a module name or a tuple of functions"
<         self._commands[name] = (mod_or_funcs, help)
< 
<     def print_main_help(self):
<         optparse.OptionParser.print_help(self)
<         print '\ncommands:'
<         for cmdname, (_, help) in self._commands.items():
<             print '% 10s - %s' % (cmdname, help)
<         
<     def parse_command(self, args):
<         if len(args) == 0:
<             self.print_main_help()
<             sys.exit(1)
<         cmd = args[0]
< 	args = args[1:]
<         if cmd not in self._commands:
<             if cmd in ('-h', '--help'):
<                 self.print_main_help()
<                 sys.exit(0)
<             elif self.version is not None and cmd == "--version":
<                 self.print_version()
<                 sys.exit(0)
<             self.error('unknow command')
<         self.prog = '%s %s' % (self.prog, cmd)
<         mod_or_f, help = self._commands[cmd]
<         # optparse inserts self.description between usage and options help
<         self.description = help
<         if isinstance(mod_or_f, str):
<             exec 'from %s import run, add_options' % mod_or_f
< 	else:
< 	    run, add_options = mod_or_f
<         add_options(self)
<         (options, args) = self.parse_args(args)        
<         if not (self.min_args <= len(args) <= self.max_args):
<             self.error('incorrect number of arguments')
<         return run, options, args
< 
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/patricia.py code-worker/code-worker/tasks/clonedigger/logilab/common/patricia.py
1,191d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< 
< a Python implementation of PATRICIA tree
< 
< PATRICIA - Practical Algorithm to Retrieve Information Coded in Alphanumeric
<            D.R.Morrison (1968).
< See http://www.csse.monash.edu.au/~lloyd/tildeAlgDS/Tree/PATRICIA.html if you
< want to know what's a PATRICIA tree...
< 
< TODO: _ advanced search
<       _ profile code
<       _ use mxTextTools ?
< """
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = "$Id: patricia.py,v 1.5 2003-10-31 14:18:32 syt Exp $"
< 
< def prefix(prfx, string):
<     """return the index of the first character from string which differs from
<     prefix
<     """
<     i = 0
<     while i < len(prfx):
<         if i == len(string) or prfx[i] != string[i]:
<             break
<         i += 1
<     return i
< 
< def split(index, string):
<     """split a string on index, returning a 3-uple :
<         (string before index, character at index, string after index)
<     """
<     return string[:index], string[index], string[index+1:]
< 
< 
< class PatriciaNode:
<     """a PATRICIA trie node
<     """
<     
<     def __init__(self, value='', leaf=0, data=None):
<         self.value = value
<         self.edges = {}
<         if leaf:
<             self.datas = [data]
<         else:
<             self.datas = []
<         
<     def insert(self, string, data):
<         """ insert the string in the trie and associate data to it
<         if the string exists is the trie, data is added to the existing datas
<         """
<         # are we arrived ?
<         if self.value == string:
<             self.datas.append(data)
<         # not yet !
<         else:
<             # check we don't break compression (value don't match)
<             ind = prefix(self.value, string)
<             if ind < len(self.value):
<                 # split this node
<                 pfx, e, self.value = split(ind, self.value)
<                 if ind < len(string):
<                     n = PatriciaNode(pfx)
<                     n.edges[string[ind]] = PatriciaNode(string[ind+1:], 1, data)
<                 else:
<                     n = PatriciaNode(pfx, 1, data)
<                 n.edges[e] = self
<                 return n
<             n_pfx, n_e, n_sfx = split(len(self.value), string)
<             if self.edges.has_key(n_e):
<                 self.edges[n_e] = self.edges[n_e].insert(n_sfx, data)
<             else:
<                 self.edges[n_e] = PatriciaNode(n_sfx, 1, data)
<         return self
< 
<     def remove(self, string):
<         """ return datas associated with string and remove string from the trie
<         raise KeyError if the key isn't found
<         FIXME: we should change the trie structure
<         """
<         if string == self.value and self.datas:
<             datas = self.datas
<             self.datas = []
<             return datas
<         else: 
<             pfx, e, sfx = split(len(self.value), string)
<             if self.value == pfx:
<                 return self.edges[e].remove(sfx)
<         raise KeyError(string)
<     
<     def lookup(self, string):
<         """ return datas associated with string
<         raise KeyError if the key isn't found
<         """
<         if string == self.value:
<             if self.datas:
<                 return self.datas
<             raise KeyError(string)
<         else: # len(self.value) < len(string): 
<             pfx, e, sfx = split(len(self.value), string)
<             if self.value == pfx:
<                 return self.edges[e].lookup(sfx)
<         raise KeyError(string)
<     
<     def pfx_search(self, pfx, depth=-1):
<         """ return all string with prefix pfx """
<         sfxs = []
<         if pfx and self.value[:len(pfx)] != pfx:
<             pfx, e, sfx = split(len(self.value), pfx)
<             if self.value == pfx and self.edges.has_key(e):
<                 sfxs = ['%s%s%s' % (self.value, e, sfx)
<                         for sfx in self.edges[e].pfx_search(sfx, depth)]
<         else:
<             if depth != 0:
<                 for e, child in self.edges.items():
<                     search = child.pfx_search('', depth-1-len(self.value))
<                     sfxs += ['%s%s%s' % (self.value, e, sfx)
<                              for sfx in search]
<             if (depth < 0 or len(self.value) <= depth):
<                 if self.datas:
<                     sfxs.append(self.value)
<         return sfxs
<         
<     def __str__(self, indent=''):
<         node_str = ''.join([' %s%s:\n%s' % (indent, key,
<                                             a.__str__('  %s' % indent))
<                             for key, a in self.edges.items()])
<         return '%s%s, %s\n%s' % (indent, self.value, self.datas, node_str)
< 
<     def __repr__(self):
<         return '<PatriciaNode id=%s value=%s childs=%s datas=%s>' % (
<             id(self), self.value, self.edges.keys(), self.datas)
< 
< 
< class PatriciaTrie:
<     """ wrapper class for a patricia tree
<     delegates to the root of the tree (PatriciaNode)
<     """
<     
<     def __init__(self):
<         self._trie = None
<         self.words = 0
< 
<     def insert(self, string, data=None):
<         """ insert a string into the tree """
<         self.words += 1
<         if self._trie is None:
<             self._trie = PatriciaNode(string, 1, data)
<         else:
<             self._trie = self._trie.insert(string, data)
<             
<     def remove(self, string):
<         """ remove a string from the tree """
<         if self._trie is not None:
<             return self._trie.remove(string)
<         raise KeyError(string)
< 
<     def lookup(self, string):
<         """ look for a string into the tree """
<         if self._trie is not None:
<             return self._trie.lookup(string)
<         raise KeyError(string)
< 
<     def pfx_search(self, string, depth=-1):
<         """ search all words begining by <string> """
<         if self._trie is not None:
<             return self._trie.pfx_search(string, depth)
<         raise KeyError(string)
< 
<     def __str__(self):
<         return self._trie.__str__()
<     
<     def __repr__(self):
<         return '<PatriciaTrie id=%s words=%s>' % (id(self), self.words)
diff -r -N code-worker/tasks/clonedigger/logilab/common/pdf_ext.py code-worker/code-worker/tasks/clonedigger/logilab/common/pdf_ext.py
1,100d0
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2003-2007 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< manipulate pdf and fdf files. pdftk recommended.
< 
< Notes regarding pdftk, pdf forms and fdf files (form definition file) 
< fields names can be extracted with:
<     pdftk orig.pdf generate_fdf output truc.fdf
< to merge fdf and pdf:      
<     pdftk orig.pdf fill_form test.fdf output result.pdf [flatten]
< without flatten, one could further edit the resulting form.
< with flatten, everything is turned into text.
< """
< # XXX seems very unix specific
< # TODO: check availability of pdftk at import 
< 
< 
< import os
< 
< HEAD="""%FDF-1.2
< %\xE2\xE3\xCF\xD3
< 1 0 obj 
< <<
< /FDF 
< <<
< /Fields [
< """
< 
< TAIL="""]
< >>
< >>
< endobj 
< trailer
< 
< <<
< /Root 1 0 R
< >>
< %%EOF
< """
< 
< def output_field( f ):
<     return "\xfe\xff" + "".join( [ "\x00"+c for c in f ] )
< 
< def extract_keys(lines):
<     keys = []
<     for line in lines:
<         if line.startswith('/V'):
<             pass #print 'value',line
<         elif line.startswith('/T'):
<             key = line[7:-2]
<             key = ''.join(key.split('\x00'))
<             keys.append( key )
<     return keys
< 
< def write_field(out, key, value):
<     out.write("<<\n")
<     if value:
<         out.write("/V (%s)\n" %value)
<     else:
<         out.write("/V /\n")
<     out.write("/T (%s)\n" % output_field(key) )
<     out.write(">> \n")
< 
< def write_fields(out, fields):
<     out.write(HEAD)
<     for (key,value,comment) in fields:
<         write_field(out, key, value)
<         write_field(out, key+"a", value) # pour copie-carbone sur autres pages
<     out.write(TAIL)
< 
< def extract_keys_from_pdf(filename):
<     # what about using 'pdftk filename dump_data_fields' and parsing the output ?
<     os.system('pdftk %s generate_fdf output /tmp/toto.fdf' % filename)
<     lines = file('/tmp/toto.fdf').readlines()
<     return extract_keys(lines)
< 
< 
< def fill_pdf(infile, outfile, fields):
<     write_fields(file('/tmp/toto.fdf', 'w'), fields)
<     os.system('pdftk %s fill_form /tmp/toto.fdf output %s flatten' % (infile, outfile))
< 
< def testfill_pdf(infile, outfile):
<     keys = extract_keys_from_pdf(infile)
<     fields = []
<     for key in keys:
<         fields.append( (key, key, '') )
<     fill_pdf(infile, outfile, fields)
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/__pkginfo__.py code-worker/code-worker/tasks/clonedigger/logilab/common/__pkginfo__.py
1,59d0
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< 
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< 
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """logilab.common packaging information"""
< 
< distname = 'logilab-common'
< modname = 'common'
< numversion = (0, 31, 0)
< version = '.'.join([str(num) for num in numversion])
< 
< license = 'GPL'
< copyright = '''Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr'''
< 
< author = "Logilab"
< author_email = "devel@logilab.fr"
< 
< short_desc = "useful miscellaneous modules used by Logilab projects"
< 
< long_desc = """logilab-common is a collection of low-level Python packages and \
< modules,
<  designed to ease:
<   * handling command line options and configuration files
<   * writing interactive command line tools
<   * manipulation files and character strings
<   * interfacing to OmniORB
<   * generating of SQL queries
<   * running unit tests
<   * manipulating tree structures
<   * accessing RDBMS (currently postgreSQL, mysql and sqlite)
<   * generating text and HTML reports
<   * logging"""
< 
< 
< web = "http://www.logilab.org/project/%s" % distname
< ftp = "ftp://ftp.logilab.org/pub/%s" % modname
< mailinglist = "mailto://python-projects@lists.logilab.org"
< 
< subpackage_of = 'logilab'
< subpackage_master = True
< 
< scripts = ('bin/pytest',)
< from os.path import join
< include_dirs = [join('test', 'data')]
< pyversions = ['2.3', '2.4', '2.5']
< debian_maintainer = 'Alexandre Fayolle'
< debian_maintainer_email = 'afayolle@debian.org'
diff -r -N code-worker/tasks/clonedigger/logilab/common/pytest.py code-worker/code-worker/tasks/clonedigger/logilab/common/pytest.py
1,639d0
< """pytest is a tool that eases test running and debugging.
< 
< To be able to use pytest, you should either write tests using
< the logilab.common.testlib's framework or the unittest module of the
< Python's standard library.
< 
< You can customize pytest's behaviour by defining a ``pytestconf.py`` file
< somewhere in your test directory. In this file, you can add options or
< change the way tests are run.
< 
< To add command line options, you must define a ``update_parser`` function in
< your ``pytestconf.py`` file. The function must accept a single parameter
< that will be the OptionParser's instance to customize.
< 
< If you wish to customize the tester, you'll have to define a class named
< ``CustomPyTester``. This class should extend the default `PyTester` class
< defined in the pytest module. Take a look at the `PyTester` and `DjangoTester`
< classes for more information about what can be done.
< 
< 
< For instance, if you wish to add a custom -l option to specify a loglevel, you
< could define the following ``pytestconf.py`` file ::
< 
<     import logging
<     from clonedigger.logilab.common.pytest import PyTester
<     
<     def update_parser(parser):
<         parser.add_option('-l', '--loglevel', dest='loglevel', action='store',
<                           choices=('debug', 'info', 'warning', 'error', 'critical'),
<                           default='critical', help="the default log level possible choices are "
<                           "('debug', 'info', 'warning', 'error', 'critical')")
<         return parser
<     
<     
<     class CustomPyTester(PyTester):
<         def __init__(self, cvg, options):
<             super(CustomPyTester, self).__init__(cvg, options)
<             loglevel = options.loglevel.upper()
<             logger = logging.getLogger('erudi')
<             logger.setLevel(logging.getLevelName(loglevel))
< 
< 
< In your TestCase class you can then get the value of a specific option with
< the ``optval`` method::
<     
<     class MyTestCase(TestCase):
<         def test_foo(self):
<             loglevel = self.optval('loglevel')
<             # ...
<             
< """
< 
< PYTEST_DOC = """%prog [OPTIONS] [testfile [testpattern]]
< 
< examples:
< 
< pytest path/to/mytests.py
< pytest path/to/mytests.py TheseTests
< pytest path/to/mytests.py TheseTests.test_thisone
< 
< pytest one (will run both test_thisone and test_thatone)
< pytest path/to/mytests.py -s not (will skip test_notthisone)
< 
< pytest --coverage test_foo.py
<   (only if logilab.devtools is available)
< """
< 
< import os, sys
< import os.path as osp
< from time import time, clock
< 
< from clonedigger.logilab.common.fileutils import abspath_listdir
< from clonedigger.logilab.common import testlib
< import doctest
< import unittest
< 
< 
< import imp
< 
< import __builtin__
< 
< 
< try:
<     import django
<     from clonedigger.logilab.common.modutils import modpath_from_file, load_module_from_modpath
<     DJANGO_FOUND = True
< except ImportError:
<     DJANGO_FOUND = False
< 
< CONF_FILE = 'pytestconf.py'
< 
< ## coverage hacks, do not read this, do not read this, do not read this
< 
< # hey, but this is an aspect, right ?!!!
< class TraceController(object):
<     nesting = 0
< 
<     def pause_tracing(cls):
<         if not cls.nesting:
<             cls.tracefunc = getattr(sys, '__settrace__', sys.settrace)
<             cls.oldtracer = getattr(sys, '__tracer__', None)
<             sys.__notrace__ = True
<             cls.tracefunc(None)
<         cls.nesting += 1
<     pause_tracing = classmethod(pause_tracing)
< 
<     def resume_tracing(cls):
<         cls.nesting -= 1
<         assert cls.nesting >= 0
<         if not cls.nesting:
<             cls.tracefunc(cls.oldtracer)
<             delattr(sys, '__notrace__')
<     resume_tracing = classmethod(resume_tracing)
<     
< 
< pause_tracing = TraceController.pause_tracing
< resume_tracing = TraceController.resume_tracing
< 
< 
< def nocoverage(func):
<     if hasattr(func, 'uncovered'):
<         return func
<     func.uncovered = True
<     def not_covered(*args, **kwargs):
<         pause_tracing()
<         try:
<             return func(*args, **kwargs)
<         finally:
<             resume_tracing()
<     not_covered.uncovered = True
<     return not_covered
< 
< 
< ## end of coverage hacks
< 
< 
< # monkeypatch unittest and doctest (ouch !)
< unittest.TestCase = testlib.TestCase
< unittest.main = testlib.unittest_main
< unittest._TextTestResult = testlib.SkipAwareTestResult
< unittest.TextTestRunner = testlib.SkipAwareTextTestRunner
< unittest.TestLoader = testlib.NonStrictTestLoader
< unittest.TestProgram = testlib.SkipAwareTestProgram
< if sys.version_info >= (2, 4):
<     doctest.DocTestCase.__bases__ = (testlib.TestCase,)
< else:
<     unittest.FunctionTestCase.__bases__ = (testlib.TestCase,)
< 
< 
< 
< def this_is_a_testfile(filename):
<     """returns True if `filename` seems to be a test file"""
<     filename = osp.basename(filename)
<     return ((filename.startswith('unittest')
<              or filename.startswith('test')
<              or filename.startswith('smoketest')) 
<             and filename.endswith('.py'))
<     
< 
< def this_is_a_testdir(dirpath):
<     """returns True if `filename` seems to be a test directory"""
<     return osp.basename(dirpath) in ('test', 'tests', 'unittests')
< 
< 
< def load_pytest_conf(path, parser):
<     """loads a ``pytestconf.py`` file and update default parser
<     and / or tester.
<     """
<     namespace = {}
<     execfile(path, namespace)
<     if 'update_parser' in namespace:
<         namespace['update_parser'](parser)
<     return namespace.get('CustomPyTester', PyTester)
< 
< 
< def project_root(parser, projdir=os.getcwd()):
<     """try to find project's root and add it to sys.path"""
<     curdir = osp.abspath(projdir)
<     previousdir = curdir
<     testercls = PyTester
<     conf_file_path = osp.join(curdir, CONF_FILE)
<     if osp.isfile(conf_file_path):
<         testercls = load_pytest_conf(conf_file_path, parser)
<     while this_is_a_testdir(curdir) or \
<               osp.isfile(osp.join(curdir, '__init__.py')):
<         newdir = osp.normpath(osp.join(curdir, os.pardir))
<         if newdir == curdir:
<             break
<         previousdir = curdir
<         curdir = newdir
<         conf_file_path = osp.join(curdir, CONF_FILE)
<         if osp.isfile(conf_file_path):
<             testercls = load_pytest_conf(conf_file_path, parser)
<     return previousdir, testercls
< 
< 
< class GlobalTestReport(object):
<     """this class holds global test statistics"""
<     def __init__(self):
<         self.ran = 0
<         self.skipped = 0
<         self.failures = 0
<         self.errors = 0
<         self.ttime = 0
<         self.ctime = 0
<         self.modulescount = 0
<         self.errmodules = []
< 
<     def feed(self, filename, testresult, ttime, ctime):
<         """integrates new test information into internal statistics"""
<         ran = testresult.testsRun
<         self.ran += ran
<         self.skipped += len(getattr(testresult, 'skipped', ()))
<         self.failures += len(testresult.failures)
<         self.errors += len(testresult.errors)
<         self.ttime += ttime
<         self.ctime += ctime
<         self.modulescount += 1
<         if not testresult.wasSuccessful():
<             problems = len(testresult.failures) + len(testresult.errors)
<             self.errmodules.append((filename[:-3], problems, ran))
< 
< 
<     def failed_to_test_module(self, filename):
<         """called when the test module could not be imported by unittest
<         """
<         self.errors += 1
<         self.errmodules.append((filename[:-3], 1, 1))
<         
<     
<     def __str__(self):
<         """this is just presentation stuff"""
<         line1 = ['Ran %s test cases in %.2fs (%.2fs CPU)'
<                  % (self.ran, self.ttime, self.ctime)]
<         if self.errors:
<             line1.append('%s errors' % self.errors)
<         if self.failures:
<             line1.append('%s failures' % self.failures)
<         if self.skipped:
<             line1.append('%s skipped' % self.skipped)
<         modulesok = self.modulescount - len(self.errmodules)
<         if self.errors or self.failures:
<             line2 = '%s modules OK (%s failed)' % (modulesok,
<                                                    len(self.errmodules))
<             descr = ', '.join(['%s [%s/%s]' % info for info in self.errmodules])
<             line3 = '\nfailures: %s' % descr
<         elif modulesok:
<             line2 = 'All %s modules OK' % modulesok
<             line3 = ''
<         else:
<             return ''
<         return '%s\n%s%s' % (', '.join(line1), line2, line3)
< 
< 
< 
< def remove_local_modules_from_sys(testdir):
<     """remove all modules from cache that come from `testdir`
< 
<     This is used to avoid strange side-effects when using the
<     testall() mode of pytest.
<     For instance, if we run pytest on this tree::
<     
<       A/test/test_utils.py
<       B/test/test_utils.py
< 
<     we **have** to clean sys.modules to make sure the correct test_utils
<     module is ran in B
<     """
<     for modname, mod in sys.modules.items():
<         if mod is None:
<             continue
<         if not hasattr(mod, '__file__'):
<             # this is the case of some built-in modules like sys, imp, marshal
<             continue
<         modfile = mod.__file__
<         # if modfile is not an asbolute path, it was probably loaded locally
<         # during the tests
<         if not osp.isabs(modfile) or modfile.startswith(testdir):
<             del sys.modules[modname]
< 
< 
< 
< class PyTester(object):
<     """encaspulates testrun logic"""
<     
<     def __init__(self, cvg, options):
<         self.tested_files = []
<         self.report = GlobalTestReport()
<         self.cvg = cvg
<         self.options = options
< 
<     def show_report(self):
<         """prints the report and returns appropriate exitcode"""
<         # everything has been ran, print report
<         print "*" * 79
<         print self.report
<         return self.report.failures + self.report.errors
<         
< 
<     def testall(self, exitfirst=False):
<         """walks trhough current working directory, finds something
<         which can be considered as a testdir and runs every test there
<         """
<         for dirname, dirs, files in os.walk(os.getcwd()):
<             for skipped in ('CVS', '.svn', '.hg'):
<                 if skipped in dirs:
<                     dirs.remove(skipped)
<             basename = osp.basename(dirname)
<             if basename in ('test', 'tests'):
<                 print "going into", dirname
<                 # we found a testdir, let's explore it !
<                 self.testonedir(dirname, exitfirst)
<                 dirs[:] = []
< 
<  
<     def testonedir(self, testdir, exitfirst=False):
<         """finds each testfile in the `testdir` and runs it"""
<         for filename in abspath_listdir(testdir):
<             if this_is_a_testfile(filename):
<                 # run test and collect information
<                 prog = self.testfile(filename, batchmode=True)
<                 if exitfirst and (prog is None or not prog.result.wasSuccessful()):
<                     break
<         # clean local modules
<         remove_local_modules_from_sys(testdir)
< 
< 
<     def testfile(self, filename, batchmode=False):
<         """runs every test in `filename`
< 
<         :param filename: an absolute path pointing to a unittest file
<         """
<         here = os.getcwd()
<         dirname = osp.dirname(filename)
<         if dirname:
<             os.chdir(dirname)
<         modname = osp.basename(filename)[:-3]
<         try:
<             print >>sys.stderr, ('  %s  ' % osp.basename(filename)).center(70, '=')
<         except TypeError: # < py 2.4 bw compat
<             print >>sys.stderr, ('  %s  ' % osp.basename(filename)).center(70)
<         try:
<             try:
<                 tstart, cstart = time(), clock()
<                 testprog = testlib.unittest_main(modname, batchmode=batchmode, cvg=self.cvg,
<                                                  options=self.options)
<                 tend, cend = time(), clock()
<                 ttime, ctime = (tend - tstart), (cend - cstart)
<                 self.report.feed(filename, testprog.result, ttime, ctime)
<                 return testprog
<             except (KeyboardInterrupt, SystemExit):
<                 raise
<             except Exception, exc:
<                 self.report.failed_to_test_module(filename)
<                 print 'unhandled exception occured while testing', modname
<                 import traceback
<                 traceback.print_exc()
<                 return None                
<         finally:
<             if dirname:
<                 os.chdir(here)
< 
< 
< 
< class DjangoTester(PyTester):
< 
<     def load_django_settings(self, dirname):
<         """try to find project's setting and load it"""
<         curdir = osp.abspath(dirname)
<         previousdir = curdir
<         while not osp.isfile(osp.join(curdir, 'settings.py')) and \
<                   osp.isfile(osp.join(curdir, '__init__.py')):
<             newdir = osp.normpath(osp.join(curdir, os.pardir))
<             if newdir == curdir:
<                 raise AssertionError('could not find settings.py')
<             previousdir = curdir
<             curdir = newdir
<         # late django initialization
<         settings = load_module_from_modpath(modpath_from_file(osp.join(curdir, 'settings.py')))
<         from django.core.management import setup_environ
<         setup_environ(settings)
<         settings.DEBUG = False
<         self.settings = settings
<         # add settings dir to pythonpath since it's the project's root
<         if curdir not in sys.path:
<             sys.path.insert(1, curdir)
< 
<     def before_testfile(self):
<         # Those imports must be done **after** setup_environ was called
<         from django.test.utils import setup_test_environment
<         from django.test.utils import create_test_db
<         setup_test_environment()
<         create_test_db(verbosity=0)
<         self.dbname = self.settings.TEST_DATABASE_NAME
<         
< 
<     def after_testfile(self):
<         # Those imports must be done **after** setup_environ was called
<         from django.test.utils import teardown_test_environment
<         from django.test.utils import destroy_test_db
<         teardown_test_environment()
<         print 'destroying', self.dbname
<         destroy_test_db(self.dbname, verbosity=0)
<         
< 
<     def testall(self, exitfirst=False):
<         """walks trhough current working directory, finds something
<         which can be considered as a testdir and runs every test there
<         """
<         for dirname, dirs, files in os.walk(os.getcwd()):
<             for skipped in ('CVS', '.svn', '.hg'):
<                 if skipped in dirs:
<                     dirs.remove(skipped)
<             if 'tests.py' in files:
<                 self.testonedir(dirname, exitfirst)
<                 dirs[:] = []
<             else:
<                 basename = osp.basename(dirname)
<                 if basename in ('test', 'tests'):
<                     print "going into", dirname
<                     # we found a testdir, let's explore it !
<                     self.testonedir(dirname, exitfirst)
<                     dirs[:] = []
< 
< 
<     def testonedir(self, testdir, exitfirst=False):
<         """finds each testfile in the `testdir` and runs it"""
<         # special django behaviour : if tests are splited in several files,
<         # remove the main tests.py file and tests each test file separately
<         testfiles = [fpath for fpath in abspath_listdir(testdir)
<                      if this_is_a_testfile(fpath)]
<         if len(testfiles) > 1:
<             try:
<                 testfiles.remove(osp.join(testdir, 'tests.py'))
<             except ValueError:
<                 pass
<         for filename in testfiles:
<             # run test and collect information
<             prog = self.testfile(filename, batchmode=True)
<             if exitfirst and (prog is None or not prog.result.wasSuccessful()):
<                 break
<         # clean local modules
<         remove_local_modules_from_sys(testdir)
< 
< 
<     def testfile(self, filename, batchmode=False):
<         """runs every test in `filename`
< 
<         :param filename: an absolute path pointing to a unittest file
<         """
<         here = os.getcwd()
<         dirname = osp.dirname(filename)
<         if dirname:
<             os.chdir(dirname)
<         self.load_django_settings(dirname)
<         modname = osp.basename(filename)[:-3]
<         print >>sys.stderr, ('  %s  ' % osp.basename(filename)).center(70, '=')
<         try:
<             try:
<                 tstart, cstart = time(), clock()
<                 self.before_testfile()
<                 testprog = testlib.unittest_main(modname, batchmode=batchmode, cvg=self.cvg)
<                 tend, cend = time(), clock()
<                 ttime, ctime = (tend - tstart), (cend - cstart)
<                 self.report.feed(filename, testprog.result, ttime, ctime)
<                 return testprog
<             except SystemExit:
<                 raise
<             except Exception, exc:
<                 import traceback
<                 traceback.print_exc()
<                 self.report.failed_to_test_module(filename)
<                 print 'unhandled exception occured while testing', modname
<                 print 'error: %s' % exc
<                 return None                
<         finally:
<             self.after_testfile()
<             if dirname:
<                 os.chdir(here)
< 
< 
< def make_parser():
<     """creates the OptionParser instance
<     """
<     from optparse import OptionParser
<     parser = OptionParser(usage=PYTEST_DOC)
< 
<     parser.newargs = []
<     def rebuild_cmdline(option, opt, value, parser):
<         """carry the option to unittest_main"""
<         parser.newargs.append(opt)
<         
< 
<     def rebuild_and_store(option, opt, value, parser):
<         """carry the option to unittest_main and store
<         the value on current parser
<         """
<         parser.newargs.append(opt)
<         setattr(parser.values, option.dest, True)
< 
<     # pytest options
<     parser.add_option('-t', dest='testdir', default=None,
<                       help="directory where the tests will be found")
<     parser.add_option('-d', dest='dbc', default=False,
<                       action="store_true", help="enable design-by-contract")
<     # unittest_main options provided and passed through pytest
<     parser.add_option('-v', '--verbose', callback=rebuild_cmdline,
<                       action="callback", help="Verbose output")
<     parser.add_option('-i', '--pdb', callback=rebuild_and_store,
<                       dest="pdb", action="callback",
<                       help="Enable test failure inspection (conflicts with --coverage)")
<     parser.add_option('-x', '--exitfirst', callback=rebuild_and_store,
<                       dest="exitfirst",
<                       action="callback", help="Exit on first failure "
<                       "(only make sense when pytest run one test file)")
<     parser.add_option('-c', '--capture', callback=rebuild_cmdline,
<                       action="callback", 
<                       help="Captures and prints standard out/err only on errors "
<                       "(only make sense when pytest run one test file)")
<     parser.add_option('-p', '--printonly',
<                       # XXX: I wish I could use the callback action but it
<                       #      doesn't seem to be able to get the value
<                       #      associated to the option
<                       action="store", dest="printonly", default=None,
<                       help="Only prints lines matching specified pattern (implies capture) "
<                       "(only make sense when pytest run one test file)")
<     parser.add_option('-s', '--skip',
<                       # XXX: I wish I could use the callback action but it
<                       #      doesn't seem to be able to get the value
<                       #      associated to the option
<                       action="store", dest="skipped", default=None,
<                       help="test names matching this name will be skipped "
<                       "to skip several patterns, use commas")
<     parser.add_option('-q', '--quiet', callback=rebuild_cmdline,
<                       action="callback", help="Minimal output")
<     parser.add_option('-P', '--profile', default=None, dest='profile',
<                       help="Profile execution and store data in the given file")
< 
<     try:
<         from clonedigger.logilab.devtools.lib.coverage import Coverage
<         parser.add_option('--coverage', dest="coverage", default=False,
<                           action="store_true",
<                           help="run tests with pycoverage (conflicts with --pdb)")
<     except ImportError:
<         pass
< 
<     if DJANGO_FOUND:
<         parser.add_option('-J', '--django', dest='django', default=False,
<                           action="store_true",
<                           help='use pytest for django test cases')
<     return parser
< 
< 
< def parseargs(parser):
<     """Parse the command line and return (options processed), (options to pass to
<     unittest_main()), (explicitfile or None).
<     """
<     # parse the command line
<     options, args = parser.parse_args()
<     if options.pdb and getattr(options, 'coverage', False):
<         parser.error("'pdb' and 'coverage' options are exclusive")
<     filenames = [arg for arg in args if arg.endswith('.py')]
<     if filenames:
<         if len(filenames) > 1:
<             parser.error("only one filename is acceptable")
<         explicitfile = filenames[0]
<         args.remove(explicitfile)
<     else:
<         explicitfile = None
<     # someone wants DBC
<     testlib.ENABLE_DBC = options.dbc
<     newargs = parser.newargs
<     if options.printonly:
<         newargs.extend(['--printonly', options.printonly])
<     if options.skipped:
<         newargs.extend(['--skip', options.skipped])
<     # append additional args to the new sys.argv and let unittest_main
<     # do the rest
<     newargs += args
<     return options, explicitfile 
< 
< 
< 
< def run():
<     parser = make_parser()
<     rootdir, testercls = project_root(parser)
<     options, explicitfile = parseargs(parser)
<     # mock a new command line
<     sys.argv[1:] = parser.newargs
<     covermode = getattr(options, 'coverage', None)
<     cvg = None
<     if not '' in sys.path:
<         sys.path.insert(0, '')    
<     if covermode:
<         # control_import_coverage(rootdir)
<         from clonedigger.logilab.devtools.lib.coverage import Coverage
<         cvg = Coverage([rootdir])
<         cvg.erase()
<         cvg.start()
<     if DJANGO_FOUND and options.django:
<         tester = DjangoTester(cvg, options)
<     else:
<         tester = testercls(cvg, options)
<     if explicitfile:
<         cmd, args = tester.testfile, (explicitfile,)
<     elif options.testdir:
<         cmd, args = tester.testonedir, (options.testdir, options.exitfirst)
<     else:
<         cmd, args = tester.testall, (options.exitfirst,)
<     try:
<         try:
<             if options.profile:
<                 import hotshot
<                 prof = hotshot.Profile(options.profile)
<                 prof.runcall(cmd, *args)
<                 prof.close()
<                 print 'profile data saved in', options.profile
<             else:
<                  cmd(*args)           
<         except SystemExit:
<             raise
<         except:
<             import traceback
<             traceback.print_exc()
<     finally:
<         errcode = tester.show_report()
<         if covermode:
<             cvg.stop()
<             cvg.save()
<             here = osp.abspath(os.getcwd())
<             if this_is_a_testdir(here):
<                 morfdir = osp.normpath(osp.join(here, '..'))
<             else:
<                 morfdir = here
<             print "computing code coverage (%s), this might take some time" % \
<                   morfdir
<             cvg.annotate([morfdir])
<             cvg.report([morfdir], False)
<         sys.exit(errcode)
diff -r -N code-worker/tasks/clonedigger/logilab/common/shellutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/shellutils.py
1,207d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< Some shell/term utilities, useful to write some python scripts instead of shell
< scripts
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< import os        
< import glob
< import shutil
< import sys
< import tempfile
< import time
< from os.path import exists, isdir, islink, basename, join, walk
< 
< from clonedigger.logilab.common import STD_BLACKLIST
< 
< 
< def chown(path, login=None, group=None):
<     """same as `os.chown` function but accepting user login or group name as
<     argument. If login or group is omitted, it's left unchanged.
< 
<     Note: you must own the file to chown it (or be root). Otherwise OSError is raised. 
<     """
<     if login is None:
<         uid = -1
<     else:
<         try:
<             uid = int(login)
<         except ValueError:
<             import pwd
<             uid = pwd.getpwnam(login).pw_uid
<     if group is None:
<         gid = -1
<     else:
<         try:
<             gid = int(group)
<         except ValueError:
<             import grp
<             gid = grp.getgrname(group).gr_gid
<     os.chown(path, uid, gid)
<         
< 
< def mv(source, destination, _action=shutil.move):
<     """a shell like mv, supporting wildcards
<     """
<     sources = glob.glob(source)
<     if len(sources) > 1:
<         assert isdir(destination)
<         for filename in sources:
<             _action(filename, join(destination, basename(filename)))
<     else:
<         try:
<             source = sources[0]
<         except IndexError:
<             raise OSError('No file matching %s' % source)
<         if isdir(destination) and exists(destination):
<             destination = join(destination, basename(source))
<         try:
<             _action(source, destination)
<         except OSError, ex:
<             raise OSError('Unable to move %r to %r (%s)' % (
<                 source, destination, ex))
<         
< def rm(*files):
<     """a shell like rm, supporting wildcards
<     """
<     for wfile in files:
<         for filename in glob.glob(wfile):
<             if islink(filename):
<                 os.remove(filename)
<             elif isdir(filename):
<                 shutil.rmtree(filename)
<             else:
<                 os.remove(filename)
<     
< def cp(source, destination):
<     """a shell like cp, supporting wildcards
<     """
<     mv(source, destination, _action=shutil.copy)
< 
< 
< def find(directory, exts, exclude=False, blacklist=STD_BLACKLIST):
<     """recursivly find files ending with the given extensions from the directory
< 
<     :type directory: str
<     :param directory:
<       directory where the search should start
< 
<     :type exts: basestring or list or tuple
<     :param exts:
<       extensions or lists or extensions to search
< 
<     :type exclude: boolean
<     :param exts:
<       if this argument is True, returning files NOT ending with the given
<       extensions
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       optional list of files or directory to ignore, default to the value of
<       `logilab.common.STD_BLACKLIST`
< 
<     :rtype: list
<     :return:
<       the list of all matching files
<     """
<     if isinstance(exts, basestring):
<         exts = (exts,)
<     if exclude:
<         def match(filename, exts):
<             for ext in exts:
<                 if filename.endswith(ext):
<                     return False
<             return True
<     else:
<         def match(filename, exts):
<             for ext in exts:
<                 if filename.endswith(ext):
<                     return True
<             return False
<     def func(files, directory, fnames):
<         """walk handler"""
<         # remove files/directories in the black list
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         for filename in fnames:
<             src = join(directory, filename)
<             if isdir(src):
<                 continue
<             if match(filename, exts):
<                 files.append(src)
<     files = []
<     walk(directory, func, files)
<     return files
< 
< 
< class Execute:
<     """This is a deadlock safe version of popen2 (no stdin), that returns
<     an object with errorlevel, out and err
<     """
<     
<     def __init__(self, command):
<         outfile = tempfile.mktemp()
<         errfile = tempfile.mktemp()
<         self.status = os.system("( %s ) >%s 2>%s" %
<                                 (command, outfile, errfile)) >> 8
<         self.out = open(outfile,"r").read()
<         self.err = open(errfile,"r").read()
<         os.remove(outfile)
<         os.remove(errfile)
< 
< 
< def acquire_lock(lock_file, max_try=10, delay=10):
<     """acquire a lock represented by a file on the file system"""
<     count = 0
<     while max_try <= 0 or count < max_try:
<         if not exists(lock_file):
<             break
<         count += 1
<         time.sleep(delay)
<     else:
<         raise Exception('Unable to acquire %s' % lock_file)
<     stream = open(lock_file, 'w')
<     stream.write(str(os.getpid()))
<     stream.close()
<     
< def release_lock(lock_file):
<     """release a lock represented by a file on the file system"""
<     os.remove(lock_file)
< 
< 
< class ProgressBar(object):
<     """a simple text progression bar"""
<     
<     def __init__(self, nbops, size=20., stream=sys.stdout):
<         self._dotevery = max(nbops / size, 1)
<         self._fstr = '\r[%-20s]'
<         self._dotcount, self._dots = 1, []
<         self._stream = stream
< 
<     def update(self):
<         """update the progression bar"""
<         self._dotcount += 1
<         if self._dotcount >= self._dotevery:
<             self._dotcount = 1
<             self._dots.append('.')
<             self._stream.write(self._fstr % ''.join(self._dots))
<             self._stream.flush()
diff -r -N code-worker/tasks/clonedigger/logilab/common/sqlgen.py code-worker/code-worker/tasks/clonedigger/logilab/common/sqlgen.py
1,241d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Help to generate SQL string usable by the Python DB-API
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< 
< # SQLGenerator ################################################################
< 
< class SQLGenerator :
<     """
<     Helper class to generate SQL strings to use with python's DB-API
<     """
< 
<     def where(self, keys, addon=None) :
<         """
<         keys : list of keys
<         
<         >>> s = SQLGenerator()
<         >>> s.where(['nom'])
<         'nom = %(nom)s'
<         >>> s.where(['nom','prenom'])
<         'nom = %(nom)s AND prenom = %(prenom)s'
<         >>> s.where(['nom','prenom'], 'x.id = y.id')
<         'x.id = y.id AND nom = %(nom)s AND prenom = %(prenom)s'
<         """
<         restriction = ["%s = %%(%s)s" % (x, x) for x in keys]
<         if addon:
<             restriction.insert(0, addon)
<         return " AND ".join(restriction)
< 
<     def set(self, keys) :
<         """
<         keys : list of keys
<         
<         >>> s = SQLGenerator()
<         >>> s.set(['nom'])
<         'nom = %(nom)s'
<         >>> s.set(['nom','prenom'])
<         'nom = %(nom)s, prenom = %(prenom)s'
<         """
<         return ", ".join(["%s = %%(%s)s" % (x, x) for x in keys])
< 
<     def insert(self, table, params) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
<         
<         >>> s = SQLGenerator()
<         >>> s.insert('test',{'nom':'dupont'})
<         'INSERT INTO test ( nom ) VALUES ( %(nom)s )'
<         >>> s.insert('test',{'nom':'dupont','prenom':'jean'})
<         'INSERT INTO test ( nom, prenom ) VALUES ( %(nom)s, %(prenom)s )'
<         """
<         keys = ', '.join(params.keys())
<         values = ', '.join(["%%(%s)s" % x for x in params])
<         sql = 'INSERT INTO %s ( %s ) VALUES ( %s )' % (table, keys, values)
<         return sql
< 
<     def select(self, table, params) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
< 
<         >>> s = SQLGenerator()
<         >>> s.select('test',{})
<         'SELECT * FROM test'
<         >>> s.select('test',{'nom':'dupont'})
<         'SELECT * FROM test WHERE nom = %(nom)s'
<         >>> s.select('test',{'nom':'dupont','prenom':'jean'})
<         'SELECT * FROM test WHERE nom = %(nom)s AND prenom = %(prenom)s'
<         """
<         sql = 'SELECT * FROM %s' % table
<         where = self.where(params.keys())
<         if where :
<             sql = sql + ' WHERE %s' % where
<         return sql
< 
<     def adv_select(self, model, tables, params, joins=None) :
<         """
<         model  : list of columns to select
<         tables : list of tables used in from
<         params   :  dictionnary that will be used as in cursor.execute(sql, params)
<         joins  : optional list of restriction statements to insert in the where
<                  clause. Usually used to perform joins.
< 
<         >>> s = SQLGenerator()
<         >>> s.adv_select(['column'],[('test', 't')], {})
<         'SELECT column FROM test AS t'
<         >>> s.adv_select(['column'],[('test', 't')], {'nom':'dupont'})
<         'SELECT column FROM test AS t WHERE nom = %(nom)s'
<         """
<         table_names = ["%s AS %s" % (k, v) for k, v in tables]
<         sql = 'SELECT %s FROM %s' % (', '.join(model), ', '.join(table_names))
<         if joins and type(joins) != type(''):
<             joins = ' AND '.join(joins)
<         where = self.where(params.keys(), joins)
<         if where :
<             sql = sql + ' WHERE %s' % where
<         return sql
< 
<     def delete(self, table, params) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
< 
<         >>> s = SQLGenerator()
<         >>> s.delete('test',{'nom':'dupont'})
<         'DELETE FROM test WHERE nom = %(nom)s'
<         >>> s.delete('test',{'nom':'dupont','prenom':'jean'})
<         'DELETE FROM test WHERE nom = %(nom)s AND prenom = %(prenom)s'
<         """
<         where = self.where(params.keys())
<         sql = 'DELETE FROM %s WHERE %s' % (table, where)
<         return sql
< 
<     def update(self, table, params, unique) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
< 
<         >>> s = SQLGenerator()
<         >>> s.update('test', {'id':'001','nom':'dupont'}, ['id'])
<         'UPDATE test SET nom = %(nom)s WHERE id = %(id)s'
<         >>> s.update('test',{'id':'001','nom':'dupont','prenom':'jean'},['id'])
<         'UPDATE test SET nom = %(nom)s, prenom = %(prenom)s WHERE id = %(id)s'
<         """
<         where = self.where(unique)
<         set = self.set([key for key in params if key not in unique])
<         sql = 'UPDATE %s SET %s WHERE %s' % (table, set, where)
<         return sql
< 
< class BaseTable:
<     """
<     Another helper class to ease SQL table manipulation
<     """
<     # table_name = "default"
<     # supported types are s/i/d
<     # table_fields = ( ('first_field','s'), )
<     # primary_key = 'first_field'
< 
<     def __init__(self, table_name, table_fields, primary_key=None):
<         if primary_key is None:
<             self._primary_key = table_fields[0][0]
<         else:
<             self._primary_key = primary_key
< 
<         self._table_fields = table_fields
<         self._table_name = table_name
<         info = {
<             'key' : self._primary_key,
<             'table' : self._table_name,
<             'columns' : ",".join( [ f for f,t in self._table_fields ] ),
<             'values' : ",".join( [sql_repr(t, "%%(%s)s" % f)
<                                   for f,t in self._table_fields] ),
<             'updates' : ",".join( ["%s=%s" % (f, sql_repr(t, "%%(%s)s" % f))
<                                    for f,t in self._table_fields] ),
<             }
<         self._insert_stmt = ("INSERT into %(table)s (%(columns)s) "
<                              "VALUES (%(values)s) WHERE %(key)s=%%(key)s") % info
<         self._update_stmt = ("UPDATE %(table)s SET (%(updates)s) "
<                              "VALUES WHERE %(key)s=%%(key)s") % info
<         self._select_stmt = ("SELECT %(columns)s FROM %(table)s "
<                              "WHERE %(key)s=%%(key)s") % info
<         self._delete_stmt = ("DELETE FROM %(table)s "
<                              "WHERE %(key)s=%%(key)s") % info
< 
<         for k, t in table_fields:
<             if hasattr(self, k):
<                 raise ValueError("Cannot use %s as a table field" % k)
<             setattr(self, k,None)
< 
< 
<     def as_dict(self):
<         d = {}
<         for k, t in self._table_fields:
<             d[k] = getattr(self, k)
<         return d
< 
<     def select(self, cursor):
<         d = { 'key' : getattr(self,self._primary_key) }
<         cursor.execute(self._select_stmt % d)
<         rows = cursor.fetchall()
<         if len(rows)!=1:
<             msg = "Select: ambiguous query returned %d rows"
<             raise ValueError(msg % len(rows))
<         for (f, t), v in zip(self._table_fields, rows[0]):
<             setattr(self, f, v)
< 
<     def update(self, cursor):
<         d = self.as_dict()
<         cursor.execute(self._update_stmt % d)
< 
<     def delete(self, cursor):
<         d = { 'key' : getattr(self,self._primary_key) }
< 
< 
< # Helper functions #############################################################
< 
< def name_fields(cursor, records) :
<     """
<     Take a cursor and a list of records fetched with that cursor, then return a
<     list of dictionnaries (one for each record) whose keys are column names and
<     values are records' values.
< 
<     cursor : cursor used to execute the query
<     records : list returned by fetch*()
<     """
<     result = []
<     for record in records :
<         record_dict = {}
<         for i in range(len(record)) :
<             record_dict[cursor.description[i][0]] = record[i]
<         result.append(record_dict)
<     return result
< 
< def sql_repr(type, val):
<     if type == 's':
<         return "'%s'" % (val,)
<     else:
<         return val
<             
<         
< if __name__ == "__main__":
<     import doctest
<     from clonedigger.logilab.common import sqlgen
<     print doctest.testmod(sqlgen)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/all-wcprops
1,269d0
< K 25
< svn:wc:ra_dav:version-url
< V 65
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common
< END
< pytest.py
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/pytest.py
< END
< shellutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/shellutils.py
< END
< __pkginfo__.py
< K 25
< svn:wc:ra_dav:version-url
< V 80
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/__pkginfo__.py
< END
< patricia.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/patricia.py
< END
< deprecation.py
< K 25
< svn:wc:ra_dav:version-url
< V 80
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/deprecation.py
< END
< __init__.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/__init__.py
< END
< visitor.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/visitor.py
< END
< modutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/modutils.py
< END
< fileutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/fileutils.py
< END
< vcgutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/vcgutils.py
< END
< logservice.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/logservice.py
< END
< daemon.py
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/daemon.py
< END
< html.py
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/html.py
< END
< optik_ext.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/optik_ext.py
< END
< cli.py
< K 25
< svn:wc:ra_dav:version-url
< V 72
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/cli.py
< END
< corbautils.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/corbautils.py
< END
< astutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/astutils.py
< END
< bind.py
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/bind.py
< END
< optparser.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/optparser.py
< END
< logger.py
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/logger.py
< END
< clcommands.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/clcommands.py
< END
< db.py
< K 25
< svn:wc:ra_dav:version-url
< V 71
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/db.py
< END
< monclient.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/monclient.py
< END
< pdf_ext.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/pdf_ext.py
< END
< sqlgen.py
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/sqlgen.py
< END
< adbh.py
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/adbh.py
< END
< tree.py
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/tree.py
< END
< interface.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/interface.py
< END
< graph.py
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/graph.py
< END
< cache.py
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/cache.py
< END
< textutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/textutils.py
< END
< decorators.py
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/decorators.py
< END
< logging_ext.py
< K 25
< svn:wc:ra_dav:version-url
< V 80
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/logging_ext.py
< END
< testlib.py
< K 25
< svn:wc:ra_dav:version-url
< V 76
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/testlib.py
< END
< configuration.py
< K 25
< svn:wc:ra_dav:version-url
< V 82
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/configuration.py
< END
< umessage.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/umessage.py
< END
< date.py
< K 25
< svn:wc:ra_dav:version-url
< V 73
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/date.py
< END
< monserver.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/monserver.py
< END
< compat.py
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/compat.py
< END
< debugger.py
< K 25
< svn:wc:ra_dav:version-url
< V 77
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/debugger.py
< END
< xmlrpcutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 80
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/xmlrpcutils.py
< END
< changelog.py
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/changelog.py
< END
< table.py
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/table.py
< END
< twisted_distutils.py
< K 25
< svn:wc:ra_dav:version-url
< V 86
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/common/twisted_distutils.py
< END
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/entries code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/entries
1,1527d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/logilab/common
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< pytest.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 142bdb3e9d494d5cb083df08d5016255
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 23457
< 
< shellutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 9273b81019286e19266cf2e6b2225f57
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 6431
< 
< __pkginfo__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 4e8b6d81590b309f15cfcdb66ffaa329
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2149
< 
< patricia.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 6a40c0f7e2b5a8fc47c48e6b6c6d6793
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 6815
< 
< deprecation.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 892f3538cccf63faea1a71bfad40a15f
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5297
< 
< __init__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< f9abad628471607bf70fbf00160934ae
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5136
< 
< visitor.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 880d3119c6815e05079f40fa8d0ac143
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3387
< 
< modutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 294cacf2d4d1db47d5cdf348fa82625f
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 18991
< 
< fileutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< cda7afb2c6d90e316023c93c14049c93
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 15587
< 
< vcgutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 166c1df4ae6c63fb773acaae7877c7b5
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7714
< 
< logservice.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 2656e83432c4865d8c9d830e78f997f7
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 1291
< 
< daemon.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< bc3bbbd255cd6efc4f13686c84ba4a07
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5456
< 
< html.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 50dca7a4a85f7089ce984ca2c2e9847c
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2276
< 
< optik_ext.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 97376c120619b1db7961d863822661c2
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 11304
< 
< corbautils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< fe083ff8ff04b0a877b49f2bb402f397
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3112
< 
< cli.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 031a92a40067687275647a747a69a45c
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7166
< 
< astutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< a401ebda0d98e81ba7d58f8c0f26696e
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2638
< 
< bind.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 1ae6b3051365284605e93f3a8488a9b7
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 8837
< 
< optparser.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 6d606a663b35ab12cb736b2cf66699a1
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3178
< 
< logger.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< abe1e1201f25226cb54c51c1e753b909
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5605
< 
< clcommands.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< fec30513ce92ec88fc519d1c2b183706
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5470
< 
< db.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< d44deadffe7e487fc5860632c7e11595
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 25269
< 
< monclient.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 50616e8b2d766d66ef9b64f5604e3d9a
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 1682
< 
< pdf_ext.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 05fe466daa5f5b166501db721753d629
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2904
< 
< sqlgen.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< b9a6d25fe3c510f9735f2c604e25c066
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 8861
< 
< ureports
< dir
< 
< adbh.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 49cc6c75ffb2ec5bd04cb777cc7fe4d3
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 19678
< 
< tree.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 6ab27ed9c0370f78be9be4c0d8bb8ccc
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 10667
< 
< interface.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< cc9da3b1be0ef6751bd111e006417ab0
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2563
< 
< graph.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< e14539bd9768e1a11ede2b82d78a1ee2
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5810
< 
< cache.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 147dab4460d1d88d9ead2742a6f3affd
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3200
< 
< decorators.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< b03e63f55f50af0f8b85f40ed17da55e
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 4143
< 
< textutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< fd916e43e96662d5726324eb8fa8c626
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 12146
< 
< logging_ext.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 543fce08dadc51ebf7e6d1575358ad2e
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3044
< 
< testlib.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 063d240c64c81d7c7858f8b77b7296ed
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 51697
< 
< configuration.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< faf3b27713bb73ebe452788e9d861375
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 34117
< 
< umessage.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 226cd3c9fe4cf8a11f1c7d4a0be81d1a
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3818
< 
< date.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< ef4496d90019db5f5b24a3fbf3f0722b
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 4112
< 
< monserver.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 39c677e1b97e6c1bbe8609528b12f856
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3799
< 
< compat.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 842d0976847a21c13ebb3312f541445a
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7016
< 
< debugger.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 5ccb5ce02ea833f875e1e325c3d7893d
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5651
< 
< xmlrpcutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 2abdf6ea7b1b8e887dc5fceb3047cfc9
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5192
< 
< changelog.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< e94f3df26b3d5065017228c6131bc804
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 6520
< 
< table.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 511b63bf4e7072357c32d63f548621e4
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 32901
< 
< twisted_distutils.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 4b35b57ebe549f4f951b1487feb7f3f8
< 2008-06-08T13:05:28.933773Z
< 40
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7092
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/adbh.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/adbh.py.svn-base
1,525d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """This module contains helpers for DBMS specific (advanced or non standard)
< functionalities
< 
< Helpers are provided for postgresql, mysql and sqlite.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.deprecation import obsolete
< 
< class BadQuery(Exception): pass
< class UnsupportedFunction(BadQuery): pass
< 
< 
< class metafunc(type):
<     def __new__(mcs, name, bases, dict):
<         dict['name'] = name.upper()
<         return type.__new__(mcs, name, bases, dict)
< 
<     
< class FunctionDescr(object):
<     __metaclass__ = metafunc
< 
<     rtype = None # None <-> returned type should be the same as the first argument
<     aggregat = False
<     minargs = 1
<     maxargs = 1
< 
<     def __init__(self, name=None, rtype=rtype, aggregat=aggregat):
<         if name is not None:
<             name = name.upper()
<         self.name = name
<         self.rtype = rtype
<         self.aggregat = aggregat
< 
<     #@classmethod
<     def check_nbargs(cls, nbargs):
<         if cls.minargs is not None and \
<                nbargs < cls.minargs:
<             raise BadQuery('not enough argument for function %s' % cls.name)
<         if cls.maxargs is not None and \
<                nbargs < cls.maxargs:
<             raise BadQuery('too many arguments for function %s' % cls.name)
<     check_nbargs = classmethod(check_nbargs)
< 
< class AggrFunctionDescr(FunctionDescr):
<     aggregat = True
<     rtype = None 
< 
< class MAX(AggrFunctionDescr): pass
< class MIN(AggrFunctionDescr): pass
< class SUM(AggrFunctionDescr): pass
< class COUNT(AggrFunctionDescr): 
<     rtype = 'Int'
< class AVG(AggrFunctionDescr):
<     rtype = 'Float'
< 
< class UPPER(FunctionDescr):
<     rtype = 'String'
< class LOWER(FunctionDescr):
<     rtype = 'String'
< class IN(FunctionDescr):
<     """this is actually a 'keyword' function..."""
<     maxargs = None
< class LENGTH(FunctionDescr):
<     rtype = 'Int'
< 
< class _GenericAdvFuncHelper:
<     """Generic helper, trying to provide generic way to implement
<     specific functionnalities from others DBMS
< 
<     An exception is raised when the functionality is not emulatable
<     """    
<     # DBMS resources descriptors and accessors
<     
<     needs_from_clause = False
<     union_parentheses_support = True
<     users_support = True
<     groups_support = True
<     ilike_support = True
< 
<     FUNCTIONS = {
<         # aggregat functions
<         'MIN': MIN, 'MAX': MAX,
<         'SUM': SUM,
<         'COUNT': COUNT,
<         'AVG': AVG,
<         # transformation functions
<         'UPPER': UPPER, 'LOWER': LOWER,
<         'LENGTH': LENGTH,
<         # keyword function
<         'IN': IN
<         }
< 
<     TYPE_MAPPING = {
<         'String' :   'text',
<         'Int' :      'integer',
<         'Float' :    'float',
<         'Boolean' :  'boolean',
<         'Date' :     'date', 
<         'Time' :     'time', 
<         'Datetime' : 'timestamp',
<         'Interval' : 'interval',
<         'Password' : 'bytea',
<         'Bytes' :    'bytea',
<         # FIXME: still there for use from erudi, should be moved out
<         # XXX think it can be safely removed now
<         'COUNT' : 'integer',
<         'MIN' :   'integer',
<         'MAX' :   'integer',
<         'SUM' :   'integer',
<         'LOWER' : 'text',
<         'UPPER' : 'text',
<         'LENGTH' :'integer',
<         }
< 
< 
<     #@classmethod
<     def register_function(cls, funcdef):
<         if isinstance(funcdef, basestring) :
<             funcdef = FunctionDescr(funcdef.upper())
<         assert not funcdef.name in cls.FUNCTIONS, \
<                '%s is already registered' % funcdef.name
<         cls.FUNCTIONS[funcdef.name] = funcdef
<     register_function = classmethod(register_function)
<     
<     #@classmethod
<     def function_description(cls, funcname):
<         """return the description (`FunctionDescription`) for a RQL function"""
<         try:
<             return cls.FUNCTIONS[funcname.upper()]
<         except KeyError:
<             raise UnsupportedFunction(funcname)
<     function_description = classmethod(function_description)
<     
<     #@obsolete('use users_support attribute')
<     def support_users(self):
<         """return True if the DBMS support users (this is usually
<         not true for in memory DBMS)
<         """
<         return self.users_support
<     support_user = obsolete('use users_support attribute')(support_users)
<     
<     #@obsolete('use groups_support attribute')    
<     def support_groups(self):
<         """return True if the DBMS support groups"""
<         return self.groups_support
<     support_user = obsolete('use groups_support attribute')(support_groups)
< 
<     def system_database(self):
<         """return the system database for the given driver"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def backup_command(self, dbname, dbhost, dbuser, dbpassword, backupfile,
<                        keepownership=True):
<         """return a command to backup the given database"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def restore_commands(self, dbname, dbhost, dbuser, backupfile,
<                          encoding='utf-8', keepownership=True, drop=True):
<         """return a list of commands to restore a backup the given database"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     # helpers to standardize SQL according to the database
<     
<     def sql_current_date(self):
<         return 'CURRENT_DATE'
<     
<     def sql_current_time(self):
<         return 'CURRENT_TIME'
<     
<     def sql_current_timestamp(self):
<         return 'CURRENT_TIMESTAMP'
<     
<     def sql_create_sequence(self, seq_name):
<         return '''CREATE TABLE %s (last INTEGER);
< INSERT INTO %s VALUES (0);''' % (seq_name, seq_name)
<     
<     def sql_create_index(self, table, column, unique=False):
<         idx = self._index_name(table, column, unique)
<         if unique:
<             return 'CREATE UNIQUE INDEX %s ON %s(%s);' % (idx, table, column)
<         else:
<             return 'CREATE INDEX %s ON %s(%s);' % (idx, table, column)
<     
<     def sql_drop_sequence(self, seq_name):
<         return 'DROP TABLE %s;' % seq_name
<     
<     def sqls_increment_sequence(self, seq_name):
<         return ('UPDATE %s SET last=last+1;' % seq_name,
<                 'SELECT last FROM %s;' % seq_name)
< 
<     def sql_temporary_table(self, table_name, table_schema,
<                             drop_on_commit=True):
<         return "CREATE TEMPORARY TABLE %s (%s);" % (table_name, table_schema)
<     
<     def boolean_value(self, value):
<         if value:
<             return 'TRUE'
<         else:
<             return 'FALSE'
<         
<     def increment_sequence(self, cursor, seq_name):
<         for sql in self.sqls_increment_sequence(seq_name):
<             cursor.execute(sql)
<         return cursor.fetchone()[0]
< 
<     def create_user(self, cursor, user, password):
<         """create a new database user"""
<         if not self.users_support:
<             raise NotImplementedError('not supported by this DBMS')
<         cursor.execute("CREATE USER %(user)s "
<                        "WITH PASSWORD '%(password)s'" % locals())
< 
<     def _index_name(self, table, column, unique=False):
<         if unique:
<             # note: this naming is consistent with indices automatically
<             # created by postgres when UNIQUE appears in a table schema
<             return '%s_%s_key' % (table.lower(), column.lower())
<         else:
<             return '%s_%s_idx' % (table.lower(), column.lower())
<     
<     def create_index(self, cursor, table, column, unique=False):
<         if not self.index_exists(cursor, table, column, unique):
<             cursor.execute(self.sql_create_index(table, column, unique))
<             
<     def drop_index(self, cursor, table, column, unique=False):
<         if self.index_exists(cursor, table, column, unique):
<             idx = self._index_name(table, column, unique)
<             cursor.execute('DROP INDEX %s' % idx)
<         
<     def index_exists(self, cursor, table, column, unique=False):
<         idx = self._index_name(table, column, unique)
<         return idx in self.list_indices(cursor, table)
< 
<     def user_exists(self, cursor, username):
<         """return True if a user with the given username exists"""
<         return username in self.list_users(cursor)
<     
<     def list_users(self, cursor):
<         """return the list of existing database users"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def create_database(self, cursor, dbname, owner=None, encoding='utf-8'):
<         """create a new database"""
<         raise NotImplementedError('not supported by this DBMS')
<         
<     def list_databases(self):
<         """return the list of existing databases"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         raise NotImplementedError('not supported by this DBMS')
<     
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         raise NotImplementedError('not supported by this DBMS')
<     
< 
< 
< def pgdbcmd(cmd, dbhost, dbuser):
<     cmd = [cmd]
<     if dbhost:
<         cmd.append('--host=%s' % dbhost)
<     if dbuser:
<         cmd.append('--username=%s' % dbuser)
<     return cmd
< 
< 
< class _PGAdvFuncHelper(_GenericAdvFuncHelper):
<     """Postgres helper, taking advantage of postgres SEQUENCE support
<     """
<     # modifiable but should not be shared
<     FUNCTIONS = _GenericAdvFuncHelper.FUNCTIONS.copy()
<     
<     def system_database(self):
<         """return the system database for the given driver"""
<         return 'template1'
<     
<     def backup_command(self, dbname, dbhost, dbuser, backupfile,
<                        keepownership=True):
<         """return a command to backup the given database"""
<         cmd = ['pg_dump -Fc']
<         if dbhost:
<             cmd.append('--host=%s' % dbhost)
<         if dbuser:
<             cmd.append('--username=%s' % dbuser)
<         if not keepownership:
<             cmd.append('--no-owner')
<         cmd.append('--file=%s' % backupfile)
<         cmd.append(dbname)
<         return ' '.join(cmd)
<     
<     def restore_commands(self, dbname, dbhost, dbuser, backupfile,
<                          encoding='utf-8', keepownership=True, drop=True):
<         """return a list of commands to restore a backup the given database"""
<         cmds = []
<         if drop:
<             cmd = pgdbcmd('dropdb', dbhost, dbuser)
<             cmd.append(dbname)
<             cmds.append(' '.join(cmd))
<         cmd = pgdbcmd('createdb -T template0 -E %s' % encoding, dbhost, dbuser)
<         cmd.append(dbname)
<         cmds.append(' '.join(cmd))
<         cmd = pgdbcmd('pg_restore -Fc', dbhost, dbuser)
<         cmd.append('--dbname %s' % dbname)
<         if not keepownership:
<             cmd.append('--no-owner')
<         cmd.append(backupfile)
<         cmds.append(' '.join(cmd))
<         return cmds
<                 
<     def sql_create_sequence(self, seq_name):
<         return 'CREATE SEQUENCE %s;' % seq_name
<     
<     def sql_drop_sequence(self, seq_name):
<         return 'DROP SEQUENCE %s;' % seq_name
<     
<     def sqls_increment_sequence(self, seq_name):
<         return ("SELECT nextval('%s');" % seq_name,)
<     
<     def sql_temporary_table(self, table_name, table_schema,
<                             drop_on_commit=True):
<         if not drop_on_commit:
<             return "CREATE TEMPORARY TABLE %s (%s);" % (table_name,
<                                                         table_schema)    
<         return "CREATE TEMPORARY TABLE %s (%s) ON COMMIT DROP;" % (table_name,
<                                                                    table_schema)
<     
<     def create_database(self, cursor, dbname, owner=None, encoding='utf-8'):
<         """create a new database"""
<         sql = "CREATE DATABASE %(dbname)s"
<         if owner:
<             sql += " WITH OWNER=%(owner)s"
<         if encoding:
<             sql += " ENCODING='%(encoding)s'"
<         cursor.execute(sql % locals())
< 
<     def create_language(self, cursor, extlang):
<         """postgres specific method to install a procedural language on a database"""
<         # make sure plpythonu is not directly in template1
<         cursor.execute("SELECT * FROM pg_language WHERE lanname='%s';" % extlang)
<         if cursor.fetchall():
<             print '%s language already installed' % extlang
<         else:
<             cursor.execute('CREATE LANGUAGE %s' % extlang)
<             print '%s language installed' % extlang
< 
<     def list_users(self, cursor, username=None):
<         """return the list of existing database users"""
<         if username:
<             warn('username argument is deprecated, use user_exists method',
<                  DeprecationWarning, stacklevel=2)
<             return self.user_exists(cursor, username)
<         cursor.execute("SELECT usename FROM pg_user")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_databases(self, cursor):
<         """return the list of existing databases"""
<         cursor.execute('SELECT datname FROM pg_database')
<         return [r[0] for r in cursor.fetchall()]
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         cursor.execute("SELECT tablename FROM pg_tables")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         sql = "SELECT indexname FROM pg_indexes"
<         if table:
<             sql += " WHERE LOWER(tablename)='%s'" % table.lower()
<         cursor.execute(sql)
<         return [r[0] for r in cursor.fetchall()]
< 
<             
< class _SqliteAdvFuncHelper(_GenericAdvFuncHelper):
<     """Generic helper, trying to provide generic way to implement
<     specific functionnalities from others DBMS
< 
<     An exception is raised when the functionality is not emulatable
<     """
<     # modifiable but should not be shared
<     FUNCTIONS = _GenericAdvFuncHelper.FUNCTIONS.copy()
<     
<     users_support = groups_support = False
<     ilike_support = False
<     union_parentheses_support = False
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         # filter type='table' else we get indices as well
<         cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         sql = "SELECT name FROM sqlite_master WHERE type='index'"
<         if table:
<             sql += " AND LOWER(tbl_name)='%s'" % table.lower()
<         cursor.execute(sql)
<         return [r[0] for r in cursor.fetchall()]
< 
<     
< class _MyAdvFuncHelper(_GenericAdvFuncHelper):
<     """MySQL helper, taking advantage of postgres SEQUENCE support
<     """
<     needs_from_clause = True
<     ilike_support = False # insensitive search by default
< 
<     # modifiable but should not be shared
<     FUNCTIONS = _GenericAdvFuncHelper.FUNCTIONS.copy() 
<     TYPE_MAPPING = _GenericAdvFuncHelper.TYPE_MAPPING.copy()
<     TYPE_MAPPING['Password'] = 'tinyblob'
<     TYPE_MAPPING['String'] = 'mediumtext'
<     TYPE_MAPPING['Bytes'] = 'longblob'
<     
<     def system_database(self):
<         """return the system database for the given driver"""
<         return ''
<     
<     def backup_command(self, dbname, dbhost, dbuser, backupfile,
<                        keepownership=True):
<         """return a command to backup the given database"""
<         # XXX compress
<         return 'mysqldump -h %s -u %s -p -r %s %s' % (dbhost, dbuser, backupfile, dbname)
<     
<     def restore_commands(self, dbname, dbhost, dbuser, backupfile,
<                          encoding='utf-8', keepownership=True, drop=True):
<         """return a list of commands to restore a backup the given database"""
<         cmds = []
<         if drop:
<             cmd = 'echo "DROP DATABASE %s;" | mysql -h %s -u %s -p' % (dbname, dbhost, dbuser)
<             cmds.append(cmd)
<         cmd = 'echo "%s;" | mysql -h %s -u %s -p' % (self.sql_create_database(dbname, encoding),
<                                                   dbhost, dbuser)
<         cmds.append(cmd)
<         cmd = pgdbcmd('mysql -h %s -u %s -p < %s' % (dbname, dbhost, dbuser, backupfile))
<         cmds.append(cmd)
<         return cmds
<                 
<     def sql_temporary_table(self, table_name, table_schema,
<                             drop_on_commit=True):
<         if not drop_on_commit:
<             return "CREATE TEMPORARY TABLE %s (%s);" % (table_name,
<                                                         table_schema)    
<         return "CREATE TEMPORARY TABLE %s (%s) ON COMMIT DROP;" % (table_name,
<                                                                    table_schema)
<     
<     def sql_create_database(self, dbname, encoding='utf-8'):
<         sql = "CREATE DATABASE %(dbname)s"
<         if encoding:
<             sql += " CHARACTER SET %(encoding)s"
<         return sql % locals()
<     
<     def create_database(self, cursor, dbname, owner=None, encoding='utf-8'):
<         """create a new database"""
<         cursor.execute(self.sql_create_database(dbname, encoding))
<         if owner:
<             cursor.execute('GRANT ALL ON `%s`.* to %s' % (dbname, owner))
< 
<     def boolean_value(self, value):
<         if value:
<             return True
<         else:
<             return False
<         
<     def list_users(self, cursor):
<         """return the list of existing database users"""
<         # Host, Password
<         cursor.execute("SELECT User FROM mysql.user")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_databases(self, cursor):
<         """return the list of existing databases"""
<         cursor.execute('SHOW DATABASES')
<         return [r[0] for r in cursor.fetchall()]
<     
<     def list_tables(self, cursor):
<         """return the list of tables of a database"""
<         cursor.execute("SHOW TABLES")
<         return [r[0] for r in cursor.fetchall()]
< 
<     def list_indices(self, cursor, table=None):
<         """return the list of indices of a database, only for the given table if specified"""
<         if table:
<             cursor.execute("SHOW INDEX FROM %s" % table)
<             return [r[2] for r in cursor.fetchall()]
<         allindices = []
<         for table in self.list_tables(cursor):
<             allindices += self.list_indices(cursor, table)
<         return allindices
< 
< 
<     
< ADV_FUNC_HELPER_DIRECTORY = {'postgres': _PGAdvFuncHelper(),
<                              'sqlite': _SqliteAdvFuncHelper(),
<                              'mysql': _MyAdvFuncHelper(),
<                              }
< 
< 
< 
< def get_adv_func_helper(driver):
<     """returns an advanced function helper for the given driver"""
<     return ADV_FUNC_HELPER_DIRECTORY[driver]
< 
< def register_function(driver, funcdef):
<     ADV_FUNC_HELPER_DIRECTORY[driver].register_function(funcdef)    
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/astutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/astutils.py.svn-base
1,84d0
< # Copyright (c) 2003 Sylvain Thenault (thenault@nerim.net)
< # Copyright (c) 2003 Logilab
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some usefull functions to manipulate ast tuples
< """
< 
< from warnings import warn
< warn('this module has been moved into logilab.astng and will disappear from \
< logilab.common in a future release',
<      DeprecationWarning, stacklevel=1)
< 
< __author__ = u"Sylvain Thenault"
< 
< import symbol
< import token
< from types import TupleType
< 
< def debuild(ast_tuple):
<     """
<     reverse ast_tuple to string
<     """
<     if type(ast_tuple[1]) is TupleType:
<         result = ''
<         for child in ast_tuple[1:]: 
<             result = '%s%s' % (result, debuild(child))
<         return result
<     else:
<         return ast_tuple[1]
< 
< def clean(ast_tuple):
<     """
<     reverse ast tuple to a list of tokens
<     merge sequences (token.NAME, token.DOT, token.NAME)
<     """
<     result = []
<     last = None
<     for couple in _clean(ast_tuple):
<         if couple[0] == token.NAME and last == token.DOT:
<             result[-1][1] += couple[1]
<         elif couple[0] == token.DOT and last == token.NAME:
<             result[-1][1] += couple[1]
<         else:
<             result.append(couple)
<         last = couple[0]
<     return result
< 
< def _clean(ast_tuple):
<     """ transform the ast into as list of tokens (i.e. final elements)
<     """
<     if type(ast_tuple[1]) is TupleType:
<         v = []
<         for c in ast_tuple[1:]:
<             v += _clean(c)
<         return v
<     else:
<         return [list(ast_tuple[:2])]
<     
< def cvrtr(tuple):
<     """debug method returning an ast string in a readable fashion"""
<     if type(tuple) is TupleType:
<         try:
<             try:
<                 txt = 'token.'+token.tok_name[tuple[0]]
<             except:
<                 txt = 'symbol.'+symbol.sym_name[tuple[0]]
<         except:
<             txt =  'Unknown token/symbol'
<         return [txt] + map(cvrtr, tuple[1:])
<     else:
<         return tuple
< 
< __all__ = ('debuild', 'clean', 'cvrtr')
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/bind.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/bind.py.svn-base
1,276d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< 
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
<  This module provides a way to optimize globals in certain functions by binding
<  their names to values provided in a dictionnary
< """
< 
< from warnings import warn
< warn('bind module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = '$Id: bind.py,v 1.8 2005-11-22 13:12:59 syt Exp $'
< 
< # TODO: unit tests
< # * this module provide a function bind(func,vars) which replaces every
< #   global variable 'm' by the value vars['m'] if such value exists in dict
< 
< from dis import HAVE_ARGUMENT
< from new import code as make_code, function as make_function
< import inspect
< 
< LOAD_GLOBAL = 116
< LOAD_CONST = 100
< EXTENDED_ARG = 143
< STORE_GLOBAL = 97
< 
< def bind_code(co, globals):
<     """
<     Take a code object and a dictionnary and returns a new code object where
<     the opcodes LOAD_GLOBAL are replaced by LOAD_CONST whenever the global's
<     name appear in the dictionnary
<     """
<     consts = list(co.co_consts)
<     assigned = {}
<     
<     code = co.co_code
<     new_code = ""
<     n = len(code)
<     i = 0
<     while i < n:
<         c = code[i]
<         op = ord(c)
<         i += 1
<         if op >= HAVE_ARGUMENT:
<             oparg = ord(code[i]) + ord(code[i+1]) * 256
<             i += 2
<         else:
<             oparg = None
<         if op == LOAD_GLOBAL:
<             name = co.co_names[oparg]
<             if globals.has_key(name):
<                 k = assigned.get(name, None)
<                 if k == None:
<                     k = len(consts)
<                     assigned[name] = len(consts)
<                     consts.append(globals[name])
<                 op = LOAD_CONST
<                 oparg = k
<         new_code += chr(op)
<         if oparg is not None:
<             new_code += chr(oparg & 255)
<             new_code += chr( (oparg>>8) & 255 )
<             
<     return make_code(co.co_argcount,
<                      co.co_nlocals,
<                      co.co_stacksize,
<                      co.co_flags,
<                      new_code,
<                      tuple(consts),
<                      co.co_names,
<                      co.co_varnames,
<                      co.co_filename,
<                      co.co_name,
<                      co.co_firstlineno,
<                      co.co_lnotab )
< 
< 
< def bind(f, globals):
<     """Returns a new function whose code object has been
<     bound by bind_code()"""
<     newcode = bind_code(f.func_code, globals)
<     defaults = f.func_defaults or ()
<     return make_function(newcode, f.func_globals, f.func_name, defaults)
< 
< if type(__builtins__) == dict:
<     builtins = __builtins__
< else:
<     builtins = __builtins__.__dict__
<     
< bind_code_opt = bind(bind_code, builtins )
< bind_code_opt = bind(bind_code_opt, globals() )
< 
< 
< def optimize_module(m, global_consts):
<     if not inspect.ismodule(m):
<         raise TypeError
<     d = {}
<     for i in global_consts:
<         v = m.__dict__.get(i)
<         d[i] = v
<     builtins = m.__builtins__
<     for name, f in m.__dict__.items():
<         if inspect.isfunction(f):
<             f = bind(f, builtins)
<             if d:
<                 f = bind(f, d)
<             m.__dict__[name] = f
<             
< 
< 
< 
< def analyze_code(co, globals, consts_dict, consts_list):
<     """Take a code object and a dictionnary and returns a
<     new code object where the opcodes LOAD_GLOBAL are replaced
<     by LOAD_CONST whenever the global's name appear in the
<     dictionnary"""
<     modified_globals = []
<     for c in co.co_consts:
<         if c not in consts_list:
<             consts_list.append(c)
<     modified = []
<     code = co.co_code
<     new_code = ""
<     n = len(code)
<     i = 0
<     extended_arg = 0
<     while i < n:
<         c = code[i]
<         op = ord(c)
<         i += 1
<         if op >= HAVE_ARGUMENT:
<             oparg = ord(code[i]) + ord(code[i+1])*256 + extended_arg
<             extended_arg = 0
<             i += 2
<         else:
<             oparg = None
<         if op == EXTENDED_ARG:
<             extended_arg = oparg*65536L
< 
<         if op == LOAD_GLOBAL:
<             name = co.co_names[oparg]
<             if globals.has_key(name):
<                 k = consts_dict.get(name, None)
<                 if k == None:
<                     k = len(consts_list)
<                     consts_dict[name] = k
<                     consts_list.append(globals[name])
<         if op == STORE_GLOBAL:
<             name = co.co_names[oparg]
<             if globals.has_key(name):
<                 modified_globals.append(name)
<     return modified_globals
< 
< def rewrite_code(co, consts_dict, consts_tuple):
<     """Take a code object and a dictionnary and returns a
<     new code object where the opcodes LOAD_GLOBAL are replaced
<     by LOAD_CONST whenever the global's name appear in the
<     dictionnary"""
<     code = co.co_code
<     new_code = ""
<     n = len(code)
<     i = 0
<     consts_list = list(consts_tuple)
<     while i < n:
<         c = code[i]
<         op = ord(c)
<         i += 1
<         extended_arg = 0
<         if op >= HAVE_ARGUMENT:
<             oparg = ord(code[i]) + ord(code[i+1])*256+extended_arg
<             extended_arg = 0
<             i += 2
<         else:
<             oparg = None
<         if op == EXTENDED_ARG:
<             extended_arg = oparg*65536L
<         elif op == LOAD_GLOBAL:
<             name = co.co_names[oparg]
<             k = consts_dict.get(name)
<             if k is not None:
<                 op = LOAD_CONST
<                 oparg = k
<         elif op == LOAD_CONST:
<             val = co.co_consts[oparg]
<             oparg = consts_list.index(val)
<         new_code += chr(op)
<         if oparg is not None:
<             new_code += chr(oparg & 255)
<             new_code += chr( (oparg>>8) & 255 )
<             
<     return make_code(co.co_argcount,
<                      co.co_nlocals,
<                      co.co_stacksize,
<                      co.co_flags,
<                      new_code,
<                      consts_tuple,
<                      co.co_names,
<                      co.co_varnames,
<                      co.co_filename,
<                      co.co_name,
<                      co.co_firstlineno,
<                      co.co_lnotab )
< 
< def optimize_module_2(m, globals_consts, bind_builtins=1):
<     if not inspect.ismodule(m):
<         raise TypeError
<     consts_dict = {}
<     consts_list = []
<     if type(globals_consts) == list or type(globals_consts) == tuple:
<         globals = {}
<         for i in globals_consts:
<             v = m.__dict__.get(i)
<             globals[i] = v
<     else:
<         globals = globals_consts
<     if bind_builtins:
<         for builtin_name, builtin_value in m.__builtins__.items():
<             # this way it is possible to redefine a builtin in globals_consts
<             globals.setdefault(builtin_name, builtin_value)
<     functions = {}
<     for name, f in m.__dict__.items():
<         if inspect.isfunction(f):
<             functions[name] = f
<             analyze_code(f.func_code, globals, consts_dict, consts_list)
<     consts_list = tuple(consts_list)
<     for name, f in functions.items():
<         newcode = rewrite_code(f.func_code, consts_dict, consts_list)
<         defaults = f.func_defaults or ()
<         m.__dict__[name] = make_function(newcode, f.func_globals, f.func_name,
<                                          defaults)
<         
< 
< def run_bench(n):
<     from time import time
<     t = time()
<     g = globals()
<     for i in range(n):
<         test = bind(bind_code, g)
<     t1 = time()-t
<     bind2 = bind(bind, {'bind_code':bind_code_opt})
<     t = time()
<     for i in range(n):
<         test=bind2(bind_code, g)
<     t2 = time()-t
<     print "1 regular version", t1
<     print "2 optimized version", t2
<     print "ratio (1-2)/1 : %f %%" % (100.*(t1-t2)/t1)
<     
< 
< def test_pystone():
<     from test import pystone
<     for _ in range(5):
<         pystone.main()
<     optimize_module(pystone, ('TRUE','FALSE','Proc0','Proc1','Proc2','Proc3',
<                               'Proc4','Proc5','Proc6','Proc7','Proc8','Func1',
<                              ' Func2','Func3'))
<     optimize_module(pystone, builtins.keys())
<     for _ in range(5):
<         pystone.main()
< 
< 
< if __name__ == "__main__":
<     run_bench(1000)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/cache.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/cache.py.svn-base
1,104d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
<  Cache module, with a least recently used algorithm for the management of the
<  deletion of entries.
< """
< 
< _marker = object()
< 
< class Cache:
<     """ a dictionnary like cache
< 
<     inv:
<         len(self._usage) <= self.size
<         len(self.data) <= self.size
<     """
<     
<     def __init__(self, size=100):
<         self.data = {}
<         self.size = size
<         self._usage = []
< 
<     def __repr__(self):
<         return repr(self.data)
< 
<     def __len__(self):
<         return len(self.data)
< 
<     def _update_usage(self, key):
<         # Special case : cache's size = 0 !
<         if self.size <= 0:
<             return
<         
<         if not self._usage:
<             self._usage.append(key)
<         
<         elif self._usage[-1] != key:
<             try:
<                 self._usage.remove(key)
<             except ValueError:
<                 # we are inserting a new key
<                 # check the size of the dictionnary
<                 # and remove the oldest item in the cache
<                 if self.size and len(self._usage) >= self.size:
<                     del self.data[self._usage[0]]
<                     del self._usage[0]
<             self._usage.append(key)
<         else:
<             pass # key is already the most recently used key
< 
<             
<     def __getitem__(self, key):
<         value = self.data[key]
<         self._update_usage(key)
<         return value
<     
<     def __setitem__(self, key, item):
<         # Just make sure that size > 0 before inserting a new item in the cache
<         if self.size > 0:
<             self.data[key] = item
<         self._update_usage(key)
<         
<     def __delitem__(self, key):
<         # If size <= 0, then we don't have anything to do
<         # XXX FIXME : Should we let the 'del' raise a KeyError ?
<         if self.size > 0:
<             del self.data[key]
<             self._usage.remove(key)
<         
<     def pop(self, value, default=_marker):
<         if value in self.data:
<             self._usage.remove(value)
<         if default is _marker:
<             return self.data.pop(value)
<         return self.data.pop(value, default)
<     
<     def clear(self):
<         self.data.clear()
<         self._usage = []
< 
<     def keys(self):
<         return self.data.keys()
< 
<     def items(self):
<         return self.data.items()
< 
<     def values(self):
<         return self.data.values()
< 
<     def has_key(self, key):
<         return self.data.has_key(key)
<     
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/changelog.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/changelog.py.svn-base
1,194d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Manipulation of upstream change log files
< 
< The upstream change log files format handled is simpler than the one
< often used such as those generated by the default Emacs changelog mode.
< 
< Sample ChangeLog format:
< ------------------------------------------------------------
< Change log for project Yoo
< ==========================
< 
<  --
<     * add a new functionnality
< 
< 2002-02-01 -- 0.1.1
<     * fix bug #435454
<     * fix bug #434356
<     
< 2002-01-01 -- 0.1
<     * initial release
<     
< ------------------------------------------------------------
< 
< There is 3 entries in this change log, one for each released version and one
< for the next version (i.e. the current entry).
< Each entry contains a set of messages corresponding to changes done in this
< release.
< All the non empty lines before the first entry are considered as the change
< log title.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< import sys
< from stat import S_IWRITE
< 
< from clonedigger.logilab.common.fileutils import ensure_fs_mode
< 
< BULLET = '*'
< INDENT = '    '
< 
< class NoEntry(Exception):
<     """raised when we are unable to find an entry"""
< 
< class EntryNotFound(Exception):
<     """raised when we are unable to find a given entry"""
< 
< class Version(tuple):
<     """simple class to handle soft version number has a tuple while
<     correctly printing it as X.Y.Z
<     """
<     def __new__(klass, versionstr):
<         if isinstance(versionstr, basestring):
<             parsed = [int(i) for i in versionstr.split('.')]
<         else:
<             parsed = versionstr
<         return tuple.__new__(klass, parsed)
<         
<     def __str__(self):
<         return '.'.join([str(i) for i in self])
< 
< # upstream change log #########################################################
< 
< class ChangeLogEntry(object):
<     """a change log entry, ie a set of messages associated to a version and
<     its release date
<     """
<     version_class = Version
<     
<     def __init__(self, date=None, version=None, **kwargs):
<         self.__dict__.update(kwargs)
<         if version:
<             self.version = self.version_class(version)
<         else:
<             self.version = None
<         self.date = date
<         self.messages = []
<         
<     def add_message(self, msg):
<         """add a new message"""
<         self.messages.append([msg])
< 
<     def complete_latest_message(self, msg_suite):
<         """complete the latest added message
<         """
<         if not self.messages:
<             print >> sys.stderr, 'Ignoring %r (unexpected format)' % msg_suite
<         self.messages[-1].append(msg_suite)
< 
<     def write(self, stream=sys.stdout):
<         """write the entry to file """
<         stream.write('%s  --  %s\n' % (self.date or '', self.version or ''))
<         for msg in self.messages:
<             stream.write('%s%s %s\n' % (INDENT, BULLET, msg[0]))
<             stream.write(''.join(msg[1:]))
< 
< 
< class ChangeLog(object):
<     """object representation of a whole ChangeLog file"""
<     
<     entry_class = ChangeLogEntry
<     
<     def __init__(self, changelog_file, title=''):
<         self.file = changelog_file
<         self.title = title
<         self.additional_content = ''
<         self.entries = []
<         self.load()
< 
<     def __repr__(self):
<         return '<ChangeLog %s at %s (%s entries)>' % (self.file, id(self),
<                                                       len(self.entries))
<     
<     def add_entry(self, entry):
<         """add a new entry to the change log"""
<         self.entries.append(entry)
< 
<     def get_entry(self, version='', create=None):
<         """ return a given changelog entry
<         if version is omited, return the current entry 
<         """
<         if not self.entries:
<             if version or not create:
<                 raise NoEntry()
<             self.entries.append(self.entry_class())
<         if not version:
<             if self.entries[0].version and create is not None:
<                 self.entries.insert(0, self.entry_class())
<             return self.entries[0]
<         version = self.version_class(version)
<         for entry in self.entries:
<             if entry.version == version:
<                 return entry
<         raise EntryNotFound()
< 
<     def add(self, msg, create=None):
<         """add a new message to the latest opened entry"""
<         entry = self.get_entry(create=create)
<         entry.add_message(msg)
<     
<     def load(self):
<         """ read a logilab's ChangeLog from file """
<         try:
<             stream = open(self.file)
<         except IOError:
<             return
<         last = None
<         for line in stream.readlines():
<             sline = line.strip()
<             words = sline.split()
<             if len(words) == 1 and words[0] == '--':
<                 last = self.entry_class()
<                 self.add_entry(last)
<             elif len(words) == 3 and words[1] == '--':
<                 last = self.entry_class(words[0], words[2])
<                 self.add_entry(last)
<             elif last is None:
<                 if not sline:
<                     continue
<                 self.title = '%s%s' % (self.title, line)
<             elif sline and sline[0] == BULLET:
<                 last.add_message(sline[1:].strip())
<             elif last.messages:
<                 last.complete_latest_message(line)
<             else:
<                 self.additional_content += line
<         stream.close()
<         
<     def format_title(self):
<         return '%s\n\n' % self.title.strip()
<     
<     def save(self):
<         """write back change log"""
<         ensure_fs_mode(self.file, S_IWRITE)
<         self.write(open(self.file, 'w'))
<             
<     def write(self, stream=sys.stdout):
<         """write changelog to stream"""
<         stream.write(self.format_title())
<         for entry in self.entries:
<             entry.write(stream)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/clcommands.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/clcommands.py.svn-base
1,165d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """provides helper functions to handle a command line tool providing more than
< one command
< e.g called as "tool command [options] args..." where <options> and <args> are
< command'specific
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< # XXX : merge with optparser ? 
< import sys
< from os.path import basename
< 
< from clonedigger.logilab.common.configuration import Configuration
< 
< 
< DEFAULT_COPYRIGHT = '''\
< Copyright (c) 2004-2008 LOGILAB S.A. (Paris, FRANCE), all rights reserved.
< http://www.logilab.fr/ -- mailto:contact@logilab.fr'''
< 
< 
< class BadCommandUsage(Exception):
<     """Raised when an unknown command is used or when a command is not
<     correctly used
<     """
< 
< 
< class Command(Configuration):
<     """base class for command line commands"""
<     arguments = ''
<     name = ''
<     # hidden from help ?
<     hidden = False
<     # max/min args, None meaning unspecified
<     min_args = None
<     max_args = None
<     def __init__(self, __doc__=None, version=None):
<         if __doc__:
<             usage = __doc__ % (self.name, self.arguments,
<                                self.__doc__.replace('    ', ''))
<         else:
<             usage = self.__doc__.replace('    ', '')
<         Configuration.__init__(self, usage=usage, version=version)
< 
<     def check_args(self, args):
<         """check command's arguments are provided"""
<         if self.min_args is not None and len(args) < self.min_args:
<             raise BadCommandUsage('missing argument')
<         if self.max_args is not None and len(args) > self.max_args:
<             raise BadCommandUsage('too many arguments')
<         
<     def run(self, args):
<         """run the command with its specific arguments"""
<         raise NotImplementedError()
< 
< 
< def pop_arg(args_list, expected_size_after=0, msg="Missing argument"):
<     """helper function to get and check command line arguments"""
<     try:
<         value = args_list.pop(0)
<     except IndexError:
<         raise BadCommandUsage(msg)
<     if expected_size_after is not None and len(args_list) > expected_size_after:
<         raise BadCommandUsage('Too much arguments')
<     return value
< 
< 
< _COMMANDS = {}
< 
< def register_commands(commands):
<     """register existing commands"""
<     for command_klass in commands:
<         _COMMANDS[command_klass.name] = command_klass
< 
< 
< def main_usage(status=0, __doc__=None, copyright=DEFAULT_COPYRIGHT):
<     """display usage for the main program (ie when no command supplied)
<     and exit
<     """
<     commands = _COMMANDS.keys()
<     commands.sort()
<     doc = __doc__ % ('<command>', '<command arguments>',
<                      '''\
< Type "%prog <command> --help" for more information about a specific
< command. Available commands are :\n''')
<     doc = doc.replace('%prog', basename(sys.argv[0]))
<     print 'usage:', doc
<     max_len = max([len(cmd) for cmd in commands]) # list comprehension for py 2.3 support
<     padding = ' '*max_len
<     for command in commands:
<         cmd = _COMMANDS[command]
<         if not cmd.hidden:
<             title = cmd.__doc__.split('.')[0]
<             print ' ', (command+padding)[:max_len], title
<     print '\n', copyright
<     sys.exit(status)
< 
< 
< def cmd_run(cmdname, *args):
<     try:
<         command = _COMMANDS[cmdname](__doc__='%%prog %s %s\n\n%s')
<     except KeyError:
<         raise BadCommandUsage('no %s command' % cmdname)
<     args = command.load_command_line_configuration(args)
<     command.check_args(args)
<     try:
<         command.run(args)
<     except KeyboardInterrupt:
<         print 'interrupted'
<     except BadCommandUsage, err:
<         print 'ERROR: ', err
<         print command.help()
< 
<         
< def main_run(args, doc):
<     """command line tool"""
<     try:
<         arg = args.pop(0)
<     except IndexError:
<         main_usage(status=1, __doc__=doc)
<     if arg in ('-h', '--help'):
<         main_usage(__doc__=doc)
<     try:
<         cmd_run(arg, *args)
<     except BadCommandUsage, err:
<         print 'ERROR: ', err
<         main_usage(1, doc)
< 
< 
< class ListCommandsCommand(Command):
<     """list available commands, useful for bash completion."""
<     name = 'listcommands'
<     arguments = '[command]'    
<     hidden = True
<     
<     def run(self, args):
<         """run the command with its specific arguments"""
<         if args:
<             command = pop_arg(args)
<             cmd = _COMMANDS[command]
<             for optname, optdict in cmd.options:
<                 print '--help'
<                 print '--' + optname
<         else:
<             commands = _COMMANDS.keys()
<             commands.sort()
<             for command in commands:
<                 cmd = _COMMANDS[command]
<                 if not cmd.hidden:
<                     print command
<                 
< register_commands([ListCommandsCommand])
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/cli.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/cli.py.svn-base
1,211d0
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Command line interface helper classes.
<  
<  It provides some default commands, a help system, a default readline
<  configuration with completion and persistent history
< 
< Exemple usage:
< 
<     class BookShell(CLIHelper):
< 
<         def __init__(self):
<             # quit and help are builtins
<             # CMD_MAP keys are commands, values are topics
<             self.CMD_MAP['pionce'] = _("Sommeil")
<             self.CMD_MAP['ronfle'] = _("Sommeil")
<             CLIHelper.__init__(self)
< 
<         help_do_pionce = ("pionce", "pionce duree", _("met ton corps en veille"))
<         def do_pionce(self):
<             print 'nap is good'
< 
<         help_do_ronfle = ("ronfle", "ronfle volume", _("met les autres en veille"))
<         def do_ronfle(self):
<             print 'fuuuuuuuuuuuu rhhhhhrhrhrrh'
< 
<     cl = BookShell()
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< 
< import __builtin__
< if not hasattr(__builtin__, '_'):
<     __builtin__._ = str
<     
< 
< def init_readline(complete_method, histfile=None):
<     """init the readline library if available"""
<     try:
<         import readline
<         readline.parse_and_bind("tab: complete")
<         readline.set_completer(complete_method)
<         string = readline.get_completer_delims().replace(':', '')
<         readline.set_completer_delims(string)
<         if histfile is not None:
<             try:
<                 readline.read_history_file(histfile)
<             except IOError:
<                 pass
<             import atexit
<             atexit.register(readline.write_history_file, histfile)
<     except:
<         print 'readline si not available :-('
< 
< 
< class Completer :
<     """readline completer"""
<     
<     def __init__(self, commands):
<         self.list = commands
<         
<     def complete(self, text, state):
<         """hook called by readline when <tab> is pressed"""
<         n = len(text)
<         matches = []
<         for cmd in self.list :
<             if cmd[:n] == text :
<                 matches.append(cmd)
<         try:
<             return matches[state]
<         except IndexError:
<             return None
< 
< 
< class CLIHelper:
<     """ an abstract command line interface client which recognize commands
<     and provide an help system
<     """
<     
<     CMD_MAP = {'help' : _("Others"),
<                'quit' : _("Others"),
<                }
<     CMD_PREFIX = ''
<     
<     def __init__(self, histfile=None) :
<         self._topics = {}
<         self.commands = None
<         self._completer = Completer(self._register_commands())
<         init_readline(self._completer.complete, histfile)
< 
<     def run(self):
<         """loop on user input, exit on EOF"""
<         while 1:
<             try:
<                 line = raw_input('>>> ')
<             except EOFError:
<                 print 
<                 break
<             s_line = line.strip()
<             if not s_line:
<                 continue
<             args = s_line.split()
<             if self.commands.has_key(args[0]):
<                 try:
<                     cmd = 'do_%s' % self.commands[args[0]]
<                     getattr(self, cmd)(*args[1:])
<                 except EOFError:
<                     break
<                 except:
<                     import traceback
<                     traceback.print_exc()
<             else:
<                 try:
<                     self.handle_line(s_line)
<                 except:
<                     import traceback
<                     traceback.print_exc()
< 
<     def handle_line(self, stripped_line):
<         """method to overload in the concrete class
<         
<         should handle lines wich are not command
<         """
<         raise NotImplementedError()
< 
< 
<     # private methods #########################################################
<     
<     def _register_commands(self):
<         """ register available commands method and return the list of
<         commands name
<         """
<         self.commands = {}
<         self._command_help = {}
<         commands = [attr[3:] for attr in dir(self) if attr[:3] == 'do_']
<         for command in commands:
<             topic = self.CMD_MAP[command]
<             help_method = getattr(self, 'help_do_%s' % command)
<             self._topics.setdefault(topic, []).append(help_method)
<             self.commands[self.CMD_PREFIX + command] = command
<             self._command_help[command] = help_method
<         return self.commands.keys()
< 
<     def _print_help(self, cmd, syntax, explanation):
<         print _('Command %s') % cmd
<         print _('Syntax: %s') % syntax
<         print '\t', explanation
<         print
< 
< 
<     # predefined commands #####################################################
<     
<     def do_help(self, command=None) :
<         """base input of the help system"""
<         if self._command_help.has_key(command):
<             self._print_help(*self._command_help[command])
<         elif command is None or not self._topics.has_key(command):
<             print _("Use help <topic> or help <command>.")
<             print _("Available topics are:")
<             topics = self._topics.keys()
<             topics.sort()
<             for topic in topics:
<                 print '\t', topic
<             print
<             print _("Available commands are:")
<             commands = self.commands.keys()
<             commands.sort()
<             for command in commands:
<                 print '\t', command[len(self.CMD_PREFIX):]
<                 
<         else:
<             print _('Available commands about %s:') % command
<             print
<             for command_help_method in self._topics[command]:
<                 try:
<                     if callable(command_help_method):
<                         self._print_help(*command_help_method())
<                     else:
<                         self._print_help(*command_help_method)
<                 except:
<                     import traceback
<                     traceback.print_exc()
<                     print 'ERROR in help method %s'% (
<                         command_help_method.func_name)
<                 
<     help_do_help = ("help", "help [topic|command]",
<                     _("print help message for the given topic/command or \
< available topics when no argument"))
< 
<     def do_quit(self):
<         """quit the CLI"""
<         raise EOFError()
<     
<     def help_do_quit(self):
<         return ("quit", "quit", _("quit the application"))
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/compat.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/compat.py.svn-base
1,214d0
< # pylint: disable-msg=E0601,W0622,W0611
< #
< # Copyright (c) 2004-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """some wrapper around some builtins introduced in python 2.3, 2.4 and
< 2.5, making them available in for earlier versions of python.
< """
< from __future__ import generators
< 
< from warnings import warn
< 
< from clonedigger.logilab.common.deprecation import class_renamed
< 
< try:
<     set = set
<     frozenset = frozenset
< except NameError:
<     try:
<         from sets import Set as set, ImmutableSet as frozenset
<     except ImportError:
<         class _baseset(object):
<             def __init__(self, values=()):
<                 self._data = {}
<                 warn("This implementation of Set is not complete !",
<                      stacklevel=2)
<                 for v in values:
<                     self._data[v] = 1
< 
<             def __or__(self, other):
<                 result = self.__class__(self._data.keys())
<                 for val in other:
<                     result.add(val)
<                 return result
<             __add__ = __or__
<             
<             def __and__(self, other):
<                 result = self.__class__()
<                 for val in other:
<                     if val in self._data:
<                         result.add(val)
<                 return result
<             
<             def __sub__(self, other):
<                 result = self.__class__(self._data.keys())
<                 for val in other:
<                     if val in self._data:
<                         result.remove(val)
<                 return result
<             
<             def __cmp__(self, other):
<                 keys = self._data.keys()
<                 okeys = other._data.keys()
<                 keys.sort()
<                 okeys.sort()
<                 return cmp(keys, okeys)
<             
<             def __len__(self):
<                 return len(self._data)
< 
<             def __repr__(self):
<                 elements = self._data.keys()
<                 return 'lcc.%s(%r)' % (self.__class__.__name__, elements)
<             __str__ = __repr__
< 
<             def __iter__(self):
<                 return iter(self._data)
< 
<         class frozenset(_baseset):
<             """immutable set (can be set in dictionnaries)"""
<             def __init__(self, values=()):
<                 super(frozenset, self).__init__(values)
<                 self._hashcode = None
<                 
<             def _compute_hash(self):
<                 """taken from python stdlib (sets.py)"""
<                 # Calculate hash code for a set by xor'ing the hash codes of
<                 # the elements.  This ensures that the hash code does not depend
<                 # on the order in which elements are added to the set.  This is
<                 # not called __hash__ because a BaseSet should not be hashable;
<                 # only an ImmutableSet is hashable.
<                 result = 0
<                 for elt in self:
<                     result ^= hash(elt)
<                 return result
<             
<             def __hash__(self):
<                 """taken from python stdlib (sets.py)"""
<                 if self._hashcode is None:
<                     self._hashcode = self._compute_hash()
<                 return self._hashcode
< 
<             
<         class set(_baseset):
<             """mutable set"""
<             def add(self, value):
<                 self._data[value] = 1
< 
<             def remove(self, element):
<                 """removes <element> from set"""
<                 del self._data[element]
< 
<             def pop(self):
<                 """pops an arbitrary element from set"""
<                 return self._data.popitem()[0]
< 
<             def __hash__(self):
<                 """mutable et cannot be hashed."""
<                 raise TypeError("set objects are not hashable")
< 
<         del _baseset # don't explicity provide this class
< 
< Set = class_renamed('Set', set, 'logilab.common.compat.Set is deprecated, '
<                     'use logilab.common.compat.set instead')
< 
< try:
<     from itertools import izip, chain, imap
< except ImportError:
<     # from itertools documentation ###
<     def izip(*iterables):
<         iterables = map(iter, iterables)
<         while iterables:
<             result = [i.next() for i in iterables]
<             yield tuple(result)
< 
<     def chain(*iterables):
<         for it in iterables:
<             for element in it:
<                 yield element
<                 
<     def imap(function, *iterables):
<         iterables = map(iter, iterables)
<         while True:
<             args = [i.next() for i in iterables]
<             if function is None:
<                 yield tuple(args)
<             else:
<                 yield function(*args)                
< try:
<     sum = sum
<     enumerate = enumerate
< except NameError:
<     # define the sum and enumerate functions (builtins introduced in py 2.3)
<     import operator
<     def sum(seq, start=0):
<         """Returns the sum of all elements in the sequence"""
<         return reduce(operator.add, seq, start)
< 
<     def enumerate(iterable):
<         """emulates the python2.3 enumerate() function"""
<         i = 0
<         for val in iterable:
<             yield i, val
<             i += 1
<         #return zip(range(len(iterable)), iterable)
< try:
<     sorted = sorted
<     reversed = reversed
< except NameError:
<     
<     def sorted(iterable, cmp=None, key=None, reverse=False):
<         original = list(iterable)
<         if key:
<             l2 = [(key(elt), index) for index, elt in enumerate(original)]
<         else:
<             l2 = original
<         l2.sort(cmp)
<         if reverse:
<             l2.reverse()
<         if key:
<             return [original[index] for elt, index in l2]
<         return l2
<     
<     def reversed(l):
<         l2 = list(l)
<         l2.reverse()
<         return l2
< 
< # Python2.5 builtins
< try:
<     any = any
<     all = all
< except NameError:
<     def any(iterable):
<         """any(iterable) -> bool
< 
<         Return True if bool(x) is True for any x in the iterable.
<         """
<         for elt in iterable:
<             if elt:
<                 return True
<         return False
<     
<     def all(iterable):
<         """all(iterable) -> bool
< 
<         Return True if bool(x) is True for all values x in the iterable.
<         """
<         for elt in iterable:
<             if not elt:
<                 return False
<         return True
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/configuration.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/configuration.py.svn-base
1,888d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some classes used to handle advanced configuration in simple to
< complex applications.
< 
< It's able to load the configuration from a file and or command line
< options, to generate a sample configuration file or to display program's
< usage. It basically fill the gap between optik/optparse and ConfigParser,
< with some additional data types (available as standalone optik extension
< in the `optik_ext` module)
< 
< 
< Quick start: simplest usage
< ```````````````````````````
< 
< import sys
< from clonedigger.logilab.common.configuration import Configuration
< 
< options = [('dothis', {'type':'yn', 'default': True, 'metavar': '<y or n>'}),
<            ('value', {'type': 'string', 'metavar': '<string>'}),
<            ('multiple', {'type': 'csv', 'default': ('yop',),
<                          'metavar': '<comma separated values>',
<                          'help': 'you can also document the option'}),
<            ('number', {'type': 'int', 'default':2, 'metavar':'<int>'}),
<            ]
< config = Configuration(options=options, name='My config')
< print config['dothis']
< print config['value']
< print config['multiple']
< print config['number']
< 
< print config.help()
< 
< f = open('myconfig.ini', 'w')
< f.write('''[MY CONFIG]
< number = 3
< dothis = no
< multiple = 1,2,3
< ''')
< f.close()
< config.load_file_configuration('myconfig.ini')
< print config['dothis']
< print config['value']
< print config['multiple']
< print config['number']
< 
< sys.argv = ['mon prog', '--value', 'bacon', '--multiple', '4,5,6',
<             'nonoptionargument']
< print config.load_command_line_configuration()
< print config['value']
< 
< config.generate_config()
< 
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< from __future__ import generators 
< 
< __docformat__ = "restructuredtext en"
< __all__ = ('OptionsManagerMixIn', 'OptionsProviderMixIn',
<            'ConfigurationMixIn', 'Configuration',
<            'OptionsManager2ConfigurationAdapter')
< 
< import os
< import sys
< import re
< from os.path import exists
< from copy import copy
< from ConfigParser import ConfigParser, NoOptionError, NoSectionError
< 
< from clonedigger.logilab.common.compat import set
< from clonedigger.logilab.common.textutils import normalize_text, unquote
< from clonedigger.logilab.common.optik_ext import OptionParser, OptionGroup, Values, \
<      OptionValueError, OptionError, HelpFormatter, generate_manpage, check_date, \
<      check_yn, check_csv, check_file, check_color, check_named, check_password,\
<      NO_DEFAULT, OPTPARSE_FORMAT_DEFAULT
< 
< REQUIRED = []
< 
< class UnsupportedAction(Exception):
<     """raised by set_option when it doesn't know what to do for an action"""
< 
< # validation functions ########################################################
< 
< def choice_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'choice'
<     """
<     if not value in opt_dict['choices']:
<         msg = "option %s: invalid value: %r, should be in %s"
<         raise OptionValueError(msg % (name, value, opt_dict['choices']))
<     return value
< 
< def multiple_choice_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'choice'
<     """
<     choices = opt_dict['choices']
<     values = check_csv(None, name, value)
<     for value in values:
<         if not value in choices:
<             msg = "option %s: invalid value: %r, should be in %s"
<             raise OptionValueError(msg % (name, value, choices))
<     return values
< 
< def csv_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'csv'
<     """
<     return check_csv(None, name, value)
< 
< def yn_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'yn'
<     """
<     return check_yn(None, name, value)
< 
< def named_validator(opt_dict, name, value):
<     """validate and return a converted value for option of type 'named'
<     """
<     return check_named(None, name, value)
< 
< def file_validator(opt_dict, name, value):
<     """validate and return a filepath for option of type 'file'"""
<     return check_file(None, name, value)
< 
< def color_validator(opt_dict, name, value):
<     """validate and return a valid color for option of type 'color'"""
<     return check_color(None, name, value)
< 
< def password_validator(opt_dict, name, value):
<     """validate and return a string for option of type 'password'"""
<     return check_password(None, name, value)
< 
< def date_validator(opt_dict, name, value):
<     """validate and return a mx DateTime object for option of type 'date'"""
<     return check_password(None, name, value)
< 
< 
< VALIDATORS = {'string' : unquote,
<               'int' : int,
<               'float': float,
<               'file': file_validator,
<               'font': unquote,
<               'color': color_validator,
<               'regexp': re.compile,
<               'csv': csv_validator,
<               'yn': yn_validator,
<               'bool': yn_validator,
<               'named': named_validator,
<               'password': password_validator,
<               'date': date_validator,
<               'choice': choice_validator,
<               'multiple_choice': multiple_choice_validator,
<               }
< 
< def _call_validator(opttype, optdict, option, value):
<     if not VALIDATORS.has_key(opttype):
<         raise Exception('Unsupported type "%s"' % opttype)
<     try:
<         return VALIDATORS[opttype](optdict, option, value)
<     except TypeError:
<         try:
<             return VALIDATORS[opttype](value)
<         except OptionValueError:
<             raise
<         except:
<             raise OptionValueError('%s value (%r) should be of type %s' %
<                                    (option, value, opttype))
< 
< # user input functions ########################################################
< 
< def input_password(optdict, question='password:'):
<     from getpass import getpass
<     while True:
<         value = getpass(question)
<         value2 = getpass('confirm: ')
<         if value == value2:
<             return value
<         print 'password mismatch, try again'
< 
< def input_string(optdict, question):
<     value = raw_input(question).strip()
<     return value or None
< 
< def _make_input_function(opttype):
<     def input_validator(optdict, question):
<         while True:
<             value = raw_input(question)
<             if not value.strip():
<                 return None
<             try:
<                 return _call_validator(opttype, optdict, None, value)
<             except OptionValueError, ex:
<                 msg = str(ex).split(':', 1)[-1].strip()
<                 print 'bad value: %s' % msg
<     return input_validator
< 
< INPUT_FUNCTIONS = {
<     'string': input_string,
<     'password': input_password,
<     }
< 
< for opttype in VALIDATORS.keys():
<     INPUT_FUNCTIONS.setdefault(opttype, _make_input_function(opttype))
<     
< def expand_default(self, option):
<     """monkey patch OptionParser.expand_default since we have a particular
<     way to handle defaults to avoid overriding values in the configuration
<     file
<     """
<     if self.parser is None or not self.default_tag:
<         return option.help
<     optname = option._long_opts[0][2:]
<     try:
<         provider = self.parser.options_manager._all_options[optname]
<     except KeyError:
<         value = None
<     else:
<         optdict = provider.get_option_def(optname)
<         optname = provider.option_name(optname, optdict)
<         value = getattr(provider.config, optname, optdict)
<         value = format_option_value(optdict, value)
<     if value is NO_DEFAULT or not value:
<         value = self.NO_DEFAULT_VALUE
<     return option.help.replace(self.default_tag, str(value))
< 
<     
< def convert(value, opt_dict, name=''):
<     """return a validated value for an option according to its type
<     
<     optional argument name is only used for error message formatting
<     """
<     try:
<         _type = opt_dict['type']
<     except KeyError:
<         # FIXME
<         return value
<     return _call_validator(_type, opt_dict, name, value)
< 
< def comment(string):
<     """return string as a comment"""
<     lines = [line.strip() for line in string.splitlines()]
<     return '# ' + ('%s# ' % os.linesep).join(lines)
< 
< def format_option_value(optdict, value):
<     """return the user input's value from a 'compiled' value"""
<     if isinstance(value, (list, tuple)):
<         value = ','.join(value)
<     elif isinstance(value, dict):
<         value = ','.join(['%s:%s' % (k,v) for k,v in value.items()])    
<     elif hasattr(value, 'match'): # optdict.get('type') == 'regexp'
<         # compiled regexp
<         value = value.pattern
<     elif optdict.get('type') == 'yn':
<         value = value and 'yes' or 'no'
<     elif isinstance(value, (str, unicode)) and value.isspace():
<         value = "'%s'" % value
<     return value
< 
< def ini_format_section(stream, section, options, doc=None):
<     """format an options section using the INI format"""
<     if doc:
<         print >> stream, comment(doc)
<     print >> stream, '[%s]' % section
<     for optname, optdict, value in options:
<         value = format_option_value(optdict, value)
<         help = optdict.get('help')
<         if help:
<             print >> stream
<             print >> stream, normalize_text(help, line_len=79, indent='# ')
<         else:
<             print >> stream
<         if value is None:
<             print >> stream, '#%s=' % optname
<         else:
<             print >> stream, '%s=%s' % (optname, str(value).strip())
<         
< format_section = ini_format_section
< 
< def rest_format_section(stream, section, options, doc=None):
<     """format an options section using the INI format"""
<     if section:
<         print >> stream, '%s\n%s' % (section, "'"*len(section))
<     if doc:
<         print >> stream, normalize_text(doc, line_len=79, indent='')
<         print >> stream
<     for optname, optdict, value in options:
<         help = optdict.get('help')
<         print >> stream, ':%s:' % optname
<         if help:
<             print >> stream, normalize_text(help, line_len=79, indent='  ')
<         if value:
<             print >> stream, '  Default: %s' % format_option_value(optdict, value)
< 
< 
< class OptionsManagerMixIn(object):
<     """MixIn to handle a configuration from both a configuration file and
<     command line options
<     """
<     
<     def __init__(self, usage, config_file=None, version=None, quiet=0):
<         self.config_file = config_file
<         self.reset_parsers(usage, version=version)
<         # list of registered options providers
<         self.options_providers = []
<         # dictionary assocating option name to checker
<         self._all_options = {}
<         self._short_options = {}
<         self._nocallback_options = {}
<         # verbosity
<         self.quiet = quiet
< 
<     def reset_parsers(self, usage='', version=None):
<         # configuration file parser
<         self._config_parser = ConfigParser()
<         # command line parser
<         self._optik_parser = OptionParser(usage=usage, version=version)
<         self._optik_parser.options_manager = self
<         
<     def register_options_provider(self, provider, own_group=True):
<         """register an options provider"""
<         assert provider.priority <= 0, "provider's priority can't be >= 0"
<         for i in range(len(self.options_providers)):
<             if provider.priority > self.options_providers[i].priority:
<                 self.options_providers.insert(i, provider)
<                 break
<         else:
<             self.options_providers.append(provider)
<         non_group_spec_options = [option for option in provider.options
<                                   if not option[1].has_key('group')]
<         groups = getattr(provider, 'option_groups', ())
<         if own_group:
<             self.add_option_group(provider.name.upper(), provider.__doc__,
<                                   non_group_spec_options, provider)
<         else:
<             for opt_name, opt_dict in non_group_spec_options:
<                 args, opt_dict = self.optik_option(provider, opt_name, opt_dict)
<                 self._optik_parser.add_option(*args, **opt_dict)
<                 self._all_options[opt_name] = provider                
<         for gname, gdoc in groups:
<             goptions = [option for option in provider.options
<                         if option[1].get('group') == gname]
<             self.add_option_group(gname, gdoc, goptions, provider)
<         
<     def add_option_group(self, group_name, doc, options, provider):
<         """add an option group including the listed options
<         """
<         # add section to the config file
<         self._config_parser.add_section(group_name)
<         # add option group to the command line parser
<         if options:
<             group = OptionGroup(self._optik_parser,
<                                 title=group_name.capitalize())
<             self._optik_parser.add_option_group(group)
<         # add provider's specific options
<         for opt_name, opt_dict in options:
<             args, opt_dict = self.optik_option(provider, opt_name, opt_dict)
<             group.add_option(*args, **opt_dict)
<             self._all_options[opt_name] = provider
<             
<     def optik_option(self, provider, opt_name, opt_dict):
<         """get our personal option definition and return a suitable form for
<         use with optik/optparse
<         """
<         opt_dict = copy(opt_dict)
<         if opt_dict.has_key('action'):
<             self._nocallback_options[provider] = opt_name
<         else:
<             opt_dict['action'] = 'callback'
<             opt_dict['callback'] = self.cb_set_provider_option
<         for specific in ('default', 'group', 'inputlevel'):
<             if opt_dict.has_key(specific):
<                 del opt_dict[specific]
<                 if (OPTPARSE_FORMAT_DEFAULT
<                     and specific == 'default' and opt_dict.has_key('help')):
<                     opt_dict['help'] += ' [current: %default]'
<         args = ['--' + opt_name]
<         if opt_dict.has_key('short'):
<             self._short_options[opt_dict['short']] = opt_name
<             args.append('-' + opt_dict['short'])
<             del opt_dict['short']
<         available_keys = set(self._optik_parser.option_class.ATTRS)
<         for key in opt_dict.keys():
<             if not key in available_keys:
<                 opt_dict.pop(key)
<         return args, opt_dict
<             
<     def cb_set_provider_option(self, option, opt_name, value, parser):
<         """optik callback for option setting"""
<         if opt_name.startswith('--'):
<             # remove -- on long option
<             opt_name = opt_name[2:]
<         else:
<             # short option, get its long equivalent
<             opt_name = self._short_options[opt_name[1:]]
<         # trick since we can't set action='store_true' on options
<         if value is None:
<             value = 1
<         self.global_set_option(opt_name, value)
<         
<     def global_set_option(self, opt_name, value):
<         """set option on the correct option provider"""
<         self._all_options[opt_name].set_option(opt_name, value)
< 
<     def generate_config(self, stream=None, skipsections=()):
<         """write a configuration file according to the current configuration
<         into the given stream or stdout
<         """
<         stream = stream or sys.stdout
<         printed = False
<         for provider in self.options_providers:
<             default_options = []
<             sections = {}
<             for section, options in provider.options_by_section():
<                 if section in skipsections:
<                     continue
<                 options = [(n, d, v) for (n, d, v) in options
<                            if d.get('type') is not None]
<                 if not options:
<                     continue
<                 if section is None:
<                     section = provider.name
<                     doc = provider.__doc__
<                 else:
<                     doc = None
<                 if printed:
<                     print >> stream, '\n'
<                 format_section(stream, section.upper(), options, doc)
<                 printed = True
< 
<     def generate_manpage(self, pkginfo, section=1, stream=None):
<         """write a man page for the current configuration into the given
<         stream or stdout
<         """
<         generate_manpage(self._optik_parser, pkginfo,
<                          section, stream=stream or sys.stdout)
<         
<     # initialization methods ##################################################
< 
<     def load_provider_defaults(self):
<         """initialize configuration using default values"""
<         for provider in self.options_providers:
<             provider.load_defaults()
<             
<     def load_file_configuration(self, config_file=None):
<         """load the configuration from file"""
<         self.read_config_file(config_file)
<         self.load_config_file()
<         
<     def read_config_file(self, config_file=None):
<         """read the configuration file but do not load it (ie dispatching
<         values to each options provider)
<         """
<         if config_file is None:
<             config_file = self.config_file
<         if config_file and exists(config_file):
<             self._config_parser.read([config_file])
<         elif not self.quiet:
<             msg = 'No config file found, using default configuration'
<             print >> sys.stderr, msg
<             return
<     
<     def input_config(self, onlysection=None, inputlevel=0, stream=None):
<         """interactivly get configuration values by asking to the user and generate
<         a configuration file
<         """
<         if onlysection is not None:
<             onlysection = onlysection.upper()
<         for provider in self.options_providers:
<             for section, option, optdict in provider.all_options():
<                 if onlysection is not None and section != onlysection:
<                     continue
<                 provider.input_option(option, optdict, inputlevel)
<         # now we can generate the configuration file
<         if stream is not None:
<             self.generate_config(stream)
< 
<     def load_config_file(self):
<         """dispatch values previously read from a configuration file to each
<         options provider)
<         """
<         parser = self._config_parser        
<         for provider in self.options_providers:
<             for section, option, optdict in provider.all_options():
<                 try:
<                     value = parser.get(section, option)
<                     provider.set_option(option, value, opt_dict=optdict)
<                 except (NoSectionError, NoOptionError), ex:
<                     continue
< 
<     def load_configuration(self, **kwargs):
<         """override configuration according to given parameters
<         """
<         for opt_name, opt_value in kwargs.items():
<             opt_name = opt_name.replace('_', '-')
<             provider = self._all_options[opt_name]
<             provider.set_option(opt_name, opt_value)
<             
<     def load_command_line_configuration(self, args=None):
<         """override configuration according to command line parameters
< 
<         return additional arguments
<         """
<         # monkey patch optparse to deal with our default values
<         try:
<             expand_default_backup = HelpFormatter.expand_default
<             HelpFormatter.expand_default = expand_default
<         except AttributeError:
<             # python < 2.4: nothing to be done
<             pass
<         try:
<             if args is None:
<                 args = sys.argv[1:]
<             else:
<                 args = list(args)
<             (options, args) = self._optik_parser.parse_args(args=args)
<             for provider in self._nocallback_options.keys():
<                 config = provider.config
<                 for attr in config.__dict__.keys():
<                     value = getattr(options, attr, None)
<                     if value is None:
<                         continue
<                     setattr(config, attr, value)
<             return args
<         finally:
<             if hasattr(HelpFormatter, 'expand_default'):
<                 # unpatch optparse to avoid side effects
<                 HelpFormatter.expand_default = expand_default_backup
< 
< 
<     # help methods ############################################################
< 
<     def add_help_section(self, title, description):
<         """add a dummy option section for help purpose """
<         group = OptionGroup(self._optik_parser,
<                             title=title.capitalize(),
<                             description=description)
<         self._optik_parser.add_option_group(group)
<         
<     def help(self):
<         """return the usage string for available options """
<         return self._optik_parser.format_help()
<     
< 
< class Method(object):
<     """used to ease late binding of default method (so you can define options
<     on the class using default methods on the configuration instance)
<     """
<     def __init__(self, methname):
<         self.method = methname
<         self._inst = None
<         
<     def bind(self, instance):
<         """bind the method to its instance"""
<         if self._inst is None:
<             self._inst = instance
<         
<     def __call__(self):
<         assert self._inst, 'unbound method'
<         return getattr(self._inst, self.method)()
< 
<         
< class OptionsProviderMixIn(object):
<     """Mixin to provide options to an OptionsManager"""
<     
<     # those attributes should be overridden
<     priority = -1
<     name = 'default'
<     options = ()
< 
<     def __init__(self):
<         self.config = Values()
<         for option in self.options:
<             try:
<                 option, optdict = option
<             except ValueError:
<                 raise Exception('Bad option: %r' % option)
<             if isinstance(optdict.get('default'), Method):
<                 optdict['default'].bind(self)
<         self.load_defaults()
<                 
<     def load_defaults(self):
<         """initialize the provider using default values"""
<         for opt_name, opt_dict in self.options:
<             action = opt_dict.get('action')
<             if action != 'callback':
<                 # callback action have no default
<                 default = self.option_default(opt_name, opt_dict)
<                 if default is REQUIRED:
<                     continue
<                 self.set_option(opt_name, default, action, opt_dict)
< 
<     def option_default(self, opt_name, opt_dict=None):
<         """return the default value for an option"""
<         if opt_dict is None:
<             opt_dict = self.get_option_def(opt_name)
<         default = opt_dict.get('default')
<         if callable(default):
<             default = default()
<         return default
<         
<     def option_name(self, opt_name, opt_dict=None):
<         """get the config attribute corresponding to opt_name
<         """
<         if opt_dict is None:
<             opt_dict = self.get_option_def(opt_name)
<         return opt_dict.get('dest', opt_name.replace('-', '_'))
<     
<     def option_value(self, opt_name):
<         """get the current value for the given option"""
<         return getattr(self.config, self.option_name(opt_name), None)
<         
<     def set_option(self, opt_name, value, action=None, opt_dict=None):
<         """method called to set an option (registered in the options list)
<         """
<         # print "************ setting option", opt_name," to value", value
<         if opt_dict is None:
<             opt_dict = self.get_option_def(opt_name)
<         if value is not None:
<             value = convert(value, opt_dict, opt_name)
<         if action is None:
<             action = opt_dict.get('action', 'store')
<         if opt_dict.get('type') == 'named': # XXX need specific handling
<             optname = self.option_name(opt_name, opt_dict)
<             currentvalue = getattr(self.config, optname, None)
<             if currentvalue:
<                 currentvalue.update(value)
<                 value = currentvalue
<         if action == 'store':
<             setattr(self.config, self.option_name(opt_name, opt_dict), value)
<         elif action in ('store_true', 'count'):
<             setattr(self.config, self.option_name(opt_name, opt_dict), 0)
<         elif action == 'store_false':
<             setattr(self.config, self.option_name(opt_name, opt_dict), 1)
<         elif action == 'append':
<             opt_name = self.option_name(opt_name, opt_dict)
<             _list = getattr(self.config, opt_name, None)
<             if _list is None:
<                 if type(value) in (type(()), type([])):
<                     _list = value
<                 elif value is not None:
<                     _list = []
<                     _list.append(value)
<                 setattr(self.config, opt_name, _list)
<             elif type(_list) is type(()):
<                 setattr(self.config, opt_name, _list + (value,))
<             else:
<                 _list.append(value)
<         else:
<             raise UnsupportedAction(action)
< 
<     def input_option(self, option, optdict, inputlevel=99):
<         default = self.option_default(option, optdict)
<         if default is REQUIRED:
<             defaultstr = '(required): '
<         elif optdict.get('inputlevel', 0) > inputlevel:
<             self.set_option(option, default, opt_dict=optdict)
<             return
<         elif optdict['type'] == 'password' or default is None:
<             defaultstr = ': '
<         else:
<             defaultstr = '(default: %s): ' % format_option_value(optdict, default)
<         print ':%s:' % option
<         print optdict.get('help') or option
<         inputfunc = INPUT_FUNCTIONS[optdict['type']]
<         value = inputfunc(optdict, defaultstr)
<         while default is REQUIRED and not value:
<             print 'please specify a value'
<             value = inputfunc(optdict, '%s: ' % option)
<         if value is None and default is not None:
<             value = default
<         self.set_option(option, value, opt_dict=optdict)
<             
<     def get_option_def(self, opt_name):
<         """return the dictionary defining an option given it's name"""
<         assert self.options
<         for opt in self.options:
<             if opt[0] == opt_name:
<                 return opt[1]
<         raise OptionError('no such option in section %r' % self.name, opt_name)
< 
< 
<     def all_options(self):
<         """return an iterator on available options for this provider
<         option are actually described by a 3-uple:
<         (section, option name, option dictionary)
<         """        
<         for section, options in self.options_by_section():
<             if section is None:
<                 section = self.name.upper()
<             for option, optiondict, value in options:
<                 yield section, option, optiondict
<                 
<     def options_by_section(self):
<         """return an iterator on options grouped by section
<         
<         (section, [list of (optname, optdict, optvalue)])
<         """
<         sections = {}
<         for optname, optdict in self.options:
<             sections.setdefault(optdict.get('group'), []).append(
<                 (optname, optdict, self.option_value(optname)))
<         if None in sections:
<             yield None, sections.pop(None)
<         for section, options in sections.items():
<             yield section.upper(), options
<        
< 
< class ConfigurationMixIn(OptionsManagerMixIn, OptionsProviderMixIn):
<     """basic mixin for simple configurations which don't need the
<     manager / providers model
<     """
<     def __init__(self, *args, **kwargs):
<         if not args:
<             kwargs.setdefault('usage', '')
<         kwargs.setdefault('quiet', 1)
<         OptionsManagerMixIn.__init__(self, *args, **kwargs)
<         OptionsProviderMixIn.__init__(self)
<         if not getattr(self, 'option_groups', None):
<             self.option_groups = []
<             for option, optdict in self.options:
<                 try:
<                     gdef = (optdict['group'], '')
<                 except KeyError:
<                     continue
<                 if not gdef in self.option_groups:
<                     self.option_groups.append(gdef)
<         self.register_options_provider(self, own_group=0)
< 
<     def register_options(self, options):
<         """add some options to the configuration"""
<         options_by_group = {}
<         for optname, optdict in options:
<             options_by_group.setdefault(optdict.get('group', self.name.upper()), []).append((optname, optdict))
<         for group, options in options_by_group.items():
<             self.add_option_group(group, None, options, self)
<         self.options += tuple(options)
<         
<     def load_defaults(self):
<         OptionsProviderMixIn.load_defaults(self)
< 
<     def __getitem__(self, key):
<         try:
<             return getattr(self.config, self.option_name(key))
<         except (OptionValueError, AttributeError):
<             raise KeyError(key)
< 
<     def __setitem__(self, key, value):
<         self.set_option(self.option_name(key), value)
<         
<     def get(self, key, default=None):
<         try:
<             return getattr(self.config, self.option_name(key))
<         except (OptionError, AttributeError):
<             return default
<         
< 
< class Configuration(ConfigurationMixIn):
<     """class for simple configurations which don't need the
<     manager / providers model and prefer delegation to inheritance
< 
<     configuration values are accessible through a dict like interface
<     """
< 
<     def __init__(self, config_file=None, options=None, name=None,
<                  usage=None, doc=None, version=None):
<         if options is not None:
<             self.options = options
<         if name is not None:
<             self.name = name
<         if doc is not None:
<             self.__doc__ = doc
<         super(Configuration, self).__init__(config_file=config_file, usage=usage, version=version)
< 
< 
< class OptionsManager2ConfigurationAdapter(object):
<     """Adapt an option manager to behave like a
<     `logilab.common.configuration.Configuration` instance
<     """
<     def __init__(self, provider):
<         self.config = provider
<         
<     def __getattr__(self, key):
<         return getattr(self.config, key)
<         
<     def __getitem__(self, key):
<         provider = self.config._all_options[key]
<         try:
<             return getattr(provider.config, provider.option_name(key))
<         except AttributeError:
<             raise KeyError(key)
< 
<     def __setitem__(self, key, value):
<         self.config.global_set_option(self.config.option_name(key), value)
< 
<     def get(self, key, default=None):
<         provider = self.config._all_options[key]
<         try:
<             return getattr(provider.config, provider.option_name(key))
<         except AttributeError:
<             return default
< 
< 
< def read_old_config(newconfig, changes, configfile):
<     """initialize newconfig from a deprecated configuration file
<     
<     possible changes:
<     * ('renamed', oldname, newname)
<     * ('moved', option, oldgroup, newgroup)
<     * ('typechanged', option, oldtype, newvalue)
<     """
<     # build an index of changes
<     changesindex = {}
<     for action in changes:
<         if action[0] == 'moved':
<             option, oldgroup, newgroup = action[1:]
<             changesindex.setdefault(option, []).append((action[0], oldgroup, newgroup))
<             continue
<         if action[0] == 'renamed':
<             oldname, newname = action[1:]
<             changesindex.setdefault(newname, []).append((action[0], oldname))
<             continue
<         if action[0] == 'typechanged':
<             option, oldtype, newvalue = action[1:]
<             changesindex.setdefault(option, []).append((action[0], oldtype, newvalue))
<             continue        
<         if action[1] in ('added', 'removed'):
<             continue # nothing to do here
<         raise Exception('unknown change %s' % action[0])    
<     # build a config object able to read the old config
<     options = []
<     for optname, optdef in newconfig.options:
<         for action in changesindex.pop(optname, ()):
<             if action[0] == 'moved':
<                 oldgroup, newgroup = action[1:]
<                 optdef = optdef.copy()
<                 optdef['group'] = oldgroup
<             elif action[0] == 'renamed':
<                 optname = action[1]
<             elif action[0] == 'typechanged':
<                 oldtype = action[1]
<                 optdef = optdef.copy()
<                 optdef['type'] = oldtype
<         options.append((optname, optdef))
<     if changesindex:
<         raise Exception('unapplied changes: %s' % changesindex)
<     oldconfig = Configuration(options=options, name=newconfig.name)
<     # read the old config
<     oldconfig.load_file_configuration(configfile)
<     # apply values reverting changes
<     changes.reverse()
<     done = set()
<     for action in changes:
<         if action[0] == 'renamed':
<             oldname, newname = action[1:]
<             newconfig[newname] = oldconfig[oldname]
<             done.add(newname)
<         elif action[0] == 'typechanged':
<             optname, oldtype, newvalue = action[1:]
<             newconfig[optname] = newvalue
<             done.add(optname)
<     for optname, optdef in newconfig.options:
<         if not optname in done:
<             newconfig.set_option(optname, oldconfig[optname], opt_dict=optdef)
< 
< 
< def merge_options(options):
<     """preprocess options to remove duplicate"""
<     alloptions = {}
<     options = list(options)
<     for i in range(len(options)-1, -1, -1):
<         optname, optdict = options[i]
<         if optname in alloptions:
<             options.pop(i)
<             alloptions[optname].update(optdict)
<         else:
<             alloptions[optname] = optdict
<     return tuple(options)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/corbautils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/corbautils.py.svn-base
1,96d0
< """A set of utility function to ease the use of OmniORBpy."""
< 
< __revision__ = '$Id: corbautils.py,v 1.2 2005-11-22 13:13:00 syt Exp $'
< 
< from omniORB import CORBA, PortableServer
< import CosNaming
< 
< orb = None
< 
< def get_orb():
<     """
<     returns a reference to the ORB.
<     The first call to the method initialized the ORB
<     This method is mainly used internally in the module.
<     """
<     
<     global orb
<     if orb is None:
<         import sys
<         orb = CORBA.ORB_init(sys.argv, CORBA.ORB_ID)
<     return orb
< 
< def get_root_context():
<     """
<     returns a reference to the NameService object.
<     This method is mainly used internally in the module.
<     """
<     
<     orb = get_orb()
<     nss = orb.resolve_initial_references("NameService")
<     rootContext = nss._narrow(CosNaming.NamingContext)
<     assert rootContext is not None,"Failed to narrow root naming context"
<     return rootContext
< 
< def register_object_name(object, namepath):
<     """
<     Registers a object in the NamingService.
<     The name path is a list of 2-uples (id,kind) giving the path.
< 
<     For instance if the path of an object is [('foo',''),('bar','')],
<     it is possible to get a reference to the object using the URL
<     'corbaname::hostname#foo/bar'.
<     [('logilab','rootmodule'),('chatbot','application'),('chatter','server')]
<     is mapped to
<     'corbaname::hostname#logilab.rootmodule/chatbot.application/chatter.server'
<     
<     The get_object_reference() function can be used to resolve such a URL.
<     """
<     context = get_root_context()
<     for id, kind in namepath[:-1]:
<         name = [CosNaming.NameComponent(id, kind)]
<         try:
<             context = context.bind_new_context(name)
<         except CosNaming.NamingContext.AlreadyBound, ex:
<             context = context.resolve(name)._narrow(CosNaming.NamingContext)
<             assert context is not None, \
<                    'test context exists but is not a NamingContext'
< 
<     id,kind = namepath[-1]
<     name = [CosNaming.NameComponent(id, kind)]
<     try:
<         context.bind(name, object._this())
<     except CosNaming.NamingContext.AlreadyBound, ex:
<         context.rebind(name, object._this())
< 
< def activate_POA():
<     """
<     This methods activates the Portable Object Adapter.
<     You need to call it to enable the reception of messages in your code,
<     on both the client and the server.
<     """
<     orb = get_orb()
<     poa = orb.resolve_initial_references('RootPOA')
<     poaManager = poa._get_the_POAManager()
<     poaManager.activate()
< 
< def run_orb():
<     """
<     Enters the ORB mainloop on the server.
<     You should not call this method on the client.
<     """
<     get_orb().run()
< 
< def get_object_reference(url):
<     """
<     Resolves a corbaname URL to an object proxy.
<     See register_object_name() for examples URLs
<     """
<     return get_orb().string_to_object(url)
< 
< def get_object_string(host, namepath):
<     """given an host name and a name path as described in register_object_name,
<     return a corba string identifier
<     """
<     strname = '/'.join(['.'.join(path_elt) for path_elt in namepath])
<     return 'corbaname::%s#%s' % (host, strname)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/daemon.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/daemon.py.svn-base
1,144d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< a daemon mix-in class
< """
< 
< __revision__ = '$Id: daemon.py,v 1.10 2005-11-22 13:13:01 syt Exp $'
< 
< import os, signal, sys, time
< from clonedigger.logilab.common.logger import make_logger, LOG_ALERT, LOG_NOTICE
< 
< class DaemonMixIn:
<     """ mixin to make a daemon from watchers/queriers
<     """
< 
<     def __init__(self, configmod) :
<         self.delay = configmod.DELAY
<         self.name = str(self.__class__).split('.')[-1]
<         self._pid_file = os.path.join('/tmp', '%s.pid'%self.name)
<         if os.path.exists(self._pid_file):
<             raise Exception('''Another instance of %s must be running.
< If it i not the case, remove the file %s''' % (self.name, self._pid_file))
<         self._alive = 1
<         self._sleeping = 0
<         treshold = configmod.LOG_TRESHOLD
<         if configmod.NODETACH:
<             configmod.log = make_logger('print', treshold, self.name).log
<         else:
<             configmod.log = make_logger('syslog', treshold, self.name).log
<         self.config = configmod
< 
<     def _daemonize(self):
<         if not self.config.NODETACH:
<             # fork so the parent can exist
<             if (os.fork()):
<                 return -1
<             # deconnect from tty and create a new session
<             os.setsid()
<             # fork again so the parent, (the session group leader), can exit.
<             # as a non-session group leader, we can never regain a controlling
<             # terminal.
<             if (os.fork()):
<                 return -1
<             # move to the root to avoit mount pb
<             os.chdir('/')
<             # set paranoid umask
<             os.umask(077)
<             # write pid in a file
<             f = open(self._pid_file, 'w')
<             f.write(str(os.getpid()))
<             f.close()
<             # close standard descriptors
<             sys.stdin.close()
<             sys.stdout.close()
<             sys.stderr.close()
<             # put signal handler
<             signal.signal(signal.SIGTERM, self.signal_handler)
<             signal.signal(signal.SIGHUP, self.signal_handler)
< 		
<         
<     def run(self):
<         """ optionaly go in daemon mode and
<         do what concrete classe has to do and pauses for delay between runs
<         If self.delay is negative, do a pause before starting
<         """
<         if self._daemonize() == -1:
<             return
<         self.config.log(LOG_NOTICE, '%s instance started' % self.name)
<         if self.delay < 0:
<             self.delay = -self.delay
<             time.sleep(self.delay)
<         while 1:
<             try:
<                 self._run()
<             except Exception, e:
<                 # display for info, sleep, and hope the problem will be solved
<                 # later.
<                 self.config.log(LOG_ALERT, 'Internal error: %s'%(e))
<             if not self._alive:
<                 break
<             try:
<                 self._sleeping = 1
<                 time.sleep(self.delay)
<                 self._sleeping = 0
<             except SystemExit:
<                 break
<         self.config.log(LOG_NOTICE, '%s instance exited'%self.name)
<         # remove pid file
<         os.remove(self._pid_file)
<         
<     def signal_handler(self, sig_num, stack_frame):
<         if sig_num == signal.SIGTERM:
<             if self._sleeping:
<                 # we are sleeping so we can exit without fear
<                 self.config.log(LOG_NOTICE, 'exit on SIGTERM')
<                 sys.exit(0)
<             else:
<                 self.config.log(LOG_NOTICE, 'exit on SIGTERM (on next turn)')
<                 self._alive = 0
<         elif sig_num == signal.SIGHUP:
<             self.config.log(LOG_NOTICE, 'reloading configuration on SIGHUP')
<             reload(self.config)
< 
<     def _run(self):
<         """should be overidden in the mixed class"""
<         raise NotImplementedError()
<     
< ## command line utilities ######################################################
< 
< L_OPTIONS = ["help", "log=", "delay=", 'no-detach']
< S_OPTIONS = 'hl:d:n'
< 
< def print_help(modconfig):
<     print """  --help or -h
<     displays this message
<   --log <log_level>
<     log treshold (7 record everything, 0 record only emergency.)
<     Defaults to %s
<   --delay <delay>
<     the number of seconds between two runs.
<     Defaults to %s""" % (modconfig.LOG_TRESHOLD, modconfig.DELAY)
< 
< def handle_option(modconfig, opt_name, opt_value, help_meth):
<     if opt_name in ('-h','--help'):            
<         help_meth()
<         sys.exit(0)
<     elif opt_name in ('-l','--log'):
<         modconfig.LOG_TRESHOLD = int(opt_value)
<     elif opt_name in ('-d', '--delay'):
<         modconfig.DELAY = int(opt_value)
<     elif opt_name in ('-n', '--no-detach'):
<         modconfig.NODETACH = 1
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/date.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/date.py.svn-base
1,117d0
< # Copyright (c) 2006-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< 
< """date manipulation helper functions"""
< 
< import math
< 
< try:
<     from mx.DateTime import RelativeDateTime, strptime, Date
<     STEP = 1
< except ImportError:
<     from warnings import warn
<     warn("mxDateTime not found, holiday management won't be available")
<     from datetime import timedelta
<     STEP = timedelta(days=1)
< else:
<     endOfMonth = RelativeDateTime(months=1, day=-1)
< 
<     FRENCH_FIXED_HOLIDAYS = {
<         'jour_an'        : '%s-01-01',
<         'fete_travail'   : '%s-05-01',
<         'armistice1945'  : '%s-05-08',
<         'fete_nat'       : '%s-07-14',
<         'assomption'     : '%s-08-15',
<         'toussaint'      : '%s-11-01',
<         'armistice1918'  : '%s-11-11',
<         'noel'           : '%s-12-25',
<         }
< 
< 
<     FRENCH_MOBILE_HOLIDAYS = {
<         'paques2004'    : '2004-04-12',
<         'ascension2004' : '2004-05-20',
<         'pentecote2004' : '2004-05-31',
< 
<         'paques2005'    : '2005-03-28',
<         'ascension2005' : '2005-05-05',
<         'pentecote2005' : '2005-05-16',
< 
<         'paques2006'    : '2006-04-17',
<         'ascension2006' : '2006-05-25',
<         'pentecote2006' : '2006-06-05',
< 
<         'paques2007'    : '2007-04-09',
<         'ascension2007' : '2007-05-17',
<         'pentecote2007' : '2007-05-28',
< 
<         'paques2008'    : '2008-03-24',
<         'ascension2008' : '2008-05-01',
<         'pentecote2008' : '2008-05-12',
<         }
< 
<     def get_national_holidays(begin, end):
<         """return french national days off between begin and end"""
<         begin = Date(begin.year, begin.month, begin.day)
<         end = Date(end.year, end.month, end.day)
<         holidays = [strptime(datestr, '%Y-%m-%d')
<                     for datestr in FRENCH_MOBILE_HOLIDAYS.values()]
<         for year in xrange(begin.year, end.year+1):
<             for datestr in FRENCH_FIXED_HOLIDAYS.values():
<                 date = strptime(datestr % year, '%Y-%m-%d')
<                 if date not in holidays:
<                     holidays.append(date)
<         return [day for day in holidays if begin <= day < end]
< 
< 
<     def add_days_worked(start, days):
<         """adds date but try to only take days worked into account"""
<         weeks, plus = divmod(days, 5)
<         end = start+(weeks * 7) + plus
<         if end.day_of_week >= 5: # saturday or sunday
<             end += 2
<         end += len([x for x in get_national_holidays(start, end+1)
<                     if x.day_of_week < 5])
<         if end.day_of_week >= 5: # saturday or sunday
<             end += 2
<         return end
< 
<     def nb_open_days(start, end):
<         assert start <= end
<         days = int(math.ceil((end - start).days))
<         weeks, plus = divmod(days, 7)
<         if start.day_of_week > end.day_of_week:
<             plus -= 2
<         elif end.day_of_week == 6:
<             plus -= 1
<         open_days = weeks * 5 + plus
<         nb_week_holidays = len([x for x in get_national_holidays(start, end+1)
<                                 if x.day_of_week < 5 and x < end])
<         return open_days  - nb_week_holidays
< 
< 
< def date_range(begin, end, step=STEP):
<     """
<     enumerate dates between begin and end dates.
< 
<     step can either be oneDay, oneHour, oneMinute, oneSecond, oneWeek
<     use endOfMonth to enumerate months
<     """
<     date = begin
<     while date < end :
<         yield date
<         date += step
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/db.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/db.py.svn-base
1,650d0
< # Copyright (c) 2002-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """This modules contains wrappers to get actually replaceable DBAPI2 compliant
< modules and database connection whatever the database and client lib used.
< 
< Currently support:
< 
< - postgresql (pgdb, psycopg, psycopg2, pyPgSQL)
< - mysql (MySQLdb)
< - sqlite (pysqlite2, sqlite, sqlite3)
< 
< just use the `get_connection` function from this module to get a
< wrapped connection.  If multiple drivers for a database are available,
< you can control which one you want to use using the
< `set_prefered_driver` function.
< 
< Additional helpers are also provided for advanced functionalities such
< as listing existing users or databases, creating database... Get the
< helper for your database using the `get_adv_func_helper` function.
< """
< 
< import sys
< import re
< from warnings import warn
< 
< from clonedigger.logilab.common.deprecation import obsolete
< try:
<     from mx.DateTime import DateTimeType, DateTimeDeltaType, strptime
<     HAS_MX_DATETIME = True
< except:
<     HAS_MX_DATETIME = False
<     
< __all__ = ['get_dbapi_compliant_module', 
<            'get_connection', 'set_prefered_driver',
<            'PyConnection', 'PyCursor',
<            'UnknownDriver', 'NoAdapterFound',
<            ]
< 
< class UnknownDriver(Exception):
<     """raised when a unknown driver is given to get connexion"""
< 
< class NoAdapterFound(Exception):
<     """Raised when no Adpater to DBAPI was found"""
<     def __init__(self, obj, objname=None, protocol='DBAPI'):
<         if objname is None:
<             objname = obj.__name__
<         Exception.__init__(self, "Could not adapt %s to protocol %s" %
<                            (objname, protocol))
<         self.adapted_obj = obj
<         self.objname = objname
<         self._protocol = protocol
< 
< 
< def _import_driver_module(driver, drivers, imported_elements=None, quiet=True):
<     """Imports the first module found in 'drivers' for 'driver'
< 
<     :rtype: tuple
<     :returns: the tuple module_object, module_name where module_object
<               is the dbapi module, and modname the module's name
<     """
<     if not driver in drivers:
<         raise UnknownDriver(driver)
<     imported_elements = imported_elements or []
<     for modname in drivers[driver]:
<         try:
<             if not quiet:
<                 print >> sys.stderr, 'Trying %s' % modname
<             module = __import__(modname, globals(), locals(), imported_elements)
<             break
<         except ImportError:
<             if not quiet:
<                 print >> sys.stderr, '%s is not available' % modname
<             continue
<     else:
<         raise ImportError('Unable to import a %s module' % driver)
<     if not imported_elements:
<         for part in modname.split('.')[1:]:
<             module = getattr(module, part)
<     return module, modname
< 
< 
< ## Connection and cursor wrappers #############################################
<         
< class SimpleConnectionWrapper:
<     """A simple connection wrapper in python to decorated C-level connections
<     with additional attributes
<     """
<     def __init__(self, cnx):
<         """Wraps the original connection object"""
<         self._cnx = cnx
< 
<     # XXX : Would it work if only __getattr__ was defined 
<     def cursor(self):
<         """Wraps cursor()"""
<         return self._cnx.cursor()
< 
<     def commit(self):
<         """Wraps commit()"""
<         return self._cnx.commit()
< 
<     def rollback(self):
<         """Wraps rollback()"""
<         return self._cnx.rollback()
< 
<     def close(self):
<         """Wraps close()"""
<         return self._cnx.close()
< 
<     def __getattr__(self, attrname):
<         return getattr(self._cnx, attrname)    
< 
< class PyConnection(SimpleConnectionWrapper):
<     """A simple connection wrapper in python, generating wrapper for cursors as
<     well (useful for profiling)
<     """
<     def __init__(self, cnx):
<         """Wraps the original connection object"""
<         self._cnx = cnx
<         
<     def cursor(self):
<         """Wraps cursor()"""
<         return PyCursor(self._cnx.cursor())
< 
< 
< 
< class PyCursor:
<     """A simple cursor wrapper in python (useful for profiling)"""
<     def __init__(self, cursor):
<         self._cursor = cursor
< 
<     def close(self):
<         """Wraps close()"""
<         return self._cursor.close()
<         
<     def execute(self, *args, **kwargs):
<         """Wraps execute()"""
<         return self._cursor.execute(*args, **kwargs)
< 
<     def executemany(self, *args, **kwargs):
<         """Wraps executemany()"""
<         return self._cursor.executemany(*args, **kwargs)
< 
<     def fetchone(self, *args, **kwargs):
<         """Wraps fetchone()"""
<         return self._cursor.fetchone(*args, **kwargs)
< 
<     def fetchmany(self, *args, **kwargs):
<         """Wraps execute()"""
<         return self._cursor.fetchmany(*args, **kwargs)
< 
<     def fetchall(self, *args, **kwargs):
<         """Wraps fetchall()"""
<         return self._cursor.fetchall(*args, **kwargs)
< 
<     def __getattr__(self, attrname):
<         return getattr(self._cursor, attrname)
<     
< 
< ## Adapters list ##############################################################
<     
< class DBAPIAdapter:
<     """Base class for all DBAPI adpaters"""
< 
<     def __init__(self, native_module, pywrap=False):
<         """
<         :type native_module: module
<         :param native_module: the database's driver adapted module
<         """
<         self._native_module = native_module
<         self._pywrap = pywrap
< 
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Wraps the native module connect method"""
<         kwargs = {'host' : host, 'port' : port, 'database' : database,
<                   'user' : user, 'password' : password}
<         cnx = self._native_module.connect(**kwargs)
<         return self._wrap_if_needed(cnx, user)
< 
<     def _wrap_if_needed(self, cnx, user):
<         """Wraps the connection object if self._pywrap is True, and returns it
<         If false, returns the original cnx object
<         """
<         if self._pywrap:
<             cnx = PyConnection(cnx)
<         try:
<             cnx.logged_user = user
<         except AttributeError:
<             # C or __slots__ object
<             cnx = SimpleConnectionWrapper(cnx)
<             cnx.logged_user = user            
<         return cnx
<     
<     def __getattr__(self, attrname):
<         return getattr(self._native_module, attrname)
< 
<     def process_value(self, value, description, encoding='utf-8', binarywrap=None):
<         typecode = description[1]
<         assert typecode is not None, self # dbapi module isn't supporting type codes, override to return value directly
<         if typecode == self.STRING:
<             if isinstance(value, str):
<                 return unicode(value, encoding, 'replace')
<         elif typecode == self.BOOLEAN:
<             return bool(value)
<         elif typecode == self.BINARY and not binarywrap is None:
<             return binarywrap(value)
< ##                 elif typecode == dbapimod.DATETIME:
< ##                     pass
< ##                 elif typecode == dbapimod.NUMBER:
< ##                     pass
< ##                 else:
< ##                     self.warning("type -%s- unknown for %r (%s) ",
< ##                         typecode, value, type(value))
<         return value
<         
<     
< # Postgresql #########################################################
< 
< class _PgdbAdapter(DBAPIAdapter):
<     """Simple PGDB Adapter to DBAPI (pgdb modules lacks Binary() and NUMBER)
<     """
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self.NUMBER = native_module.pgdbType('int2', 'int4', 'serial',
<                                              'int8', 'float4', 'float8',
<                                              'numeric', 'bool', 'money')
<         
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Wraps the native module connect method"""
<         if port:
<             warn("pgdb doesn't support 'port' parameter in connect()", UserWarning)
<         kwargs = {'host' : host, 'database' : database,
<                   'user' : user, 'password' : password}
<         cnx = self._native_module.connect(**kwargs)
<         return self._wrap_if_needed(cnx, user)
< 
< 
< class _PsycopgAdapter(DBAPIAdapter):
<     """Simple Psycopg Adapter to DBAPI (cnx_string differs from classical ones)
<     """
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Handles psycopg connexion format"""
<         if host:
<             cnx_string = 'host=%s  dbname=%s  user=%s' % (host, database, user)
<         else:
<             cnx_string = 'dbname=%s  user=%s' % (database, user)
<         if port:
<             cnx_string += ' port=%s' % port
<         if password:
<             cnx_string = '%s password=%s' % (cnx_string, password)
<         cnx = self._native_module.connect(cnx_string)
<         cnx.set_isolation_level(1)
<         return self._wrap_if_needed(cnx, user)
<     
< class _Psycopg2Adapter(_PsycopgAdapter):
<     """Simple Psycopg2 Adapter to DBAPI (cnx_string differs from classical ones)
<     """
<     BOOLEAN = 16 # XXX see additional types in psycopg2.extensions
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self._init_psycopg2()
< 
<     def _init_psycopg2(self):
<         """initialize psycopg2 to use mx.DateTime for date and timestamps
<         instead for datetime.datetime"""
<         psycopg2 = self._native_module
<         if hasattr(psycopg2, '_lc_initialized'):
<             return
<         psycopg2._lc_initialized = 1
<         # use mxDateTime instead of datetime if available
<         if HAS_MX_DATETIME:
<             from psycopg2 import extensions
<             extensions.register_type(psycopg2._psycopg.MXDATETIME)
<             extensions.register_type(psycopg2._psycopg.MXINTERVAL)
<             extensions.register_type(psycopg2._psycopg.MXDATE)
<             extensions.register_type(psycopg2._psycopg.MXTIME)
<             # StringIO/cStringIO adaptation
<             # XXX (syt) todo, see my december discussion on the psycopg2 list
<             # for a working solution
<             #def adapt_stringio(stringio):
<             #    print 'ADAPTING', stringio
<             #    return psycopg2.Binary(stringio.getvalue())
<             #import StringIO
<             #extensions.register_adapter(StringIO.StringIO, adapt_stringio)
<             #import cStringIO
<             #extensions.register_adapter(cStringIO.StringIO, adapt_stringio)
<         
< 
< class _PgsqlAdapter(DBAPIAdapter):
<     """Simple pyPgSQL Adapter to DBAPI
<     """
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Handles psycopg connexion format"""
<         kwargs = {'host' : host, 'port': port or None,
<                   'database' : database,
<                   'user' : user, 'password' : password or None}
<         cnx = self._native_module.connect(**kwargs)
<         return self._wrap_if_needed(cnx, user)
< 
< 
<     def Binary(self, string):
<         """Emulates the Binary (cf. DB-API) function"""
<         return str
<     
<     def __getattr__(self, attrname):
<         # __import__('pyPgSQL.PgSQL', ...) imports the toplevel package
<         return getattr(self._native_module, attrname)
< 
< 
< # Sqlite #############################################################
< 
< class _PySqlite2Adapter(DBAPIAdapter):
<     """Simple pysqlite2 Adapter to DBAPI
<     """
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self._init_pysqlite2()
<         # no type code in pysqlite2
<         self.BINARY = 'XXX'
<         self.STRING = 'XXX'
<         self.DATETIME = 'XXX'
<         self.NUMBER = 'XXX'
< 
<     def _init_pysqlite2(self):
<         """initialize pysqlite2 to use mx.DateTime for date and timestamps"""
<         sqlite = self._native_module
<         if hasattr(sqlite, '_lc_initialized'):
<             return
<         sqlite._lc_initialized = 1
< 
<         # bytea type handling
<         from StringIO import StringIO
<         def adapt_bytea(data):
<             return data.getvalue()
<         sqlite.register_adapter(StringIO, adapt_bytea)
<         def convert_bytea(data):
<             return StringIO(data)
<         sqlite.register_converter('bytea', convert_bytea)
< 
<         # boolean type handling
<         def convert_boolean(ustr):
<             if ustr.upper() in ('F', 'FALSE'):
<                 return False
<             return True
<         sqlite.register_converter('boolean', convert_boolean)
<         def adapt_boolean(bval):
<             return str(bval).upper()
<         sqlite.register_adapter(bool, adapt_boolean)
< 
<         # date/time types handling
<         if HAS_MX_DATETIME:
<             def adapt_mxdatetime(mxd):
<                 return mxd.strftime('%Y-%m-%d %H:%M:%S')
<             sqlite.register_adapter(DateTimeType, adapt_mxdatetime)
<             def adapt_mxdatetimedelta(mxd):
<                 return mxd.strftime('%H:%M:%S')
<             sqlite.register_adapter(DateTimeDeltaType, adapt_mxdatetimedelta)
<             
<             def convert_mxdate(ustr):
<                 return strptime(ustr, '%Y-%m-%d %H:%M:%S')
<             sqlite.register_converter('date', convert_mxdate)
<             def convert_mxdatetime(ustr):
<                 return strptime(ustr, '%Y-%m-%d %H:%M:%S')
<             sqlite.register_converter('timestamp', convert_mxdatetime)
<             def convert_mxtime(ustr):
<                 try:
<                     return strptime(ustr, '%H:%M:%S')
<                 except:
<                     # DateTime used as Time?
<                     return strptime(ustr, '%Y-%m-%d %H:%M:%S')
<             sqlite.register_converter('time', convert_mxtime)
<         # XXX else use datetime.datetime
<     
<             
<     def connect(self, host='', database='', user='', password='', port=None):
<         """Handles sqlite connexion format"""
<         sqlite = self._native_module
<         
<         class PySqlite2Cursor(sqlite.Cursor):
<             """cursor adapting usual dict format to pysqlite named format
<             in SQL queries
<             """
<             def _replace_parameters(self, sql, kwargs):
<                 if isinstance(kwargs, dict):
<                     return re.sub(r'%\(([^\)]+)\)s', r':\1', sql)
<                 # XXX dumb
<                 return re.sub(r'%s', r'?', sql)
<                     
<             def execute(self, sql, kwargs=None):
<                 if kwargs is None:
<                     self.__class__.__bases__[0].execute(self, sql)
<                 else:
<                     self.__class__.__bases__[0].execute(self, self._replace_parameters(sql, kwargs), kwargs)
<             def executemany(self, sql, kwargss):
<                 if not isinstance(kwargss, (list, tuple)):
<                     kwargss = tuple(kwargss)
<                 self.__class__.__bases__[0].executemany(self, self._replace_parameters(sql, kwargss[0]), kwargss)
<                     
<         class PySqlite2CnxWrapper:
<             def __init__(self, cnx):
<                 self._cnx = cnx
<                 
<             def cursor(self):
<                 return self._cnx.cursor(PySqlite2Cursor)
<             def __getattr__(self, attrname):
<                 return getattr(self._cnx, attrname)
<         cnx = sqlite.connect(database, detect_types=sqlite.PARSE_DECLTYPES)
<         return self._wrap_if_needed(PySqlite2CnxWrapper(cnx), user)
<     
<     def process_value(self, value, description, encoding='utf-8', binarywrap=None):
<         if not binarywrap is None and isinstance(value, self._native_module.Binary):
<             return binarywrap(value)
<         return value # no type code support, can't do anything
< 
<     
< class _SqliteAdapter(DBAPIAdapter):
<     """Simple sqlite Adapter to DBAPI
<     """
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self.DATETIME = native_module.TIMESTAMP
<         
<     def connect(self, host='', database='', user='', password='', port=''):
<         """Handles sqlite connexion format"""
<         cnx = self._native_module.connect(database)
<         return self._wrap_if_needed(cnx, user)
< 
< 
< # Mysql ##############################################################
< 
< class _MySqlDBAdapter(DBAPIAdapter):
<     """Simple mysql Adapter to DBAPI
<     """
<     BOOLEAN = 'XXX' # no specific type code for boolean
< 
<     def __init__(self, native_module, pywrap=False):
<         DBAPIAdapter.__init__(self, native_module, pywrap)
<         self._init_module()
< 
<     def _init_module(self):
<         """initialize mysqldb to use mx.DateTime for date and timestamps"""
<         natmod = self._native_module
<         if hasattr(natmod, '_lc_initialized'):
<             return
<         natmod._lc_initialized = 1
<         # date/time types handling
<         if HAS_MX_DATETIME:
<             from MySQLdb import times
<             from mx import DateTime as mxdt
<             times.Date = times.date = mxdt.Date
<             times.Time = times.time = mxdt.Time
<             times.Timestamp = times.datetime = mxdt.DateTime
<             times.TimeDelta = times.timedelta = mxdt.TimeDelta
<             times.DateTimeType = mxdt.DateTimeType
<             times.DateTimeDeltaType = mxdt.DateTimeDeltaType
<             
<     def connect(self, host='', database='', user='', password='', port=None,
<                 unicode=True, charset='utf8'):
<         """Handles mysqldb connexion format
<         the unicode named argument asks to use Unicode objects for strings
<         in result sets and query parameters
<         """
<         kwargs = {'host' : host or '', 'db' : database,
<                   'user' : user, 'passwd' : password,
<                   'use_unicode' : unicode}
<         # MySQLdb doesn't support None port
<         if port:
<             kwargs['port'] = int(port)
<         cnx = self._native_module.connect(**kwargs)
<         if unicode:
<             if charset.lower() == 'utf-8':
<                 charset = 'utf8'
<             cnx.set_character_set(charset)
<         return self._wrap_if_needed(cnx, user)
< 
<     def process_value(self, value, description, encoding='utf-8', binarywrap=None):
<         typecode = description[1]
<         # hack to differentiate mediumtext (String) and tinyblob/longblog
<         # (Password/Bytes) which are all sharing the same type code :(
<         if typecode == self.BINARY:
<             if hasattr(value, 'tostring'): # may be an array
<                 value = value.tostring()
<             maxsize = description[3]
<             # mediumtext can hold up to (2**24 - 1) characters (16777215)
<             # but if utf8 is set, each character is stored on 3 bytes words,
<             # so we have to test for 3 * (2**24 - 1)  (i.e. 50331645)
<             # XXX: what about other encodings ??
<             if maxsize in (16777215, 50331645): # mediumtext (2**24 - 1)
<                 if isinstance(value, str):
<                     return unicode(value, encoding)
<                 return value
<             #if maxsize == 255: # tinyblob (2**8 - 1)
<             #    return value
<             if binarywrap is None:
<                 return value
<             return binarywrap(value)
<         return DBAPIAdapter.process_value(self, value, description, encoding, binarywrap)
< 
<     def type_code_test(self, cursor):
<         print '*'*80
<         print 'module type codes'
<         for typename in ('STRING', 'BOOLEAN', 'BINARY', 'DATETIME', 'NUMBER'):
<             print typename, getattr(self, typename)
<         try:
<             cursor.execute("""CREATE TABLE _type_code_test(
<             varchar_field varchar(50),
<             text_field text unicode, 
<             mtext_field mediumtext,
<             binary_field tinyblob,
<             blob_field blob,
<             lblob_field longblob
<             )""")
<             cursor.execute("INSERT INTO _type_code_test VALUES ('1','2','3','4', '5', '6')")
<             cursor.execute("SELECT * FROM _type_code_test")
<             descr = cursor.description
<             print 'db fields type codes'
<             for i, name in enumerate(('varchar', 'text', 'mediumtext',
<                                       'binary', 'blob', 'longblob')):
<                 print name, descr[i]
<         finally:
<             cursor.execute("DROP TABLE _type_code_test")
<             
< 
< 
< ## Drivers, Adapters and helpers registries ###################################
< 
< 
< PREFERED_DRIVERS = {
<     "postgres" : [ 'psycopg2', 'psycopg', 'pgdb', 'pyPgSQL.PgSQL', ],
<     "mysql" : [ 'MySQLdb', ], # 'pyMySQL.MySQL, ],
<     "sqlite" : ['pysqlite2.dbapi2', 'sqlite', 'sqlite3',],
<     }
< 
< _ADAPTERS = {
<     'postgres' : { 'pgdb' : _PgdbAdapter,
<                    'psycopg' : _PsycopgAdapter,
<                    'psycopg2' : _Psycopg2Adapter,
<                    'pyPgSQL.PgSQL' : _PgsqlAdapter,
<                    },
<     'mysql' : { 'MySQLdb' : _MySqlDBAdapter, },
<     'sqlite' : { 'pysqlite2.dbapi2' : _PySqlite2Adapter,
<                  'sqlite' : _SqliteAdapter,
<                  'sqlite3' : _PySqlite2Adapter, },
<     }
< 
< # _AdapterDirectory could be more generic by adding a 'protocol' parameter
< # This one would become an adapter for 'DBAPI' protocol
< class _AdapterDirectory(dict):
<     """A simple dict that registers all adapters"""
<     def register_adapter(self, adapter, driver, modname):
<         """Registers 'adapter' in directory as adapting 'mod'"""
<         try:
<             driver_dict = self[driver]
<         except KeyError:
<             self[driver] = {}
<             
<         # XXX Should we have a list of adapters ?
<         driver_dict[modname] = adapter
<     
<     def adapt(self, database, prefered_drivers = None, pywrap = False):
<         """Returns an dbapi-compliant object based for database"""
<         prefered_drivers = prefered_drivers or PREFERED_DRIVERS
<         module, modname = _import_driver_module(database, prefered_drivers)
<         try:
<             return self[database][modname](module, pywrap=pywrap)
<         except KeyError:
<             raise NoAdapterFound(obj=module)        
< 
<     def get_adapter(self, database, modname):
<         try:
<             return self[database][modname]
<         except KeyError:
<             raise NoAdapterFound(None, modname)
< 
< ADAPTER_DIRECTORY = _AdapterDirectory(_ADAPTERS)
< del _AdapterDirectory
< 
< 
< ## Main functions #############################################################
<     
< def set_prefered_driver(database, module, _drivers=PREFERED_DRIVERS):
<     """sets the prefered driver module for database
<     database is the name of the db engine (postgresql, mysql...)
<     module is the name of the module providing the connect function
<     syntax is (params_func, post_process_func_or_None)
<     _drivers is a optionnal dictionnary of drivers
<     """
<     try:
<         modules = _drivers[database]
<     except KeyError:
<         raise UnknownDriver('Unknown database %s' % database)
<     # Remove module from modules list, and re-insert it in first position
<     try:
<         modules.remove(module)
<     except ValueError:
<         raise UnknownDriver('Unknown module %s for %s' % (module, database))
<     modules.insert(0, module)
<     
< def get_dbapi_compliant_module(driver, prefered_drivers = None, quiet = False,
<                                pywrap = False):
<     """returns a fully dbapi compliant module"""
<     try:
<         mod = ADAPTER_DIRECTORY.adapt(driver, prefered_drivers, pywrap=pywrap)
<     except NoAdapterFound, err:
<         if not quiet:
<             msg = 'No Adapter found for %s, returning native module'
<             print >> sys.stderr, msg % err.objname
<         mod = err.adapted_obj
<     from clonedigger.logilab.common.adbh import get_adv_func_helper
<     mod.adv_func_helper = get_adv_func_helper(driver)
<     return mod
< 
< def get_connection(driver='postgres', host='', database='', user='', 
<                   password='', port='', quiet=False, drivers=PREFERED_DRIVERS,
<                   pywrap=False):
<     """return a db connexion according to given arguments"""
<     module, modname = _import_driver_module(driver, drivers, ['connect'])
<     try:
<         adapter = ADAPTER_DIRECTORY.get_adapter(driver, modname)
<     except NoAdapterFound, err:
<         if not quiet:
<             msg = 'No Adapter found for %s, using default one' % err.objname
<             print >> sys.stderr, msg
<         adapted_module = DBAPIAdapter(module, pywrap)
<     else:
<         adapted_module = adapter(module, pywrap)
<     if host and not port:
<         try:
<             host, port = host.split(':', 1)
<         except ValueError:
<             pass
<     if port:
<         port = int(port)
<     return adapted_module.connect(host, database, user, password, port=port)
< 
< 
< from clonedigger.logilab.common.deprecation import moved
< get_adv_func_helper = moved('logilab.common.adbh', 'get_adv_func_helper')
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/debugger.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/debugger.py.svn-base
1,172d0
< """customized version of pdb's default debugger.
< 
< - sets up a history file
< - uses ipython if available to colorize lines of code
< - overrides list command to search for current block instead
<   of using 5 lines of context
< """
< 
< try:
<     import readline
< except ImportError:
<     readline = None
< import os
< import os.path as osp
< import sys
< from pdb import Pdb
< from cStringIO import StringIO
< import inspect
< 
< try:
<     from IPython import PyColorize
< except ImportError:
<     def colorize(source, *args):
<         """fallback colorize function"""
<         return source
< else:
<     def colorize(source, start_lineno, curlineno):
<         """"""
<         parser = PyColorize.Parser()
<         output = StringIO()
<         parser.format(source, output)
<         annotated = []
<         for index, line in enumerate(output.getvalue().splitlines()):
<             lineno = index + start_lineno
<             if lineno == curlineno:
<                 annotated.append('%4s\t->\t%s' % (lineno, line))
<             else:
<                 annotated.append('%4s\t\t%s' % (lineno, line))                
<         return '\n'.join(annotated)
< 
< def getsource(obj):
<     """Return the text of the source code for an object.
< 
<     The argument may be a module, class, method, function, traceback, frame,
<     or code object.  The source code is returned as a single string.  An
<     IOError is raised if the source code cannot be retrieved."""
<     lines, lnum = inspect.getsourcelines(obj)
<     return ''.join(lines), lnum
< 
< 
< ################################################################
< class Debugger(Pdb):
<     """custom debugger
<     
<     - sets up a history file
<     - uses ipython if available to colorize lines of code
<     - overrides list command to search for current block instead
<       of using 5 lines of context
<     """
<     def __init__(self, tcbk):
<         Pdb.__init__(self)
<         self.reset()
<         while tcbk.tb_next is not None:
<             tcbk = tcbk.tb_next
<         self._tcbk = tcbk
<         self._histfile = osp.join(os.environ["HOME"], ".pdbhist")
<         
<     def setup_history_file(self):
<         """if readline is available, read pdb history file
<         """
<         if readline is not None:
<             try:
<                 readline.read_history_file(self._histfile)
<             except IOError:
<                 pass
< 
<     def start(self):
<         """starts the interactive mode"""
<         self.interaction(self._tcbk.tb_frame, self._tcbk)
< 
<     def setup(self, frame, tcbk):
<         """setup hook: set up history file"""
<         self.setup_history_file()
<         Pdb.setup(self, frame, tcbk)
< 
<     def set_quit(self):
<         """quit hook: save commands in the history file"""
<         if readline is not None:
<             readline.write_history_file(self._histfile)
<         Pdb.set_quit(self)
< 
<     def complete_p(self, text, line, begin_idx, end_idx):
<         """provide variable names completion for the ``p`` command"""
<         namespace = dict(self.curframe.f_globals)
<         namespace.update(self.curframe.f_locals)
<         if '.' in text:
<             return self.attr_matches(text, namespace)
<         return [varname for varname in namespace if varname.startswith(text)]
< 
< 
<     def attr_matches(self, text, namespace):
<         """implementation coming from rlcompleter.Completer.attr_matches
<         Compute matches when text contains a dot.
< 
<         Assuming the text is of the form NAME.NAME....[NAME], and is
<         evaluatable in self.namespace, it will be evaluated and its attributes
<         (as revealed by dir()) are used as possible completions.  (For class
<         instances, class members are also considered.)
< 
<         WARNING: this can still invoke arbitrary C code, if an object
<         with a __getattr__ hook is evaluated.
< 
<         """
<         import re
<         m = re.match(r"(\w+(\.\w+)*)\.(\w*)", text)
<         if not m:
<             return
<         expr, attr = m.group(1, 3)
<         object = eval(expr, namespace)
<         words = dir(object)
<         if hasattr(object,'__class__'):
<             words.append('__class__')
<             words = words + self.get_class_members(object.__class__)
<         matches = []
<         n = len(attr)
<         for word in words:
<             if word[:n] == attr and word != "__builtins__":
<                 matches.append("%s.%s" % (expr, word))
<         return matches
<     
<     def get_class_members(self, klass):
<         """implementation coming from rlcompleter.get_class_members"""
<         ret = dir(klass)
<         if hasattr(klass,'__bases__'):
<             for base in klass.__bases__:
<                 ret = ret + self.get_class_members(base)
<         return ret
<         
<     ## specific / overidden commands 
<     def do_list(self, arg):
<         """overrides default list command to display the surrounding block
<         instead of 5 lines of context
<         """
<         self.lastcmd = 'list'
<         if not arg:
<             try:
<                 source, start_lineno = getsource(self.curframe)
<                 print colorize(''.join(source), start_lineno,
<                                self.curframe.f_lineno)
<             except KeyboardInterrupt:
<                 pass
<             except IOError:
<                 Pdb.do_list(self, arg)
<         else:
<             Pdb.do_list(self, arg)
<     do_l = do_list
< 
<     def do_open(self, arg):
<         """opens source file corresponding to the current stack level"""
<         filename = self.curframe.f_code.co_filename
<         lineno = self.curframe.f_lineno
<         cmd = 'emacsclient --no-wait +%s %s' % (lineno, filename)
<         os.system(cmd)
<         
<     do_o = do_open
< 
< 
< def pm():
<     """use our custom debugger"""
<     dbg = Debugger(sys.last_traceback)
<     dbg.start()
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/decorators.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/decorators.py.svn-base
1,124d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """this module contains some function/method decorators
< 
< :author:    Logilab
< :copyright: 2006-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< # XXX rewrite so we can use the decorator syntax when keyarg has to be specified
< 
< def cached(callableobj, keyarg=None):
<     """simple decorator to cache result of method call"""
<     #print callableobj, keyarg, callableobj.func_code.co_argcount
<     if callableobj.func_code.co_argcount == 1 or keyarg == 0:
<         
<         def cache_wrapper1(self, *args):
<             cache = '_%s_cache_' % callableobj.__name__
<             #print 'cache1?', cache
<             try:
<                 return self.__dict__[cache]
<             except KeyError:
<                 #print 'miss'
<                 value = callableobj(self, *args)
<                 setattr(self, cache, value)
<                 return value
<         return cache_wrapper1
<     
<     elif keyarg:
<         
<         def cache_wrapper2(self, *args, **kwargs):
<             cache = '_%s_cache_' % callableobj.__name__
<             key = args[keyarg-1]
<             #print 'cache2?', cache, self, key
<             try:
<                 _cache = self.__dict__[cache]
<             except KeyError:
<                 #print 'init'
<                 _cache = {}
<                 setattr(self, cache, _cache)
<             try:
<                 return _cache[key]
<             except KeyError:
<                 #print 'miss', self, cache, key
<                 _cache[key] = callableobj(self, *args, **kwargs)
<             return _cache[key]
<         return cache_wrapper2
< 
<     def cache_wrapper3(self, *args):
<         cache = '_%s_cache_' % callableobj.__name__
<         #print 'cache3?', cache, self, args
<         try:
<             _cache = self.__dict__[cache]
<         except KeyError:
<             #print 'init'
<             _cache = {}
<             setattr(self, cache, _cache)
<         try:
<             return _cache[args]
<         except KeyError:
<             #print 'miss'
<             _cache[args] = callableobj(self, *args)
<         return _cache[args]
<     return cache_wrapper3
< 
< def clear_cache(obj, funcname):
<     """function to clear a cache handled by the cached decorator"""
<     try:
<         del obj.__dict__['_%s_cache_' % funcname]
<     except KeyError:
<         pass
< 
< def copy_cache(obj, funcname, cacheobj):
<     """copy cache for <funcname> from cacheobj to obj"""
<     cache = '_%s_cache_' % funcname
<     try:
<         setattr(obj, cache, cacheobj.__dict__[cache])
<     except KeyError:
<         pass
< 
< 
< class wproperty(object):
<     """simple descriptor expecting to take a modifier function as first argument
<     and looking for a _<function name> to retrieve the attribute
<     """
<     def __init__(self, setfunc):
<         self.setfunc = setfunc
<         self.attrname = '_%s' % setfunc.__name__
<         
<     def __set__(self, obj, value):
<         self.setfunc(obj, value)
<         
<     def __get__(self, obj, cls):
<         assert obj is not None
<         return getattr(obj, self.attrname)
< 
< 
< class classproperty(object):
<     def __init__(self, get):
<         self.get = get
<     def __get__(self, inst, cls):
<         return self.get(cls)
< 
< from time import clock
< def timed(f):
<     def wrap(*args, **kwargs):
<         t = clock()
<         #for i in range(100):
<         res = f(*args, **kwargs)
<         print '%s time: %.9f' % (f.__name__, clock() - t)
<         return res
<     return wrap
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/deprecation.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/deprecation.py.svn-base
1,144d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Deprecation utilities
< 
< :author:    Logilab
< :copyright: 2006-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< import sys
< from warnings import warn
< 
< from clonedigger.logilab.common.modutils import LazyObject, load_module_from_name
< 
< 
< class deprecated(type):
<     """metaclass to print a warning on instantiation of a deprecated class"""
<     
<     def __call__(cls, *args, **kwargs):
<         msg = getattr(cls, "__deprecation_warning__",
<                       "%s is deprecated" % cls.__name__)
<         warn(msg, DeprecationWarning, stacklevel=2)
<         return type.__call__(cls, *args, **kwargs)
< 
< 
< def class_renamed(old_name, new_class, message=None):
<     """automatically creates a class which fires a DeprecationWarning
<     when instantiated.
<     
<     >>> Set = class_renamed('Set', set, 'Set is now replaced by set')
<     >>> s = Set()
<     sample.py:57: DeprecationWarning: Set is now replaced by set
<       s = Set()
<     >>>
<     """
<     clsdict = {}
<     if message is None:
<         message = '%s is deprecated' % old_name
<     clsdict['__deprecation_warning__'] = message
<     try:
<         # new-style class
<         return deprecated(old_name, (new_class,), clsdict)
<     except (NameError, TypeError):
<         # old-style class
<         class DeprecatedClass(new_class):
<             """FIXME: There might be a better way to handle old/new-style class
<             """
<             def __init__(self, *args, **kwargs):
<                 warn(message, DeprecationWarning, stacklevel=2)
<                 new_class.__init__(self, *args, **kwargs)
<         return DeprecatedClass
< 
< 
< def class_moved(new_class, old_name=None, message=None):
<     """nice wrapper around class_renamed when a class has been moved into
<     another module
<     """
<     if old_name is None:
<         old_name = new_class.__name__
<     if message is None:
<         message = 'class %s is now available as %s.%s' % (
<             old_name, new_class.__module__, new_class.__name__)
<     return class_renamed(old_name, new_class, message)
< 
< 
< def deprecated_function(new_func, message=None):
<     """creates a function which fires a DeprecationWarning when used
< 
<     For example, if <bar> is deprecated in favour of <foo> :
<     >>> bar = deprecated_function(foo, 'bar is deprecated')
<     >>> bar()
<     sample.py:57: DeprecationWarning: bar is deprecated
<       bar()
<     >>>
<     """
<     if message is None:
<         message = "this function is deprecated, use %s instead" % (
<             new_func.func_name)
<     def deprecated(*args, **kwargs):
<         warn(message, DeprecationWarning, stacklevel=2)
<         return new_func(*args, **kwargs)
<     return deprecated
< 
< 
< def moved(modpath, objname):
<     """use to tell that a callable has been moved to a new module.
< 
<     It returns a callable wrapper, so that when its called a warning is printed
<     telling where the object can be found, import is done (and not before) and
<     the actual object is called.
< 
<     NOTE: the usage is somewhat limited on classes since it will fail if the
<     wrapper is use in a class ancestors list, use the `class_moved` function
<     instead (which has no lazy import feature though).
<     """
<     def callnew(*args, **kwargs):
<         message = "object %s has been moved to module %s" % (objname, modpath)
<         warn(message, DeprecationWarning, stacklevel=2)
<         m = load_module_from_name(modpath)
<         return getattr(m, objname)(*args, **kwargs)
<     return callnew
< 
< 
< class WarnLazyObject(LazyObject):
<     def __init__(self, oldname, newname):
<         # XXX doesn't work if module isn't in a package
<         package, module = newname.rsplit('.', 1)
<         super(WarnLazyObject, self).__init__(package, module)
<         self.oldname = oldname
<         self.newname = newname
<         print 'hop', oldname, newname
<         sys.modules[oldname] = self
< 
<     def __getobj(self):
<         if self._imported is None:
<             message = "module %s has moved, it's now %s" % (
<                 self.oldname, self.newname)
<             warn(message, DeprecationWarning, stacklevel=2)
<         return super(WarnLazyObject, self).__getobj()
< 
< module_moved = WarnLazyObject
< 
< def obsolete(reason="This function is obsolete"):
<     """this function is an alternative to `deprecated_function`
<     when there's no real replacement for the deprecated function
<     """
<     def newdecorator(func):
<         def wrapped(*args, **kwargs):
<             warn(reason, DeprecationWarning, stacklevel=2)
<             return func(*args, **kwargs)
<         return wrapped
<     return newdecorator
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/fileutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/fileutils.py.svn-base
1,480d0
< # Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some file / file path manipulation utilities.
< 
< :group path manipulation: first_level_directory, relative_path, is_binary,\
< get_by_ext, remove_dead_links
< :group file manipulation: norm_read, norm_open, lines, stream_lines, lines,\
< write_open_mode, ensure_fs_mode, export
< :sort: path manipulation, file manipulation
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< import shutil
< import mimetypes
< from os.path import isabs, isdir, islink, split, exists, walk, normpath, join
< from os.path import abspath
< from os import sep, mkdir, remove, listdir, stat, chmod
< from stat import ST_MODE, S_IWRITE
< from cStringIO import StringIO
< 
< from clonedigger.logilab.common import STD_BLACKLIST as BASE_BLACKLIST, IGNORED_EXTENSIONS
< from clonedigger.logilab.common.shellutils import find
< 
< def first_level_directory(path):
<     """return the first level directory of a path
<     
<     >>> first_level_directory('home/syt/work')
<     'home'
<     >>> first_level_directory('/home/syt/work')
<     '/'
<     >>> first_level_directory('work')
<     'work'
<     >>>
< 
<     :type path: str
<     :param path: the path for which we want the first level directory
< 
<     :rtype: str
<     :return: the first level directory appearing in `path`
<     """
<     head, tail = split(path)
<     while head and tail:
<         head, tail = split(head)
<     if tail:
<         return tail
<     # path was absolute, head is the fs root
<     return head
< 
< def abspath_listdir(path):
<     """lists path's content using absolute paths
< 
<     >>> os.listdir('/home')
<     ['adim', 'alf', 'arthur', 'auc']    
<     >>> abspath_listdir('/home')
<     ['/home/adim', '/home/alf', '/home/arthur', '/home/auc']
<     """
<     path = abspath(path)
<     return [join(path, filename) for filename in listdir(path)]
< 
<     
< def is_binary(filename):
<     """return true if filename may be a binary file, according to it's
<     extension
< 
<     :type filename: str
<     :param filename: the name of the file
< 
<     :rtype: bool
<     :return:
<       true if the file is a binary file (actually if it's mime type
<       isn't begining by text/)
<     """
<     try:
<         return not mimetypes.guess_type(filename)[0].startswith('text')
<     except AttributeError:
<         return 1
< 
< 
< def write_open_mode(filename):
<     """return the write mode that should used to open file
< 
<     :type filename: str
<     :param filename: the name of the file
< 
<     :rtype: str
<     :return: the mode that should be use to open the file ('w' or 'wb') 
<     """
<     if is_binary(filename):
<         return 'wb'
<     return 'w'
< 
< 
< def ensure_fs_mode(filepath, desired_mode=S_IWRITE):
<     """check that the given file has the given mode(s) set, else try to
<     set it
< 
<     :type filepath: str
<     :param filepath: path of the file
< 
<     :type desired_mode: int
<     :param desired_mode:
<       ORed flags describing the desired mode. Use constants from the
<       `stat` module for file permission's modes
<     """
<     mode = stat(filepath)[ST_MODE]
<     if not mode & desired_mode:
<         chmod(filepath, mode | desired_mode)
<         
< 
< class ProtectedFile(file):
<     """a special file-object class that automatically that automatically
<     does a 'chmod +w' when needed
< 
<     XXX: for now, the way it is done allows 'normal file-objects' to be
<     created during the ProtectedFile object lifetime.
<     One way to circumvent this would be to chmod / unchmod on each
<     write operation.
<     
<     One other way would be to :
<     
<     - catch the IOError in the __init__
<     
<     - if IOError, then create a StringIO object
<     
<     - each write operation writes in this StringIO obejct
<     
<     - on close()/del(), write/append the StringIO content to the file and
<       do the chmod only once
<     """
<     def __init__(self, filepath, mode):
<         self.original_mode = stat(filepath)[ST_MODE]
<         self.mode_changed = False
<         if mode in ('w', 'a', 'wb', 'ab'):
<             if not self.original_mode & S_IWRITE:
<                 chmod(filepath, self.original_mode | S_IWRITE)
<                 self.mode_changed = True
<         file.__init__(self, filepath, mode)
< 
<     def _restore_mode(self):
<         """restores the original mode if needed"""
<         if self.mode_changed:
<             chmod(self.name, self.original_mode)
<             # Don't re-chmod in case of several restore
<             self.mode_changed = False
<     
<     def close(self):
<         """restore mode before closing"""
<         self._restore_mode()
<         file.close(self)
< 
<     def __del__(self):
<         if not self.closed:
<             self.close()
< 
< 
< class UnresolvableError(Exception):
<     """exception raised by relative path when it's unable to compute relative
<     path between two paths
<     """
< 
< def relative_path(from_file, to_file):
<     """try to get a relative path from from `from_file` to `to_file`
<     (path will be absolute if to_file is an absolute file). This function
<     is useful to create link in `from_file` to `to_file`. This typical use
<     case is used in this function description.
<     
<     If both files are relative, they're expected to be relative to the same
<     directory.
<     
<     >>> relative_path( from_file='toto/index.html', to_file='index.html')
<     '../index.html'
<     >>> relative_path( from_file='index.html', to_file='toto/index.html')
<     'toto/index.html'
<     >>> relative_path( from_file='tutu/index.html', to_file='toto/index.html')
<     '../toto/index.html'
<     >>> relative_path( from_file='toto/index.html', to_file='/index.html')
<     '/index.html'
<     >>> relative_path( from_file='/toto/index.html', to_file='/index.html')
<     '../index.html'
<     >>> relative_path( from_file='/toto/index.html', to_file='/toto/summary.html')
<     'summary.html'
<     >>> relative_path( from_file='index.html', to_file='index.html')
<     ''
<     >>> relative_path( from_file='/index.html', to_file='toto/index.html')
<     Traceback (most recent call last):
<       File "<string>", line 1, in ?
<       File "<stdin>", line 37, in relative_path
<     UnresolvableError
<     >>> relative_path( from_file='/index.html', to_file='/index.html')
<     ''
<     >>>
< 
<     :type from_file: str
<     :param from_file: source file (where links will be inserted)
<     
<     :type to_file: str
<     :param to_file: target file (on which links point)
< 
<     :raise UnresolvableError: if it has been unable to guess a correct path
<     
<     :rtype: str
<     :return: the relative path of `to_file` from `from_file`
<     """
<     from_file = normpath(from_file)
<     to_file = normpath(to_file)
<     if from_file == to_file:
<         return ''
<     if isabs(to_file):
<         if not isabs(from_file):
<             return to_file
<     elif isabs(from_file):
<         raise UnresolvableError()
<     from_parts = from_file.split(sep)
<     to_parts = to_file.split(sep)
<     idem = 1
<     result = []
<     while len(from_parts) > 1:
<         dirname = from_parts.pop(0)
<         if idem and len(to_parts) > 1 and dirname == to_parts[0]:
<             to_parts.pop(0)
<         else:
<             idem = 0
<             result.append('..')
<     result += to_parts
<     return sep.join(result)
< 
< 
< from clonedigger.logilab.common.textutils import _LINE_RGX
< from sys import version_info
< _HAS_UNIV_OPEN = version_info[:2] >= (2, 3)
< del version_info
< 
< def norm_read(path):
<     """return the content of the file with normalized line feeds
< 
<     :type path: str
<     :param path: path to the file to read
< 
<     :rtype: str
<     :return: the content of the file with normalized line feeds
<     """
<     if _HAS_UNIV_OPEN:
<         return open(path, 'U').read()
<     return _LINE_RGX.sub('\n', open(path).read())
< 
< 
< def norm_open(path):
<     """return a stream for a file with content with normalized line feeds
< 
<     :type path: str
<     :param path: path to the file to open
< 
<     :rtype: file or StringIO
<     :return: the opened file with normalized line feeds
<     """
<     if _HAS_UNIV_OPEN:
<         return open(path, 'U')
<     return StringIO(_LINE_RGX.sub('\n', open(path).read()))
< 
<       
< def lines(path, comments=None):
<     """return a list of non empty lines in the file located at `path`
< 
<     :type path: str
<     :param path: path to the file
< 
<     :type comments: str or None
<     :param comments:
<       optional string which can be used to comment a line in the file
<       (ie lines starting with this string won't be returned)
< 
<     :rtype: list
<     :return:
<       a list of stripped line in the file, without empty and commented
<       lines
< 
<     :warning: at some point this function will probably return an iterator
<     """
<     stream = norm_open(path)
<     result = stream_lines(stream, comments)
<     stream.close()
<     return result
< 
< 
< def stream_lines(stream, comments=None):
<     """return a list of non empty lines in the given `stream`
< 
<     :type stream: object implementing 'xreadlines' or 'readlines'
<     :param stream: file like object
< 
<     :type comments: str or None
<     :param comments:
<       optional string which can be used to comment a line in the file
<       (ie lines starting with this string won't be returned)
< 
<     :rtype: list
<     :return:
<       a list of stripped line in the file, without empty and commented
<       lines
< 
<     :warning: at some point this function will probably return an iterator
<     """
<     try:
<         readlines = stream.xreadlines
<     except AttributeError:
<         readlines = stream.readlines
<     result = []
<     for line in readlines():
<         line = line.strip()
<         if line and (comments is None or not line.startswith(comments)):
<             result.append(line)
<     return result
< 
< 
< def export(from_dir, to_dir,
<            blacklist=BASE_BLACKLIST, ignore_ext=IGNORED_EXTENSIONS,
<            verbose=0):
<     """make a mirror of `from_dir` in `to_dir`, omitting directories and
<     files listed in the black list or ending with one of the given
<     extensions
< 
<     :type from_dir: str
<     :param from_dir: directory to export
<     
<     :type to_dir: str
<     :param to_dir: destination directory
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       list of files or directories to ignore, default to the content of
<       `BASE_BLACKLIST`
< 
<     :type ignore_ext: list or tuple
<     :param ignore_ext:
<       list of extensions to ignore, default to  the content of
<       `IGNORED_EXTENSIONS`
< 
<     :type verbose: bool
<     :param verbose:
<       flag indicating wether information about exported files should be
<       printed to stderr, default to False
<     """
<     def make_mirror(_, directory, fnames):
<         """walk handler"""
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         for filename in fnames:
<             # don't include binary files
<             for ext in ignore_ext:
<                 if filename.endswith(ext):
<                     break
<             else:
<                 src = join(directory, filename)
<                 dest = to_dir + src[len(from_dir):]
<                 if verbose:
<                     print >> sys.stderr, src, '->', dest
<                 if isdir(src):
<                     if not exists(dest):
<                         mkdir(dest)
<                 else:
<                     if exists(dest):
<                         remove(dest)
<                     shutil.copy2(src, dest)
<     try:
<         mkdir(to_dir)
<     except OSError:
<         pass
<     walk(from_dir, make_mirror, None)
< 
< 
< def remove_dead_links(directory, verbose=0):
<     """recursivly traverse directory and remove all dead links
< 
<     :type directory: str
<     :param directory: directory to cleanup
< 
<     :type verbose: bool
<     :param verbose:
<       flag indicating wether information about deleted links should be
<       printed to stderr, default to False
<     """
<     def _remove_dead_link(_, directory, fnames):
<         """walk handler"""
<         for filename in fnames:
<             src = join(directory, filename)
<             if islink(src) and not exists(src):
<                 if verbose:
<                     print 'remove dead link', src
<                 remove(src)
<     walk(directory, _remove_dead_link, None)
< 
< 
< from warnings import warn
< 
< def files_by_ext(directory, include_exts=None, exclude_exts=None,
<                  exclude_dirs=BASE_BLACKLIST):
<     """return a list of files in a directory matching (or not) some
<     extensions: you should either give the `include_exts` argument (and
<     only files ending with one of the listed extensions will be
<     considered) or the `exclude_exts` argument (and only files not
<     ending by one of the listed extensions will be considered).
<     Subdirectories are processed recursivly.
< 
<     :type directory: str
<     :param directory: directory where files should be searched
< 
<     :type include_exts: list or tuple or None
<     :param include_exts: list of file extensions to consider
<     
<     :type exclude_exts: list or tuple or None
<     :param exclude_exts: list of file extensions to ignore
< 
<     :type exclude_dirs: list or tuple or None
<     :param exclude_dirs: list of directory where we should not recurse
< 
<     :rtype: list
<     :return: the list of files matching input criteria
<     """
<     assert not (include_exts and exclude_exts)
<     warn("files_by_ext is deprecated, use shellutils.find instead" ,
<          DeprecationWarning, stacklevel=2)
<     if include_exts:
<         return find(directory, include_exts, blacklist=exclude_dirs)
<     return find(directory, exclude_exts, exclude=True, blacklist=exclude_dirs)
< 
< def include_files_by_ext(directory, include_exts, exclude_dirs=BASE_BLACKLIST):
<     """return a list of files in a directory matching some extensions
< 
<     :type directory: str
<     :param directory: directory where files should be searched
< 
<     :type include_exts: list or tuple or None
<     :param include_exts: list of file extensions to consider
< 
<     :type exclude_dirs: list or tuple or None
<     :param exclude_dirs: list of directory where we should not recurse
< 
<     :rtype: list
<     :return: the list of files matching input criterias
<     """
<     warn("include_files_by_ext is deprecated, use shellutils.find instead" ,
<          DeprecationWarning, stacklevel=2)
<     return find(directory, include_exts, blacklist=exclude_dirs)
< 
< def exclude_files_by_ext(directory, exclude_exts, exclude_dirs=BASE_BLACKLIST):
<     """return a list of files in a directory not matching some extensions
< 
<     :type directory: str
<     :param directory: directory where files should be searched
< 
<     :type exclude_exts: list or tuple or None
<     :param exclude_exts: list of file extensions to ignore
< 
<     :type exclude_dirs: list or tuple or None
<     :param exclude_dirs: list of directory where we should not recurse
< 
<     :rtype: list
<     :return: the list of files matching input criterias
<     """
<     warn("exclude_files_by_ext is deprecated, use shellutils.find instead" ,
<          DeprecationWarning, stacklevel=2)
<     return find(directory, exclude_exts, exclude=True, blacklist=exclude_dirs)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/graph.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/graph.py.svn-base
1,165d0
< """some various graph manipuliation utilities
< 
< (dot generation adapted from pypy/translator/tool/make_dot.py)
< 
< :organization: Logilab
< :copyright: 2003-2007 LOGILAB S.A. (Paris, FRANCE), all rights reserved.
< :contact: http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< __docformat__ = "restructuredtext en"
< __metaclass__ = type
< 
< import os.path as osp
< import os
< 
< def escape(value):
<     """make <value> usable in a dot file"""
<     lines = [line.replace('"', '\\"') for line in value.split('\n')]
<     data = '\\l'.join(lines)
<     return '\\n' + data
< 
< def target_info_from_filename(filename):
<     """transforms /some/path/foo.png into ('/some/path', 'foo.png', 'png')"""
<     abspath = osp.abspath(filename)
<     basename = osp.basename(filename)
<     storedir = osp.dirname(abspath)
<     target = filename.split('.')[-1]
<     return storedir, basename, target
< 
< 
< class DotBackend:
<     """Dot File backend"""
<     def __init__(self, graphname, rankdir=None, size=None, ratio=None, charset='utf-8'):
<         self.graphname = graphname
<         self.lines = []
<         self._source = None
<         self.emit("digraph %s {" % normalize_node_id(graphname))
<         if rankdir:
<             self.emit('rankdir=%s' % rankdir)
<         if ratio:
<             self.emit('ratio=%s' % ratio)
<         if size:
<             self.emit('size="%s"' % size)
<         if charset:
<             assert charset.lower() in ('utf-8', 'iso-8859-1', 'latin1'), \
<                    'unsupported charset %s' % charset
<             self.emit('charset="%s"' % charset)
< 
<     def get_source(self):
<         """returns self._source"""
<         if self._source is None:
<             self.emit("}")
<             self._source = '\n'.join(self.lines)
<             del self.lines
<         return self._source
< 
<     source = property(get_source)
<     
<     def generate(self, outputfile=None, dotfile=None):
<         """generates a graph file
<         :param target: output format ('png', 'ps', etc.). If None,
<                        the raw dot source will be returned
<         :return: a path to the generated file
<         """
<         if outputfile is not None:
<             storedir, basename, target = target_info_from_filename(outputfile)
<         else:
<             storedir = '/tmp'
<             basename = '%s.png' % (self.graphname)
<             target = 'png'
<             outputfile = osp.join(storedir, basename)
<         dotfile = dotfile or ('%s.dot' % self.graphname)
<         dot_sourcepath = osp.join(storedir, dotfile)
<         pdot = file(dot_sourcepath, 'w')
<         if isinstance(self.source, unicode):
<             pdot.write(self.source.encode('UTF8'))
<         else:
<             pdot.write(self.source)
<         pdot.close()
<         if target != 'dot':
<             os.system('dot -T%s %s -o%s' % (target, dot_sourcepath, outputfile))
<             os.unlink(dot_sourcepath)
<         return outputfile
< 
<     def emit(self, line):
<         """adds <line> to final output"""
<         self.lines.append(line)
< 
<     def emit_edge(self, name1, name2, **props):
<         """emits edge from <name1> to <name2>
<         
<         authorized props: see http://www.graphviz.org/doc/info/attrs.html
<         """
<         attrs = ['%s="%s"' % (prop, value) for prop, value in props.items()]
<         self.emit('edge [%s];' % ", ".join(attrs))
<         self.emit('%s -> %s' % (normalize_node_id(name1), normalize_node_id(name2)))
< 
<     def emit_node(self, name, **props):
<         """authorized props: see http://www.graphviz.org/doc/info/attrs.html
<         """
<         attrs = ['%s="%s"' % (prop, value) for prop, value in props.items()]
<         self.emit('%s [%s];' % (normalize_node_id(name), ", ".join(attrs)))
< 
< def normalize_node_id(nid):
<     """returns a suitable DOT node id for `nid`"""
<     return '"%s"' % nid
< 
< class GraphGenerator:
<     def __init__(self, backend):
<         # the backend is responsible to output the graph is a particular format
<         self.backend = backend
< 
<     def generate(self, visitor, propshdlr, outputfile=None):
<         # the visitor 
<         # the properties handler is used to get nodes and edges properties
<         # according to the graph and to the backend
<         self.propshdlr = propshdlr
<         for nodeid, node in visitor.nodes():
<             props = propshdlr.node_properties(node)
<             self.backend.emit_node(nodeid, **props)
<         for subjnode, objnode, edge in visitor.edges():
<             props = propshdlr.edge_properties(edge, subjnode, objnode)
<             self.backend.emit_edge(subjnode, objnode, **props)
<         return self.backend.generate(outputfile)
< 
< 
< 
< def get_cycles(graph_dict, vertices=None):
<     '''given a dictionnary representing an ordered graph (i.e. key are vertices
<     and values is a list of destination vertices representing edges), return a
<     list of detected cycles
<     '''
<     if not graph_dict:
<         return ()
<     result = []
<     if vertices is None:
<         vertices = graph_dict.keys()
<     for vertice in vertices:
<         _get_cycles(graph_dict, vertice, [], result)
<     return result
< 
< def _get_cycles(graph_dict, vertice=None, path=None, result=None):
<     """recursive function doing the real work for get_cycles"""
<     if vertice in path:
<         cycle = [vertice]
<         for i in range(len(path)-1, 0, -1):
<             node = path[i]
<             if node == vertice:
<                 break
<             cycle.insert(0, node)
<         # make a canonical representation
<         start_from = min(cycle)
<         index = cycle.index(start_from)
<         cycle = cycle[index:] + cycle[0:index]
<         # append it to result if not already in
<         if not cycle in result:
<             result.append(cycle)
<         return
<     path.append(vertice)
<     try:
<         for node in graph_dict[vertice]:
<             _get_cycles(graph_dict, node, path, result)
<     except KeyError:
<         pass
<     path.pop()
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/html.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/html.py.svn-base
1,52d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2006 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< from warnings import warn
< warn('html module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=2)
< 
< __revision__ = "$Id: html.py,v 1.5 2003-09-12 11:54:47 syt Exp $"
< 
< import traceback
< from xml.sax.saxutils import escape  
< 
< # mk html traceback error #####################################################
< 
< def html_traceback(info, exception,
<                    title='', encoding='ISO-8859-1', body=''):
<     """ return an html formatted traceback from python exception infos.
<     """
<     #typ, value, tbck = info
<     stacktb = traceback.extract_tb(info[2]) #tbck)
<     strings = []
<     if body:
<         strings.append('<div class="error_body">')
<         strings.append(body)
<         strings.append('</div>')
<     if title:
<         strings.append('<h1 class="error">%s</h1>'% escape(title))
<     strings.append('<p class="error">%s</p>' % escape(str(exception)))
<     strings.append('<div class="error_traceback">')
<     for stackentry in stacktb :
<         strings.append('<b>File</b> <b class="file">%s</b>, <b>line</b> '
<                       '<b class="line">%s</b>, <b>function</b> '
<                       '<b class="function">%s</b>:<br/>'%(
<             escape(stackentry[0]), stackentry[1], stackentry[2]))
<         if stackentry[3]:
<             string = escape(repr(stackentry[3])[1:-1])#.encode(encoding)
<             strings.append('&nbsp;&nbsp;%s<br/>\n' % string)
<     strings.append('</div>')
<     return '\n'.join(strings)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/__init__.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/__init__.py.svn-base
1,165d0
< # Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Logilab common libraries:
< 
< a set of common functionnalities shared among logilab projects
< 
< 
< :type STD_BLACKLIST: tuple
< :var STD_BLACKLIST:
<   directories ignored by default by the functions in this package which have
<   to recurse into directories
< 
< :type IGNORED_EXTENSIONS: tuple
< :var IGNORED_EXTENSIONS:
<   file extensions that may usually be ignored
< """
< 
< STD_BLACKLIST = ('CVS', '.svn', '.hg', 'debian', 'dist', 'build')
< 
< IGNORED_EXTENSIONS = ('.pyc', '.pyo', '.elc', '~')
< 
< 
< 
< from clonedigger.logilab.common.deprecation import moved
< 
< get_cycles = moved('logilab.common.graph', 'get_cycles')
< cached = moved('logilab.common.decorators', 'cached')
< ProgressBar = moved('logilab.common.shellutils', 'ProgressBar')
< Execute = moved('logilab.common.shellutils', 'Execute')
< acquire_lock = moved('logilab.common.shellutils', 'acquire_lock')
< release_lock = moved('logilab.common.shellutils', 'release_lock')
< deprecated_function = moved('logilab.common.deprecation', 'deprecated_function')
< class_renamed = moved('logilab.common.deprecation', 'class_renamed')
< 
< def intersection(list1, list2):
<     """return the intersection of list1 and list2"""
<     warn('this function is deprecated, use a set instead', DeprecationWarning,
<          stacklevel=2)
<     intersect_dict, result = {}, []
<     for item in list1:
<         intersect_dict[item] = 1
<     for item in list2:
<         if intersect_dict.has_key(item):
<             result.append(item)
<     return result
< 
< def difference(list1, list2):
<     """return elements of list1 not in list2"""
<     warn('this function is deprecated, use a set instead', DeprecationWarning,
<          stacklevel=2)
<     tmp, result = {}, []
<     for i in list2:
<         tmp[i] = 1
<     for i in list1:
<         if not tmp.has_key(i):
<             result.append(i)
<     return result
< 
< def union(list1, list2):
<     """return list1 union list2"""
<     warn('this function is deprecated, use a set instead', DeprecationWarning,
<          stacklevel=2)
<     tmp = {}
<     for i in list1:
<         tmp[i] = 1
<     for i in list2:
<         tmp[i] = 1
<     return tmp.keys()
< 
< 
< class attrdict(dict):
<     """a dictionary whose keys are also accessible as attributes"""
<     def __getattr__(self, attr):
<         try:
<             return self[attr]
<         except KeyError:
<             raise AttributeError(attr)
<         
< class nullobject(object):
<     def __nonzero__(self):
<         return False
< 
< # flatten -----
< # XXX move in a specific module and use yield instead
< # do not mix flatten and translate
< #
< # def iterable(obj):
< #    try: iter(obj)
< #    except: return False
< #    return True
< #
< # def is_string_like(obj):
< #    try: obj +''
< #    except (TypeError, ValueError): return False
< #    return True
< #
< #def is_scalar(obj):
< #    return is_string_like(obj) or not iterable(obj)
< #
< #def flatten(seq):
< #    for item in seq:
< #        if is_scalar(item): 
< #            yield item
< #        else:
< #            for subitem in flatten(item):
< #               yield subitem
< 
< def flatten(iterable, tr_func=None, results=None):
<     """flatten a list of list with any level
< 
<     if tr_func is not None, it should be a one argument function that'll be called
<     on each final element
<     """
<     if results is None:
<         results = []
<     for val in iterable:
<         if isinstance(val, (list, tuple)):
<             flatten(val, tr_func, results)
<         elif tr_func is None:
<             results.append(val)
<         else:
<             results.append(tr_func(val))
<     return results
< 
< 
< # XXX is function below still used ?
< 
< def make_domains(lists):
<     """
<     given a list of lists, return a list of domain for each list to produce all
<     combinaisons of possibles values
< 
<     ex: (['a', 'b'], ['c','d', 'e'])
<        -> (['a', 'b', 'a', 'b', 'a', 'b'],
<            ['c', 'c', 'd', 'd', 'e', 'e'])
<     """
<     domains = []
<     for iterable in lists:
<         new_domain = iterable[:]
<         for i in range(len(domains)):
<             domains[i] = domains[i]*len(iterable)
<         if domains:
<             missing = (len(domains[0]) - len(iterable)) / len(iterable)
<             i = 0
<             for j in range(len(iterable)):
<                 value = iterable[j]
<                 for dummy in range(missing):
<                     new_domain.insert(i, value)
<                     i += 1
<                 i += 1
<         domains.append(new_domain)
<     return domains
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/interface.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/interface.py.svn-base
1,70d0
< # Copyright (c) 2002-2007 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
<  bases class for interfaces to provide "light" interface handling.
< 
<  TODO:
<   _ implements a check method which check that an object implements the
<     interface
<   _ Attribute objects
< 
<   This module requires at least python 2.2
< """
< 
< from types import ListType, TupleType
< 
< class Interface:
<     """base class for interfaces"""
<     def is_implemented_by(cls, instance):
<         return implements(instance, cls)
<     is_implemented_by = classmethod(is_implemented_by)
< 
<     
< def implements(obj, interface):
<     """return true if the give object (maybe an instance or class) implements
<     the interface
<     """
<     kimplements = getattr(obj, '__implements__', ())
<     if not isinstance(kimplements, (list, tuple)):
<         kimplements = (kimplements,)
<     for implementedinterface in kimplements:
<         if issubclass(implementedinterface, interface):
<             return True
<     return False
< 
< 
< def extend(klass, interface, _recurs=False):
<     """add interface to klass'__implements__ if not already implemented in.
< 
<     if klass is subclassed, ensure subclasses __implements__ it as well.
<     
<     NOTE: klass should be e new class.
<     """
<     if not implements(klass, interface):
<         try:
<             kimplements = klass.__implements__
<             kimplementsklass = type(kimplements)
<             kimplements = list(kimplements)
<         except AttributeError:
<             kimplementsklass = tuple
<             kimplements = []
<         kimplements.append(interface)
<         klass.__implements__ = kimplementsklass(kimplements)
<         for subklass in klass.__subclasses__():
<             extend(subklass, interface, _recurs=True)
<     elif _recurs:
<         for subklass in klass.__subclasses__():
<             extend(subklass, interface, _recurs=True)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/logger.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/logger.py.svn-base
1,161d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< Define a logger interface and two concrete loggers : one which prints
< everything on stdout, the other using syslog.
< """
< 
< from warnings import warn
< warn('logger module is deprecated and will disappear in a future release. \
< use logging module instead.',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = "$Id: logger.py,v 1.18 2006-02-03 14:17:42 adim Exp $"
< 
< 
< import sys
< import traceback
< import time
< 
< 
< LOG_EMERG   = 0
< LOG_ALERT   = 1
< LOG_CRIT    = 2
< LOG_ERR     = 3
< LOG_WARN    = 4
< LOG_NOTICE  = 5
< LOG_INFO    = 6
< LOG_DEBUG   = 7
< 
< INDICATORS = ['emergency', 'alert', 'critical', 'error',
<               'warning', 'notice', 'info', 'debug']
< 
< 
< def make_logger(method='print', threshold=LOG_DEBUG, sid=None, output=None):
<     """return a logger for the given method
<     
<     known methods are 'print', 'eprint' and syslog'
<     """
<     if method == 'print':
<         if output is None:
<             output = sys.stdout
<         return PrintLogger(threshold, output, sid=sid)
<     elif method == 'eprint':
<         return PrintLogger(threshold, sys.stderr, sid=sid)
<     elif method == 'syslog':
<         return SysLogger(threshold, sid)
<     elif method == 'file':
<         if not output:
<             raise ValueError('No logfile specified')
<         else:
<             logfile = open(output, 'a')
<             return PrintLogger(threshold, logfile, sid=sid)
<     else:
<         raise ValueError('Unknown logger method: %r' % method)
< 
< 
< class AbstractLogger:
<     """logger interface.
<     Priorities allow to filter on the importance of events
<     An event gets logged if it's priority is lower than the threshold"""
< 
<     def __init__(self, threshold=LOG_DEBUG, priority_indicator=1):
<         self.threshold = threshold
<         self.priority_indicator = priority_indicator
<         
<     def log(self, priority=LOG_DEBUG, message='', substs=None):
<         """log a message with priority <priority>
<         substs are optional substrings
<         """
<         #print 'LOG', self, priority, self.threshold, message
<         if priority <= self.threshold :
<             if substs is not None:
<                 message = message % substs
<             if self.priority_indicator:
<                 message = '[%s] %s' % (INDICATORS[priority], message)
<             self._writelog(priority, message)
< 
<     def _writelog(self, priority, message):
<         """Override this method in concrete class """
<         raise NotImplementedError()
< 
<     def log_traceback(self, priority=LOG_ERR, tb_info=None):
<         """log traceback information with priority <priority>
<         """
<         assert tb_info is not None
<         e_type, value, tbck = tb_info
<         stacktb = traceback.extract_tb(tbck)
<         l = ['Traceback (most recent call last):']
<         for stackentry in stacktb :
<             if stackentry[3]:
<                 plus = '\n    %s' % stackentry[3]
<             else:
<                 plus = ''
<             l.append('filename="%s" line_number="%s" function_name="%s"%s' %
<                      (stackentry[0], stackentry[1], stackentry[2], plus))
<         try:
<             l.append(str(e_type) + ': ' + value.__str__())
<         except UnicodeError:
<             l.append(str(e_type) + ' (message can\'t be displayed)')
<             
<         self.log(priority, '\n'.join(l))
< 
< 
< class PrintLogger(AbstractLogger):
<     """logger implementation
< 
<     log everything to a file, using the standard output by default
<     """
<     
<     def __init__(self, threshold, output=sys.stdout, sid=None,
<                  encoding='UTF-8'):
<         AbstractLogger.__init__(self, threshold)
<         self.output = output
<         self.sid = sid
<         self.encoding = encoding
<         
<     def _writelog(self, priority, message):
<         """overridden from AbstractLogger"""
<         if isinstance(message, unicode):
<             message = message.encode(self.encoding, 'replace')
<         if self.sid is not None:
<             self.output.write('[%s] [%s] %s\n' % (time.asctime(), self.sid,
<                                                   message))
<         else:
<             self.output.write('[%s] %s\n' % (time.asctime(), message))
<         self.output.flush()
< 
< class SysLogger(AbstractLogger):
<     """ logger implementation
< 
<     log everything to syslog daemon
<     use the LOCAL_7 facility
<     """
< 
<     def __init__(self, threshold, sid=None, encoding='UTF-8'):
<         import syslog
<         AbstractLogger.__init__(self, threshold)
<         if sid is None:
<             sid = 'syslog'
<         self.encoding = encoding
<         syslog.openlog(sid, syslog.LOG_PID)
<         
<     def _writelog(self, priority, message):
<         """overridden from AbstractLogger"""
<         import syslog
<         if isinstance(message, unicode):
<             message = message.encode(self.encoding, 'replace')
<         syslog.syslog(priority | syslog.LOG_LOCAL7, message)
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/logging_ext.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/logging_ext.py.svn-base
1,83d0
< # -*- coding: iso-8859-1 -*-
< # Copyright (c) 2007 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2007 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< This module provides extensions to the logging module from the standard library.
< """
< 
< import logging
< 
< from clonedigger.logilab.common.textutils import colorize_ansi
< 
< def xxx_cyan(record):
<     if 'XXX' in record.message:
<         return 'cyan'
< 
< class ColorFormatter(logging.Formatter):
<     """
<     A color Formatter for the logging standard module.
< 
<     By default, colorize CRITICAL and ERROR in red, WARNING in orange
<     and INFO in yellow.
< 
<     self.colors is customizable via the 'color' constructor argument (dictionnary).
< 
<     self.colorfilters is a list of functions that get the LogRecord
<     and return a color name or None.
<     """
< 
<     def __init__(self, fmt=None, datefmt=None, colors=None):
<         logging.Formatter.__init__(self, fmt, datefmt)
<         self.colorfilters = []
<         self.colors = {'CRITICAL': 'red',
<                        'ERROR': 'red',
<                        'WARNING': 'magenta',
<                        'INFO': 'yellow',
<                        }
<         if colors is not None:
<             assert isinstance(colors, dict)
<             self.colors.update(colors)            
<                                
<     def format(self, record):
<         msg = logging.Formatter.format(self, record)
<         if record.levelname in self.colors:
<             color = self.colors[record.levelname]
<             return colorize_ansi(msg, color)
<         else:
<             for cf in self.colorfilters:
<                 color = cf(record)
<                 if color: 
<                     return colorize_ansi(msg, color)
<         return msg
< 
< def set_color_formatter(logger=None, **kw):
<     """
<     Install a color formatter on the 'logger'. If not given, it will
<     defaults to the default logger.
< 
<     Any additional keyword will be passed as-is to the ColorFormatter
<     constructor.
<     """
<     if logger is None:
<         logger = logging.getLogger()
<         if not logger.handlers:
<             logging.basicConfig()
<     format_msg = logger.handlers[0].formatter._fmt
<     fmt = ColorFormatter(format_msg, **kw)
<     fmt.colorfilters.append(xxx_cyan)
<     logger.handlers[0].setFormatter(fmt)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/logservice.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/logservice.py.svn-base
1,35d0
< """log utilities
< 
< Copyright (c) 2003-2004 LOGILAB S.A. (Paris, FRANCE), all rights reserved.
< http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< from warnings import warn
< warn('logservice module is deprecated and will disappear in a near release. \
< use logging module instead.',
<      DeprecationWarning, stacklevel=2)
< 
< __revision__ = "$Id: logservice.py,v 1.5 2006-03-05 16:13:28 syt Exp $"
< 
< from clonedigger.logilab.common.logger import make_logger, LOG_ERR, LOG_WARN, LOG_NOTICE, \
<      LOG_INFO, LOG_CRIT, LOG_DEBUG
< 
< def init_log(treshold, method='eprint', sid='common-log-service',
<              logger=None, output=None):
<     """init the logging system and and log methods to builtins"""
<     if logger is None:
<         logger = make_logger(method, treshold, sid, output=output)
<     # add log functions and constants to builtins
<     __builtins__.update({'log': logger.log,
<                          'log_traceback' : logger.log_traceback,
<                          'LOG_CRIT':   LOG_CRIT,
<                          'LOG_ERR':    LOG_ERR,
<                          'LOG_WARN':   LOG_WARN,
<                          'LOG_NOTICE': LOG_NOTICE,
<                          'LOG_INFO' :  LOG_INFO,
<                          'LOG_DEBUG':  LOG_DEBUG,
<                          })
< 
< init_log(LOG_ERR)
< 
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/modutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/modutils.py.svn-base
1,596d0
< # -*- coding: iso-8859-1 -*-
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Python modules manipulation utility functions.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< 
< 
< 
< :type PY_SOURCE_EXTS: tuple(str)
< :var PY_SOURCE_EXTS: list of possible python source file extension
< 
< :type STD_LIB_DIR: str
< :var STD_LIB_DIR: directory where standard modules are located
< 
< :type BUILTIN_MODULES: dict
< :var BUILTIN_MODULES: dictionary with builtin module names has key
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import sys
< import os
< from os.path import walk, splitext, join, abspath, isdir, dirname, exists
< from imp import find_module, load_module, C_BUILTIN, PY_COMPILED, PKG_DIRECTORY
< 
< from clonedigger.logilab.common import STD_BLACKLIST
< 
< if sys.platform.startswith('win'):
<     PY_SOURCE_EXTS = ('py', 'pyw')
<     PY_COMPILED_EXTS = ('dll', 'pyd')
<     STD_LIB_DIR = join(sys.prefix, 'lib')
< else:
<     PY_SOURCE_EXTS = ('py',)
<     PY_COMPILED_EXTS = ('so',)
<     STD_LIB_DIR = join(sys.prefix, 'lib', 'python%s' % sys.version[:3])
<     
< BUILTIN_MODULES = dict(zip(sys.builtin_module_names,
<                            [1]*len(sys.builtin_module_names)))
< 
< 
< class NoSourceFile(Exception):
<     """exception raised when we are not able to get a python
<     source file for a precompiled file
<     """
< 
< class LazyObject(object):
<     def __init__(self, module, obj):
<         self.module = module
<         self.obj = obj
<         self._imported = None
<         
<     def __getobj(self):
<         if self._imported is None:
<            self._imported = getattr(load_module_from_name(self.module),
<                                     self.obj)
<         return self._imported
<     
<     def __getattribute__(self, attr):
<         try:
<             return super(LazyObject, self).__getattribute__(attr)
<         except AttributeError, ex:
<             return getattr(self.__getobj(), attr)
<         
<     def __call__(self, *args, **kwargs):
<         return self.__getobj()(*args, **kwargs)
< 
< 
< def load_module_from_name(dotted_name, path=None, use_sys=1):
<     """load a Python module from it's name
< 
<     :type dotted_name: str
<     :param dotted_name: python name of a module or package
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type use_sys: bool
<     :param use_sys:
<       boolean indicating whether the sys.modules dictionary should be
<       used or not
< 
< 
<     :raise ImportError: if the module or package is not found
<     
<     :rtype: module
<     :return: the loaded module
<     """
<     return load_module_from_modpath(dotted_name.split('.'), path, use_sys)
< 
< 
< def load_module_from_modpath(parts, path=None, use_sys=1):
<     """load a python module from it's splitted name
< 
<     :type parts: list(str) or tuple(str)
<     :param parts:
<       python name of a module or package splitted on '.'
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type use_sys: bool
<     :param use_sys:
<       boolean indicating whether the sys.modules dictionary should be used or not
< 
<     :param _prefix: used internally, should not be specified
< 
< 
<     :raise ImportError: if the module or package is not found
<     
<     :rtype: module
<     :return: the loaded module
<     """
<     if use_sys:
<         try:
<             return sys.modules['.'.join(parts)]
<         except KeyError:
<             pass
<     modpath = []
<     prevmodule = None
<     for part in parts:
<         modpath.append(part)
<         curname = ".".join(modpath)
<         module = None
<         if len(modpath) != len(parts):
<             # even with use_sys=False, should try to get outer packages from sys.modules
<             module = sys.modules.get(curname)
<         if module is None:
<             mp_file, mp_filename, mp_desc = find_module(part, path)
<             module = load_module(curname, mp_file, mp_filename, mp_desc)
<         if prevmodule:
<             setattr(prevmodule, part, module)
<         _file = getattr(module, "__file__", "")
<         if not _file and len(modpath) != len(parts):
<             raise ImportError("no module in %s" % ".".join(parts[len(modpath):]) )
<         path = [dirname( _file )]
<         prevmodule = module
<     return module
< 
< 
< def load_module_from_file(filepath, path=None, use_sys=1):
<     """load a Python module from it's path
< 
<     :type filepath: str
<     :param dotted_name: path to the python module or package
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type use_sys: bool
<     :param use_sys:
<       boolean indicating whether the sys.modules dictionary should be
<       used or not
< 
< 
<     :raise ImportError: if the module or package is not found
<     
<     :rtype: module
<     :return: the loaded module
<     """
<     return load_module_from_modpath(modpath_from_file(filepath), path, use_sys)
< 
< 
< def modpath_from_file(filename):
<     """given a file path return the corresponding splitted module's name
<     (i.e name of a module or package splitted on '.')
< 
<     :type filename: str
<     :param filename: file's path for which we want the module's name
< 
< 
<     :raise ImportError:
<       if the corresponding module's name has not been found
< 
<     :rtype: list(str)
<     :return: the corresponding splitted module's name
<     """
<     base = splitext(abspath(filename))[0]
<     for path in sys.path:
<         path = abspath(path)
<         if path and base[:len(path)] == path:
<             if filename.find('site-packages') != -1 and \
<                    path.find('site-packages') == -1:
<                 continue
<             mod_path = [module for module in base[len(path):].split(os.sep)
<                         if module]
<             for part in mod_path[:-1]:
<                 path = join(path, part)
<                 if not _has_init(path):
<                     break
<             else:
<                 break
<     else:
<         raise ImportError('Unable to find module for %s in %s' % (
<             filename, ', \n'.join(sys.path)))
<     return mod_path
< 
< 
< 
< def file_from_modpath(modpath, path=None, context_file=None):
<     """given a mod path (ie splited module / package name), return the
<     corresponding file, giving priority to source file over precompiled
<     file if it exists
< 
<     :type modpath: list or tuple
<     :param modpath:
<       splitted module's name (i.e name of a module or package splitted
<       on '.')
<       (this means explicit relative imports that start with dots have
<       empty strings in this list!)
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<     :type context_file: str or None
<     :param context_file:
<       context file to consider, necessary if the identifier has been
<       introduced using a relative import unresolvable in the actual
<       context (i.e. modutils)
<       
<     :raise ImportError: if there is no such module in the directory
< 
<     :rtype: str or None
<     :return:
<       the path to the module's file or None if it's an integrated
<       builtin module such as 'sys'
<     """
<     if context_file is not None:
<         context = dirname(context_file)
<     else:
<         context = context_file
<     if modpath[0] == 'xml':
<         # handle _xmlplus
<         try:
<             return _file_from_modpath(['_xmlplus'] + modpath[1:], path, context)
<         except ImportError:
<             return _file_from_modpath(modpath, path, context)
<     elif modpath == ['os', 'path']:
<         # FIXME: currently ignoring search_path...
<         return os.path.__file__
<     return _file_from_modpath(modpath, path, context)
< 
< 
<     
< def get_module_part(dotted_name, context_file=None):
<     """given a dotted name return the module part of the name :
<     
<     >>> get_module_part('logilab.common.modutils.get_module_part')
<     'logilab.common.modutils'
< 
<     
<     :type dotted_name: str
<     :param dotted_name: full name of the identifier we are interested in
< 
<     :type context_file: str or None
<     :param context_file:
<       context file to consider, necessary if the identifier has been
<       introduced using a relative import unresolvable in the actual
<       context (i.e. modutils)
< 
<     
<     :raise ImportError: if there is no such module in the directory
<     
<     :rtype: str or None
<     :return:
<       the module part of the name or None if we have not been able at
<       all to import the given name
< 
<     XXX: deprecated, since it doesn't handle package precedence over module
<     (see #10066)
<     """
<     # os.path trick
<     if dotted_name.startswith('os.path'):
<         return 'os.path'
<     parts = dotted_name.split('.')
<     if context_file is not None:
<         # first check for builtin module which won't be considered latter
<         # in that case (path != None)
<         if parts[0] in BUILTIN_MODULES:
<             if len(parts) > 2:
<                 raise ImportError(dotted_name)
<             return parts[0]
<         # don't use += or insert, we want a new list to be created !
<     path = None
<     starti = 0
<     if parts[0] == '':
<         assert context_file is not None, \
<                 'explicit relative import, but no context_file?'
<         path = [] # prevent resolving the import non-relatively
<         starti = 1
<     while parts[starti] == '': # for all further dots: change context
<         starti += 1
<         context_file = dirname(context_file)
<     for i in range(starti, len(parts)):
<         try:
<             file_from_modpath(parts[starti:i+1],
<                     path=path, context_file=context_file)
<         except ImportError:
<             if not i >= max(1, len(parts) - 2):
<                 raise
<             return '.'.join(parts[:i])
<     return dotted_name
< 
< 
<     
< def get_modules(package, src_directory, blacklist=STD_BLACKLIST):
<     """given a package directory return a list of all available python
<     modules in the package and its subpackages
< 
<     :type package: str
<     :param package: the python name for the package
< 
<     :type src_directory: str
<     :param src_directory:
<       path of the directory corresponding to the package
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       optional list of files or directory to ignore, default to
<       the value of `logilab.common.STD_BLACKLIST`
< 
<     :rtype: list
<     :return:
<       the list of all available python modules in the package and its
<       subpackages
<     """
<     def func(modules, directory, fnames):
<         """walk handler"""
<         # remove files/directories in the black list
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         # check for __init__.py
<         if not '__init__.py' in fnames:
<             while fnames:
<                 fnames.pop()
<         elif directory != src_directory:
<             #src = join(directory, file)
<             dir_package = directory[len(src_directory):].replace(os.sep, '.')
<             modules.append(package + dir_package)
<         for filename in fnames:
<             src = join(directory, filename)
<             if isdir(src):
<                 continue
<             if _is_python_file(filename) and filename != '__init__.py':
<                 module = package + src[len(src_directory):-3]
<                 modules.append(module.replace(os.sep, '.'))
<     modules = []
<     walk(src_directory, func, modules)
<     return modules
< 
< 
< 
< def get_module_files(src_directory, blacklist=STD_BLACKLIST):
<     """given a package directory return a list of all available python
<     module's files in the package and its subpackages
< 
<     :type src_directory: str
<     :param src_directory:
<       path of the directory corresponding to the package
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       optional list of files or directory to ignore, default to the value of
<       `logilab.common.STD_BLACKLIST`
< 
<     :rtype: list
<     :return:
<       the list of all available python module's files in the package and
<       its subpackages
<     """
<     def func(files, directory, fnames):
<         """walk handler"""
<         # remove files/directories in the black list
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         # check for __init__.py
<         if not '__init__.py' in fnames:
<             while fnames:
<                 fnames.pop()            
<         for filename in fnames:
<             src = join(directory, filename)
<             if isdir(src):
<                 continue
<             if _is_python_file(filename):
<                 files.append(src)
<     files = []
<     walk(src_directory, func, files)
<     return files
< 
< 
< def get_source_file(filename, include_no_ext=False):
<     """given a python module's file name return the matching source file
<     name (the filename will be returned identically if it's a already an
<     absolute path to a python source file...)
< 
<     :type filename: str
<     :param filename: python module's file name
< 
< 
<     :raise NoSourceFile: if no source file exists on the file system
<     
<     :rtype: str
<     :return: the absolute path of the source file if it exists
<     """
<     base, orig_ext = splitext(abspath(filename))
<     for ext in PY_SOURCE_EXTS:
<         source_path = '%s.%s' % (base, ext)
<         if exists(source_path):
<             return source_path
<     if include_no_ext and not orig_ext and exists(base):
<         return base
<     raise NoSourceFile(filename)
< 
< 
< 
< def is_python_source(filename):
<     """
<     rtype: bool
<     return: True if the filename is a python source file
<     """
<     return splitext(filename)[1][1:] in PY_SOURCE_EXTS
< 
< 
<     
< def is_standard_module(modname, std_path=(STD_LIB_DIR,)):
<     """try to guess if a module is a standard python module (by default,
<     see `std_path` parameter's description)
<     
<     :type modname: str
<     :param modname: name of the module we are interested in
< 
<     :type std_path: list(str) or tuple(str)
<     :param std_path: list of path considered has standard
< 
< 
<     :rtype: bool
<     :return:
<       true if the module:
<       - is located on the path listed in one of the directory in `std_path`
<       - is a built-in module
<     """
<     modpath = modname.split('.')
<     modname = modpath[0]
<     try:
<         filename = file_from_modpath(modpath)
<     except ImportError:
<         # import failed, i'm probably not so wrong by supposing it's
<         # not standard...
<         return 0
<     # modules which are not living in a file are considered standard
<     # (sys and __builtin__ for instance)
<     if filename is None:
<         return 1
<     filename = abspath(filename)
<     for path in std_path:
<         path = abspath(path)
<         if filename.startswith(path):
<             pfx_len = len(path)
<             if filename[pfx_len+1:pfx_len+14] != 'site-packages':
<                 return 1
<             return 0
<     return False
< 
<     
< 
< def is_relative(modname, from_file):
<     """return true if the given module name is relative to the given
<     file name
<     
<     :type modname: str
<     :param modname: name of the module we are interested in
< 
<     :type from_file: str
<     :param from_file:
<       path of the module from which modname has been imported
<     
<     :rtype: bool
<     :return:
<       true if the module has been imported relativly to `from_file`
<     """
<     if not isdir(from_file):
<         from_file = dirname(from_file)
<     if from_file in sys.path:
<         return False
<     try:
<         find_module(modname.split('.')[0], [from_file])
<         return True
<     except ImportError:
<         return False
< 
< 
< # internal only functions #####################################################
< 
< def _file_from_modpath(modpath, path=None, context=None):
<     """given a mod path (ie splited module / package name), return the
<     corresponding file
< 
<     this function is used internally, see `file_from_modpath`'s
<     documentation for more information
<     """
<     assert len(modpath) > 0
<     if context is not None:
<         try:
<             mtype, mp_filename = _module_file(modpath, [context])
<         except ImportError:
<             mtype, mp_filename = _module_file(modpath, path)
<     else:
<         mtype, mp_filename = _module_file(modpath, path)
<     if mtype == PY_COMPILED:
<         try:
<             return get_source_file(mp_filename)
<         except NoSourceFile:
<             return mp_filename
<     elif mtype == C_BUILTIN:
<         # integrated builtin module
<         return None
<     elif mtype == PKG_DIRECTORY:
<         mp_filename = _has_init(mp_filename)
<     return mp_filename
< 
< def _module_file(modpath, path=None):
<     """get a module type / file path
< 
<     :type modpath: list or tuple
<     :param modpath:
<       splitted module's name (i.e name of a module or package splitted
<       on '.'), with leading empty strings for explicit relative import
< 
<     :type path: list or None
<     :param path:
<       optional list of path where the module or package should be
<       searched (use sys.path if nothing or None is given)
< 
<       
<     :rtype: tuple(int, str)
<     :return: the module type flag and the file path for a module
<     """
<     while modpath:
<         _, mp_filename, mp_desc = find_module(modpath[0], path)
<         modpath.pop(0)
<         mtype = mp_desc[2]
<         if modpath:
<             if mtype != PKG_DIRECTORY:
<                 raise ImportError('No module %r' % '.'.join(modpath))
<             path = [mp_filename]
<     return mtype, mp_filename
< 
< def _is_python_file(filename):
<     """return true if the given filename should be considered as a python file
< 
<     .pyc and .pyo are ignored
<     """
<     for ext in ('.py', '.so', '.pyd', '.pyw'):
<         if filename.endswith(ext):
<             return True
<     return False
< 
< 
< def _has_init(directory):
<     """if the given directory has a valid __init__ file, return its path,
<     else return None
<     """
<     mod_or_pack = join(directory, '__init__')
<     for ext in ('.py', '.pyw', '.pyc', '.pyo'):
<         if exists(mod_or_pack + ext):
<             return mod_or_pack + ext
<     return None
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/monclient.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/monclient.py.svn-base
1,64d0
< """Simple interpreter client for monserver
< provides a simple readline interface.
< """
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< from socket import socket, SOCK_STREAM, AF_INET
< from select import select
< import sys
< import readline
< import threading
< 
< class SocketPrinter(threading.Thread):
<     """A thread that reads from a socket and output
<     to stdout as data are received"""
<     def __init__(self, sock):
<         threading.Thread.__init__(self)
<         self.socket = sock
<         self.stop = False
<         
<     def run(self):
<         """prints socket input indefinitely"""
<         fd = self.socket.fileno()
<         self.socket.setblocking(0)
<         while not self.stop:
<             iwl, _, _ = select([fd], [], [], 2)
<             if fd in iwl:
<                 data = self.socket.recv(100)
<                 if data:
<                     sys.stdout.write(data)
<                     sys.stdout.flush()
<             
< 
< 
< def client( host, port ):
<     """simple client that just sends input to the server"""
<     sock = socket( AF_INET, SOCK_STREAM )
<     sock.connect( (host, port) )
<     sp_thread = SocketPrinter(sock)
<     sp_thread.start()
<     while 1:
<         try:
<             line = raw_input() + "\n"
<             sock.send( line )
<         except EOFError:
<             print "Bye"
<             break
<         except:
<             sp_thread.stop = True
<             sp_thread.join()
<             raise
<     sp_thread.stop = True
<     sp_thread.join()
< 
< 
< if __name__ == "__main__":
<     server_host = sys.argv[1]
<     server_port = int(sys.argv[2])
<     client(server_host, server_port)
< 
<         
<         
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/monserver.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/monserver.py.svn-base
1,121d0
< # -*- coding: iso-8859-1 -*-
< """This module implements a TCP server in a separate thread that
< allows *one* client to connect and provides a command line interpreter
< allowing the remote client to explore the process on the fly
< """
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = '$Id: monserver.py,v 1.2 2005-11-22 13:13:02 syt Exp $'
< 
< import threading
< import SocketServer
< import traceback
< import code
< import sys
< import time
< 
< 
< # NOTES: ce module tant utilis pour l'introspection, il peut
< # tre utile de fournir dans les locales de l'interpreteur des
< # objets dj initialiss (par exemple le module __main__ ou
< # bien __main__.*) ou encore des objets servant  l'introspection
< # comme on en trouve dans pymonitor (qui prend la liste des objets
< # maintenus par le garbage collector) ou a des statistiques
< # pour faire des oprations du style:
< # inspector.count_types( MyClass )
< # inspector.list_types( MyClass ) etc...
< 
< class MonitorInterpreter(code.InteractiveConsole):
<     """Subclasses InteractiveConsole so that all inputs
<     and outputs are done through a socket"""
<     def __init__(self, rfile, wfile ):
<         code.InteractiveConsole.__init__(self)
<         self.wfile = wfile
<         self.rfile = rfile
<         sys.stdout = self.wfile
<         sys.stderr = self.wfile
< 
<     def write(self, data):
<         """replace stderr output by writing to wfile"""
<         self.wfile.write( data )
<         self.wfile.flush()
< 
<     def raw_input( self, prompt = None ):
<         """Provides reading lines through the network"""
<         if prompt is not None:
<             self.wfile.write(prompt)
<             self.wfile.flush()
<         line = self.rfile.readline()
<         if line.endswith("\r\n"):
<             line = line[:-2]
<         elif line.endswith("\n"):
<             line = line[:-1]
<         return line
<         
< 
< class MonitorRequestHandler(SocketServer.BaseRequestHandler):
<     """Request handler for remote interpreter"""
<     def __init__(self, request, clientaddress, server ):
<         self.locals = {}
<         self.globals = globals().copy()
<         self.wfile = request.makefile("w")
<         self.rfile = request.makefile("r")
<         SocketServer.BaseRequestHandler.__init__(self, request, clientaddress,
<                                                  server )
<         
<     def handle(self):
<         """handle on request, through MonitorInterpreter"""
<         saved_stdout = sys.stdout
<         saved_stderr = sys.stderr
<         interpreter = MonitorInterpreter(self.rfile, self.wfile)
<         try:
<             interpreter.interact()
<         except KeyboardInterrupt:
<             self.server.exit = True
<         except:
<             sys.stdout = saved_stdout
<             sys.stderr = saved_stderr
<             traceback.print_exc()
<         print "Monitor handler exited"
< 
< class Monitor(threading.Thread):
<     """Monitor server. monothreaded we only
<     allow one client at a time"""
<     def __init__(self, host, port):
<         threading.Thread.__init__(self)
<         self.host = host
<         self.port = port
<         self.exit = False
< 
< 
<     def run(self):
<         """run the server loop"""
<         server = SocketServer.TCPServer( (self.host, self.port),
<                                          MonitorRequestHandler )
<         while not self.exit:
<             server.handle_request()
< 
< 
< 
< def demo_forever():
<     """sample demo server that outputs
<     numbers on screen"""
<     cnt = 1
<     while 1:
<         print cnt
<         time.sleep(2)
<         cnt += 1
< 
< if __name__ == "__main__":
<     listen_port = int(sys.argv[1])
<     mon = Monitor( "", listen_port )
<     mon.start()
<     try:
<         demo_forever()
<     except Exception:
<         traceback.print_exc()
<     mon.exit = True
<     mon.join()
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/optik_ext.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/optik_ext.py.svn-base
1,331d0
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< add an abstraction level to transparently import optik classes from optparse
< (python >= 2.3) or the optik package.
< It also defines three new types for optik/optparse command line parser :
< 
<   * regexp
<     argument of this type will be converted using re.compile
<   * csv
<     argument of this type will be converted using split(',')
<   * yn
<     argument of this type will be true if 'y' or 'yes', false if 'n' or 'no'
<   * named
<     argument of this type are in the form <NAME>=<VALUE> or <NAME>:<VALUE>
< 
< """
< 
< import re
< import sys
< import time
< from copy import copy
< from os.path import exists
< 
< try:
<     # python >= 2.3
<     from optparse import OptionParser as BaseParser, Option as BaseOption, \
<          OptionGroup, OptionValueError, OptionError, Values, HelpFormatter, \
<          NO_DEFAULT
< except ImportError:
<     # python < 2.3
<     from optik import OptionParser as BaseParser, Option as BaseOption, \
<          OptionGroup, OptionValueError, OptionError, Values, HelpFormatter
<     try:
<         from optik import NO_DEFAULT
<     except:
<         NO_DEFAULT = []
< 
< try:
<     from mx import DateTime
<     HAS_MX_DATETIME = True
< except ImportError:
<     HAS_MX_DATETIME = False
< 
< 
< OPTPARSE_FORMAT_DEFAULT = sys.version_info >= (2, 4)
< 
< from clonedigger.logilab.common.textutils import get_csv
< 
< def check_regexp(option, opt, value):
<     """check a regexp value by trying to compile it
<     return the compiled regexp
<     """
<     if hasattr(value, 'pattern'):
<         return value
<     try:
<         return re.compile(value)
<     except ValueError:
<         raise OptionValueError(
<             "option %s: invalid regexp value: %r" % (opt, value))
<     
< def check_csv(option, opt, value):
<     """check a csv value by trying to split it
<     return the list of separated values
<     """
<     if isinstance(value, (list, tuple)):
<         return value
<     try:
<         return get_csv(value)
<     except ValueError:
<         raise OptionValueError(
<             "option %s: invalid csv value: %r" % (opt, value))
< 
< def check_yn(option, opt, value):
<     """check a yn value
<     return true for yes and false for no
<     """
<     if isinstance(value, int):
<         return bool(value)
<     if value in ('y', 'yes'):
<         return True
<     if value in ('n', 'no'):
<         return False
<     msg = "option %s: invalid yn value %r, should be in (y, yes, n, no)"
<     raise OptionValueError(msg % (opt, value))
< 
< def check_named(option, opt, value):
<     """check a named value
<     return a dictionnary containing (name, value) associations
<     """
<     if isinstance(value, dict):
<         return value
<     values = []
<     for value in check_csv(option, opt, value):
<         if value.find('=') != -1:
<             values.append(value.split('=', 1))
<         elif value.find(':') != -1:
<             values.append(value.split(':', 1))
<     if values:
<         return dict(values)
<     msg = "option %s: invalid named value %r, should be <NAME>=<VALUE> or \
< <NAME>:<VALUE>"
<     raise OptionValueError(msg % (opt, value))
< 
< def check_password(option, opt, value):
<     """check a password value (can't be empty)
<     """
<     # no actual checking, monkey patch if you want more
<     return value
< 
< def check_file(option, opt, value):
<     """check a file value
<     return the filepath
<     """
<     if exists(value):
<         return value
<     msg = "option %s: file %r does not exist"
<     raise OptionValueError(msg % (opt, value))
< 
< def check_date(option, opt, value):
<     """check a file value
<     return the filepath
<     """
<     try:
<         return DateTime.strptime(value, "%Y/%m/%d")
<     except DateTime.Error :
<         raise OptionValueError(
<             "expected format of %s is yyyy/mm/dd" % opt)
< 
< def check_color(option, opt, value):
<     """check a color value and returns it
<     /!\ does *not* check color labels (like 'red', 'green'), only
<     checks hexadecimal forms
<     """
<     # Case (1) : color label, we trust the end-user
<     if re.match('[a-z0-9 ]+$', value, re.I):
<         return value
<     # Case (2) : only accepts hexadecimal forms
<     if re.match('#[a-f0-9]{6}', value, re.I):
<         return value
<     # Else : not a color label neither a valid hexadecimal form => error
<     msg = "option %s: invalid color : %r, should be either hexadecimal \
<     value or predefinied color"
<     raise OptionValueError(msg % (opt, value))
< 
< import types
< 
< class Option(BaseOption):
<     """override optik.Option to add some new option types
<     """
<     TYPES = BaseOption.TYPES + ('regexp', 'csv', 'yn', 'named', 'password',
<                                 'multiple_choice', 'file', 'font', 'color')
<     TYPE_CHECKER = copy(BaseOption.TYPE_CHECKER)
<     TYPE_CHECKER['regexp'] = check_regexp
<     TYPE_CHECKER['csv'] = check_csv
<     TYPE_CHECKER['yn'] = check_yn
<     TYPE_CHECKER['named'] = check_named
<     TYPE_CHECKER['multiple_choice'] = check_csv
<     TYPE_CHECKER['file'] = check_file
<     TYPE_CHECKER['color'] = check_color
<     TYPE_CHECKER['password'] = check_password
<     if HAS_MX_DATETIME:
<         TYPES += ('date',)
<         TYPE_CHECKER['date'] = check_date
< 
<     def _check_choice(self):
<         """FIXME: need to override this due to optik misdesign"""
<         if self.type in ("choice", "multiple_choice"):
<             if self.choices is None:
<                 raise OptionError(
<                     "must supply a list of choices for type 'choice'", self)
<             elif type(self.choices) not in (types.TupleType, types.ListType):
<                 raise OptionError(
<                     "choices must be a list of strings ('%s' supplied)"
<                     % str(type(self.choices)).split("'")[1], self)
<         elif self.choices is not None:
<             raise OptionError(
<                 "must not supply choices for type %r" % self.type, self)
<     BaseOption.CHECK_METHODS[2] = _check_choice
< 
< 
<     def process(self, opt, value, values, parser):
<         # First, convert the value(s) to the right type.  Howl if any
<         # value(s) are bogus.
<         try:
<             value = self.convert_value(opt, value)
<         except AttributeError: # py < 2.4
<             value = self.check_value(opt, value)
<         if self.type == 'named': 
<             existant = getattr(values, self.dest)
<             if existant:
<                 existant.update(value)
<                 value = existant
<        # And then take whatever action is expected of us.
<         # This is a separate method to make life easier for
<         # subclasses to add new actions.
<         return self.take_action(
<             self.action, self.dest, opt, value, values, parser)
<     
< class OptionParser(BaseParser):
<     """override optik.OptionParser to use our Option class
<     """
<     def __init__(self, option_class=Option, *args, **kwargs):
<         BaseParser.__init__(self, option_class=Option, *args, **kwargs)
< 
< 
< class ManHelpFormatter(HelpFormatter):
<     """Format help using man pages ROFF format"""
< 
<     def __init__ (self,
<                   indent_increment=0,
<                   max_help_position=24,
<                   width=79,
<                   short_first=0):
<         HelpFormatter.__init__ (
<             self, indent_increment, max_help_position, width, short_first)
< 
<     def format_heading(self, heading):
<         return '.SH %s\n' % heading.upper()
< 
<     def format_description(self, description):
<         return description
< 
<     def format_option(self, option):
<         try:
<             optstring = option.option_strings
<         except AttributeError:
<             optstring = self.format_option_strings(option)
<         if option.help:
<             help = ' '.join([l.strip() for l in option.help.splitlines()])
<         else:
<             help = ''
<         return '''.IP "%s"
< %s
< ''' % (optstring, help)
< 
<     def format_head(self, optparser, pkginfo, section=1):
<         try:
<             pgm = optparser._get_prog_name()
<         except AttributeError:
<             # py >= 2.4.X (dunno which X exactly, at least 2)
<             pgm = optparser.get_prog_name()
<         short_desc = self.format_short_description(pgm, pkginfo.short_desc)
<         long_desc = self.format_long_description(pgm, pkginfo.long_desc)
<         return '%s\n%s\n%s\n%s' % (self.format_title(pgm, section), short_desc,
<                                    self.format_synopsis(pgm), long_desc)
< 
<     def format_title(self, pgm, section):
<         date = '-'.join([str(num) for num in time.localtime()[:3]])
<         return '.TH %s %s "%s" %s' % (pgm, section, date, pgm)
< 
<     def format_short_description(self, pgm, short_desc):
<         return '''.SH NAME
< .B %s 
< \- %s
< ''' % (pgm, short_desc.strip())
<         
<     def format_synopsis(self, pgm):
<         return '''.SH SYNOPSIS
< .B  %s
< [
< .I OPTIONS
< ] [
< .I <arguments>
< ]
< ''' % pgm
<         
<     def format_long_description(self, pgm, long_desc):
<         long_desc = '\n'.join([line.lstrip()
<                                for line in long_desc.splitlines()])
<         long_desc = long_desc.replace('\n.\n', '\n\n')
<         if long_desc.lower().startswith(pgm):
<             long_desc = long_desc[len(pgm):]
<         return '''.SH DESCRIPTION
< .B %s 
< %s
< ''' % (pgm, long_desc.strip())
<         
<     def format_tail(self, pkginfo):
<         return '''.SH SEE ALSO
< /usr/share/doc/pythonX.Y-%s/
< 
< .SH COPYRIGHT 
< %s
< 
< This program is free software; you can redistribute it and/or modify 
< it under the terms of the GNU General Public License as published 
< by the Free Software Foundation; either version 2 of the License, 
< or (at your option) any later version.
< 
< This program is distributed in the hope that it will be useful, 
< but WITHOUT ANY WARRANTY; without even the implied warranty of 
< MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the 
< GNU General Public License for more details.
< 
< You should have received a copy of the GNU General Public License 
< along with this program; if not, write to the Free Software 
< Foundation, Inc., 59 Temple Place, Suite 330, Boston, 
< MA 02111-1307 USA.
< .SH BUGS 
< Please report bugs on the project\'s mailing list:
< %s
< 
< .SH AUTHOR
< %s <%s>
< ''' % (getattr(pkginfo, 'debian_name', pkginfo.modname), pkginfo.copyright,
<        pkginfo.mailinglist, pkginfo.author, pkginfo.author_email)
< 
< 
< def generate_manpage(optparser, pkginfo, section=1, stream=sys.stdout):
<     """generate a man page from an optik parser"""
<     formatter = ManHelpFormatter()
<     print >> stream, formatter.format_head(optparser, pkginfo, section)
<     print >> stream, optparser.format_option_help(formatter)
<     print >> stream, formatter.format_tail(pkginfo)
< 
<     
< __all__ = ('OptionParser', 'Option', 'OptionGroup', 'OptionValueError',
<            'Values')
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/optparser.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/optparser.py.svn-base
1,85d0
< # -*- coding: iso-8859-15 -*-
< # Copyright (c) 2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Extend OptionParser with commands.
< 
< Example:
< 
< >>> parser = OptionParser()
< >>> parser.usage = '%prog COMMAND [options] <arg> ...'
< >>> parser.add_command('build', 'mymod.build')
< >>> parser.add_command('clean', run_clean, add_opt_clean)
< >>> run, options, args = parser.parse_command(sys.argv[1:])
< >>> return run(options, args[1:])
< 
< With mymod.build that defines two functions run and add_options
< """
< 
< # XXX merge with optik_ext ? merge with clcommands ? 
< 
< import sys
< import optparse
< 
< class OptionParser(optparse.OptionParser):
< 
<     def __init__(self, *args, **kwargs):
<         optparse.OptionParser.__init__(self, *args, **kwargs)
<         self._commands = {}
<         self.min_args, self.max_args = 0, 1
<         
<     def add_command(self, name, mod_or_funcs, help=''):
<         """name of the command
< 	name of module or tuple of functions (run, add_options)
< 	"""
<         assert isinstance(mod_or_funcs, str) or isinstance(mod_or_funcs, tuple), \
< 	       "mod_or_funcs has to be a module name or a tuple of functions"
<         self._commands[name] = (mod_or_funcs, help)
< 
<     def print_main_help(self):
<         optparse.OptionParser.print_help(self)
<         print '\ncommands:'
<         for cmdname, (_, help) in self._commands.items():
<             print '% 10s - %s' % (cmdname, help)
<         
<     def parse_command(self, args):
<         if len(args) == 0:
<             self.print_main_help()
<             sys.exit(1)
<         cmd = args[0]
< 	args = args[1:]
<         if cmd not in self._commands:
<             if cmd in ('-h', '--help'):
<                 self.print_main_help()
<                 sys.exit(0)
<             elif self.version is not None and cmd == "--version":
<                 self.print_version()
<                 sys.exit(0)
<             self.error('unknow command')
<         self.prog = '%s %s' % (self.prog, cmd)
<         mod_or_f, help = self._commands[cmd]
<         # optparse inserts self.description between usage and options help
<         self.description = help
<         if isinstance(mod_or_f, str):
<             exec 'from %s import run, add_options' % mod_or_f
< 	else:
< 	    run, add_options = mod_or_f
<         add_options(self)
<         (options, args) = self.parse_args(args)        
<         if not (self.min_args <= len(args) <= self.max_args):
<             self.error('incorrect number of arguments')
<         return run, options, args
< 
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/patricia.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/patricia.py.svn-base
1,191d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< 
< a Python implementation of PATRICIA tree
< 
< PATRICIA - Practical Algorithm to Retrieve Information Coded in Alphanumeric
<            D.R.Morrison (1968).
< See http://www.csse.monash.edu.au/~lloyd/tildeAlgDS/Tree/PATRICIA.html if you
< want to know what's a PATRICIA tree...
< 
< TODO: _ advanced search
<       _ profile code
<       _ use mxTextTools ?
< """
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = "$Id: patricia.py,v 1.5 2003-10-31 14:18:32 syt Exp $"
< 
< def prefix(prfx, string):
<     """return the index of the first character from string which differs from
<     prefix
<     """
<     i = 0
<     while i < len(prfx):
<         if i == len(string) or prfx[i] != string[i]:
<             break
<         i += 1
<     return i
< 
< def split(index, string):
<     """split a string on index, returning a 3-uple :
<         (string before index, character at index, string after index)
<     """
<     return string[:index], string[index], string[index+1:]
< 
< 
< class PatriciaNode:
<     """a PATRICIA trie node
<     """
<     
<     def __init__(self, value='', leaf=0, data=None):
<         self.value = value
<         self.edges = {}
<         if leaf:
<             self.datas = [data]
<         else:
<             self.datas = []
<         
<     def insert(self, string, data):
<         """ insert the string in the trie and associate data to it
<         if the string exists is the trie, data is added to the existing datas
<         """
<         # are we arrived ?
<         if self.value == string:
<             self.datas.append(data)
<         # not yet !
<         else:
<             # check we don't break compression (value don't match)
<             ind = prefix(self.value, string)
<             if ind < len(self.value):
<                 # split this node
<                 pfx, e, self.value = split(ind, self.value)
<                 if ind < len(string):
<                     n = PatriciaNode(pfx)
<                     n.edges[string[ind]] = PatriciaNode(string[ind+1:], 1, data)
<                 else:
<                     n = PatriciaNode(pfx, 1, data)
<                 n.edges[e] = self
<                 return n
<             n_pfx, n_e, n_sfx = split(len(self.value), string)
<             if self.edges.has_key(n_e):
<                 self.edges[n_e] = self.edges[n_e].insert(n_sfx, data)
<             else:
<                 self.edges[n_e] = PatriciaNode(n_sfx, 1, data)
<         return self
< 
<     def remove(self, string):
<         """ return datas associated with string and remove string from the trie
<         raise KeyError if the key isn't found
<         FIXME: we should change the trie structure
<         """
<         if string == self.value and self.datas:
<             datas = self.datas
<             self.datas = []
<             return datas
<         else: 
<             pfx, e, sfx = split(len(self.value), string)
<             if self.value == pfx:
<                 return self.edges[e].remove(sfx)
<         raise KeyError(string)
<     
<     def lookup(self, string):
<         """ return datas associated with string
<         raise KeyError if the key isn't found
<         """
<         if string == self.value:
<             if self.datas:
<                 return self.datas
<             raise KeyError(string)
<         else: # len(self.value) < len(string): 
<             pfx, e, sfx = split(len(self.value), string)
<             if self.value == pfx:
<                 return self.edges[e].lookup(sfx)
<         raise KeyError(string)
<     
<     def pfx_search(self, pfx, depth=-1):
<         """ return all string with prefix pfx """
<         sfxs = []
<         if pfx and self.value[:len(pfx)] != pfx:
<             pfx, e, sfx = split(len(self.value), pfx)
<             if self.value == pfx and self.edges.has_key(e):
<                 sfxs = ['%s%s%s' % (self.value, e, sfx)
<                         for sfx in self.edges[e].pfx_search(sfx, depth)]
<         else:
<             if depth != 0:
<                 for e, child in self.edges.items():
<                     search = child.pfx_search('', depth-1-len(self.value))
<                     sfxs += ['%s%s%s' % (self.value, e, sfx)
<                              for sfx in search]
<             if (depth < 0 or len(self.value) <= depth):
<                 if self.datas:
<                     sfxs.append(self.value)
<         return sfxs
<         
<     def __str__(self, indent=''):
<         node_str = ''.join([' %s%s:\n%s' % (indent, key,
<                                             a.__str__('  %s' % indent))
<                             for key, a in self.edges.items()])
<         return '%s%s, %s\n%s' % (indent, self.value, self.datas, node_str)
< 
<     def __repr__(self):
<         return '<PatriciaNode id=%s value=%s childs=%s datas=%s>' % (
<             id(self), self.value, self.edges.keys(), self.datas)
< 
< 
< class PatriciaTrie:
<     """ wrapper class for a patricia tree
<     delegates to the root of the tree (PatriciaNode)
<     """
<     
<     def __init__(self):
<         self._trie = None
<         self.words = 0
< 
<     def insert(self, string, data=None):
<         """ insert a string into the tree """
<         self.words += 1
<         if self._trie is None:
<             self._trie = PatriciaNode(string, 1, data)
<         else:
<             self._trie = self._trie.insert(string, data)
<             
<     def remove(self, string):
<         """ remove a string from the tree """
<         if self._trie is not None:
<             return self._trie.remove(string)
<         raise KeyError(string)
< 
<     def lookup(self, string):
<         """ look for a string into the tree """
<         if self._trie is not None:
<             return self._trie.lookup(string)
<         raise KeyError(string)
< 
<     def pfx_search(self, string, depth=-1):
<         """ search all words begining by <string> """
<         if self._trie is not None:
<             return self._trie.pfx_search(string, depth)
<         raise KeyError(string)
< 
<     def __str__(self):
<         return self._trie.__str__()
<     
<     def __repr__(self):
<         return '<PatriciaTrie id=%s words=%s>' % (id(self), self.words)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/pdf_ext.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/pdf_ext.py.svn-base
1,100d0
< # This program is free software; you can redistribute it and/or modify
< # it under the terms of the GNU General Public License as published by
< # the Free Software Foundation; either version 2 of the License, or
< # (at your option) any later version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2003-2007 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< manipulate pdf and fdf files. pdftk recommended.
< 
< Notes regarding pdftk, pdf forms and fdf files (form definition file) 
< fields names can be extracted with:
<     pdftk orig.pdf generate_fdf output truc.fdf
< to merge fdf and pdf:      
<     pdftk orig.pdf fill_form test.fdf output result.pdf [flatten]
< without flatten, one could further edit the resulting form.
< with flatten, everything is turned into text.
< """
< # XXX seems very unix specific
< # TODO: check availability of pdftk at import 
< 
< 
< import os
< 
< HEAD="""%FDF-1.2
< %\xE2\xE3\xCF\xD3
< 1 0 obj 
< <<
< /FDF 
< <<
< /Fields [
< """
< 
< TAIL="""]
< >>
< >>
< endobj 
< trailer
< 
< <<
< /Root 1 0 R
< >>
< %%EOF
< """
< 
< def output_field( f ):
<     return "\xfe\xff" + "".join( [ "\x00"+c for c in f ] )
< 
< def extract_keys(lines):
<     keys = []
<     for line in lines:
<         if line.startswith('/V'):
<             pass #print 'value',line
<         elif line.startswith('/T'):
<             key = line[7:-2]
<             key = ''.join(key.split('\x00'))
<             keys.append( key )
<     return keys
< 
< def write_field(out, key, value):
<     out.write("<<\n")
<     if value:
<         out.write("/V (%s)\n" %value)
<     else:
<         out.write("/V /\n")
<     out.write("/T (%s)\n" % output_field(key) )
<     out.write(">> \n")
< 
< def write_fields(out, fields):
<     out.write(HEAD)
<     for (key,value,comment) in fields:
<         write_field(out, key, value)
<         write_field(out, key+"a", value) # pour copie-carbone sur autres pages
<     out.write(TAIL)
< 
< def extract_keys_from_pdf(filename):
<     # what about using 'pdftk filename dump_data_fields' and parsing the output ?
<     os.system('pdftk %s generate_fdf output /tmp/toto.fdf' % filename)
<     lines = file('/tmp/toto.fdf').readlines()
<     return extract_keys(lines)
< 
< 
< def fill_pdf(infile, outfile, fields):
<     write_fields(file('/tmp/toto.fdf', 'w'), fields)
<     os.system('pdftk %s fill_form /tmp/toto.fdf output %s flatten' % (infile, outfile))
< 
< def testfill_pdf(infile, outfile):
<     keys = extract_keys_from_pdf(infile)
<     fields = []
<     for key in keys:
<         fields.append( (key, key, '') )
<     fill_pdf(infile, outfile, fields)
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/__pkginfo__.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/__pkginfo__.py.svn-base
1,59d0
< # Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< 
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< 
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """logilab.common packaging information"""
< 
< distname = 'logilab-common'
< modname = 'common'
< numversion = (0, 31, 0)
< version = '.'.join([str(num) for num in numversion])
< 
< license = 'GPL'
< copyright = '''Copyright (c) 2003-2008 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr'''
< 
< author = "Logilab"
< author_email = "devel@logilab.fr"
< 
< short_desc = "useful miscellaneous modules used by Logilab projects"
< 
< long_desc = """logilab-common is a collection of low-level Python packages and \
< modules,
<  designed to ease:
<   * handling command line options and configuration files
<   * writing interactive command line tools
<   * manipulation files and character strings
<   * interfacing to OmniORB
<   * generating of SQL queries
<   * running unit tests
<   * manipulating tree structures
<   * accessing RDBMS (currently postgreSQL, mysql and sqlite)
<   * generating text and HTML reports
<   * logging"""
< 
< 
< web = "http://www.logilab.org/project/%s" % distname
< ftp = "ftp://ftp.logilab.org/pub/%s" % modname
< mailinglist = "mailto://python-projects@lists.logilab.org"
< 
< subpackage_of = 'logilab'
< subpackage_master = True
< 
< scripts = ('bin/pytest',)
< from os.path import join
< include_dirs = [join('test', 'data')]
< pyversions = ['2.3', '2.4', '2.5']
< debian_maintainer = 'Alexandre Fayolle'
< debian_maintainer_email = 'afayolle@debian.org'
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/pytest.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/pytest.py.svn-base
1,639d0
< """pytest is a tool that eases test running and debugging.
< 
< To be able to use pytest, you should either write tests using
< the logilab.common.testlib's framework or the unittest module of the
< Python's standard library.
< 
< You can customize pytest's behaviour by defining a ``pytestconf.py`` file
< somewhere in your test directory. In this file, you can add options or
< change the way tests are run.
< 
< To add command line options, you must define a ``update_parser`` function in
< your ``pytestconf.py`` file. The function must accept a single parameter
< that will be the OptionParser's instance to customize.
< 
< If you wish to customize the tester, you'll have to define a class named
< ``CustomPyTester``. This class should extend the default `PyTester` class
< defined in the pytest module. Take a look at the `PyTester` and `DjangoTester`
< classes for more information about what can be done.
< 
< 
< For instance, if you wish to add a custom -l option to specify a loglevel, you
< could define the following ``pytestconf.py`` file ::
< 
<     import logging
<     from clonedigger.logilab.common.pytest import PyTester
<     
<     def update_parser(parser):
<         parser.add_option('-l', '--loglevel', dest='loglevel', action='store',
<                           choices=('debug', 'info', 'warning', 'error', 'critical'),
<                           default='critical', help="the default log level possible choices are "
<                           "('debug', 'info', 'warning', 'error', 'critical')")
<         return parser
<     
<     
<     class CustomPyTester(PyTester):
<         def __init__(self, cvg, options):
<             super(CustomPyTester, self).__init__(cvg, options)
<             loglevel = options.loglevel.upper()
<             logger = logging.getLogger('erudi')
<             logger.setLevel(logging.getLevelName(loglevel))
< 
< 
< In your TestCase class you can then get the value of a specific option with
< the ``optval`` method::
<     
<     class MyTestCase(TestCase):
<         def test_foo(self):
<             loglevel = self.optval('loglevel')
<             # ...
<             
< """
< 
< PYTEST_DOC = """%prog [OPTIONS] [testfile [testpattern]]
< 
< examples:
< 
< pytest path/to/mytests.py
< pytest path/to/mytests.py TheseTests
< pytest path/to/mytests.py TheseTests.test_thisone
< 
< pytest one (will run both test_thisone and test_thatone)
< pytest path/to/mytests.py -s not (will skip test_notthisone)
< 
< pytest --coverage test_foo.py
<   (only if logilab.devtools is available)
< """
< 
< import os, sys
< import os.path as osp
< from time import time, clock
< 
< from clonedigger.logilab.common.fileutils import abspath_listdir
< from clonedigger.logilab.common import testlib
< import doctest
< import unittest
< 
< 
< import imp
< 
< import __builtin__
< 
< 
< try:
<     import django
<     from clonedigger.logilab.common.modutils import modpath_from_file, load_module_from_modpath
<     DJANGO_FOUND = True
< except ImportError:
<     DJANGO_FOUND = False
< 
< CONF_FILE = 'pytestconf.py'
< 
< ## coverage hacks, do not read this, do not read this, do not read this
< 
< # hey, but this is an aspect, right ?!!!
< class TraceController(object):
<     nesting = 0
< 
<     def pause_tracing(cls):
<         if not cls.nesting:
<             cls.tracefunc = getattr(sys, '__settrace__', sys.settrace)
<             cls.oldtracer = getattr(sys, '__tracer__', None)
<             sys.__notrace__ = True
<             cls.tracefunc(None)
<         cls.nesting += 1
<     pause_tracing = classmethod(pause_tracing)
< 
<     def resume_tracing(cls):
<         cls.nesting -= 1
<         assert cls.nesting >= 0
<         if not cls.nesting:
<             cls.tracefunc(cls.oldtracer)
<             delattr(sys, '__notrace__')
<     resume_tracing = classmethod(resume_tracing)
<     
< 
< pause_tracing = TraceController.pause_tracing
< resume_tracing = TraceController.resume_tracing
< 
< 
< def nocoverage(func):
<     if hasattr(func, 'uncovered'):
<         return func
<     func.uncovered = True
<     def not_covered(*args, **kwargs):
<         pause_tracing()
<         try:
<             return func(*args, **kwargs)
<         finally:
<             resume_tracing()
<     not_covered.uncovered = True
<     return not_covered
< 
< 
< ## end of coverage hacks
< 
< 
< # monkeypatch unittest and doctest (ouch !)
< unittest.TestCase = testlib.TestCase
< unittest.main = testlib.unittest_main
< unittest._TextTestResult = testlib.SkipAwareTestResult
< unittest.TextTestRunner = testlib.SkipAwareTextTestRunner
< unittest.TestLoader = testlib.NonStrictTestLoader
< unittest.TestProgram = testlib.SkipAwareTestProgram
< if sys.version_info >= (2, 4):
<     doctest.DocTestCase.__bases__ = (testlib.TestCase,)
< else:
<     unittest.FunctionTestCase.__bases__ = (testlib.TestCase,)
< 
< 
< 
< def this_is_a_testfile(filename):
<     """returns True if `filename` seems to be a test file"""
<     filename = osp.basename(filename)
<     return ((filename.startswith('unittest')
<              or filename.startswith('test')
<              or filename.startswith('smoketest')) 
<             and filename.endswith('.py'))
<     
< 
< def this_is_a_testdir(dirpath):
<     """returns True if `filename` seems to be a test directory"""
<     return osp.basename(dirpath) in ('test', 'tests', 'unittests')
< 
< 
< def load_pytest_conf(path, parser):
<     """loads a ``pytestconf.py`` file and update default parser
<     and / or tester.
<     """
<     namespace = {}
<     execfile(path, namespace)
<     if 'update_parser' in namespace:
<         namespace['update_parser'](parser)
<     return namespace.get('CustomPyTester', PyTester)
< 
< 
< def project_root(parser, projdir=os.getcwd()):
<     """try to find project's root and add it to sys.path"""
<     curdir = osp.abspath(projdir)
<     previousdir = curdir
<     testercls = PyTester
<     conf_file_path = osp.join(curdir, CONF_FILE)
<     if osp.isfile(conf_file_path):
<         testercls = load_pytest_conf(conf_file_path, parser)
<     while this_is_a_testdir(curdir) or \
<               osp.isfile(osp.join(curdir, '__init__.py')):
<         newdir = osp.normpath(osp.join(curdir, os.pardir))
<         if newdir == curdir:
<             break
<         previousdir = curdir
<         curdir = newdir
<         conf_file_path = osp.join(curdir, CONF_FILE)
<         if osp.isfile(conf_file_path):
<             testercls = load_pytest_conf(conf_file_path, parser)
<     return previousdir, testercls
< 
< 
< class GlobalTestReport(object):
<     """this class holds global test statistics"""
<     def __init__(self):
<         self.ran = 0
<         self.skipped = 0
<         self.failures = 0
<         self.errors = 0
<         self.ttime = 0
<         self.ctime = 0
<         self.modulescount = 0
<         self.errmodules = []
< 
<     def feed(self, filename, testresult, ttime, ctime):
<         """integrates new test information into internal statistics"""
<         ran = testresult.testsRun
<         self.ran += ran
<         self.skipped += len(getattr(testresult, 'skipped', ()))
<         self.failures += len(testresult.failures)
<         self.errors += len(testresult.errors)
<         self.ttime += ttime
<         self.ctime += ctime
<         self.modulescount += 1
<         if not testresult.wasSuccessful():
<             problems = len(testresult.failures) + len(testresult.errors)
<             self.errmodules.append((filename[:-3], problems, ran))
< 
< 
<     def failed_to_test_module(self, filename):
<         """called when the test module could not be imported by unittest
<         """
<         self.errors += 1
<         self.errmodules.append((filename[:-3], 1, 1))
<         
<     
<     def __str__(self):
<         """this is just presentation stuff"""
<         line1 = ['Ran %s test cases in %.2fs (%.2fs CPU)'
<                  % (self.ran, self.ttime, self.ctime)]
<         if self.errors:
<             line1.append('%s errors' % self.errors)
<         if self.failures:
<             line1.append('%s failures' % self.failures)
<         if self.skipped:
<             line1.append('%s skipped' % self.skipped)
<         modulesok = self.modulescount - len(self.errmodules)
<         if self.errors or self.failures:
<             line2 = '%s modules OK (%s failed)' % (modulesok,
<                                                    len(self.errmodules))
<             descr = ', '.join(['%s [%s/%s]' % info for info in self.errmodules])
<             line3 = '\nfailures: %s' % descr
<         elif modulesok:
<             line2 = 'All %s modules OK' % modulesok
<             line3 = ''
<         else:
<             return ''
<         return '%s\n%s%s' % (', '.join(line1), line2, line3)
< 
< 
< 
< def remove_local_modules_from_sys(testdir):
<     """remove all modules from cache that come from `testdir`
< 
<     This is used to avoid strange side-effects when using the
<     testall() mode of pytest.
<     For instance, if we run pytest on this tree::
<     
<       A/test/test_utils.py
<       B/test/test_utils.py
< 
<     we **have** to clean sys.modules to make sure the correct test_utils
<     module is ran in B
<     """
<     for modname, mod in sys.modules.items():
<         if mod is None:
<             continue
<         if not hasattr(mod, '__file__'):
<             # this is the case of some built-in modules like sys, imp, marshal
<             continue
<         modfile = mod.__file__
<         # if modfile is not an asbolute path, it was probably loaded locally
<         # during the tests
<         if not osp.isabs(modfile) or modfile.startswith(testdir):
<             del sys.modules[modname]
< 
< 
< 
< class PyTester(object):
<     """encaspulates testrun logic"""
<     
<     def __init__(self, cvg, options):
<         self.tested_files = []
<         self.report = GlobalTestReport()
<         self.cvg = cvg
<         self.options = options
< 
<     def show_report(self):
<         """prints the report and returns appropriate exitcode"""
<         # everything has been ran, print report
<         print "*" * 79
<         print self.report
<         return self.report.failures + self.report.errors
<         
< 
<     def testall(self, exitfirst=False):
<         """walks trhough current working directory, finds something
<         which can be considered as a testdir and runs every test there
<         """
<         for dirname, dirs, files in os.walk(os.getcwd()):
<             for skipped in ('CVS', '.svn', '.hg'):
<                 if skipped in dirs:
<                     dirs.remove(skipped)
<             basename = osp.basename(dirname)
<             if basename in ('test', 'tests'):
<                 print "going into", dirname
<                 # we found a testdir, let's explore it !
<                 self.testonedir(dirname, exitfirst)
<                 dirs[:] = []
< 
<  
<     def testonedir(self, testdir, exitfirst=False):
<         """finds each testfile in the `testdir` and runs it"""
<         for filename in abspath_listdir(testdir):
<             if this_is_a_testfile(filename):
<                 # run test and collect information
<                 prog = self.testfile(filename, batchmode=True)
<                 if exitfirst and (prog is None or not prog.result.wasSuccessful()):
<                     break
<         # clean local modules
<         remove_local_modules_from_sys(testdir)
< 
< 
<     def testfile(self, filename, batchmode=False):
<         """runs every test in `filename`
< 
<         :param filename: an absolute path pointing to a unittest file
<         """
<         here = os.getcwd()
<         dirname = osp.dirname(filename)
<         if dirname:
<             os.chdir(dirname)
<         modname = osp.basename(filename)[:-3]
<         try:
<             print >>sys.stderr, ('  %s  ' % osp.basename(filename)).center(70, '=')
<         except TypeError: # < py 2.4 bw compat
<             print >>sys.stderr, ('  %s  ' % osp.basename(filename)).center(70)
<         try:
<             try:
<                 tstart, cstart = time(), clock()
<                 testprog = testlib.unittest_main(modname, batchmode=batchmode, cvg=self.cvg,
<                                                  options=self.options)
<                 tend, cend = time(), clock()
<                 ttime, ctime = (tend - tstart), (cend - cstart)
<                 self.report.feed(filename, testprog.result, ttime, ctime)
<                 return testprog
<             except (KeyboardInterrupt, SystemExit):
<                 raise
<             except Exception, exc:
<                 self.report.failed_to_test_module(filename)
<                 print 'unhandled exception occured while testing', modname
<                 import traceback
<                 traceback.print_exc()
<                 return None                
<         finally:
<             if dirname:
<                 os.chdir(here)
< 
< 
< 
< class DjangoTester(PyTester):
< 
<     def load_django_settings(self, dirname):
<         """try to find project's setting and load it"""
<         curdir = osp.abspath(dirname)
<         previousdir = curdir
<         while not osp.isfile(osp.join(curdir, 'settings.py')) and \
<                   osp.isfile(osp.join(curdir, '__init__.py')):
<             newdir = osp.normpath(osp.join(curdir, os.pardir))
<             if newdir == curdir:
<                 raise AssertionError('could not find settings.py')
<             previousdir = curdir
<             curdir = newdir
<         # late django initialization
<         settings = load_module_from_modpath(modpath_from_file(osp.join(curdir, 'settings.py')))
<         from django.core.management import setup_environ
<         setup_environ(settings)
<         settings.DEBUG = False
<         self.settings = settings
<         # add settings dir to pythonpath since it's the project's root
<         if curdir not in sys.path:
<             sys.path.insert(1, curdir)
< 
<     def before_testfile(self):
<         # Those imports must be done **after** setup_environ was called
<         from django.test.utils import setup_test_environment
<         from django.test.utils import create_test_db
<         setup_test_environment()
<         create_test_db(verbosity=0)
<         self.dbname = self.settings.TEST_DATABASE_NAME
<         
< 
<     def after_testfile(self):
<         # Those imports must be done **after** setup_environ was called
<         from django.test.utils import teardown_test_environment
<         from django.test.utils import destroy_test_db
<         teardown_test_environment()
<         print 'destroying', self.dbname
<         destroy_test_db(self.dbname, verbosity=0)
<         
< 
<     def testall(self, exitfirst=False):
<         """walks trhough current working directory, finds something
<         which can be considered as a testdir and runs every test there
<         """
<         for dirname, dirs, files in os.walk(os.getcwd()):
<             for skipped in ('CVS', '.svn', '.hg'):
<                 if skipped in dirs:
<                     dirs.remove(skipped)
<             if 'tests.py' in files:
<                 self.testonedir(dirname, exitfirst)
<                 dirs[:] = []
<             else:
<                 basename = osp.basename(dirname)
<                 if basename in ('test', 'tests'):
<                     print "going into", dirname
<                     # we found a testdir, let's explore it !
<                     self.testonedir(dirname, exitfirst)
<                     dirs[:] = []
< 
< 
<     def testonedir(self, testdir, exitfirst=False):
<         """finds each testfile in the `testdir` and runs it"""
<         # special django behaviour : if tests are splited in several files,
<         # remove the main tests.py file and tests each test file separately
<         testfiles = [fpath for fpath in abspath_listdir(testdir)
<                      if this_is_a_testfile(fpath)]
<         if len(testfiles) > 1:
<             try:
<                 testfiles.remove(osp.join(testdir, 'tests.py'))
<             except ValueError:
<                 pass
<         for filename in testfiles:
<             # run test and collect information
<             prog = self.testfile(filename, batchmode=True)
<             if exitfirst and (prog is None or not prog.result.wasSuccessful()):
<                 break
<         # clean local modules
<         remove_local_modules_from_sys(testdir)
< 
< 
<     def testfile(self, filename, batchmode=False):
<         """runs every test in `filename`
< 
<         :param filename: an absolute path pointing to a unittest file
<         """
<         here = os.getcwd()
<         dirname = osp.dirname(filename)
<         if dirname:
<             os.chdir(dirname)
<         self.load_django_settings(dirname)
<         modname = osp.basename(filename)[:-3]
<         print >>sys.stderr, ('  %s  ' % osp.basename(filename)).center(70, '=')
<         try:
<             try:
<                 tstart, cstart = time(), clock()
<                 self.before_testfile()
<                 testprog = testlib.unittest_main(modname, batchmode=batchmode, cvg=self.cvg)
<                 tend, cend = time(), clock()
<                 ttime, ctime = (tend - tstart), (cend - cstart)
<                 self.report.feed(filename, testprog.result, ttime, ctime)
<                 return testprog
<             except SystemExit:
<                 raise
<             except Exception, exc:
<                 import traceback
<                 traceback.print_exc()
<                 self.report.failed_to_test_module(filename)
<                 print 'unhandled exception occured while testing', modname
<                 print 'error: %s' % exc
<                 return None                
<         finally:
<             self.after_testfile()
<             if dirname:
<                 os.chdir(here)
< 
< 
< def make_parser():
<     """creates the OptionParser instance
<     """
<     from optparse import OptionParser
<     parser = OptionParser(usage=PYTEST_DOC)
< 
<     parser.newargs = []
<     def rebuild_cmdline(option, opt, value, parser):
<         """carry the option to unittest_main"""
<         parser.newargs.append(opt)
<         
< 
<     def rebuild_and_store(option, opt, value, parser):
<         """carry the option to unittest_main and store
<         the value on current parser
<         """
<         parser.newargs.append(opt)
<         setattr(parser.values, option.dest, True)
< 
<     # pytest options
<     parser.add_option('-t', dest='testdir', default=None,
<                       help="directory where the tests will be found")
<     parser.add_option('-d', dest='dbc', default=False,
<                       action="store_true", help="enable design-by-contract")
<     # unittest_main options provided and passed through pytest
<     parser.add_option('-v', '--verbose', callback=rebuild_cmdline,
<                       action="callback", help="Verbose output")
<     parser.add_option('-i', '--pdb', callback=rebuild_and_store,
<                       dest="pdb", action="callback",
<                       help="Enable test failure inspection (conflicts with --coverage)")
<     parser.add_option('-x', '--exitfirst', callback=rebuild_and_store,
<                       dest="exitfirst",
<                       action="callback", help="Exit on first failure "
<                       "(only make sense when pytest run one test file)")
<     parser.add_option('-c', '--capture', callback=rebuild_cmdline,
<                       action="callback", 
<                       help="Captures and prints standard out/err only on errors "
<                       "(only make sense when pytest run one test file)")
<     parser.add_option('-p', '--printonly',
<                       # XXX: I wish I could use the callback action but it
<                       #      doesn't seem to be able to get the value
<                       #      associated to the option
<                       action="store", dest="printonly", default=None,
<                       help="Only prints lines matching specified pattern (implies capture) "
<                       "(only make sense when pytest run one test file)")
<     parser.add_option('-s', '--skip',
<                       # XXX: I wish I could use the callback action but it
<                       #      doesn't seem to be able to get the value
<                       #      associated to the option
<                       action="store", dest="skipped", default=None,
<                       help="test names matching this name will be skipped "
<                       "to skip several patterns, use commas")
<     parser.add_option('-q', '--quiet', callback=rebuild_cmdline,
<                       action="callback", help="Minimal output")
<     parser.add_option('-P', '--profile', default=None, dest='profile',
<                       help="Profile execution and store data in the given file")
< 
<     try:
<         from clonedigger.logilab.devtools.lib.coverage import Coverage
<         parser.add_option('--coverage', dest="coverage", default=False,
<                           action="store_true",
<                           help="run tests with pycoverage (conflicts with --pdb)")
<     except ImportError:
<         pass
< 
<     if DJANGO_FOUND:
<         parser.add_option('-J', '--django', dest='django', default=False,
<                           action="store_true",
<                           help='use pytest for django test cases')
<     return parser
< 
< 
< def parseargs(parser):
<     """Parse the command line and return (options processed), (options to pass to
<     unittest_main()), (explicitfile or None).
<     """
<     # parse the command line
<     options, args = parser.parse_args()
<     if options.pdb and getattr(options, 'coverage', False):
<         parser.error("'pdb' and 'coverage' options are exclusive")
<     filenames = [arg for arg in args if arg.endswith('.py')]
<     if filenames:
<         if len(filenames) > 1:
<             parser.error("only one filename is acceptable")
<         explicitfile = filenames[0]
<         args.remove(explicitfile)
<     else:
<         explicitfile = None
<     # someone wants DBC
<     testlib.ENABLE_DBC = options.dbc
<     newargs = parser.newargs
<     if options.printonly:
<         newargs.extend(['--printonly', options.printonly])
<     if options.skipped:
<         newargs.extend(['--skip', options.skipped])
<     # append additional args to the new sys.argv and let unittest_main
<     # do the rest
<     newargs += args
<     return options, explicitfile 
< 
< 
< 
< def run():
<     parser = make_parser()
<     rootdir, testercls = project_root(parser)
<     options, explicitfile = parseargs(parser)
<     # mock a new command line
<     sys.argv[1:] = parser.newargs
<     covermode = getattr(options, 'coverage', None)
<     cvg = None
<     if not '' in sys.path:
<         sys.path.insert(0, '')    
<     if covermode:
<         # control_import_coverage(rootdir)
<         from clonedigger.logilab.devtools.lib.coverage import Coverage
<         cvg = Coverage([rootdir])
<         cvg.erase()
<         cvg.start()
<     if DJANGO_FOUND and options.django:
<         tester = DjangoTester(cvg, options)
<     else:
<         tester = testercls(cvg, options)
<     if explicitfile:
<         cmd, args = tester.testfile, (explicitfile,)
<     elif options.testdir:
<         cmd, args = tester.testonedir, (options.testdir, options.exitfirst)
<     else:
<         cmd, args = tester.testall, (options.exitfirst,)
<     try:
<         try:
<             if options.profile:
<                 import hotshot
<                 prof = hotshot.Profile(options.profile)
<                 prof.runcall(cmd, *args)
<                 prof.close()
<                 print 'profile data saved in', options.profile
<             else:
<                  cmd(*args)           
<         except SystemExit:
<             raise
<         except:
<             import traceback
<             traceback.print_exc()
<     finally:
<         errcode = tester.show_report()
<         if covermode:
<             cvg.stop()
<             cvg.save()
<             here = osp.abspath(os.getcwd())
<             if this_is_a_testdir(here):
<                 morfdir = osp.normpath(osp.join(here, '..'))
<             else:
<                 morfdir = here
<             print "computing code coverage (%s), this might take some time" % \
<                   morfdir
<             cvg.annotate([morfdir])
<             cvg.report([morfdir], False)
<         sys.exit(errcode)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/shellutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/shellutils.py.svn-base
1,207d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< Some shell/term utilities, useful to write some python scripts instead of shell
< scripts
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< import os        
< import glob
< import shutil
< import sys
< import tempfile
< import time
< from os.path import exists, isdir, islink, basename, join, walk
< 
< from clonedigger.logilab.common import STD_BLACKLIST
< 
< 
< def chown(path, login=None, group=None):
<     """same as `os.chown` function but accepting user login or group name as
<     argument. If login or group is omitted, it's left unchanged.
< 
<     Note: you must own the file to chown it (or be root). Otherwise OSError is raised. 
<     """
<     if login is None:
<         uid = -1
<     else:
<         try:
<             uid = int(login)
<         except ValueError:
<             import pwd
<             uid = pwd.getpwnam(login).pw_uid
<     if group is None:
<         gid = -1
<     else:
<         try:
<             gid = int(group)
<         except ValueError:
<             import grp
<             gid = grp.getgrname(group).gr_gid
<     os.chown(path, uid, gid)
<         
< 
< def mv(source, destination, _action=shutil.move):
<     """a shell like mv, supporting wildcards
<     """
<     sources = glob.glob(source)
<     if len(sources) > 1:
<         assert isdir(destination)
<         for filename in sources:
<             _action(filename, join(destination, basename(filename)))
<     else:
<         try:
<             source = sources[0]
<         except IndexError:
<             raise OSError('No file matching %s' % source)
<         if isdir(destination) and exists(destination):
<             destination = join(destination, basename(source))
<         try:
<             _action(source, destination)
<         except OSError, ex:
<             raise OSError('Unable to move %r to %r (%s)' % (
<                 source, destination, ex))
<         
< def rm(*files):
<     """a shell like rm, supporting wildcards
<     """
<     for wfile in files:
<         for filename in glob.glob(wfile):
<             if islink(filename):
<                 os.remove(filename)
<             elif isdir(filename):
<                 shutil.rmtree(filename)
<             else:
<                 os.remove(filename)
<     
< def cp(source, destination):
<     """a shell like cp, supporting wildcards
<     """
<     mv(source, destination, _action=shutil.copy)
< 
< 
< def find(directory, exts, exclude=False, blacklist=STD_BLACKLIST):
<     """recursivly find files ending with the given extensions from the directory
< 
<     :type directory: str
<     :param directory:
<       directory where the search should start
< 
<     :type exts: basestring or list or tuple
<     :param exts:
<       extensions or lists or extensions to search
< 
<     :type exclude: boolean
<     :param exts:
<       if this argument is True, returning files NOT ending with the given
<       extensions
< 
<     :type blacklist: list or tuple
<     :param blacklist:
<       optional list of files or directory to ignore, default to the value of
<       `logilab.common.STD_BLACKLIST`
< 
<     :rtype: list
<     :return:
<       the list of all matching files
<     """
<     if isinstance(exts, basestring):
<         exts = (exts,)
<     if exclude:
<         def match(filename, exts):
<             for ext in exts:
<                 if filename.endswith(ext):
<                     return False
<             return True
<     else:
<         def match(filename, exts):
<             for ext in exts:
<                 if filename.endswith(ext):
<                     return True
<             return False
<     def func(files, directory, fnames):
<         """walk handler"""
<         # remove files/directories in the black list
<         for norecurs in blacklist:
<             try:
<                 fnames.remove(norecurs)
<             except ValueError:
<                 continue
<         for filename in fnames:
<             src = join(directory, filename)
<             if isdir(src):
<                 continue
<             if match(filename, exts):
<                 files.append(src)
<     files = []
<     walk(directory, func, files)
<     return files
< 
< 
< class Execute:
<     """This is a deadlock safe version of popen2 (no stdin), that returns
<     an object with errorlevel, out and err
<     """
<     
<     def __init__(self, command):
<         outfile = tempfile.mktemp()
<         errfile = tempfile.mktemp()
<         self.status = os.system("( %s ) >%s 2>%s" %
<                                 (command, outfile, errfile)) >> 8
<         self.out = open(outfile,"r").read()
<         self.err = open(errfile,"r").read()
<         os.remove(outfile)
<         os.remove(errfile)
< 
< 
< def acquire_lock(lock_file, max_try=10, delay=10):
<     """acquire a lock represented by a file on the file system"""
<     count = 0
<     while max_try <= 0 or count < max_try:
<         if not exists(lock_file):
<             break
<         count += 1
<         time.sleep(delay)
<     else:
<         raise Exception('Unable to acquire %s' % lock_file)
<     stream = open(lock_file, 'w')
<     stream.write(str(os.getpid()))
<     stream.close()
<     
< def release_lock(lock_file):
<     """release a lock represented by a file on the file system"""
<     os.remove(lock_file)
< 
< 
< class ProgressBar(object):
<     """a simple text progression bar"""
<     
<     def __init__(self, nbops, size=20., stream=sys.stdout):
<         self._dotevery = max(nbops / size, 1)
<         self._fstr = '\r[%-20s]'
<         self._dotcount, self._dots = 1, []
<         self._stream = stream
< 
<     def update(self):
<         """update the progression bar"""
<         self._dotcount += 1
<         if self._dotcount >= self._dotevery:
<             self._dotcount = 1
<             self._dots.append('.')
<             self._stream.write(self._fstr % ''.join(self._dots))
<             self._stream.flush()
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/sqlgen.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/sqlgen.py.svn-base
1,241d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Help to generate SQL string usable by the Python DB-API
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< __docformat__ = "restructuredtext en"
< 
< 
< # SQLGenerator ################################################################
< 
< class SQLGenerator :
<     """
<     Helper class to generate SQL strings to use with python's DB-API
<     """
< 
<     def where(self, keys, addon=None) :
<         """
<         keys : list of keys
<         
<         >>> s = SQLGenerator()
<         >>> s.where(['nom'])
<         'nom = %(nom)s'
<         >>> s.where(['nom','prenom'])
<         'nom = %(nom)s AND prenom = %(prenom)s'
<         >>> s.where(['nom','prenom'], 'x.id = y.id')
<         'x.id = y.id AND nom = %(nom)s AND prenom = %(prenom)s'
<         """
<         restriction = ["%s = %%(%s)s" % (x, x) for x in keys]
<         if addon:
<             restriction.insert(0, addon)
<         return " AND ".join(restriction)
< 
<     def set(self, keys) :
<         """
<         keys : list of keys
<         
<         >>> s = SQLGenerator()
<         >>> s.set(['nom'])
<         'nom = %(nom)s'
<         >>> s.set(['nom','prenom'])
<         'nom = %(nom)s, prenom = %(prenom)s'
<         """
<         return ", ".join(["%s = %%(%s)s" % (x, x) for x in keys])
< 
<     def insert(self, table, params) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
<         
<         >>> s = SQLGenerator()
<         >>> s.insert('test',{'nom':'dupont'})
<         'INSERT INTO test ( nom ) VALUES ( %(nom)s )'
<         >>> s.insert('test',{'nom':'dupont','prenom':'jean'})
<         'INSERT INTO test ( nom, prenom ) VALUES ( %(nom)s, %(prenom)s )'
<         """
<         keys = ', '.join(params.keys())
<         values = ', '.join(["%%(%s)s" % x for x in params])
<         sql = 'INSERT INTO %s ( %s ) VALUES ( %s )' % (table, keys, values)
<         return sql
< 
<     def select(self, table, params) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
< 
<         >>> s = SQLGenerator()
<         >>> s.select('test',{})
<         'SELECT * FROM test'
<         >>> s.select('test',{'nom':'dupont'})
<         'SELECT * FROM test WHERE nom = %(nom)s'
<         >>> s.select('test',{'nom':'dupont','prenom':'jean'})
<         'SELECT * FROM test WHERE nom = %(nom)s AND prenom = %(prenom)s'
<         """
<         sql = 'SELECT * FROM %s' % table
<         where = self.where(params.keys())
<         if where :
<             sql = sql + ' WHERE %s' % where
<         return sql
< 
<     def adv_select(self, model, tables, params, joins=None) :
<         """
<         model  : list of columns to select
<         tables : list of tables used in from
<         params   :  dictionnary that will be used as in cursor.execute(sql, params)
<         joins  : optional list of restriction statements to insert in the where
<                  clause. Usually used to perform joins.
< 
<         >>> s = SQLGenerator()
<         >>> s.adv_select(['column'],[('test', 't')], {})
<         'SELECT column FROM test AS t'
<         >>> s.adv_select(['column'],[('test', 't')], {'nom':'dupont'})
<         'SELECT column FROM test AS t WHERE nom = %(nom)s'
<         """
<         table_names = ["%s AS %s" % (k, v) for k, v in tables]
<         sql = 'SELECT %s FROM %s' % (', '.join(model), ', '.join(table_names))
<         if joins and type(joins) != type(''):
<             joins = ' AND '.join(joins)
<         where = self.where(params.keys(), joins)
<         if where :
<             sql = sql + ' WHERE %s' % where
<         return sql
< 
<     def delete(self, table, params) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
< 
<         >>> s = SQLGenerator()
<         >>> s.delete('test',{'nom':'dupont'})
<         'DELETE FROM test WHERE nom = %(nom)s'
<         >>> s.delete('test',{'nom':'dupont','prenom':'jean'})
<         'DELETE FROM test WHERE nom = %(nom)s AND prenom = %(prenom)s'
<         """
<         where = self.where(params.keys())
<         sql = 'DELETE FROM %s WHERE %s' % (table, where)
<         return sql
< 
<     def update(self, table, params, unique) :
<         """
<         table : name of the table
<         params :  dictionnary that will be used as in cursor.execute(sql,params)
< 
<         >>> s = SQLGenerator()
<         >>> s.update('test', {'id':'001','nom':'dupont'}, ['id'])
<         'UPDATE test SET nom = %(nom)s WHERE id = %(id)s'
<         >>> s.update('test',{'id':'001','nom':'dupont','prenom':'jean'},['id'])
<         'UPDATE test SET nom = %(nom)s, prenom = %(prenom)s WHERE id = %(id)s'
<         """
<         where = self.where(unique)
<         set = self.set([key for key in params if key not in unique])
<         sql = 'UPDATE %s SET %s WHERE %s' % (table, set, where)
<         return sql
< 
< class BaseTable:
<     """
<     Another helper class to ease SQL table manipulation
<     """
<     # table_name = "default"
<     # supported types are s/i/d
<     # table_fields = ( ('first_field','s'), )
<     # primary_key = 'first_field'
< 
<     def __init__(self, table_name, table_fields, primary_key=None):
<         if primary_key is None:
<             self._primary_key = table_fields[0][0]
<         else:
<             self._primary_key = primary_key
< 
<         self._table_fields = table_fields
<         self._table_name = table_name
<         info = {
<             'key' : self._primary_key,
<             'table' : self._table_name,
<             'columns' : ",".join( [ f for f,t in self._table_fields ] ),
<             'values' : ",".join( [sql_repr(t, "%%(%s)s" % f)
<                                   for f,t in self._table_fields] ),
<             'updates' : ",".join( ["%s=%s" % (f, sql_repr(t, "%%(%s)s" % f))
<                                    for f,t in self._table_fields] ),
<             }
<         self._insert_stmt = ("INSERT into %(table)s (%(columns)s) "
<                              "VALUES (%(values)s) WHERE %(key)s=%%(key)s") % info
<         self._update_stmt = ("UPDATE %(table)s SET (%(updates)s) "
<                              "VALUES WHERE %(key)s=%%(key)s") % info
<         self._select_stmt = ("SELECT %(columns)s FROM %(table)s "
<                              "WHERE %(key)s=%%(key)s") % info
<         self._delete_stmt = ("DELETE FROM %(table)s "
<                              "WHERE %(key)s=%%(key)s") % info
< 
<         for k, t in table_fields:
<             if hasattr(self, k):
<                 raise ValueError("Cannot use %s as a table field" % k)
<             setattr(self, k,None)
< 
< 
<     def as_dict(self):
<         d = {}
<         for k, t in self._table_fields:
<             d[k] = getattr(self, k)
<         return d
< 
<     def select(self, cursor):
<         d = { 'key' : getattr(self,self._primary_key) }
<         cursor.execute(self._select_stmt % d)
<         rows = cursor.fetchall()
<         if len(rows)!=1:
<             msg = "Select: ambiguous query returned %d rows"
<             raise ValueError(msg % len(rows))
<         for (f, t), v in zip(self._table_fields, rows[0]):
<             setattr(self, f, v)
< 
<     def update(self, cursor):
<         d = self.as_dict()
<         cursor.execute(self._update_stmt % d)
< 
<     def delete(self, cursor):
<         d = { 'key' : getattr(self,self._primary_key) }
< 
< 
< # Helper functions #############################################################
< 
< def name_fields(cursor, records) :
<     """
<     Take a cursor and a list of records fetched with that cursor, then return a
<     list of dictionnaries (one for each record) whose keys are column names and
<     values are records' values.
< 
<     cursor : cursor used to execute the query
<     records : list returned by fetch*()
<     """
<     result = []
<     for record in records :
<         record_dict = {}
<         for i in range(len(record)) :
<             record_dict[cursor.description[i][0]] = record[i]
<         result.append(record_dict)
<     return result
< 
< def sql_repr(type, val):
<     if type == 's':
<         return "'%s'" % (val,)
<     else:
<         return val
<             
<         
< if __name__ == "__main__":
<     import doctest
<     from clonedigger.logilab.common import sqlgen
<     print doctest.testmod(sqlgen)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/table.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/table.py.svn-base
1,958d0
< """Table management module
< """
< 
< __revision__ = '$Id: table.py,v 1.18 2006-04-09 22:30:53 nico Exp $'
< 
< from warnings import warn
< 
< from clonedigger.logilab.common.compat import enumerate, sum, set
< 
< class Table(object):
<     """Table defines a data table with column and row names.
<     inv:
<         len(self.data) <= len(self.row_names)
<         forall(self.data, lambda x: len(x) <= len(self.col_names))
<     """
< 
<     def __init__(self, default_value=0, col_names=None, row_names=None):
<         self.col_names = []
<         self.row_names = []
<         self.data = []
<         self.default_value = default_value
<         if col_names:
<             self.create_columns(col_names)
<         if row_names:
<             self.create_rows(row_names)
<         
<     def _next_row_name(self):
<         return 'row%s' % (len(self.row_names)+1)
< 
<     def __iter__(self):
<         return iter(self.data)
<     
<     def __eq__(self, other):
<         if other is None:
<             return False
<         else:
<             return list(self) == list(other)
< 
<     def __ne__(self, other):
<         return not self == other
< 
<     def __len__(self):
<         return len(self.row_names)
<     
<     ## Rows / Columns creation #################################################
<     def create_rows(self, row_names):
<         """Appends row_names to the list of existing rows
<         """
<         self.row_names.extend(row_names)
<         for row_name in row_names:
<             self.data.append([self.default_value]*len(self.col_names))
<         
<     def create_columns(self, col_names):
<         """Appends col_names to the list of existing columns
<         """
<         for col_name in col_names:
<             self.create_column(col_name)
< 
<     def create_row(self, row_name=None):
<         """Creates a rowname to the row_names list
<         """
<         row_name = row_name or self._next_row_name()
<         self.row_names.append(row_name)
<         self.data.append([self.default_value]*len(self.col_names))
< 
<     
<     def create_column(self, col_name):
<         """Creates a colname to the col_names list
<         """
<         self.col_names.append(col_name)
<         for row in self.data:
<             row.append(self.default_value)
< 
<     ## Sort by column ##########################################################
<     def sort_by_column_id(self, col_id, method = 'asc'):
<         """Sorts the table (in-place) according to data stored in col_id
<         """
<         try:
<             col_index = self.col_names.index(col_id)
<             self.sort_by_column_index(col_index, method)
<         except ValueError:
<             raise KeyError("Col (%s) not found in table" % (col_id))
<         
< 
<     def sort_by_column_index(self, col_index, method = 'asc'):
<         """Sorts the table 'in-place' according to data stored in col_index
< 
<         method should be in ('asc', 'desc')
<         """
<         sort_list = [(row[col_index], row, row_name)
<                      for row, row_name in zip(self.data, self.row_names)]
<         # Sorting sort_list will sort according to col_index
<         sort_list.sort()
<         # If we want reverse sort, then reverse list
<         if method.lower() == 'desc':
<             sort_list.reverse()
<         
<         # Rebuild data / row names
<         self.data = []
<         self.row_names = []
<         for val, row, row_name in sort_list:
<             self.data.append(row)
<             self.row_names.append(row_name)
< 
<     def groupby(self, colname, *others):
<         """builds indexes of data
<         :returns: nested dictionnaries pointing to actual rows
<         """
<         groups = {}
<         colnames = (colname,) + others
<         col_indexes = [self.col_names.index(col_id) for col_id in colnames]
<         for row in self.data:
<             ptr = groups
<             for col_index in col_indexes[:-1]:
<                 ptr = ptr.setdefault(row[col_index], {})
<             ptr = ptr.setdefault(row[col_indexes[-1]],
<                                  Table(default_value=self.default_value,
<                                        col_names=self.col_names))
<             ptr.append_row(tuple(row))
<         return groups
< 
<     def select(self, colname, value):
<         grouped = self.groupby(colname)
<         try:
<             return grouped[value]
<         except KeyError:
<             return []
< 
<     def remove(self, colname, value):
<         col_index = self.col_names.index(colname)
<         for row in self.data[:]:
<             if row[col_index] == value:
<                 self.data.remove(row)
<         
<     
<     ## The 'setter' part #######################################################
<     def set_cell(self, row_index, col_index, data):
<         """sets value of cell 'row_indew', 'col_index' to data
<         """
<         self.data[row_index][col_index] = data
<         
< 
<     def set_cell_by_ids(self, row_id, col_id, data):
<         """sets value of cell mapped by row_id and col_id to data
<         Raises a KeyError if row_id or col_id are not found in the table
<         """
<         try:
<             row_index = self.row_names.index(row_id)
<         except ValueError:
<             raise KeyError("Row (%s) not found in table" % (row_id))
<         else:
<             try:
<                 col_index = self.col_names.index(col_id)
<                 self.data[row_index][col_index] = data
<             except ValueError:
<                 raise KeyError("Column (%s) not found in table" % (col_id))
<     
<     
<     def set_row(self, row_index, row_data):
<         """sets the 'row_index' row
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.col_names)
<         """
<         self.data[row_index] = row_data
< 
<         
<     def set_row_by_id(self, row_id, row_data):
<         """sets the 'row_id' column
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.row_names)
<         Raises a KeyError if row_id is not found
<         """
<         try:
<             row_index = self.row_names.index(row_id)
<             self.set_row(row_index, row_data)
<         except ValueError:
<             raise KeyError('Row (%s) not found in table' % (row_id))
<         
< 
<     def append_row(self, row_data, row_name=None):
<         """Appends a row to the table
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.col_names)
<         """
<         row_name = row_name or self._next_row_name()
<         self.row_names.append(row_name)
<         self.data.append(row_data)
<         return len(self.data) - 1
< 
<     def insert_row(self, index, row_data, row_name=None):
<         """Appends row_data before 'index' in the table. To make 'insert'
<         behave like 'list.insert', inserting in an out of range index will
<         insert row_data to the end of the list
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.col_names)
<         """
<         row_name = row_name or self._next_row_name()
<         self.row_names.insert(index, row_name)
<         self.data.insert(index, row_data)
<     
< 
<     def delete_row(self, index):
<         """Deletes the 'index' row in the table, and returns it.
<         Raises an IndexError if index is out of range
<         """
<         self.row_names.pop(index)
<         return self.data.pop(index)
<         
< 
<     def delete_row_by_id(self, row_id):
<         """Deletes the 'row_id' row in the table.
<         Raises a KeyError if row_id was not found.
<         """
<         try:
<             row_index = self.row_names.index(row_id)
<             self.delete_row(row_index)
<         except ValueError:
<             raise KeyError('Row (%s) not found in table' % (row_id))
<     
< 
<     def set_column(self, col_index, col_data):
<         """sets the 'col_index' column
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.row_names)
<         """
<         
<         for row_index, cell_data in enumerate(col_data):
<             self.data[row_index][col_index] = cell_data
< 
< 
<     def set_column_by_id(self, col_id, col_data):
<         """sets the 'col_id' column
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.col_names)
<         Raises a KeyError if col_id is not found
<         """
<         try:
<             col_index = self.col_names.index(col_id)
<             self.set_column(col_index, col_data)
<         except ValueError:
<             raise KeyError('Column (%s) not found in table' % (col_id))
<         
< 
<     def append_column(self, col_data, col_name):
<         """Appends the 'col_index' column
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.row_names)
<         """
<         self.col_names.append(col_name)
<         for row_index, cell_data in enumerate(col_data):
<             self.data[row_index].append(cell_data)
<         
< 
<     def insert_column(self, index, col_data, col_name):
<         """Appends col_data before 'index' in the table. To make 'insert'
<         behave like 'list.insert', inserting in an out of range index will
<         insert col_data to the end of the list
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.row_names)
<         """
<         self.col_names.insert(index, col_name)
<         for row_index, cell_data in enumerate(col_data):
<             self.data[row_index].insert(index, cell_data)
<         
< 
<     def delete_column(self, index):
<         """Deletes the 'index' column in the table, and returns it.
<         Raises an IndexError if index is out of range
<         """
<         self.col_names.pop(index)
<         return [row.pop(index) for row in self.data]
< 
< 
<     def delete_column_by_id(self, col_id):
<         """Deletes the 'col_id' col in the table.
<         Raises a KeyError if col_id was not found.
<         """
<         try:
<             col_index = self.col_names.index(col_id)
<             self.delete_column(col_index)
<         except ValueError:
<             raise KeyError('Column (%s) not found in table' % (col_id))
< 
<     
<     ## The 'getter' part #######################################################
< 
<     def get_shape(self):
<         """Returns a tuple which represents the table's shape
<         """    
<         return len(self.row_names), len(self.col_names)
<     shape = property(get_shape)
<     
<     def __getitem__(self, indices):
<         """provided for convenience"""
<         rows, multirows = None, False
<         cols, multicols = None, False
<         if isinstance(indices, tuple):
<             rows = indices[0]
<             if len(indices) > 1:
<                 cols = indices[1]
<         else:
<             rows = indices
<         # define row slice
<         if isinstance(rows,str):
<             try:
<                 rows = self.row_names.index(rows)
<             except ValueError:
<                 raise KeyError("Row (%s) not found in table" % (rows))
<         if isinstance(rows,int):
<             rows = slice(rows,rows+1)
<             multirows = False
<         else:
<             rows = slice(None)
<             multirows = True
<         # define col slice
<         if isinstance(cols,str):
<             try:
<                 cols = self.col_names.index(cols)
<             except ValueError:
<                 raise KeyError("Column (%s) not found in table" % (cols))
<         if isinstance(cols,int):
<             cols = slice(cols,cols+1)
<             multicols = False
<         else:
<             cols = slice(None)
<             multicols = True
<         # get sub-table
<         tab = Table()
<         tab.default_value = self.default_value
<         tab.create_rows(self.row_names[rows])
<         tab.create_columns(self.col_names[cols])
<         for idx,row in enumerate(self.data[rows]):
<             tab.set_row(idx, row[cols])
<         if multirows :
<             if multicols:
<                 return tab
<             else:
<                 return [item[0] for item in tab.data]
<         else:
<             if multicols:
<                 return tab.data[0]
<             else:
<                 return tab.data[0][0]
< 
<     def get_dimensions(self):
<         """Returns a tuple which represents the table's shape
<         """
<         warn('table.get_dimensions() is deprecated, use table.shape instead',
<              DeprecationWarning, stacklevel=2)
<         return self.shape
< 
<     def get_element(self, row_index, col_index):
<         """Returns the element at [row_index][col_index]
<         """
<         warn('Table.get_element() is deprecated, use Table.get_cell instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data[row_index][col_index]
< 
<     def get_cell(self, row_index, col_index):
<         warn('table.get_cell(i,j) is deprecated, use table[i,j] instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data[row_index][col_index]
<         
<     def get_cell_by_ids(self, row_id, col_id):
<         """Returns the element at [row_id][col_id]
<         """
<         #warn('table.get_cell_by_ids(i,j) is deprecated, use table[i,j] instead',
<         #     DeprecationWarning, stacklevel=2)
<         try:
<             row_index = self.row_names.index(row_id)
<         except ValueError:
<             raise KeyError("Row (%s) not found in table" % (row_id))
<         else:
<             try:
<                 col_index = self.col_names.index(col_id)
<             except ValueError:
<                 raise KeyError("Column (%s) not found in table" % (col_id))
<         return self.data[row_index][col_index]
< 
<     def get_row(self, row_index):
<         """Returns the 'row_index' row
<         """
<         warn('table.get_row(i) is deprecated, use table[i] instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data[row_index]
< 
<     def get_row_by_id(self, row_id):
<         """Returns the 'row_id' row
<         """
<         #warn('table.get_row_by_id(i) is deprecated, use table[i] instead',
<         #     DeprecationWarning, stacklevel=2)
<         try:
<             row_index = self.row_names.index(row_id)
<         except ValueError:
<             raise KeyError("Row (%s) not found in table" % (row_id))
<         return self.data[row_index]
< 
<     def get_column(self, col_index, distinct=False):
<         """Returns the 'col_index' col
<         """
<         warn('table.get_column(i) is deprecated, use table[:,i] instead',
<              DeprecationWarning, stacklevel=2)
<         col = [row[col_index] for row in self.data]
<         if distinct:
<             return set(col)
<         else:
<             return col
<     
<     def get_column_by_id(self, col_id, distinct=False):
<         """Returns the 'col_id' col
<         """
<         #warn('table.get_column_by_id(i) is deprecated, use table[:,i] instead',
<         #     DeprecationWarning, stacklevel=2)
<         try:
<             col_index = self.col_names.index(col_id)
<         except ValueError:
<             raise KeyError("Column (%s) not found in table" % (col_id))
<         return self.get_column(col_index, distinct)
<     
< 
<     def get_rows(self):
<         """Returns all the rows in the table
<         """
<         warn('table.get_rows() is deprecated, just iterate over table instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data
< 
< 
<     def get_columns(self):
<         """Returns all the columns in the table
<         """
<         return [self[:,index] for index in range(len(self.col_names))]
< 
<     
<     def apply_stylesheet(self, stylesheet):
<         """Applies the stylesheet to this table
<         """
<         for instruction in stylesheet.instructions:
<             eval(instruction)
<         
< 
<     def transpose(self):
<         """Keeps the self object intact, and returns the transposed (rotated)
<         table.
<         """
<         transposed = Table()
<         transposed.create_rows(self.col_names)
<         transposed.create_columns(self.row_names)
<         for col_index, column in enumerate(self.get_columns()):
<             transposed.set_row(col_index, column)
<         return transposed
< 
< 
<     def pprint(self):
<         """returns a string representing the table in a pretty
<         printed 'text' format.
<         """
<         # The maxium row name (to know the start_index of the first col)
<         max_row_name = 0
<         for row_name in self.row_names:
<             if len(row_name) > max_row_name:
<                 max_row_name = len(row_name)
<         col_start = max_row_name + 5
< 
<         lines = []
<         # Build the 'first' line <=> the col_names one
<         # The first cell <=> an empty one
<         col_names_line = [' '*col_start]
<         for col_name in self.col_names:
<             col_names_line.append(col_name.encode('iso-8859-1') + ' '*5)
<         lines.append('|' + '|'.join(col_names_line) + '|')
<         max_line_length = len(lines[0])
< 
<         # Build the table
<         for row_index, row in enumerate(self.data):
<             line = []
<             # First, build the row_name's cell
<             row_name = self.row_names[row_index].encode('iso-8859-1')
<             line.append(row_name + ' '*(col_start-len(row_name)))
< 
<             # Then, build all the table's cell for this line.
<             for col_index, cell in enumerate(row):
<                 col_name_length = len(self.col_names[col_index]) + 5
<                 data = str(cell)
<                 line.append(data + ' '*(col_name_length - len(data)))
<             lines.append('|' + '|'.join(line) + '|')
<             if len(lines[-1]) > max_line_length:
<                 max_line_length = len(lines[-1])
< 
<         # Wrap the table with '-' to make a frame
<         lines.insert(0, '-'*max_line_length)
<         lines.append('-'*max_line_length)
<         return '\n'.join(lines)
<     
< 
<     def __repr__(self):
<         return repr(self.data)
< 
<     def as_text(self):
<         data = []
<         # We must convert cells into strings before joining them
<         for row in self.data:
<             data.append([str(cell) for cell in row])
<         lines = ['\t'.join(row) for row in data]
<         return '\n'.join(lines)
<     
< 
<     
< class TableStyle:
<     """Defines a table's style
<     """
< 
<     def __init__(self, table):
< 
<         self._table = table
<         self.size = dict([(col_name,'1*') for col_name in table.col_names])
<         # __row_column__ is a special key to define the first column which
<         # actually has no name (<=> left most column <=> row names column)
<         self.size['__row_column__'] = '1*'
<         self.alignment = dict([(col_name,'right')
<                                for col_name in table.col_names])
<         self.alignment['__row_column__'] = 'right'
< 
<         # We shouldn't have to create an entry for
<         # the 1st col (the row_column one)
<         self.units = dict([(col_name,'') for col_name in table.col_names])
<         self.units['__row_column__'] = '' 
<        
<     # XXX FIXME : params order should be reversed for all set() methods
<     def set_size(self, value, col_id):
<         """sets the size of the specified col_id to value
<         """
<         self.size[col_id] = value
< 
<     def set_size_by_index(self, value, col_index):
<         """Allows to set the size according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         self.size[col_id] = value
< 
< 
<     def set_alignment(self, value, col_id):
<         """sets the alignment of the specified col_id to value
<         """
<         self.alignment[col_id] = value
< 
< 
<     def set_alignment_by_index(self, value, col_index):
<         """Allows to set the alignment according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         self.alignment[col_id] = value
< 
< 
<     def set_unit(self, value, col_id):
<         """sets the unit of the specified col_id to value
<         """
<         self.units[col_id] = value
< 
<     
<     def set_unit_by_index(self, value, col_index):
<         """Allows to set the unit according to the column index rather than
<         using the column's id.
<         BE CAREFUL :  the '0' column is the '__row_column__' one !
<         (Note that in the 'unit' case, you shouldn't have to set a unit
<         for the 1st column (the __row__column__ one))
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         self.units[col_id] = value
<     
< 
<     def get_size(self, col_id):
<         """Returns the size of the specified col_id
<         """
<         return self.size[col_id]
<     
< 
<     def get_size_by_index(self, col_index):
<         """Allows to get the size  according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         return self.size[col_id]
< 
< 
<     def get_alignment(self, col_id):
<         """Returns the alignment of the specified col_id
<         """
<         return self.alignment[col_id]
< 
< 
<     def get_alignment_by_index(self, col_index):
<         """Allors to get the alignment according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         return self.alignment[col_id]
< 
< 
<     def get_unit(self, col_id):
<         """Returns the unit of the specified col_id
<         """
<         return self.units[col_id]
< 
< 
<     def get_unit_by_index(self, col_index):
<         """Allors to get the unit according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         return self.units[col_id]
< 
< 
< import re    
< CELL_PROG = re.compile("([0-9]+)_([0-9]+)")
< 
< class TableStyleSheet:
<     """A simple Table stylesheet
<     Rules are expressions where cells are defined by the row_index
<     and col_index separated by an underscore ('_').
<     For example, suppose you want to say that the (2,5) cell must be
<     the sum of its two preceding cells in the row, you would create
<     the following rule :
<         2_5 = 2_3 + 2_4
<     You can also use all the math.* operations you want. For example:
<         2_5 = sqrt(2_3**2 + 2_4**2)    
<     """
<     
<     def __init__(self, rules = None):
<         rules = rules or []
<         self.rules = []
<         self.instructions = []
<         for rule in rules:
<             self.add_rule(rule)
< 
< 
<     def add_rule(self, rule):
<         """Adds a rule to the stylesheet rules
<         """
<         try:
<             source_code = ['from math import *']
<             source_code.append(CELL_PROG.sub(r'self.data[\1][\2]', rule))
<             self.instructions.append(compile('\n'.join(source_code),
<                 'table.py', 'exec'))
<             self.rules.append(rule)
<         except SyntaxError:
<             print "Bad Stylesheet Rule : %s [skipped]"%rule
< 
<     
<     def add_rowsum_rule(self, dest_cell, row_index, start_col, end_col):
<         """Creates and adds a rule to sum over the row at row_index from
<         start_col to end_col.
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_col >= 0
<             end_col > start_col
<         """
<         cell_list = ['%d_%d'%(row_index, index) for index in range(start_col,
<                                                                    end_col + 1)]
<         rule = '%d_%d=' % dest_cell + '+'.join(cell_list)
<         self.add_rule(rule)
<             
< 
<     def add_rowavg_rule(self, dest_cell, row_index, start_col, end_col):
<         """Creates and adds a rule to make the row average (from start_col
<         to end_col)
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_col >= 0
<             end_col > start_col
<         """
<         cell_list = ['%d_%d'%(row_index, index) for index in range(start_col,
<                                                                    end_col + 1)]
<         num = (end_col - start_col + 1)
<         rule = '%d_%d=' % dest_cell + '('+'+'.join(cell_list)+')/%f'%num
<         self.add_rule(rule)
<         
< 
<     def add_colsum_rule(self, dest_cell, col_index, start_row, end_row):
<         """Creates and adds a rule to sum over the col at col_index from
<         start_row to end_row.
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_row >= 0
<             end_row > start_row
<         """        
<         cell_list = ['%d_%d'%(index, col_index) for index in range(start_row,
<                                                                    end_row + 1)]
<         rule = '%d_%d=' % dest_cell + '+'.join(cell_list)
<         self.add_rule(rule)
<         
<     
<     def add_colavg_rule(self, dest_cell, col_index, start_row, end_row):
<         """Creates and adds a rule to make the col average (from start_row
<         to end_row)
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_row >= 0
<             end_row > start_row
<         """
<         cell_list = ['%d_%d'%(index, col_index) for index in range(start_row,
<                                                                    end_row + 1)]
<         num = (end_row - start_row + 1)
<         rule = '%d_%d=' % dest_cell + '('+'+'.join(cell_list)+')/%f'%num
<         self.add_rule(rule)
< 
< 
< 
< class TableCellRenderer:
<     """Defines a simple text renderer
<     """
< 
<     def __init__(self, **properties):
<         """keywords should be properties with an associated boolean as value.
<         For example :
<             renderer = TableCellRenderer(units = True, alignment = False)
<         An unspecified property will have a 'False' value by default.
<         Possible properties are :
<             alignment, unit
<         """
<         self.properties = properties
< 
< 
<     def render_cell(self, cell_coord, table, table_style):
<         """Renders the cell at 'cell_coord' in the table, using table_style
<         """
<         row_index, col_index = cell_coord
<         cell_value = table.data[row_index][col_index]
<         final_content = self._make_cell_content(cell_value,
<                                                 table_style, col_index  +1)
<         return self._render_cell_content(final_content,
<                                          table_style, col_index + 1)
<         
< 
<     def render_row_cell(self, row_name, table, table_style):
<         """Renders the cell for 'row_id' row
<         """
<         cell_value = row_name.encode('iso-8859-1')
<         return self._render_cell_content(cell_value, table_style, 0)
< 
< 
<     def render_col_cell(self, col_name, table, table_style):
<         """Renders the cell for 'col_id' row
<         """
<         cell_value = col_name.encode('iso-8859-1')
<         col_index = table.col_names.index(col_name)
<         return self._render_cell_content(cell_value, table_style, col_index +1)
< 
<     
< 
<     def _render_cell_content(self, content, table_style, col_index):
<         """Makes the appropriate rendering for this cell content.
<         Rendering properties will be searched using the
<         *table_style.get_xxx_by_index(col_index)' methods
< 
<         **This method should be overridden in the derived renderer classes.**
<         """
<         return content
< 
<     
<     def _make_cell_content(self, cell_content, table_style, col_index):
<         """Makes the cell content (adds decoration data, like units for
<         example)
<         """
<         final_content = cell_content
<         if 'skip_zero' in self.properties:
<             replacement_char = self.properties['skip_zero']
<         else:
<             replacement_char = 0
<         if replacement_char and final_content == 0:
<             return replacement_char
<         
<         try:
<             units_on = self.properties['units']
<             if units_on:
<                 final_content = self._add_unit(
<                     cell_content, table_style, col_index)
<         except KeyError:
<             pass
<         
<         return final_content
<         
<         
<     def _add_unit(self, cell_content, table_style, col_index):
<         """Adds unit to the cell_content if needed
<         """
<         unit = table_style.get_unit_by_index(col_index)
<         return str(cell_content) + " " + unit
<         
<         
< 
< class DocbookRenderer(TableCellRenderer):
<     """Defines how to render a cell for a docboook table
<     """
< 
<     def define_col_header(self, col_index, table_style):
<         """Computes the colspec element according to the style
<         """
<         size = table_style.get_size_by_index(col_index)
<         return '<colspec colname="c%d" colwidth="%s"/>\n' % \
<                (col_index, size)
<     
<         
<     def _render_cell_content(self, cell_content, table_style, col_index):
<         """Makes the appropriate rendering for this cell content.
<         Rendering properties will be searched using the
<         *table_style.get_xxx_by_index(col_index)' methods.
<         """
<         try:
<             align_on = self.properties['alignment']
<             alignment = table_style.get_alignment_by_index(col_index)
<             if align_on:
<                 return "<entry align='%s'>%s</entry>\n" % \
<                        (alignment, cell_content)
<         except KeyError:
<             # KeyError <=> Default alignment
<             return "<entry>%s</entry>\n" % cell_content
< 
< 
< class TableWriter:
<     """A class to write tables
<     """
<     
<     def __init__(self, stream, table, style, **properties):
<         self._stream = stream
<         self.style = style or TableStyle(table)
<         self._table = table
<         self.properties = properties
<         self.renderer = None
<         
< 
<     def set_style(self, style):
<         """sets the table's associated style
<         """
<         self.style = style
< 
< 
<     def set_renderer(self, renderer):
<         """sets the way to render cell
<         """
<         self.renderer = renderer
<     
<         
<     def update_properties(self, **properties):
<         """Updates writer's properties (for cell rendering)
<         """
<         self.properties.update(properties)
< 
< 
<     def write_table(self, title = ""):
<         """Writes the table
<         """
<         raise NotImplementedError("write_table must be implemented !")
<         
< 
< 
< class DocbookTableWriter(TableWriter):
<     """Defines an implementation of TableWriter to write a table in Docbook
<     """
< 
<     def _write_headers(self):
<         """Writes col headers
<         """
<         # Define col_headers (colstpec elements)
<         for col_index in range(len(self._table.col_names)+1):
<             self._stream.write(self.renderer.define_col_header(col_index,
<                                                               self.style))
<         
<         self._stream.write("<thead>\n<row>\n")
<         # XXX FIXME : write an empty entry <=> the first (__row_column) column
<         self._stream.write('<entry></entry>\n')
<         for col_name in self._table.col_names:
<             self._stream.write(self.renderer.render_col_cell(
<                 col_name, self._table,
<                 self.style))
<             
<         self._stream.write("</row>\n</thead>\n")
< 
< 
<     def _write_body(self):
<         """Writes the table body
<         """
<         self._stream.write('<tbody>\n')
<         
<         for row_index, row in enumerate(self._table.data):
<             self._stream.write('<row>\n')
<             row_name = self._table.row_names[row_index]
<             # Write the first entry (row_name)
<             self._stream.write(self.renderer.render_row_cell(row_name,
<                                                             self._table,
<                                                             self.style))
<             
<             for col_index, cell in enumerate(row):
<                 self._stream.write(self.renderer.render_cell(
<                     (row_index, col_index),
<                     self._table, self.style))
<                 
<             self._stream.write('</row>\n')
<             
<         self._stream.write('</tbody>\n')
< 
< 
<     def write_table(self, title = ""):
<         """Writes the table
<         """
<         self._stream.write('<table>\n<title>%s></title>\n'%(title))
<         self._stream.write(
<             '<tgroup cols="%d" align="left" colsep="1" rowsep="1">\n'%
<             (len(self._table.col_names)+1))
<         self._write_headers()
<         self._write_body()
<         
<         self._stream.write('</tgroup>\n</table>\n')
< 
<     
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/testlib.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/testlib.py.svn-base
1,1446d0
< # modified copy of some functions from test/regrtest.py from PyXml
< """Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr  
< 
< Run tests.
< 
< This will find all modules whose name match a given prefix in the test
< directory, and run them.  Various command line options provide
< additional facilities.
< 
< Command line options:
< 
< -v: verbose -- run tests in verbose mode with output to stdout
< -q: quiet -- don't print anything except if a test fails
< -t: testdir -- directory where the tests will be found
< -x: exclude -- add a test to exclude
< -p: profile -- profiled execution
< -c: capture -- capture standard out/err during tests
< -d: dbc     -- enable design-by-contract
< 
< If no non-option arguments are present, prefixes used are 'test',
< 'regrtest', 'smoketest' and 'unittest'.
< 
< """
< import sys
< import os, os.path as osp
< import re
< import time
< import getopt
< import traceback
< import unittest
< import difflib
< import types
< from warnings import warn
< from compiler.consts import CO_GENERATOR
< try:
<     import readline
< except ImportError:
<     readline = None
< 
< # PRINT_ = file('stdout.txt', 'w').write
< 
< try:
<     from test import test_support
< except ImportError:
<     # not always available
<     class TestSupport:
<         def unload(self, test):
<             pass
<     test_support = TestSupport()
< 
< from clonedigger.logilab.common.deprecation import class_renamed, deprecated_function, \
<      obsolete
< from clonedigger.logilab.common.compat import set, enumerate, any
< from clonedigger.logilab.common.modutils import load_module_from_name
< from clonedigger.logilab.common.debugger import Debugger
< from clonedigger.logilab.common.decorators import cached
< 
< __all__ = ['main', 'unittest_main', 'find_tests', 'run_test', 'spawn']
< 
< DEFAULT_PREFIXES = ('test', 'regrtest', 'smoketest', 'unittest',
<                     'func', 'validation')
< 
< ENABLE_DBC = False
< 
< def main(testdir=None, exitafter=True):
<     """Execute a test suite.
< 
<     This also parses command-line options and modifies its behaviour
<     accordingly.
< 
<     tests -- a list of strings containing test names (optional)
<     testdir -- the directory in which to look for tests (optional)
< 
<     Users other than the Python test suite will certainly want to
<     specify testdir; if it's omitted, the directory containing the
<     Python test suite is searched for.
< 
<     If the tests argument is omitted, the tests listed on the
<     command-line will be used.  If that's empty, too, then all *.py
<     files beginning with test_ will be used.
< 
<     """
< 
<     try:
<         opts, args = getopt.getopt(sys.argv[1:], 'hvqx:t:pcd', ['help'])
<     except getopt.error, msg:
<         print msg
<         print __doc__
<         return 2
<     verbose = 0
<     quiet = False
<     profile = False
<     exclude = []
<     capture = 0
<     for o, a in opts:
<         if o == '-v':
<             verbose += 1
<         elif o == '-q':
<             quiet = True
<             verbose = 0
<         elif o == '-x':
<             exclude.append(a)
<         elif o == '-t':
<             testdir = a
<         elif o == '-p':
<             profile = True
<         elif o == '-c':
<             capture += 1
<         elif o == '-d':
<             global ENABLE_DBC
<             ENABLE_DBC = True
<         elif o in ('-h', '--help'):
<             print __doc__
<             sys.exit(0)
< 
<     args = [item.rstrip('.py') for item in args]
<     exclude = [item.rstrip('.py') for item in exclude]
< 
<     if testdir is not None:
<         os.chdir(testdir)
<     sys.path.insert(0, '')
<     tests = find_tests('.', args or DEFAULT_PREFIXES, excludes=exclude)
<     # Tell tests to be moderately quiet
<     test_support.verbose = verbose
<     if profile:
<         print >> sys.stderr, '** profiled run'
<         from hotshot import Profile
<         prof = Profile('stones.prof')
<         start_time, start_ctime = time.time(), time.clock()
<         good, bad, skipped, all_result = prof.runcall(run_tests, tests, quiet,
<                                                       verbose, None, capture)
<         end_time, end_ctime = time.time(), time.clock()
<         prof.close()
<     else:
<         start_time, start_ctime = time.time(), time.clock()
<         good, bad, skipped, all_result = run_tests(tests, quiet, verbose, None, capture)
<         end_time, end_ctime = time.time(), time.clock()
<     if not quiet:
<         print '*'*80
<         if all_result:
<             print 'Ran %s test cases in %0.2fs (%0.2fs CPU)' % (all_result.testsRun,
<                                                                 end_time - start_time,
<                                                                 end_ctime - start_ctime), 
<             if all_result.errors:
<                 print ', %s errors' % len(all_result.errors),
<             if all_result.failures:
<                 print ', %s failed' % len(all_result.failures),
<             if all_result.skipped:
<                 print ', %s skipped' % len(all_result.skipped),
<             print
<         if good:
<             if not bad and not skipped and len(good) > 1:
<                 print "All",
<             print _count(len(good), "test"), "OK."
<         if bad:
<             print _count(len(bad), "test"), "failed:",
<             print ', '.join(bad)
<         if skipped:
<             print _count(len(skipped), "test"), "skipped:",
<             print ', '.join(['%s (%s)' % (test, msg) for test, msg in skipped])
<     if profile:
<         from hotshot import stats
<         stats = stats.load('stones.prof')
<         stats.sort_stats('time', 'calls')
<         stats.print_stats(30)
<     if exitafter:
<         sys.exit(len(bad) + len(skipped))
<     else:
<         sys.path.pop(0)
<         return len(bad)
< main = obsolete("testlib.main() is obsolete, use the pytest tool instead")(main)
< 
< 
< def run_tests(tests, quiet, verbose, runner=None, capture=0):
<     """ execute a list of tests
<     return a 3-uple with :
<        _ the list of passed tests
<        _ the list of failed tests
<        _ the list of skipped tests
<     """
<     good = []
<     bad = []
<     skipped = []
<     all_result = None
<     for test in tests:
<         if not quiet:
<             print 
<             print '-'*80
<             print "Executing", test
<         result = run_test(test, verbose, runner, capture)
<         if type(result) is type(''):
<             # an unexpected error occured
<             skipped.append( (test, result))
<         else:
<             if all_result is None:
<                 all_result = result
<             else:
<                 all_result.testsRun += result.testsRun
<                 all_result.failures += result.failures
<                 all_result.errors += result.errors
<                 all_result.skipped += result.skipped
<             if result.errors or result.failures:
<                 bad.append(test)
<                 if verbose:
<                     print "test", test, \
<                           "failed -- %s errors, %s failures" % (
<                         len(result.errors), len(result.failures))
<             else:
<                 good.append(test)
<             
<     return good, bad, skipped, all_result
<     
< def find_tests(testdir,
<                prefixes=DEFAULT_PREFIXES, suffix=".py",
<                excludes=(),
<                remove_suffix=True):
<     """
<     Return a list of all applicable test modules.
<     """
<     tests = []
<     for name in os.listdir(testdir):
<         if not suffix or name.endswith(suffix):
<             for prefix in prefixes:
<                 if name.startswith(prefix):
<                     if remove_suffix and name.endswith(suffix):
<                         name = name[:-len(suffix)]
<                     if name not in excludes:
<                         tests.append(name)
<     tests.sort()
<     return tests
< 
< 
< def run_test(test, verbose, runner=None, capture=0):
<     """
<     Run a single test.
< 
<     test -- the name of the test
<     verbose -- if true, print more messages
<     """
<     test_support.unload(test)
<     try:
<         m = load_module_from_name(test, path=sys.path)
< #        m = __import__(test, globals(), locals(), sys.path)
<         try:
<             suite = m.suite
<             if callable(suite):
<                 suite = suite()
<         except AttributeError:
<             loader = unittest.TestLoader()
<             suite = loader.loadTestsFromModule(m)
<         if runner is None:
<             runner = SkipAwareTextTestRunner(capture=capture) # verbosity=0)
<         return runner.run(suite)
<     except KeyboardInterrupt, v:
<         raise KeyboardInterrupt, v, sys.exc_info()[2]
<     except:
<         # raise
<         type, value = sys.exc_info()[:2]
<         msg = "test %s crashed -- %s : %s" % (test, type, value)
<         if verbose:
<             traceback.print_exc()
<         return msg
< 
< def _count(n, word):
<     """format word according to n"""
<     if n == 1:
<         return "%d %s" % (n, word)
<     else:
<         return "%d %ss" % (n, word)
< 
< 
<     
< 
< ## PostMortem Debug facilities #####
< def start_interactive_mode(result):
<     """starts an interactive shell so that the user can inspect errors
<     """
<     debuggers = result.debuggers
<     descrs = result.error_descrs + result.fail_descrs
<     if len(debuggers) == 1:
<         # don't ask for test name if there's only one failure
<         debuggers[0].start()
<     else:
<         while True:
<             testindex = 0
<             print "Choose a test to debug:"
<             # order debuggers in the same way than errors were printed
<             print "\n".join(['\t%s : %s' % (i, descr) for i, (_, descr) in enumerate(descrs)])
<             print "Type 'exit' (or ^D) to quit"
<             print
<             try:
<                 todebug = raw_input('Enter a test name: ')
<                 if todebug.strip().lower() == 'exit':
<                     print
<                     break
<                 else:
<                     try:
<                         testindex = int(todebug)
<                         debugger = debuggers[descrs[testindex][0]]
<                     except (ValueError, IndexError):
<                         print "ERROR: invalid test number %r" % (todebug,)
<                     else:
<                         debugger.start()
<             except (EOFError, KeyboardInterrupt):
<                 print
<                 break
< 
< 
< # test utils ##################################################################
< from cStringIO import StringIO
< 
< class SkipAwareTestResult(unittest._TextTestResult):
< 
<     def __init__(self, stream, descriptions, verbosity,
<                  exitfirst=False, capture=0, printonly=None,
<                  pdbmode=False, cvg=None):
<         super(SkipAwareTestResult, self).__init__(stream,
<                                                   descriptions, verbosity)
<         self.skipped = []
<         self.debuggers = []
<         self.fail_descrs = []
<         self.error_descrs = []
<         self.exitfirst = exitfirst
<         self.capture = capture
<         self.printonly = printonly
<         self.pdbmode = pdbmode
<         self.cvg = cvg
<         self.pdbclass = Debugger
< 
<     def descrs_for(self, flavour):
<         return getattr(self, '%s_descrs' % flavour.lower())
<     
<     def _create_pdb(self, test_descr, flavour):
<         self.descrs_for(flavour).append( (len(self.debuggers), test_descr) )
<         if self.pdbmode:
<             self.debuggers.append(self.pdbclass(sys.exc_info()[2]))
<         
<     def addError(self, test, err):
<         exc_type, exc, tcbk = err
<         if exc_type == TestSkipped:
<             self.addSkipped(test, exc)
<         else:
<             if self.exitfirst:
<                 self.shouldStop = True
<             descr = self.getDescription(test)
<             super(SkipAwareTestResult, self).addError(test, err)
<             self._create_pdb(descr, 'error')
< 
<     def addFailure(self, test, err):
<         if self.exitfirst:
<             self.shouldStop = True
<         descr = self.getDescription(test)
<         super(SkipAwareTestResult, self).addFailure(test, err)
<         self._create_pdb(descr, 'fail')
< 
<     def addSkipped(self, test, reason):
<         self.skipped.append((test, self.getDescription(test), reason))
<         if self.showAll:
<             self.stream.writeln("SKIPPED")
<         elif self.dots:
<             self.stream.write('S')
< 
<     def printErrors(self):
<         super(SkipAwareTestResult, self).printErrors()
<         self.printSkippedList()
<         
<     def printSkippedList(self):
<         for test, descr, err in self.skipped:
<             self.stream.writeln(self.separator1)
<             self.stream.writeln("%s: %s" % ('SKIPPED', descr))
<             self.stream.writeln("\t%s" % err)
< 
<     def printErrorList(self, flavour, errors):
<         for (_, descr), (test, err) in zip(self.descrs_for(flavour), errors):
<             self.stream.writeln(self.separator1)
<             self.stream.writeln("%s: %s" % (flavour, descr))
<             self.stream.writeln(self.separator2)
<             self.stream.writeln("%s" % err)
<             try:
<                 output, errput = test.captured_output()
<             except AttributeError:
<                 pass # original unittest
<             else:
<                 if output:
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln("captured stdout".center(len(self.separator2)))
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln(output)
<                 else:
<                     self.stream.writeln('no stdout'.center(len(self.separator2)))
<                 if errput:
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln("captured stderr".center(len(self.separator2)))
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln(errput)
<                 else:
<                     self.stream.writeln('no stderr'.center(len(self.separator2)))
< 
< 
< 
< class TestSuite(unittest.TestSuite):
<     def run(self, result, runcondition=None, options=None):
<         for test in self._tests:
<             if result.shouldStop:
<                 break
<             test(result, runcondition, options)
<         return result
<     
<     # python2.3 compat
<     def __call__(self, *args, **kwds):
<         return self.run(*args, **kwds)
< 
< 
< class SkipAwareTextTestRunner(unittest.TextTestRunner):
< 
<     def __init__(self, stream=sys.stderr, verbosity=1,
<                  exitfirst=False, capture=False, printonly=None,
<                  pdbmode=False, cvg=None, test_pattern=None, skipped_patterns=(),
<                  options=None):
<         super(SkipAwareTextTestRunner, self).__init__(stream=stream,
<                                                       verbosity=verbosity)
<         self.exitfirst = exitfirst
<         self.capture = capture
<         self.printonly = printonly
<         self.pdbmode = pdbmode
<         self.cvg = cvg
<         self.test_pattern = test_pattern
<         self.skipped_patterns = skipped_patterns
<         self.options = options
< 
<     def _this_is_skipped(self, testedname):
<         return any([(pat in testedname) for pat in self.skipped_patterns])
< 
<     def _runcondition(self, test, skipgenerator=True):
<         if isinstance(test, InnerTest):
<             testname = test.name
<         else:
<             if isinstance(test, TestCase):
<                 meth = test._get_test_method()
<                 func = meth.im_func
<                 testname = '%s.%s' % (meth.im_class.__name__, func.__name__)
<             elif isinstance(test, types.FunctionType):
<                 func = test
<                 testname = func.__name__
<             elif isinstance(test, types.MethodType):
<                 func = test.im_func
<                 testname = '%s.%s' % (test.im_class.__name__, func.__name__)
<             else:
<                 return True # Not sure when this happens
<             if is_generator(func) and skipgenerator:
<                 return True # Let inner tests decide at run time
<         # print 'testname', testname, self.test_pattern
<         if self._this_is_skipped(testname):
<             return False # this was explicitly skipped
<         if self.test_pattern is None:
<             return True # no pattern
<         try:
<             classpattern, testpattern = self.test_pattern.split('.')
<             klass, name = testname.split('.')
<             return classpattern in klass and testpattern in name
<         except ValueError:
<             return self.test_pattern in testname
<     
<     def _makeResult(self):
<         return SkipAwareTestResult(self.stream, self.descriptions, self.verbosity,
<                                    self.exitfirst, self.capture, self.printonly,
<                                    self.pdbmode, self.cvg)
< 
<     def run(self, test):
<         "Run the given test case or test suite."
<         result = self._makeResult()
<         startTime = time.time()
<         test(result, self._runcondition, self.options)
<         stopTime = time.time()
<         timeTaken = stopTime - startTime
<         result.printErrors()
<         self.stream.writeln(result.separator2)
<         run = result.testsRun
<         self.stream.writeln("Ran %d test%s in %.3fs" %
<                             (run, run != 1 and "s" or "", timeTaken))
<         self.stream.writeln()
<         if not result.wasSuccessful():
<             self.stream.write("FAILED (")
<             failed, errored = map(len, (result.failures, result.errors))
<             if failed:
<                 self.stream.write("failures=%d" % failed)
<             if errored:
<                 if failed: self.stream.write(", ")
<                 self.stream.write("errors=%d" % errored)
<             self.stream.writeln(")")
<         else:
<             self.stream.writeln("OK")
<         return result
< 
< 
< class keywords(dict):
<     """keyword args (**kwargs) support for generative tests"""
< 
< class starargs(tuple):
<     """variable arguments (*args) for generative tests"""
<     def __new__(cls, *args):
<         return tuple.__new__(cls, args)
< 
< 
< 
< class NonStrictTestLoader(unittest.TestLoader):
<     """
<     overrides default testloader to be able to omit classname when
<     specifying tests to run on command line. For example, if the file
<     test_foo.py contains ::
<     
<         class FooTC(TestCase):
<             def test_foo1(self): # ...
<             def test_foo2(self): # ...
<             def test_bar1(self): # ...
< 
<         class BarTC(TestCase):
<             def test_bar2(self): # ...
< 
<     python test_foo.py will run the 3 tests in FooTC
<     python test_foo.py FooTC will run the 3 tests in FooTC
<     python test_foo.py test_foo will run test_foo1 and test_foo2
<     python test_foo.py test_foo1 will run test_foo1
<     python test_foo.py test_bar will run FooTC.test_bar1 and BarTC.test_bar2
<     """
<     suiteClass = TestSuite
< 
<     def __init__(self):
<         self.skipped_patterns = []
< 
<     def loadTestsFromNames(self, names, module=None):
<         suites = []
<         for name in names:
<             suites.extend(self.loadTestsFromName(name, module))
<         return self.suiteClass(suites)
< 
<     def _collect_tests(self, module):
<         tests = {}
<         for obj in vars(module).values():
<             if (issubclass(type(obj), (types.ClassType, type)) and
<                  issubclass(obj, unittest.TestCase)):
<                 classname = obj.__name__
<                 if self._this_is_skipped(classname):
<                     continue
<                 methodnames = []
<                 # obj is a TestCase class
<                 for attrname in dir(obj):
<                     if attrname.startswith(self.testMethodPrefix):
<                         attr = getattr(obj, attrname)
<                         if callable(attr):
<                             methodnames.append(attrname)
<                 # keep track of class (obj) for convenience
<                 tests[classname] = (obj, methodnames)
<         return tests
< 
<     def loadTestsFromSuite(self, module, suitename):
<         try:
<             suite = getattr(module, suitename)()
<         except AttributeError:
<             return []
<         assert hasattr(suite, '_tests'), \
<                "%s.%s is not a valid TestSuite" % (module.__name__, suitename)
<         # python2.3 does not implement __iter__ on suites, we need to return
<         # _tests explicitly
<         return suite._tests
<     
<     def loadTestsFromName(self, name, module=None):
<         parts = name.split('.')
<         if module is None or len(parts) > 2:
<             # let the base class do its job here
<             return [super(NonStrictTestLoader, self).loadTestsFromName(name)]
<         tests = self._collect_tests(module)
<         # import pprint
<         # pprint.pprint(tests)
<         collected = []
<         if len(parts) == 1:
<             pattern = parts[0]
<             if callable(getattr(module, pattern, None)) and pattern not in tests:
<                 # consider it as a suite
<                 return self.loadTestsFromSuite(module, pattern)
<             if pattern in tests:
<                 # case python unittest_foo.py MyTestTC
<                 klass, methodnames = tests[pattern]
<                 for methodname in methodnames:
<                     collected = [klass(methodname) for methodname in methodnames]
<             else:
<                 # case python unittest_foo.py something
<                 for klass, methodnames in tests.values():
<                     collected += [klass(methodname) for methodname in methodnames]
<         elif len(parts) == 2:
<             # case "MyClass.test_1"
<             classname, pattern = parts
<             klass, methodnames = tests.get(classname, (None, []))
<             for methodname in methodnames:
<                 collected = [klass(methodname) for methodname in methodnames]
<         return collected
< 
<     def _this_is_skipped(self, testedname):
<         return any([(pat in testedname) for pat in self.skipped_patterns])
< 
<     def getTestCaseNames(self, testCaseClass):
<         """Return a sorted sequence of method names found within testCaseClass
<         """
<         is_skipped = self._this_is_skipped
<         if is_skipped(testCaseClass.__name__):
<             return []
<         testnames = super(NonStrictTestLoader, self).getTestCaseNames(testCaseClass)
<         return [testname for testname in testnames if not is_skipped(testname)]
< 
<     
< class SkipAwareTestProgram(unittest.TestProgram):
<     # XXX: don't try to stay close to unittest.py, use optparse
<     USAGE = """\
< Usage: %(progName)s [options] [test] [...]
< 
< Options:
<   -h, --help       Show this message
<   -v, --verbose    Verbose output
<   -i, --pdb        Enable test failure inspection
<   -x, --exitfirst  Exit on first failure
<   -c, --capture    Captures and prints standard out/err only on errors
<   -p, --printonly  Only prints lines matching specified pattern (implies capture)
<   -s, --skip       skip test matching this pattern (no regexp for now)
<   -q, --quiet      Minimal output
< 
< Examples:
<   %(progName)s                               - run default set of tests
<   %(progName)s MyTestSuite                   - run suite 'MyTestSuite'
<   %(progName)s MyTestCase.testSomething      - run MyTestCase.testSomething
<   %(progName)s MyTestCase                    - run all 'test*' test methods
<                                                in MyTestCase
< """
<     def __init__(self, module='__main__', defaultTest=None, batchmode=False,
<                  cvg=None, options=None):
<         self.batchmode = batchmode
<         self.cvg = cvg
<         self.options = options
<         super(SkipAwareTestProgram, self).__init__(
<             module=module, defaultTest=defaultTest,
<             testLoader=NonStrictTestLoader())
<     
<     def parseArgs(self, argv):
<         self.pdbmode = False
<         self.exitfirst = False
<         self.capture = 0
<         self.printonly = None
<         self.skipped_patterns = []
<         self.test_pattern = None
<         import getopt
<         try:
<             options, args = getopt.getopt(argv[1:], 'hHvixqcp:s:',
<                                           ['help','verbose','quiet', 'pdb',
<                                            'exitfirst', 'capture', 'printonly=',
<                                            'skip='])
<             for opt, value in options:
<                 if opt in ('-h','-H','--help'):
<                     self.usageExit()
<                 if opt in ('-i', '--pdb'):
<                     self.pdbmode = True
<                 if opt in ('-x', '--exitfirst'):
<                     self.exitfirst = True
<                 if opt in ('-q','--quiet'):
<                     self.verbosity = 0
<                 if opt in ('-v','--verbose'):
<                     self.verbosity = 2
<                 if opt in ('-c', '--capture'):
<                     self.capture += 1
<                 if opt in ('-p', '--printonly'):
<                     self.printonly = re.compile(value)
<                 if opt in ('-s', '--skip'):
<                     self.skipped_patterns = [pat.strip() for pat in value.split(',')]
<             self.testLoader.skipped_patterns = self.skipped_patterns
<             if self.printonly is not None:
<                 self.capture += 1
<             if len(args) == 0 and self.defaultTest is None:
<                 suitefunc = getattr(self.module, 'suite', None)
<                 if isinstance(suitefunc, (types.FunctionType, types.MethodType)):
<                     self.test = self.module.suite()
<                 else:
<                     self.test = self.testLoader.loadTestsFromModule(self.module)
<                 return
<             if len(args) > 0:
<                 self.test_pattern = args[0]
<                 self.testNames = args
<             else:
<                 self.testNames = (self.defaultTest,)
<             self.createTests()
<         except getopt.error, msg:
<             self.usageExit(msg)
< 
< 
<     def runTests(self):
<         if hasattr(self.module, 'setup_module'):
<             try:
<                 self.module.setup_module(self.options)
<             except Exception, exc:
<                 print 'setup_module error:', exc
<                 sys.exit(1)
<         self.testRunner = SkipAwareTextTestRunner(verbosity=self.verbosity,
<                                                   exitfirst=self.exitfirst,
<                                                   capture=self.capture,
<                                                   printonly=self.printonly,
<                                                   pdbmode=self.pdbmode,
<                                                   cvg=self.cvg,
<                                                   test_pattern=self.test_pattern,
<                                                   skipped_patterns=self.skipped_patterns,
<                                                   options=self.options)
<         result = self.testRunner.run(self.test)
<         if hasattr(self.module, 'teardown_module'):
<             try:
<                 self.module.teardown_module(self.options)
<             except Exception, exc:
<                 print 'teardown_module error:', exc
<                 sys.exit(1)
<         if os.environ.get('PYDEBUG'):
<             warn("PYDEBUG usage is deprecated, use -i / --pdb instead", DeprecationWarning)
<             self.pdbmode = True
<         if result.debuggers and self.pdbmode:
<             start_interactive_mode(result)
<         if not self.batchmode:
<             sys.exit(not result.wasSuccessful())
<         self.result = result
< 
< 
< 
< 
< class FDCapture: 
<     """adapted from py lib (http://codespeak.net/py)
<     Capture IO to/from a given os-level filedescriptor.
<     """
<     def __init__(self, fd, attr='stdout', printonly=None):
<         self.targetfd = fd
<         self.tmpfile = os.tmpfile() # self.maketempfile()
<         self.printonly = printonly
<         # save original file descriptor
<         self._savefd = os.dup(fd)
<         # override original file descriptor
<         os.dup2(self.tmpfile.fileno(), fd)
<         # also modify sys module directly
<         self.oldval = getattr(sys, attr)
<         setattr(sys, attr, self) # self.tmpfile)
<         self.attr = attr
< 
<     def write(self, msg):
<         # msg might be composed of several lines
<         for line in msg.splitlines():
<             line += '\n' # keepdend=True is not enough
<             if self.printonly is None or self.printonly.search(line) is None:
<                 self.tmpfile.write(line)
<             else:
<                 os.write(self._savefd, line)
<         
< ##     def maketempfile(self):
< ##         tmpf = os.tmpfile()
< ##         fd = os.dup(tmpf.fileno())
< ##         newf = os.fdopen(fd, tmpf.mode, 0) # No buffering
< ##         tmpf.close()
< ##         return newf
<         
<     def restore(self):
<         """restore original fd and returns captured output"""
<         # hack hack hack
<         self.tmpfile.flush()
<         try:
<             ref_file = getattr(sys, '__%s__' % self.attr)
<             ref_file.flush()
<         except AttributeError:
<             pass
<         if hasattr(self.oldval, 'flush'):
<             self.oldval.flush()
<         # restore original file descriptor
<         os.dup2(self._savefd, self.targetfd)
<         # restore sys module
<         setattr(sys, self.attr, self.oldval)
<         # close backup descriptor
<         os.close(self._savefd)
<         # go to beginning of file and read it
<         self.tmpfile.seek(0)
<         return self.tmpfile.read()
< 
< 
< def _capture(which='stdout', printonly=None):
<     """private method, should not be called directly
<     (cf. capture_stdout() and capture_stderr())
<     """
<     assert which in ('stdout', 'stderr'), "Can only capture stdout or stderr, not %s" % which
<     if which == 'stdout':
<         fd = 1
<     else:
<         fd = 2
<     return FDCapture(fd, which, printonly)
<     
< def capture_stdout(printonly=None):
<     """captures the standard output
< 
<     returns a handle object which has a `restore()` method.
<     The restore() method returns the captured stdout and restores it
<     """
<     return _capture('stdout', printonly)
<         
< def capture_stderr(printonly=None):
<     """captures the standard error output
< 
<     returns a handle object which has a `restore()` method.
<     The restore() method returns the captured stderr and restores it
<     """
<     return _capture('stderr', printonly)
< 
< 
< def unittest_main(module='__main__', defaultTest=None,
<                   batchmode=False, cvg=None, options=None):
<     """use this functon if you want to have the same functionality
<     as unittest.main"""
<     return SkipAwareTestProgram(module, defaultTest, batchmode, cvg, options)
< 
< class TestSkipped(Exception):
<     """raised when a test is skipped"""
< 
< def is_generator(function):
<     flags = function.func_code.co_flags
<     return flags & CO_GENERATOR
< 
< 
< def parse_generative_args(params):
<     args = []
<     varargs = ()
<     kwargs = {}
<     flags = 0 # 2 <=> starargs, 4 <=> kwargs
<     for param in params:
<         if isinstance(param, starargs):
<             varargs = param
<             if flags:
<                 raise TypeError('found starargs after keywords !')
<             flags |= 2
<             args += list(varargs)
<         elif isinstance(param, keywords):
<             kwargs = param
<             if flags & 4:
<                 raise TypeError('got multiple keywords parameters')
<             flags |= 4
<         elif flags & 2 or flags & 4:
<             raise TypeError('found parameters after kwargs or args')
<         else:
<             args.append(param)
< 
<     return args, kwargs
< 
< class InnerTest(tuple):
<     def __new__(cls, name, *data):
<         instance = tuple.__new__(cls, data)
<         instance.name = name
<         return instance
< 
< class ClassGetProperty(object):
<     """this is a simple property-like class but for
<     class attributes.
<     """
<     
<     def __init__(self, getter):
<         self.getter = getter
< 
<     def __get__(self, obj, objtype):
<         return self.getter(objtype)
< 
< 
< class TestCase(unittest.TestCase):
<     """unittest.TestCase with some additional methods"""
< 
<     capture = False
<     pdbclass = Debugger
<     
<     def __init__(self, methodName='runTest'):
<         super(TestCase, self).__init__(methodName)
<         # internal API changed in python2.5
<         if sys.version_info >= (2, 5):
<             self.__exc_info = self._exc_info
<             self.__testMethodName = self._testMethodName
<         else:
<             # let's give easier access to _testMethodName to every subclasses
<             self._testMethodName = self.__testMethodName
<         self._captured_stdout = ""
<         self._captured_stderr = ""
<         self._out = []
<         self._err = []
<         self._current_test_descr = None
<         self._options_ = None
< 
<     def datadir(cls):
<         """helper attribute holding the standard test's data directory
<         
<         NOTE: this is a logilab's standard
<         """
<         mod = __import__(cls.__module__)
<         return osp.join(osp.dirname(osp.abspath(mod.__file__)), 'data')
<     # cache it (use a class method to cache on class since TestCase is
<     # instantiated for each test run)
<     datadir = ClassGetProperty(cached(datadir))
< 
<     def datapath(self, fname):
<         """joins the object's datadir and `fname`"""
<         return osp.join(self.datadir, fname)
< 
<     def set_description(self, descr):
<         """sets the current test's description.
<         This can be useful for generative tests because it allows to specify
<         a description per yield
<         """
<         self._current_test_descr = descr
< 
<     # override default's unittest.py feature
<     def shortDescription(self):
< 	"""override default unitest shortDescription to handle correctly
< 	generative tests
< 	"""
<         if self._current_test_descr is not None:
< 	    return self._current_test_descr
< 	return super(TestCase, self).shortDescription()
< 
<     
<     def captured_output(self):
<         return self._captured_stdout.strip(), self._captured_stderr.strip()
< 
<     def _start_capture(self):
<         if self.capture:
<             self.start_capture()
< 
<     def _stop_capture(self):
<         self._force_output_restore()
<     
<     def start_capture(self, printonly=None):
<         self._out.append(capture_stdout(printonly or self._printonly))
<         self._err.append(capture_stderr(printonly or self._printonly))
< 
<     def printonly(self, pattern, flags=0):
<         rgx = re.compile(pattern, flags)
<         if self._out:
<             self._out[-1].printonly = rgx
<             self._err[-1].printonly = rgx
<         else:
<             self.start_capture(printonly=rgx)
<         
<     def stop_capture(self):
<         if self._out:
<             _out = self._out.pop()
<             _err = self._err.pop()
<             return _out.restore(), _err.restore()
<         return '', ''
<     
<     def _force_output_restore(self):
<         while self._out:
<             self._captured_stdout += self._out.pop().restore()
<             self._captured_stderr += self._err.pop().restore()
<     
<     def quiet_run(self, result, func, *args, **kwargs):
<         self._start_capture()
<         try:
<             func(*args, **kwargs)
<         except (KeyboardInterrupt, SystemExit):
<             self._stop_capture()
<             raise
<         except:
<             self._stop_capture()
<             result.addError(self, self.__exc_info())
<             return False
<         self._stop_capture()
<         return True
< 
<     def _get_test_method(self):
<         return getattr(self, self.__testMethodName)
< 
< 
<     def optval(self, option, default=None):
<         return getattr(self._options_, option, default)
< 
<     def __call__(self, result=None, runcondition=None, options=None):
<         """rewrite TestCase.__call__ to support generative tests
<         This is mostly a copy/paste from unittest.py (i.e same
<         variable names, same logic, except for the generative tests part)
<         """
<         if result is None:
<             result = self.defaultTestResult()
<         result.pdbclass = self.pdbclass
<         # if self.capture is True here, it means it was explicitly specified
<         # in the user's TestCase class. If not, do what was asked on cmd line
<         self.capture = self.capture or getattr(result, 'capture', False)
<         self._options_ = options
<         self._printonly = getattr(result, 'printonly', None)
<         # if result.cvg:
<         #     result.cvg.start()
<         testMethod = self._get_test_method()
<         if runcondition and not runcondition(testMethod):
<             return # test is skipped
<         result.startTest(self)
<         try:
<             if not self.quiet_run(result, self.setUp):
<                 return
<             # generative tests
<             if is_generator(testMethod.im_func):
<                 success = self._proceed_generative(result, testMethod, runcondition)
<             else:
<                 status = self._proceed(result, testMethod)
<                 success = (status == 0)
<             if not self.quiet_run(result, self.tearDown):
<                 return
<             if success:
<                 result.addSuccess(self)
<         finally:
<             # if result.cvg:
<             #     result.cvg.stop()
<             result.stopTest(self)
< 
< 
<             
<     def _proceed_generative(self, result, testfunc, runcondition=None):
<         # cancel startTest()'s increment
<         result.testsRun -= 1
<         self._start_capture()
<         success = True
<         try:
<             for params in testfunc():
<                 if runcondition and not runcondition(testfunc, skipgenerator=False):
<                     if not (isinstance(params, InnerTest) and runcondition(params)):
<                         continue
<                 if not isinstance(params, (tuple, list)):
<                     params = (params,)
<                 func = params[0]
<                 args, kwargs = parse_generative_args(params[1:])
<                 # increment test counter manually
<                 result.testsRun += 1
<                 status = self._proceed(result, func, args, kwargs)
<                 if status == 0:
<                     result.addSuccess(self)
<                     success = True
<                 else:
<                     success = False
<                     if status == 2:
<                         result.shouldStop = True
<                 if result.shouldStop: # either on error or on exitfirst + error
<                     break
<         except:
<             # if an error occurs between two yield
<             result.addError(self, self.__exc_info())
<             success = False
<         self._stop_capture()
<         return success
< 
<     def _proceed(self, result, testfunc, args=(), kwargs=None):
<         """proceed the actual test
<         returns 0 on success, 1 on failure, 2 on error
< 
<         Note: addSuccess can't be called here because we have to wait
<         for tearDown to be successfully executed to declare the test as
<         successful
<         """
<         self._start_capture()
<         kwargs = kwargs or {}
<         try:
<             testfunc(*args, **kwargs)
<             self._stop_capture()
<         except self.failureException:
<             self._stop_capture()
<             result.addFailure(self, self.__exc_info())
<             return 1
<         except KeyboardInterrupt:
<             self._stop_capture()
<             raise
<         except:
<             self._stop_capture()
<             result.addError(self, self.__exc_info())
<             return 2
<         return 0
<             
<     def defaultTestResult(self):
<         return SkipAwareTestResult()
< 
<     def skip(self, msg=None):
<         msg = msg or 'test was skipped'
<         raise TestSkipped(msg)
<     skipped_test = deprecated_function(skip)
<     
<     def assertDictEquals(self, d1, d2):
<         """compares two dicts
< 
<         If the two dict differ, the first difference is shown in the error
<         message
<         """
<         d1 = d1.copy()
<         msgs = []
<         for key, value in d2.items():
<             try:
<                 if d1[key] != value:
<                     msgs.append('%r != %r for key %r' % (d1[key], value, key))
<                 del d1[key]
<             except KeyError:
<                 msgs.append('missing %r key' % key)
<         if d1:
<             msgs.append('d2 is lacking %r' % d1)
<         if msgs:
<             self.fail('\n'.join(msgs))
<     assertDictEqual = assertDictEquals
< 
<     def assertSetEquals(self, got, expected, msg=None):
<         """compares two iterables and shows difference between both"""
<         got, expected = list(got), list(expected)
<         if msg is None:
< 	        msg1 = '%s != %s' % (got, expected)
<         else:
<             msg1 = msg
<         self.assertEquals(len(got), len(expected), msg1)
<         got, expected = set(got), set(expected)
<         if got != expected:
<             missing = expected - got
<             unexpected = got - expected
<             if msg is None:
<                 msg = '\tunexepected: %s\n\tmissing: %s' % (unexpected,
<                                                                missing)
<             self.fail(msg)
<     assertSetEqual = assertSetEquals
< 
<     def assertListEquals(self, l1, l2, msg=None):
<         """compares two lists
< 
<         If the two list differ, the first difference is shown in the error
<         message
<         """
<         _l1 = l1[:]
<         for i, value in enumerate(l2):
<             try:
<                 if _l1[0] != value:
<                     from pprint import pprint
<                     pprint(l1)
<                     pprint(l2)
<                     self.fail('%r != %r for index %d' % (_l1[0], value, i))
<                 del _l1[0]
<             except IndexError:
<                 if msg is None:
<                     msg = 'l1 has only %d elements, not %s (at least %r missing)'% (i, len(l2), value)
<                 self.fail(msg)
<         if _l1:
<             if msg is None:
<                 msg = 'l2 is lacking %r' % _l1
<             self.fail(msg)
<     assertListEqual = assertListEquals
<     
<     def assertLinesEquals(self, l1, l2, msg=None):
<         """assert list of lines are equal"""
<         self.assertListEquals(l1.splitlines(), l2.splitlines(), msg)
<     assertLineEqual = assertLinesEquals
< 
<     def assertXMLWellFormed(self, stream, msg=None):
<         """asserts the XML stream is well-formed (no DTD conformance check)"""
<         from xml.sax import make_parser, SAXParseException
<         parser = make_parser()
<         try:
<             parser.parse(stream)
<         except SAXParseException:
<             if msg is None:
<                 msg = 'XML stream not well formed'
<             self.fail(msg)
<     assertXMLValid = deprecated_function(assertXMLWellFormed,
<                                          'assertXMLValid renamed to more precise assertXMLWellFormed')
< 
<     def assertXMLStringWellFormed(self, xml_string, msg=None):
<         """asserts the XML string is well-formed (no DTD conformance check)"""
<         stream = StringIO(xml_string)
<         self.assertXMLWellFormed(stream, msg)
<         
<     assertXMLStringValid = deprecated_function(
<         assertXMLStringWellFormed, 'assertXMLStringValid renamed to more precise assertXMLStringWellFormed')
< 
< 
<     def _difftext(self, lines1, lines2, junk=None):
<         junk = junk or (' ', '\t')
<         # result is a generator
<         result = difflib.ndiff(lines1, lines2, charjunk=lambda x: x in junk)
<         read = []
<         for line in result:
<             read.append(line)
<             # lines that don't start with a ' ' are diff ones
<             if not line.startswith(' '):
<                 self.fail(''.join(read + list(result)))
<         
<     def assertTextEquals(self, text1, text2, junk=None):
<         """compare two multiline strings (using difflib and splitlines())"""
<         self._difftext(text1.splitlines(True), text2.splitlines(True), junk)
<     assertTextEqual = assertTextEquals
<             
<     def assertStreamEqual(self, stream1, stream2, junk=None):
<         """compare two streams (using difflib and readlines())"""
<         # if stream2 is stream2, readlines() on stream1 will also read lines
<         # in stream2, so they'll appear different, although they're not
<         if stream1 is stream2:
<             return
<         # make sure we compare from the beginning of the stream
<         stream1.seek(0)
<         stream2.seek(0)
<         # ocmpare
<         self._difftext(stream1.readlines(), stream2.readlines(), junk)
<             
<     def assertFileEqual(self, fname1, fname2, junk=(' ', '\t')):
<         """compares two files using difflib"""
<         self.assertStreamEqual(file(fname1), file(fname2), junk)
<             
<     def assertIsInstance(self, obj, klass, msg=None, strict=False):
<         """compares two files using difflib"""
<         if msg is None:
<             if strict:
<                 msg = '%r is not of class %s but of %s'
<             else:
<                 msg = '%r is not an instance of %s but of %s'
<             msg = msg % (obj, klass, type(obj))
<         if strict:
<             self.assert_(obj.__class__ is klass, msg)
<         else:
<             self.assert_(isinstance(obj, klass), msg)
< 
< 
<     def failUnlessRaises(self, excClass, callableObj, *args, **kwargs):
<         """override default failUnlessRaise method to return the raised
<         exception instance.
<         
<         Fail unless an exception of class excClass is thrown
<         by callableObj when invoked with arguments args and keyword
<         arguments kwargs. If a different type of exception is
<         thrown, it will not be caught, and the test case will be
<         deemed to have suffered an error, exactly as for an
<         unexpected exception.
<         """
<         try:
<             callableObj(*args, **kwargs)
<         except excClass, exc:
<             return exc
<         else:
<             if hasattr(excClass, '__name__'):
<                 excName = excClass.__name__
<             else:
<                 excName = str(excClass)
<             raise self.failureException, "%s not raised" % excName
< 
<     assertRaises = failUnlessRaises
< 
< import doctest
< 
< class SkippedSuite(unittest.TestSuite):
<     def test(self):
<         """just there to trigger test execution"""
<         self.skipped_test('doctest module has no DocTestSuite class')
< 
< 
< # DocTestFinder was introduced in python2.4
< if sys.version_info >= (2, 4):
<     class DocTestFinder(doctest.DocTestFinder):
< 
<         def __init__(self, *args, **kwargs):
<             self.skipped = kwargs.pop('skipped', ())
<             doctest.DocTestFinder.__init__(self, *args, **kwargs)
< 
<         def _get_test(self, obj, name, module, globs, source_lines):
<             """override default _get_test method to be able to skip tests
<             according to skipped attribute's value
< 
<             Note: Python (<=2.4) use a _name_filter which could be used for that
<                   purpose but it's no longer available in 2.5
<                   Python 2.5 seems to have a [SKIP] flag
<             """
<             if getattr(obj, '__name__', '') in self.skipped:
<                 return None
<             return doctest.DocTestFinder._get_test(self, obj, name, module,
<                                                    globs, source_lines)
< else:
<     # this is a hack to make skipped work with python <= 2.3
<     class DocTestFinder(object):
<         def __init__(self, skipped):
<             self.skipped = skipped
<             self.original_find_tests = doctest._find_tests
<             doctest._find_tests = self._find_tests
<             
<         def _find_tests(self, module, prefix=None):
<             tests = []
<             for testinfo  in self.original_find_tests(module, prefix):
<                 testname, _, _, _ = testinfo
<                 # testname looks like A.B.C.function_name
<                 testname = testname.split('.')[-1]
<                 if testname not in self.skipped:
<                     tests.append(testinfo)
<             return tests
< 
< 
< class DocTest(TestCase):
<     """trigger module doctest
<     I don't know how to make unittest.main consider the DocTestSuite instance
<     without this hack
<     """
<     skipped = ()
<     def __call__(self, result=None, runcondition=None, options=None):
<         try:
<             finder = DocTestFinder(skipped=self.skipped)
<             if sys.version_info >= (2, 4):
<                 suite = doctest.DocTestSuite(self.module, test_finder=finder)
<             else:
<                 suite = doctest.DocTestSuite(self.module)
<         except AttributeError:
<             suite = SkippedSuite()
<         return suite.run(result)
<     run = __call__
<     
<     def test(self):
<         """just there to trigger test execution"""
< 
< MAILBOX = None
< 
< class MockSMTP:
<     """fake smtplib.SMTP"""
<     
<     def __init__(self, host, port):
<         self.host = host
<         self.port = port
<         global MAILBOX
<         self.reveived = MAILBOX = []
<         
<     def set_debuglevel(self, debuglevel):
<         """ignore debug level"""
< 
<     def sendmail(self, fromaddr, toaddres, body):
<         """push sent mail in the mailbox"""
<         self.reveived.append((fromaddr, toaddres, body))
< 
<     def quit(self):
<         """ignore quit"""
< 
< 
< class MockConfigParser:
<     """fake ConfigParser.ConfigParser"""
<     
<     def __init__(self, options):
<         self.options = options
<         
<     def get(self, section, option):
<         """return option in section"""
<         return self.options[section][option]
< 
<     def has_option(self, section, option):
<         """ask if option exists in section"""
<         try:
<             return self.get(section, option) or 1
<         except KeyError:
<             return 0
<     
< 
< class MockConnection:
<     """fake DB-API 2.0 connexion AND cursor (i.e. cursor() return self)"""
<     
<     def __init__(self, results):
<         self.received = []
<         self.states = []
<         self.results = results
<         
<     def cursor(self):
<         return self
<     def execute(self, query, args=None):
<         self.received.append( (query, args) )
<     def fetchone(self):
<         return self.results[0]
<     def fetchall(self):
<         return self.results
<     def commit(self):
<         self.states.append( ('commit', len(self.received)) )
<     def rollback(self):
<         self.states.append( ('rollback', len(self.received)) )
<     def close(self):
<         pass
< 
< MockConnexion = class_renamed('MockConnexion', MockConnection)
< 
< def mock_object(**params):
<     """creates an object using params to set attributes
<     >>> option = mock_object(verbose=False, index=range(5))
<     >>> option.verbose
<     False
<     >>> option.index
<     [0, 1, 2, 3, 4]
<     """
<     return type('Mock', (), params)()
< 
< 
< def create_files(paths, chroot):
<     """creates directories and files found in <path>
< 
<     :param path: list of relative paths to files or directories
<     :param chroot: the root directory in which paths will be created
< 
<     >>> from os.path import isdir, isfile
<     >>> isdir('/tmp/a')
<     False
<     >>> create_files(['a/b/foo.py', 'a/b/c/', 'a/b/c/d/e.py'], '/tmp')
<     >>> isdir('/tmp/a')
<     True
<     >>> isdir('/tmp/a/b/c')
<     True
<     >>> isfile('/tmp/a/b/c/d/e.py')
<     True 
<     >>> isfile('/tmp/a/b/foo.py')
<     True
<     """
<     dirs, files = set(), set()
<     for path in paths:
<         path = osp.join(chroot, path)
<         filename = osp.basename(path)
<         # path is a directory path
<         if filename == '':
<             dirs.add(path)
<         # path is a filename path
<         else:
<             dirs.add(osp.dirname(path))
<             files.add(path)
<     for dirpath in dirs:
<         if not osp.isdir(dirpath):
<             os.makedirs(dirpath)
<     for filepath in files:
<         file(filepath, 'w').close()
< 
< def enable_dbc(*args):
<     """
<     Without arguments, return True if contracts can be enabled and should be
<     enabled (see option -d), return False otherwise.
< 
<     With arguments, return False if contracts can't or shouldn't be enabled,
<     otherwise weave ContractAspect with items passed as arguments.
<     """
<     if not ENABLE_DBC:
<         return False
<     try:
<         from clonedigger.logilab.aspects.weaver import weaver
<         from clonedigger.logilab.aspects.lib.contracts import ContractAspect
<     except ImportError:
<         sys.stderr.write('Warning: logilab.aspects is not available. Contracts disabled.')
<         return False
<     for arg in args:
<         weaver.weave_module(arg, ContractAspect)
<     return True
< 
<     
< class AttrObject: # XXX cf mock_object
<     def __init__(self, **kwargs):
<         self.__dict__.update(kwargs)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/textutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/textutils.py.svn-base
1,384d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some text manipulation utility functions.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< 
< :group text formatting: normalize_text, normalize_paragraph, pretty_match,\
< unquote, colorize_ansi
< :group text manipulation: searchall, get_csv
< :sort: text formatting, text manipulation
< 
< 
< 
< :type ANSI_STYLES: dict(str)
< :var ANSI_STYLES: dictionary mapping style identifier to ANSI terminal code
< 
< :type ANSI_COLORS: dict(str)
< :var ANSI_COLORS: dictionary mapping color identifier to ANSI terminal code
< 
< :type ANSI_PREFIX: str
< :var ANSI_PREFIX:
<   ANSI terminal code notifing the start of an ANSI escape sequence
<   
< :type ANSI_END: str
< :var ANSI_END:
<   ANSI terminal code notifing the end of an ANSI escape sequence
<   
< :type ANSI_RESET: str
< :var ANSI_RESET:
<   ANSI terminal code reseting format defined by a previous ANSI escape sequence
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import re
< from unicodedata import normalize as _uninormalize
< from os import linesep
< 
< 
< MANUAL_UNICODE_MAP = {
<     u'\xa1': u'!',    # INVERTED EXCLAMATION MARK
<     u'\u0142': u'l',  # LATIN SMALL LETTER L WITH STROKE
<     u'\u2044': u'/',  # FRACTION SLASH
<     u'\xc6': u'AE',   # LATIN CAPITAL LETTER AE
<     u'\xa9': u'(c)',  # COPYRIGHT SIGN
<     u'\xab': u'"',    # LEFT-POINTING DOUBLE ANGLE QUOTATION MARK
<     u'\xe6': u'ae',   # LATIN SMALL LETTER AE
<     u'\xae': u'(r)',  # REGISTERED SIGN
<     u'\u0153': u'oe', # LATIN SMALL LIGATURE OE
<     u'\u0152': u'OE', # LATIN CAPITAL LIGATURE OE
<     u'\xd8': u'O',    # LATIN CAPITAL LETTER O WITH STROKE
<     u'\xf8': u'o',    # LATIN SMALL LETTER O WITH STROKE
<     u'\xbb': u'"',    # RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK
<     u'\xdf': u'ss',   # LATIN SMALL LETTER SHARP S
<     }
< 
< def unormalize(ustring, ignorenonascii=False):
<     """replace diacritical characters with their corresponding ascii characters
<     """
<     res = []
<     for letter in ustring[:]:
<         try:
<             replacement = MANUAL_UNICODE_MAP[letter]
<         except KeyError:
<             if ord(letter) >= 2**8:
<                 if ignorenonascii:
<                     continue
<                 raise ValueError("can't deal with non-ascii based characters")
<             replacement = _uninormalize('NFD', letter)[0]
<         res.append(replacement)
<     return u''.join(res)
< 
< def unquote(string):
<     """remove optional quotes (simple or double) from the string
< 
<     :type string: str or unicode
<     :param string: an optionaly quoted string
< 
<     :rtype: str or unicode
<     :return: the unquoted string (or the input string if it wasn't quoted)
<     """
<     if not string:
<         return string
<     if string[0] in '"\'':
<         string = string[1:]
<     if string[-1] in '"\'':
<         string = string[:-1]
<     return string
< 
< 
< _BLANKLINES_RGX = re.compile('\r?\n\r?\n')
< _NORM_SPACES_RGX = re.compile('\s+')
< 
< def normalize_text(text, line_len=80, indent='', rest=False):
<     """normalize a text to display it with a maximum line size and
<     optionally arbitrary indentation. Line jumps are normalized but blank
<     lines are kept. The indentation string may be used to insert a
<     comment (#) or a quoting (>) mark  for instance.
< 
<     :type text: str or unicode
<     :param text: the input text to normalize
< 
<     :type line_len: int
<     :param line_len: expected maximum line's length, default to 80
< 
<     :type indent: str or unicode
<     :param indent: optional string to use as indentation
< 
<     :rtype: str or unicode
<     :return:
<       the input text normalized to fit on lines with a maximized size
<       inferior to `line_len`, and optionally prefixed by an
<       indentation string
<     """
<     if rest:
<         normp = normalize_rest_paragraph
<     else:
<         normp = normalize_paragraph
<     result = []
<     for text in _BLANKLINES_RGX.split(text):
<         result.append(normp(text, line_len, indent))
<     return ('%s%s%s' % (linesep, indent, linesep)).join(result)
< 
< 
< def normalize_paragraph(text, line_len=80, indent=''):
<     """normalize a text to display it with a maximum line size and
<     optionaly arbitrary indentation. Line jumps are normalized. The
<     indentation string may be used top insert a comment mark for
<     instance.
< 
<     :type text: str or unicode
<     :param text: the input text to normalize
< 
<     :type line_len: int
<     :param line_len: expected maximum line's length, default to 80
< 
<     :type indent: str or unicode
<     :param indent: optional string to use as indentation
< 
<     :rtype: str or unicode
<     :return:
<       the input text normalized to fit on lines with a maximized size
<       inferior to `line_len`, and optionally prefixed by an
<       indentation string
<     """
<     text = _NORM_SPACES_RGX.sub(' ', text)
<     line_len = line_len - len(indent)
<     lines = []
<     while text:
<         aline, text = splittext(text.strip(), line_len)
<         lines.append(indent + aline)
<     return linesep.join(lines)
<     
< def normalize_rest_paragraph(text, line_len=80, indent=''):
<     """normalize a ReST text to display it with a maximum line size and
<     optionaly arbitrary indentation. Line jumps are normalized. The
<     indentation string may be used top insert a comment mark for
<     instance.
< 
<     :type text: str or unicode
<     :param text: the input text to normalize
< 
<     :type line_len: int
<     :param line_len: expected maximum line's length, default to 80
< 
<     :type indent: str or unicode
<     :param indent: optional string to use as indentation
< 
<     :rtype: str or unicode
<     :return:
<       the input text normalized to fit on lines with a maximized size
<       inferior to `line_len`, and optionally prefixed by an
<       indentation string
<     """
<     toreport = ''
<     lines = []
<     line_len = line_len - len(indent)
<     for line in text.splitlines():
<         line = toreport + _NORM_SPACES_RGX.sub(' ', line.strip())
<         toreport = ''
<         while len(line) > line_len:
<             # too long line, need split
<             line, toreport = splittext(line, line_len)
<             lines.append(indent + line)
<             if toreport:
<                 line = toreport + ' '
<                 toreport = ''
<             else:
<                 line = ''
<         if line:
<             lines.append(indent + line.strip())
<     return linesep.join(lines)
< 
< def splittext(text, line_len):
<     """split the given text on space according to the given max line size
<     
<     return a 2-uple:
<     * a line <= line_len if possible
<     * the rest of the text which has to be reported on another line
<     """
<     if len(text) <= line_len:
<         return text, ''
<     pos = min(len(text)-1, line_len)
<     while pos > 0 and text[pos] != ' ':
<         pos -= 1
<     if pos == 0:
<         pos = min(len(text), line_len)
<         while len(text) > pos and text[pos] != ' ':
<             pos += 1
<     return text[:pos], text[pos+1:].strip()
< 
< 
< def get_csv(string, sep=','):
<     """return a list of string in from a csv formatted line
< 
<     >>> get_csv('a, b, c   ,  4')
<     ['a', 'b', 'c', '4']
<     >>> get_csv('a')
<     ['a']
<     >>>
< 
<     :type string: str or unicode
<     :param string: a csv line
< 
<     :type sep: str or unicode
<     :param sep: field separator, default to the comma (',')
< 
<     :rtype: str or unicode
<     :return: the unquoted string (or the input string if it wasn't quoted)    
<     """
<     return [word.strip() for word in string.split(sep) if word.strip()]
< 
< 
< _LINE_RGX = re.compile('\r\n|\r+|\n')
< 
< def pretty_match(match, string, underline_char='^'):
<     """return a string with the match location underlined:
< 
<     >>> import re
<     >>> print pretty_match(re.search('mange', 'il mange du bacon'), 'il mange du bacon')
<     il mange du bacon
<        ^^^^^
<     >>>
<     
<     :type match: _sre.SRE_match
<     :param match: object returned by re.match, re.search or re.finditer
< 
<     :type string: str or unicode
<     :param string:
<       the string on which the regular expression has been applied to
<       obtain the `match` object
< 
<     :type underline_char: str or unicode
<     :param underline_char:
<       character to use to underline the matched section, default to the
<       carret '^'
< 
<     :rtype: str or unicode
<     :return:
<       the original string with an inserted line to underline the match
<       location
<     """
<     start = match.start()
<     end = match.end()
<     string = _LINE_RGX.sub(linesep, string)
<     start_line_pos = string.rfind(linesep, 0, start)
<     if start_line_pos == -1:
<         start_line_pos = 0
<         result = []
<     else:
<         result = [string[:start_line_pos]]
<         start_line_pos += len(linesep)
<     offset = start - start_line_pos
<     underline = ' ' * offset + underline_char * (end - start)
<     end_line_pos = string.find(linesep, end)
<     if end_line_pos == -1:
<         string = string[start_line_pos:]
<         result.append(string)
<         result.append(underline)
<     else:
<         end = string[end_line_pos + len(linesep):]
<         string = string[start_line_pos:end_line_pos]
<         result.append(string)
<         result.append(underline)
<         result.append(end)
<     return linesep.join(result).rstrip()
< 
< 
< # Ansi colorization ###########################################################
< 
< ANSI_PREFIX = '\033['
< ANSI_END = 'm'
< ANSI_RESET = '\033[0m'
< ANSI_STYLES = {
<     'reset'     : "0",
<     'bold'      : "1",
<     'italic'    : "3",
<     'underline' : "4",
<     'blink'     : "5",
<     'inverse'   : "7",
<     'strike'    : "9",
< }
< ANSI_COLORS = {
<     'reset'   : "0",
<     'black'   : "30",
<     'red'     : "31",
<     'green'   : "32",
<     'yellow'  : "33",
<     'blue'    : "34",
<     'magenta' : "35",
<     'cyan'    : "36",
<     'white'   : "37",
< }
< 
< 
< def _get_ansi_code(color=None, style=None):
<     """return ansi escape code corresponding to color and style
<     
<     :type color: str or None
<     :param color:
<       the color identifier (see `ANSI_COLORS` for available values)
< 
<     :type style: str or None
<     :param style:
<       style string (see `ANSI_COLORS` for available values). To get
<       several style effects at the same time, use a coma as separator.
< 
<     :raise KeyError: if an unexistant color or style identifier is given
<     
<     :rtype: str
<     :return: the built escape code
<     """
<     ansi_code = []
<     if style:
<         style_attrs = get_csv(style)
<         for effect in style_attrs:
<             ansi_code.append(ANSI_STYLES[effect])
<     if color:
<         ansi_code.append(ANSI_COLORS[color])
<     if ansi_code:
<         return ANSI_PREFIX + ';'.join(ansi_code) + ANSI_END
<     return ''
< 
< def colorize_ansi(msg, color=None, style=None):
<     """colorize message by wrapping it with ansi escape codes
< 
<     :type msg: str or unicode
<     :param msg: the message string to colorize
< 
<     :type color: str or None
<     :param color:
<       the color identifier (see `ANSI_COLORS` for available values)
< 
<     :type style: str or None
<     :param style:
<       style string (see `ANSI_COLORS` for available values). To get
<       several style effects at the same time, use a coma as separator.
< 
<     :raise KeyError: if an unexistant color or style identifier is given
< 
<     :rtype: str or unicode
<     :return: the ansi escaped string
<     """
<     # If both color and style are not defined, then leave the text as is
<     if color is None and style is None:
<         return msg
<     escape_code = _get_ansi_code(color, style)
<     # If invalid (or unknown) color, don't wrap msg with ansi codes
<     if escape_code:
<         return '%s%s%s' % (escape_code, msg, ANSI_RESET)
<     return msg
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/tree.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/tree.py.svn-base
1,364d0
< # Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
<  base class to represent tree structure
< """
< 
< import sys
< 
< from clonedigger.logilab.common import flatten
< from clonedigger.logilab.common.visitor import VisitedMixIn, FilteredIterator, no_filter
< 
< ## Exceptions #################################################################
< 
< class NodeNotFound(Exception):
<     """raised when a node has not been found"""
< 
< EX_SIBLING_NOT_FOUND = "No such sibling as '%s'"
< EX_CHILD_NOT_FOUND = "No such child as '%s'"
< EX_NODE_NOT_FOUND = "No such node as '%s'"
< 
< 
< # Base node ###################################################################
< 
< class Node(object):
<     """a basic tree node, caracterised by an id"""
< 
<     def __init__(self, nid=None) :
<         self.id = nid
<         # navigation
<         self.parent = None
<         self.children = []
< 
<     def __str__(self, indent=0):
<         s = ['%s%s %s' % (' '*indent, self.__class__.__name__, self.id)]
<         indent += 2
<         for child in self.children:
<             try:
<                 s.append(child.__str__(indent))
<             except TypeError:
<                 s.append(child.__str__())
<         return '\n'.join(s)
< 
< 
<     def is_leaf(self):
<         return not self.children
<     
<     def append(self, child):
<         """add a node to children"""
<         self.children.append(child)
<         child.parent = self
< 
<     def remove(self, child):
<         """remove a child node"""
<         self.children.remove(child)
<         child.parent = None
< 
<     def insert(self, index, child):
<         """insert a child node"""
<         self.children.insert(index, child)
<         child.parent = self
<         
<     def replace(self, old_child, new_child):
<         """replace a child node with another"""
<         i = self.children.index(old_child)
<         self.children.pop(i)
<         self.children.insert(i, new_child)
<         new_child.parent = self
< 
<     def get_sibling(self, nid):
<         """return the sibling node that has given id"""
<         try:
<             return self.parent.get_child_by_id(nid)
<         except NodeNotFound :
<             raise NodeNotFound(EX_SIBLING_NOT_FOUND % nid)
< 
<     def next_sibling(self):
<         """
<         return the next sibling for this node if any
<         """
<         parent = self.parent
<         if parent is None:
<             # root node has no sibling
<             return None
<         index = parent.children.index(self)
<         try:
<             return parent.children[index+1]
<         except IndexError:
<             return None
<         
<     def previous_sibling(self):
<         """
<         return the previous sibling for this node if any
<         """
<         parent = self.parent
<         if parent is None:
<             # root node has no sibling
<             return None
<         index = parent.children.index(self)
<         if index > 0:
<             return parent.children[index-1]
<         return None
< 
<     def get_node_by_id(self, nid):
<         """
<         return node in whole hierarchy that has given id
<         """
<         root = self.root()
<         try:
<             return root.get_child_by_id(nid, 1)
<         except NodeNotFound :
<             raise NodeNotFound(EX_NODE_NOT_FOUND % nid)
<         
<     def get_child_by_id(self, nid, recurse=None):
<         """
<         return child of given id
<         """
<         if self.id == nid:
<             return self
<         for c in self.children :
<             if recurse:
<                 try:
<                     return c.get_child_by_id(nid, 1)
<                 except NodeNotFound :
<                     continue
<             if c.id == nid :
<                 return c
<         raise NodeNotFound(EX_CHILD_NOT_FOUND % nid)
< 
<     def get_child_by_path(self, path):
<         """
<         return child of given path (path is a list of ids)
<         """
<         if len(path) > 0 and path[0] == self.id:
<             if len(path) == 1 :
<                 return self
<             else :
<                 for c in self.children :
<                     try:
<                         return c.get_child_by_path(path[1:])
<                     except NodeNotFound :
<                         pass
<         raise NodeNotFound(EX_CHILD_NOT_FOUND % path)
< 
<     def depth(self):
<         """
<         return depth of this node in the tree
<         """
<         if self.parent is not None:
<             return 1 + self.parent.depth()
<         else :
<             return 0
< 
<     def depth_down(self):
<         """
<         return depth of the tree from this node
<         """
<         if self.children:
<             return 1 + max([c.depth_down() for c in self.children])
<         return 1
< 
<     def width(self):
<         """
<         return the width of the tree from this node
<         """
<         return len(self.leaves())
<         
<     def root(self):
<         """
<         return the root node of the tree
<         """
<         if self.parent is not None:
<             return self.parent.root()
<         return self
< 
<     def leaves(self):
<         """
<         return a list with all the leaves nodes descendant from this node
<         """
<         leaves = []
<         if self.children:
<             for child in self.children:
<                 leaves += child.leaves()
<             return leaves
<         else:
<             return [self]
< 
<     def __iter__(self):
<         return iter(self.children)
<     
<     def flatten(self, _list=None):
<         """
<         return a list with all the nodes descendant from this node
<         """
<         if _list is None:
<             _list = []
<         _list.append(self)
<         for c in self.children:
<             c.flatten(_list)
<         return _list
< 
<     def lineage(self):
<         """
<         return list of parents up to root node
<         """
<         lst = [self]
<         if self.parent is not None:
<             lst.extend(self.parent.lineage())
<         return lst
<     
< class VNode(Node, VisitedMixIn):
<     """a visitable node
<     """
<     pass
< 
<             
< class BinaryNode(VNode):
<     """a binary node (ie only two children
<     """
<     def __init__(self, lhs=None, rhs=None) :
<         VNode.__init__(self)
<         if lhs is not None or rhs is not None:
<             assert lhs and rhs
<             self.append(lhs)
<             self.append(rhs)
<             
<     def remove(self, child):
<         """remove the child and replace this node with the other child
<         """
<         self.children.remove(child)
<         self.parent.replace(self, self.children[0])
<         
<     def get_parts(self):
<         """
<         return the left hand side and the right hand side of this node
<         """
<         return self.children[0], self.children[1]
<         
< 
< 
< if sys.version_info[0:2] >= (2, 2):
<     list_class = list
< else:
<     from UserList import UserList
<     list_class = UserList
<     
< class ListNode(VNode, list_class):
<     """Used to manipulate Nodes as Lists
<     """
<     def __init__(self):
<         list_class.__init__(self)
<         VNode.__init__(self)
<         self.children = self
<         
<     def __str__(self, indent=0):
<         return '%s%s %s' % (indent*' ', self.__class__.__name__,
<                             ', '.join([str(v) for v in self]))
< 
<     def append(self, child):
<         """add a node to children"""
<         list_class.append(self, child)
<         child.parent = self
<  
<     def insert(self, index, child):
<         """add a node to children"""
<         list_class.insert(self, index, child)
<         child.parent = self
<     
<     def remove(self, child):
<         """add a node to children"""
<         list_class.remove(self, child)
<         child.parent = None
<  
<     def pop(self, index):
<         """add a node to children"""
<         child = list_class.pop(self, index)
<         child.parent = None
< 
<     def __iter__(self):
<         return list_class.__iter__(self)
< 
< # construct list from tree ####################################################
< 
< def post_order_list(node, filter_func=no_filter):
<     """ 
<     create a list with tree nodes for which the <filter> function returned true
<     in a post order fashion
<     """
<     l, stack = [], []
<     poped, index = 0, 0
<     while node:
<         if filter_func(node):
<             if node.children and not poped:
<                 stack.append((node, index))
<                 index = 0
<                 node = node.children[0]
<             else:
<                 l.append(node)
<                 index += 1
<                 try:
<                     node = stack[-1][0].children[index]
<                 except IndexError:
<                     node = None
<         else:
<             node = None
<         poped = 0
<         if node is None and stack:
<             node, index = stack.pop()
<             poped = 1
<     return l
< 
< def pre_order_list(node, filter_func=no_filter):
<     """
<     create a list with tree nodes for which the <filter> function returned true
<     in a pre order fashion
<     """
<     l, stack = [], []
<     poped, index = 0, 0
<     while node:
<         if filter_func(node):
<             if not poped:
<                 l.append(node)
<             if node.children and not poped:
<                 stack.append((node, index))
<                 index = 0
<                 node = node.children[0]
<             else:
<                 index += 1
<                 try:
<                     node = stack[-1][0].children[index]
<                 except IndexError:
<                     node = None
<         else:
<             node = None
<         poped = 0
<         if node is None and len(stack) > 1:
<             node, index = stack.pop()
<             poped = 1
<     return l
< 
< class PostfixedDepthFirstIterator(FilteredIterator):
<     """a postfixed depth first iterator, designed to be used with visitors
<     """
<     def __init__(self, node, filter_func=None):
<         FilteredIterator.__init__(self, node, post_order_list, filter_func)
< 
< class PrefixedDepthFirstIterator(FilteredIterator):
<     """a pretfixed depth first iterator, designed to be used with visitors
<     """
<     def __init__(self, node, filter_func=None):
<         FilteredIterator.__init__(self, node, pre_order_list, filter_func)
<         
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/twisted_distutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/twisted_distutils.py.svn-base
1,215d0
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< Distutils extensions for twisted framework.
< 
< This module enables the installation of plugins.tml files using standard
< distutils syntax. It adds the following commands to the standard
< setup.py commands:
< * build_twisted_plugins: build (i.e. copy) plugins
< * install_twisted_plugins: install plugins
< 
< Additionally, the following commands have been modified to deal with
< plugins files:
<  * sdist
<  * build
<  * install
< 
< To use these extenstion, you should import the setup fonction from this
< module, and use it normally. To list the plugins.tml files, use the
< twisted_plugins keyword argument to the setup function:
< 
< from twisted_distutils import setup # you can also import Extension if needed
< 
< if __name__ == '__main__':
<     setup(name='my_twisted_app',
<           version='1.0',
<           author='me',
<           packages=['my_package'],
<           twisted_plugins = ['my_package/plugins.tml'])
< 
< Note that you can use this to install files that are not twisted plugins in any
< package directory of your application.
< """
< #
< # (c) 2002 Alexandre Fayolle <alexandre.fayolle@free.fr>
< # This module is heavily based on code copied from the python distutils
< # framework, especially distutils.command.build_script,
< # distutils.command.install_script. Many thanks to the authors of these
< # modules.
< # This module is provided as is, I'm not responsible if anything bad
< # happens to you or your python library while using this module. You may
< # freely copy it, distribute it and use it in your library or to distribute
< # your applications. I'd appreciate if you could drop me an email if you plan
< # to do so <wink>.
< #
< # Happy twisting!
< #
< 
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = "$Id: twisted_distutils.py,v 1.4 2003-09-12 11:54:48 syt Exp $"
< 
< from distutils.core import Distribution, Command
< from distutils.command.install import install
< from distutils.command.build import build
< from distutils.command.sdist import sdist
< from distutils.dep_util import newer
< from distutils.util import convert_path
< import os
< 
< class twisted_sdist(sdist):
<     def add_defaults(self):
<         sdist.add_defaults(self)
<         if self.distribution.has_twisted_plugins():
<             plugins = self.get_finalized_command('build_twisted_plugins')
<             self.filelist.extend(plugins.get_source_files())
< 
< class twisted_install(install):
<     def initialize_options (self):
<         install.initialize_options(self)
<         self.twisted_plugins = None
<         
<     def has_twisted_plugins(self):
<         return self.distribution.has_twisted_plugins()
<     
<     sub_commands = []
<     sub_commands.extend(install.sub_commands)
<     sub_commands.append(('install_twisted_plugins', has_twisted_plugins))
<                    
< 
< class twisted_build(build):
<     def initialize_options (self):
<         build.initialize_options(self)
<         self.twisted_plugins = None
<         
<     def has_twisted_plugins(self):
<         return self.distribution.has_twisted_plugins()
<     
<     sub_commands = []
<     sub_commands.extend(build.sub_commands)
<     sub_commands.append(('build_twisted_plugins', has_twisted_plugins))
< 
< class build_twisted_plugins (Command):
< 
<     description = "\"build\" twisted plugins (copy)"
< 
<     user_options = [
<         ('build-dir=', 'd', "directory to \"build\" (copy) to"),
<         ('force', 'f', "forcibly build everything (ignore file timestamps"),
<         ]
< 
<     boolean_options = ['force']
< 
< 
<     def initialize_options (self):
<         self.build_dir = None
<         self.twisted_plugins = None
<         self.force = None
<         self.outfiles = None
< 
<     def get_source_files(self):
<         return self.twisted_plugins
< 
<     def finalize_options (self):
<         self.set_undefined_options('build',
<                                    ('build_lib', 'build_dir'),
<                                    ('force', 'force'))
<         self.twisted_plugins = self.distribution.twisted_plugins
< 
< 
<     def run (self):
<         if not self.twisted_plugins:
<             return
<         self.copy_twisted_plugins()
< 
< 
<     def copy_twisted_plugins (self):
<         """Copy each plugin listed in 'self.twisted_plugins'.
<         """
<         self.mkpath(self.build_dir)
<         for plugin in self.twisted_plugins:
<             adjust = 0
<             plugin = convert_path(plugin)
<             outfile = os.path.join(self.build_dir, plugin)
<             if not self.force and not newer(plugin, outfile):
<                 self.announce("not copying %s (up-to-date)" % plugin)
<                 continue
< 
<             # Always open the file, but ignore failures in dry-run mode --
<             # that way, we'll get accurate feedback if we can read the
<             # plugin.
<             try:
<                 f = open(plugin, "r")
<             except IOError:
<                 if not self.dry_run:
<                     raise
<                 f = None
<             else:
<                 f.close()
<                 self.copy_file(plugin, outfile)
< 
< 
< class install_twisted_plugins(Command):
< 
<     description = "install twisted plugins"
< 
<     user_options = [
<         ('install-dir=', 'd', "directory to install scripts to"),
<         ('build-dir=','b', "build directory (where to install from)"),
<         ('force', 'f', "force installation (overwrite existing files)"),
<         ('skip-build', None, "skip the build steps"),
<     ]
< 
<     boolean_options = ['force', 'skip-build']
< 
< 
<     def initialize_options (self):
<         self.install_dir = None
<         self.force = 0
<         self.build_dir = None
<         self.skip_build = None
< 
<     def finalize_options (self):
<         self.set_undefined_options('build', ('build_lib', 'build_dir'))
<         self.set_undefined_options('install',
<                                    ('install_lib', 'install_dir'),
<                                    ('force', 'force'),
<                                    ('skip_build', 'skip_build'),
<                                   )
< 
<     def run (self):
<         if not self.skip_build:
<             self.run_command('build_twisted_plugins')
<         self.outfiles = self.copy_tree(self.build_dir, self.install_dir)
< 
<     def get_inputs (self):
<         return self.distribution.twisted_plugins or []
< 
<     def get_outputs(self):
<         return self.outfiles or []
<         
<     
< 
< class TwistedDistribution(Distribution):
<     def __init__(self,attrs=None):
<         self.twisted_plugins = None
<         Distribution.__init__(self, attrs)
<         self.cmdclass = {'install':twisted_install,
<                          'install_twisted_plugins':install_twisted_plugins,
<                          'build':twisted_build,
<                          'build_twisted_plugins':build_twisted_plugins,
<                          'sdist':twisted_sdist,
<                          }
< 
<     def has_twisted_plugins(self):
<         return self.twisted_plugins and len(self.twisted_plugins) > 0
< 
< 
< def setup(**attrs):
<     from distutils import core
<     attrs['distclass'] = TwistedDistribution
<     core.setup(**attrs)
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/umessage.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/umessage.py.svn-base
1,125d0
< """unicode email support"""
< 
< import email
< from email.Utils import parseaddr, parsedate
< from email.Header import decode_header
< 
< try:
<     from mx.DateTime import DateTime
< except ImportError:
<     def DateTime(*args): return None
< 
< def decode_QP(string):
<     parts = []
<     for decoded, charset in decode_header(string):
<         if charset is None:
<             charset = 'iso-8859-15'
<         parts.append(unicode(decoded, charset, 'replace'))
< 
<     return u' '.join(parts)
< 
< def message_from_file(fd):
<     try:
<         return UMessage(email.message_from_file(fd))
<     except email.Errors.MessageParseError:
<         return ''
<     
< def message_from_string(string):
<     try:
<         return UMessage(email.message_from_string(string))
<     except email.Errors.MessageParseError:
<         return ''
<     
< class UMessage:
<     """Encapsulates an email.Message instance and returns only unicode objects"""
< 
<     def __init__(self, message):
<         self.message = message
< 
<     # email.Message interface #################################################
<     
<     def get(self, header, default=None):
<         value = self.message.get(header, default)
<         if value:
<             return decode_QP(value)
<         return value
< 
<     def get_all(self, header, default=()):
<         return [decode_QP(val) for val in self.message.get_all(header, default)
<                 if val is not None]
<     
<     def get_payload(self, index=None, decode=False):
<         message = self.message
<         if index is None:
<             payload = message.get_payload(index, decode)
<             if isinstance(payload, list):
<                 return [UMessage(msg) for msg in payload]
<             if message.get_content_maintype() != 'text':
<                 return payload
< 
<             charset = message.get_content_charset() or 'iso-8859-1'
<             if charset == 'unknown-8bit':
<                 charset = 'iso-8859-1'
<             return unicode(payload or '', charset)
<         else:
<             payload = UMessage(message.get_payload(index, decode))
<         return payload
< 
<     def is_multipart(self):
<         return self.message.is_multipart()
< 
<     def get_boundary(self):
<         return self.message.get_boundary()
< 
<     def walk(self):
<         for part in self.message.walk():
<             yield UMessage(part)
<     
<     def get_content_maintype(self):
<         return unicode(self.message.get_content_maintype())
< 
<     def get_content_type(self):
<         return unicode(self.message.get_content_type())
< 
<     def get_filename(self, failobj=None):
<         value = self.message.get_filename(failobj)
<         if value is failobj:
<             return value
<         try:
<             return unicode(value)
<         except UnicodeDecodeError:
<             return u'error decoding filename'
< 
<     # other convenience methods ###############################################
< 
<     def headers(self):
<         """return an unicode string containing all the message's headers"""
<         values = []
<         for header in self.message.keys():
<             values.append(u'%s: %s' % (header, self.get(header)))
<         return '\n'.join(values)
< 
<     def multi_addrs(self, header):
<         """return a list of 2-uple (name, address) for the given address (which
<         is exepected to be an header containing address such as from, to, cc...)
<         """
<         persons = []
<         for person in self.get_all(header, ()):
<             name, mail = parseaddr(person)
<             persons.append((name, mail))
<         return persons
<     
<     def date(self):
<         """return a mx.DateTime object for the email's date or None if no date is
<         set or if it can't be parsed
<         """
<         value = self.get('date')
<         if value:
<             datetuple = parsedate(value)
<             if datetuple:
<                 return DateTime(*datetuple[:6])
<         return None
< 
<     
< 
<     
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/vcgutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/vcgutils.py.svn-base
1,212d0
< # Copyright (c) 2000-2002 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< utilities functions to generate file readable with Georg Sander's vcg
< (Visualization of Compiler Graphs).
< 
< You can download vcg at http://rw4.cs.uni-sb.de/~sander/html/gshome.html
< Note that vcg exists as a debian package.
< 
< See the documentation of vcg for explanation about the different value that
< maybe used for the functions parameters
< """
< 
< __revision__ = "$Id: vcgutils.py,v 1.6 2003-12-10 08:15:09 syt Exp $"
< 
< import string
< 
< ATTRS_VAL = {
<     'algos':       ('dfs', 'tree', 'minbackward',
<                     'left_to_right','right_to_left',
<                     'top_to_bottom','bottom_to_top',
<                     'maxdepth', 'maxdepthslow', 'mindepth', 'mindepthslow',
<                     'mindegree', 'minindegree', 'minoutdegree',
<                     'maxdegree','maxindegree', 'maxoutdegree'),
<     'booleans':    ('yes', 'no'),
<     'colors':      ('black', 'white', 'blue', 'red', 'green', 'yellow',
<                     'magenta', 'lightgrey',
<                     'cyan', 'darkgrey', 'darkblue', 'darkred', 'darkgreen',
<                     'darkyellow', 'darkmagenta', 'darkcyan', 'gold',
<                     'lightblue', 'lightred', 'lightgreen', 'lightyellow',
<                     'lightmagenta', 'lightcyan', 'lilac', 'turquoise',
<                     'aquamarine', 'khaki', 'purple', 'yellowgreen', 'pink',
<                     'orange', 'orchid'),
<     'shapes':      ('box', 'ellipse', 'rhomb', 'triangle'),
<     'textmodes':   ('center', 'left_justify', 'right_justify'),
<     'arrowstyles': ('solid', 'line', 'none'),
<     'linestyles':  ('continuous', 'dashed', 'dotted', 'invisible'),
<     }
< 
< # meaning of possible values:
< #   O    -> string
< #   1    -> int 
< #   list -> value in list
< GRAPH_ATTRS = {
<     'title' :              0,
<     'label' :              0,
<     'color':               ATTRS_VAL['colors'],
<     'textcolor':           ATTRS_VAL['colors'],
<     'bordercolor':         ATTRS_VAL['colors'],
<     'width':               1,
<     'height':              1,
<     'borderwidth':         1,
<     'textmode':            ATTRS_VAL['textmodes'],
<     'shape':               ATTRS_VAL['shapes'],
<     'shrink':              1,
<     'stretch':             1,
<     'orientation':         ATTRS_VAL['algos'],
<     'vertical_order':      1,
<     'horizontal_order':    1,
<     'xspace':              1,
<     'yspace':              1,
<     'layoutalgorithm' :    ATTRS_VAL['algos'],
<     'late_edge_labels' :   ATTRS_VAL['booleans'],
<     'display_edge_labels': ATTRS_VAL['booleans'],
<     'dirty_edge_labels' :  ATTRS_VAL['booleans'],
<     'finetuning':          ATTRS_VAL['booleans'],
<     'manhattan_edges':     ATTRS_VAL['booleans'],
<     'smanhattan_edges':    ATTRS_VAL['booleans'],
<     'port_sharing':        ATTRS_VAL['booleans'],
<     'edges':               ATTRS_VAL['booleans'],
<     'nodes':               ATTRS_VAL['booleans'],
<     'splines':             ATTRS_VAL['booleans'],
<     }
< NODE_ATTRS = {
<     'title' :              0,
<     'label' :              0,
<     'color':               ATTRS_VAL['colors'],
<     'textcolor':           ATTRS_VAL['colors'],
<     'bordercolor':         ATTRS_VAL['colors'],
<     'width':               1,
<     'height':              1,
<     'borderwidth':         1,
<     'textmode':            ATTRS_VAL['textmodes'],
<     'shape':               ATTRS_VAL['shapes'],
<     'shrink':              1,
<     'stretch':             1,
<     'vertical_order':      1,
<     'horizontal_order':    1,
<     }
< EDGE_ATTRS = {
<     'sourcename' :         0,
<     'targetname' :         0,
<     'label' :              0,
<     'linestyle' :          ATTRS_VAL['linestyles'],
<     'class' :              1,
<     'thickness' :          0,
<     'color':               ATTRS_VAL['colors'],
<     'textcolor':           ATTRS_VAL['colors'],
<     'arrowcolor':          ATTRS_VAL['colors'],
<     'backarrowcolor':      ATTRS_VAL['colors'],
<     'arrowsize':           1,
<     'backarrowsize':       1,
<     'arrowstyle':          ATTRS_VAL['arrowstyles'],
<     'backarrowstyle':      ATTRS_VAL['arrowstyles'],
<     'textmode':            ATTRS_VAL['textmodes'],
<     'priority':            1,
<     'anchor':              1,
<     'horizontal_order':    1,
<     }
< 
< 
< # Misc utilities ###############################################################
< 
< def latin_to_vcg(st):
<     """convert latin characters using vcg escape sequence
<     """
<     for char in st:
<         if char not in string.ascii_letters:
<             try:
<                 num = ord(char)
<                 if num >= 192:
<                     st = st.replace(char, r'\fi%d'%ord(char))
<             except:
<                 pass
<     return st
< 
< 
< class VCGPrinter:
<     """a vcg graph writer
<     """
<     
<     def __init__(self, output_stream):
<         self._stream = output_stream
<         self._indent = ''
< 
<     def open_graph(self, **args):
<         """open a vcg graph
<         """
<         self._stream.write('%sgraph:{\n'%self._indent)
<         self._inc_indent()
<         self._write_attributes(GRAPH_ATTRS, **args)
< 
<     def close_graph(self):
<         """close a vcg graph
<         """
<         self._dec_indent()
<         self._stream.write('%s}\n'%self._indent)
< 
< 
<     def node(self, title, **args):
<         """draw a node
<         """
<         self._stream.write('%snode: {title:"%s"' % (self._indent, title))
<         self._write_attributes(NODE_ATTRS, **args)
<         self._stream.write('}\n')
< 
< 
<     def edge(self, from_node, to_node, edge_type='', **args):
<         """draw an edge from a node to another.
<         """
<         self._stream.write(
<             '%s%sedge: {sourcename:"%s" targetname:"%s"' % (
<             self._indent, edge_type, from_node, to_node))
<         self._write_attributes(EDGE_ATTRS, **args)
<         self._stream.write('}\n')
< 
< 
<     # private ##################################################################
<     
<     def _write_attributes(self, attributes_dict, **args):
<         """write graph, node or edge attributes
<         """
<         for key, value in args.items():
<             try:
<                 _type =  attributes_dict[key]
<             except KeyError:
<                 raise Exception('''no such attribute %s
< possible attributes are %s''' % (key, attributes_dict.keys()))
< 
<             if not _type:
<                 self._stream.write('%s%s:"%s"\n' % (self._indent, key, value))
<             elif _type == 1:
<                 self._stream.write('%s%s:%s\n' % (self._indent, key,
<                                                   int(value)))
<             elif value in _type:
<                 self._stream.write('%s%s:%s\n' % (self._indent, key, value))
<             else:
<                 raise Exception('''value %s isn\'t correct for attribute %s
< correct values are %s''' % (value, key, _type))
<     
<     def _inc_indent(self):
<         """increment indentation
<         """
<         self._indent = '  %s' % self._indent
<         
<     def _dec_indent(self):
<         """decrement indentation
<         """
<         self._indent = self._indent[:-2]
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/visitor.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/visitor.py.svn-base
1,106d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
<  
< a generic visitor abstract implementation
< """
< 
< def no_filter(_):
<     return 1
< 
< 
< # Iterators ###################################################################
< class FilteredIterator(object):
< 
<     def __init__(self, node, list_func, filter_func=None):
<         self._next = [(node, 0)]
<         if filter_func is None:
<             filter_func = no_filter
<         self._list = list_func(node, filter_func)
<         
<     def next(self):
<         try:
<             return self._list.pop(0)
<         except :
<             return None
< 
< 
< # Base Visitor ################################################################
< class Visitor(object):
< 
<     def __init__(self, iterator_class, filter_func=None):
<         self._iter_class = iterator_class
<         self.filter = filter_func
<         
<     def visit(self, node, *args, **kargs):
<         """
<         launch the visit on a given node
< 
<         call 'open_visit' before the begining of the visit, with extra args
<         given
<         when all nodes have been visited, call the 'close_visit' method
<         """
<         self.open_visit(node, *args, **kargs)
<         return self.close_visit(self._visit(node))
< 
<     def _visit(self, node):
<         iterator = self._get_iterator(node)
<         n = iterator.next()
<         while n:
<             result = n.accept(self)
<             n = iterator.next()
<         return result
< 
<     def _get_iterator(self, node):
<         return self._iter_class(node, self.filter)
<         
<     def open_visit(self, *args, **kargs):
<         """
<         method called at the beginning of the visit
<         """
<         pass
<     
<     def close_visit(self, result):
<         """
<         method called at the end of the visit
<         """
<         return result
< 
< 
< 
< # standard visited mixin ######################################################
< class VisitedMixIn(object):
<     """
<     Visited interface allow node visitors to use the node
<     """
<     def get_visit_name(self):
<         """
<         return the visit name for the mixed class. When calling 'accept', the
<         method <'visit_' + name returned by this method> will be called on the
<         visitor
<         """
<         try:
<             return self.TYPE.replace('-', '_')
<         except:
<             return self.__class__.__name__.lower()
<     
<     def accept(self, visitor, *args, **kwargs):
<         func = getattr(visitor, 'visit_%s' % self.get_visit_name())
<         return func(self, *args, **kwargs)
<     
<     def leave(self, visitor, *args, **kwargs):
<         func = getattr(visitor, 'leave_%s' % self.get_visit_name())
<         return func(self, *args, **kwargs)
< 
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/.svn/text-base/xmlrpcutils.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/.svn/text-base/xmlrpcutils.py.svn-base
1,131d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """XML-RPC utilities
< 
<  Copyright (c) 2003-2004 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< __revision__ = "$Id: xmlrpcutils.py,v 1.3 2005-11-22 13:13:03 syt Exp $"
< 
< import xmlrpclib
< from base64 import encodestring
< #from cStringIO import StringIO
< 
< ProtocolError = xmlrpclib.ProtocolError
< 
< ## class BasicAuthTransport(xmlrpclib.Transport):
< ##     def __init__(self, username=None, password=None):
< ##         self.username = username
< ##         self.password = password
< ##         self.verbose = None
< ##         self.has_ssl = httplib.__dict__.has_key("HTTPConnection")
<  
< ##     def request(self, host, handler, request_body, verbose=None):
< ##         # issue XML-RPC request
< ##         if self.has_ssl:
< ##             if host.startswith("https:"): h = httplib.HTTPSConnection(host)
< ##             else: h = httplib.HTTPConnection(host)
< ##         else: h = httplib.HTTP(host)
<  
< ##         h.putrequest("POST", handler)
<  
< ##         # required by HTTP/1.1
< ##         if not self.has_ssl: # HTTPConnection already does 1.1
< ##             h.putheader("Host", host)
< ##         h.putheader("Connection", "close")
<  
< ##         if request_body: h.send(request_body)
< ##         if self.has_ssl:
< ##             response = h.getresponse()
< ##             if response.status != 200:
< ##                 raise xmlrpclib.ProtocolError(host + handler,
< ##                                               response.status,
< ##                                               response.reason,
< ##                                               response.msg)
< ##             file = response.fp
< ##         else:
< ##             errcode, errmsg, headers = h.getreply()
< ##             if errcode != 200:
< ##                 raise xmlrpclib.ProtocolError(host + handler, errcode,
< ##                                               errmsg, headers)
<  
< ##             file = h.getfile()
<  
< ##         return self.parse_response(file)
<                                                                               
< 
< 
< class AuthMixin:
<     """basic http authentication mixin for xmlrpc transports"""
<     
<     def __init__(self, username, password, encoding):
<         self.verbose = 0
<         self.username = username
<         self.password = password
<         self.encoding = encoding
<         
<     def request(self, host, handler, request_body, verbose=0):
<         """issue XML-RPC request"""
<         h = self.make_connection(host)
<         h.putrequest("POST", handler)
<         # required by XML-RPC
<         h.putheader("User-Agent", self.user_agent)
<         h.putheader("Content-Type", "text/xml")
<         h.putheader("Content-Length", str(len(request_body)))
<         h.putheader("Host", host)
<         h.putheader("Connection", "close")
<         # basic auth
<         if self.username is not None and self.password is not None:
<             h.putheader("AUTHORIZATION", "Basic %s" % encodestring(
<                 "%s:%s" % (self.username, self.password)).replace("\012", ""))
<         h.endheaders()
<         # send body
<         if request_body:
<             h.send(request_body)
<         # get and check reply
<         errcode, errmsg, headers = h.getreply()
<         if errcode != 200:
<             raise ProtocolError(host + handler, errcode, errmsg, headers)
<         file = h.getfile()
< ##         # FIXME: encoding ??? iirc, this fix a bug in xmlrpclib but...
< ##         data = h.getfile().read()
< ##         if self.encoding != 'UTF-8':
< ##             data = data.replace("version='1.0'",
< ##                                 "version='1.0' encoding='%s'" % self.encoding)
< ##         result = StringIO()
< ##         result.write(data)
< ##         result.seek(0)
< ##         return self.parse_response(result)
<         return self.parse_response(file)
<     
< class BasicAuthTransport(AuthMixin, xmlrpclib.Transport):
<     """basic http authentication transport"""
<     
< class BasicAuthSafeTransport(AuthMixin, xmlrpclib.SafeTransport):
<     """basic https authentication transport"""
< 
< 
< def connect(url, user=None, passwd=None, encoding='ISO-8859-1'):
<     """return an xml rpc server on <url>, using user / password if specified
<     """
<     if user or passwd:
<         assert user and passwd is not None
<         if url.startswith('https://'):
<             transport = BasicAuthSafeTransport(user, passwd, encoding)
<         else:
<             transport = BasicAuthTransport(user, passwd, encoding)
<     else:
<         transport = None
<     server = xmlrpclib.ServerProxy(url, transport, encoding=encoding)
<     return server
diff -r -N code-worker/tasks/clonedigger/logilab/common/table.py code-worker/code-worker/tasks/clonedigger/logilab/common/table.py
1,958d0
< """Table management module
< """
< 
< __revision__ = '$Id: table.py,v 1.18 2006-04-09 22:30:53 nico Exp $'
< 
< from warnings import warn
< 
< from clonedigger.logilab.common.compat import enumerate, sum, set
< 
< class Table(object):
<     """Table defines a data table with column and row names.
<     inv:
<         len(self.data) <= len(self.row_names)
<         forall(self.data, lambda x: len(x) <= len(self.col_names))
<     """
< 
<     def __init__(self, default_value=0, col_names=None, row_names=None):
<         self.col_names = []
<         self.row_names = []
<         self.data = []
<         self.default_value = default_value
<         if col_names:
<             self.create_columns(col_names)
<         if row_names:
<             self.create_rows(row_names)
<         
<     def _next_row_name(self):
<         return 'row%s' % (len(self.row_names)+1)
< 
<     def __iter__(self):
<         return iter(self.data)
<     
<     def __eq__(self, other):
<         if other is None:
<             return False
<         else:
<             return list(self) == list(other)
< 
<     def __ne__(self, other):
<         return not self == other
< 
<     def __len__(self):
<         return len(self.row_names)
<     
<     ## Rows / Columns creation #################################################
<     def create_rows(self, row_names):
<         """Appends row_names to the list of existing rows
<         """
<         self.row_names.extend(row_names)
<         for row_name in row_names:
<             self.data.append([self.default_value]*len(self.col_names))
<         
<     def create_columns(self, col_names):
<         """Appends col_names to the list of existing columns
<         """
<         for col_name in col_names:
<             self.create_column(col_name)
< 
<     def create_row(self, row_name=None):
<         """Creates a rowname to the row_names list
<         """
<         row_name = row_name or self._next_row_name()
<         self.row_names.append(row_name)
<         self.data.append([self.default_value]*len(self.col_names))
< 
<     
<     def create_column(self, col_name):
<         """Creates a colname to the col_names list
<         """
<         self.col_names.append(col_name)
<         for row in self.data:
<             row.append(self.default_value)
< 
<     ## Sort by column ##########################################################
<     def sort_by_column_id(self, col_id, method = 'asc'):
<         """Sorts the table (in-place) according to data stored in col_id
<         """
<         try:
<             col_index = self.col_names.index(col_id)
<             self.sort_by_column_index(col_index, method)
<         except ValueError:
<             raise KeyError("Col (%s) not found in table" % (col_id))
<         
< 
<     def sort_by_column_index(self, col_index, method = 'asc'):
<         """Sorts the table 'in-place' according to data stored in col_index
< 
<         method should be in ('asc', 'desc')
<         """
<         sort_list = [(row[col_index], row, row_name)
<                      for row, row_name in zip(self.data, self.row_names)]
<         # Sorting sort_list will sort according to col_index
<         sort_list.sort()
<         # If we want reverse sort, then reverse list
<         if method.lower() == 'desc':
<             sort_list.reverse()
<         
<         # Rebuild data / row names
<         self.data = []
<         self.row_names = []
<         for val, row, row_name in sort_list:
<             self.data.append(row)
<             self.row_names.append(row_name)
< 
<     def groupby(self, colname, *others):
<         """builds indexes of data
<         :returns: nested dictionnaries pointing to actual rows
<         """
<         groups = {}
<         colnames = (colname,) + others
<         col_indexes = [self.col_names.index(col_id) for col_id in colnames]
<         for row in self.data:
<             ptr = groups
<             for col_index in col_indexes[:-1]:
<                 ptr = ptr.setdefault(row[col_index], {})
<             ptr = ptr.setdefault(row[col_indexes[-1]],
<                                  Table(default_value=self.default_value,
<                                        col_names=self.col_names))
<             ptr.append_row(tuple(row))
<         return groups
< 
<     def select(self, colname, value):
<         grouped = self.groupby(colname)
<         try:
<             return grouped[value]
<         except KeyError:
<             return []
< 
<     def remove(self, colname, value):
<         col_index = self.col_names.index(colname)
<         for row in self.data[:]:
<             if row[col_index] == value:
<                 self.data.remove(row)
<         
<     
<     ## The 'setter' part #######################################################
<     def set_cell(self, row_index, col_index, data):
<         """sets value of cell 'row_indew', 'col_index' to data
<         """
<         self.data[row_index][col_index] = data
<         
< 
<     def set_cell_by_ids(self, row_id, col_id, data):
<         """sets value of cell mapped by row_id and col_id to data
<         Raises a KeyError if row_id or col_id are not found in the table
<         """
<         try:
<             row_index = self.row_names.index(row_id)
<         except ValueError:
<             raise KeyError("Row (%s) not found in table" % (row_id))
<         else:
<             try:
<                 col_index = self.col_names.index(col_id)
<                 self.data[row_index][col_index] = data
<             except ValueError:
<                 raise KeyError("Column (%s) not found in table" % (col_id))
<     
<     
<     def set_row(self, row_index, row_data):
<         """sets the 'row_index' row
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.col_names)
<         """
<         self.data[row_index] = row_data
< 
<         
<     def set_row_by_id(self, row_id, row_data):
<         """sets the 'row_id' column
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.row_names)
<         Raises a KeyError if row_id is not found
<         """
<         try:
<             row_index = self.row_names.index(row_id)
<             self.set_row(row_index, row_data)
<         except ValueError:
<             raise KeyError('Row (%s) not found in table' % (row_id))
<         
< 
<     def append_row(self, row_data, row_name=None):
<         """Appends a row to the table
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.col_names)
<         """
<         row_name = row_name or self._next_row_name()
<         self.row_names.append(row_name)
<         self.data.append(row_data)
<         return len(self.data) - 1
< 
<     def insert_row(self, index, row_data, row_name=None):
<         """Appends row_data before 'index' in the table. To make 'insert'
<         behave like 'list.insert', inserting in an out of range index will
<         insert row_data to the end of the list
<         pre:
<             type(row_data) == types.ListType
<             len(row_data) == len(self.col_names)
<         """
<         row_name = row_name or self._next_row_name()
<         self.row_names.insert(index, row_name)
<         self.data.insert(index, row_data)
<     
< 
<     def delete_row(self, index):
<         """Deletes the 'index' row in the table, and returns it.
<         Raises an IndexError if index is out of range
<         """
<         self.row_names.pop(index)
<         return self.data.pop(index)
<         
< 
<     def delete_row_by_id(self, row_id):
<         """Deletes the 'row_id' row in the table.
<         Raises a KeyError if row_id was not found.
<         """
<         try:
<             row_index = self.row_names.index(row_id)
<             self.delete_row(row_index)
<         except ValueError:
<             raise KeyError('Row (%s) not found in table' % (row_id))
<     
< 
<     def set_column(self, col_index, col_data):
<         """sets the 'col_index' column
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.row_names)
<         """
<         
<         for row_index, cell_data in enumerate(col_data):
<             self.data[row_index][col_index] = cell_data
< 
< 
<     def set_column_by_id(self, col_id, col_data):
<         """sets the 'col_id' column
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.col_names)
<         Raises a KeyError if col_id is not found
<         """
<         try:
<             col_index = self.col_names.index(col_id)
<             self.set_column(col_index, col_data)
<         except ValueError:
<             raise KeyError('Column (%s) not found in table' % (col_id))
<         
< 
<     def append_column(self, col_data, col_name):
<         """Appends the 'col_index' column
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.row_names)
<         """
<         self.col_names.append(col_name)
<         for row_index, cell_data in enumerate(col_data):
<             self.data[row_index].append(cell_data)
<         
< 
<     def insert_column(self, index, col_data, col_name):
<         """Appends col_data before 'index' in the table. To make 'insert'
<         behave like 'list.insert', inserting in an out of range index will
<         insert col_data to the end of the list
<         pre:
<             type(col_data) == types.ListType
<             len(col_data) == len(self.row_names)
<         """
<         self.col_names.insert(index, col_name)
<         for row_index, cell_data in enumerate(col_data):
<             self.data[row_index].insert(index, cell_data)
<         
< 
<     def delete_column(self, index):
<         """Deletes the 'index' column in the table, and returns it.
<         Raises an IndexError if index is out of range
<         """
<         self.col_names.pop(index)
<         return [row.pop(index) for row in self.data]
< 
< 
<     def delete_column_by_id(self, col_id):
<         """Deletes the 'col_id' col in the table.
<         Raises a KeyError if col_id was not found.
<         """
<         try:
<             col_index = self.col_names.index(col_id)
<             self.delete_column(col_index)
<         except ValueError:
<             raise KeyError('Column (%s) not found in table' % (col_id))
< 
<     
<     ## The 'getter' part #######################################################
< 
<     def get_shape(self):
<         """Returns a tuple which represents the table's shape
<         """    
<         return len(self.row_names), len(self.col_names)
<     shape = property(get_shape)
<     
<     def __getitem__(self, indices):
<         """provided for convenience"""
<         rows, multirows = None, False
<         cols, multicols = None, False
<         if isinstance(indices, tuple):
<             rows = indices[0]
<             if len(indices) > 1:
<                 cols = indices[1]
<         else:
<             rows = indices
<         # define row slice
<         if isinstance(rows,str):
<             try:
<                 rows = self.row_names.index(rows)
<             except ValueError:
<                 raise KeyError("Row (%s) not found in table" % (rows))
<         if isinstance(rows,int):
<             rows = slice(rows,rows+1)
<             multirows = False
<         else:
<             rows = slice(None)
<             multirows = True
<         # define col slice
<         if isinstance(cols,str):
<             try:
<                 cols = self.col_names.index(cols)
<             except ValueError:
<                 raise KeyError("Column (%s) not found in table" % (cols))
<         if isinstance(cols,int):
<             cols = slice(cols,cols+1)
<             multicols = False
<         else:
<             cols = slice(None)
<             multicols = True
<         # get sub-table
<         tab = Table()
<         tab.default_value = self.default_value
<         tab.create_rows(self.row_names[rows])
<         tab.create_columns(self.col_names[cols])
<         for idx,row in enumerate(self.data[rows]):
<             tab.set_row(idx, row[cols])
<         if multirows :
<             if multicols:
<                 return tab
<             else:
<                 return [item[0] for item in tab.data]
<         else:
<             if multicols:
<                 return tab.data[0]
<             else:
<                 return tab.data[0][0]
< 
<     def get_dimensions(self):
<         """Returns a tuple which represents the table's shape
<         """
<         warn('table.get_dimensions() is deprecated, use table.shape instead',
<              DeprecationWarning, stacklevel=2)
<         return self.shape
< 
<     def get_element(self, row_index, col_index):
<         """Returns the element at [row_index][col_index]
<         """
<         warn('Table.get_element() is deprecated, use Table.get_cell instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data[row_index][col_index]
< 
<     def get_cell(self, row_index, col_index):
<         warn('table.get_cell(i,j) is deprecated, use table[i,j] instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data[row_index][col_index]
<         
<     def get_cell_by_ids(self, row_id, col_id):
<         """Returns the element at [row_id][col_id]
<         """
<         #warn('table.get_cell_by_ids(i,j) is deprecated, use table[i,j] instead',
<         #     DeprecationWarning, stacklevel=2)
<         try:
<             row_index = self.row_names.index(row_id)
<         except ValueError:
<             raise KeyError("Row (%s) not found in table" % (row_id))
<         else:
<             try:
<                 col_index = self.col_names.index(col_id)
<             except ValueError:
<                 raise KeyError("Column (%s) not found in table" % (col_id))
<         return self.data[row_index][col_index]
< 
<     def get_row(self, row_index):
<         """Returns the 'row_index' row
<         """
<         warn('table.get_row(i) is deprecated, use table[i] instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data[row_index]
< 
<     def get_row_by_id(self, row_id):
<         """Returns the 'row_id' row
<         """
<         #warn('table.get_row_by_id(i) is deprecated, use table[i] instead',
<         #     DeprecationWarning, stacklevel=2)
<         try:
<             row_index = self.row_names.index(row_id)
<         except ValueError:
<             raise KeyError("Row (%s) not found in table" % (row_id))
<         return self.data[row_index]
< 
<     def get_column(self, col_index, distinct=False):
<         """Returns the 'col_index' col
<         """
<         warn('table.get_column(i) is deprecated, use table[:,i] instead',
<              DeprecationWarning, stacklevel=2)
<         col = [row[col_index] for row in self.data]
<         if distinct:
<             return set(col)
<         else:
<             return col
<     
<     def get_column_by_id(self, col_id, distinct=False):
<         """Returns the 'col_id' col
<         """
<         #warn('table.get_column_by_id(i) is deprecated, use table[:,i] instead',
<         #     DeprecationWarning, stacklevel=2)
<         try:
<             col_index = self.col_names.index(col_id)
<         except ValueError:
<             raise KeyError("Column (%s) not found in table" % (col_id))
<         return self.get_column(col_index, distinct)
<     
< 
<     def get_rows(self):
<         """Returns all the rows in the table
<         """
<         warn('table.get_rows() is deprecated, just iterate over table instead',
<              DeprecationWarning, stacklevel=2)
<         return self.data
< 
< 
<     def get_columns(self):
<         """Returns all the columns in the table
<         """
<         return [self[:,index] for index in range(len(self.col_names))]
< 
<     
<     def apply_stylesheet(self, stylesheet):
<         """Applies the stylesheet to this table
<         """
<         for instruction in stylesheet.instructions:
<             eval(instruction)
<         
< 
<     def transpose(self):
<         """Keeps the self object intact, and returns the transposed (rotated)
<         table.
<         """
<         transposed = Table()
<         transposed.create_rows(self.col_names)
<         transposed.create_columns(self.row_names)
<         for col_index, column in enumerate(self.get_columns()):
<             transposed.set_row(col_index, column)
<         return transposed
< 
< 
<     def pprint(self):
<         """returns a string representing the table in a pretty
<         printed 'text' format.
<         """
<         # The maxium row name (to know the start_index of the first col)
<         max_row_name = 0
<         for row_name in self.row_names:
<             if len(row_name) > max_row_name:
<                 max_row_name = len(row_name)
<         col_start = max_row_name + 5
< 
<         lines = []
<         # Build the 'first' line <=> the col_names one
<         # The first cell <=> an empty one
<         col_names_line = [' '*col_start]
<         for col_name in self.col_names:
<             col_names_line.append(col_name.encode('iso-8859-1') + ' '*5)
<         lines.append('|' + '|'.join(col_names_line) + '|')
<         max_line_length = len(lines[0])
< 
<         # Build the table
<         for row_index, row in enumerate(self.data):
<             line = []
<             # First, build the row_name's cell
<             row_name = self.row_names[row_index].encode('iso-8859-1')
<             line.append(row_name + ' '*(col_start-len(row_name)))
< 
<             # Then, build all the table's cell for this line.
<             for col_index, cell in enumerate(row):
<                 col_name_length = len(self.col_names[col_index]) + 5
<                 data = str(cell)
<                 line.append(data + ' '*(col_name_length - len(data)))
<             lines.append('|' + '|'.join(line) + '|')
<             if len(lines[-1]) > max_line_length:
<                 max_line_length = len(lines[-1])
< 
<         # Wrap the table with '-' to make a frame
<         lines.insert(0, '-'*max_line_length)
<         lines.append('-'*max_line_length)
<         return '\n'.join(lines)
<     
< 
<     def __repr__(self):
<         return repr(self.data)
< 
<     def as_text(self):
<         data = []
<         # We must convert cells into strings before joining them
<         for row in self.data:
<             data.append([str(cell) for cell in row])
<         lines = ['\t'.join(row) for row in data]
<         return '\n'.join(lines)
<     
< 
<     
< class TableStyle:
<     """Defines a table's style
<     """
< 
<     def __init__(self, table):
< 
<         self._table = table
<         self.size = dict([(col_name,'1*') for col_name in table.col_names])
<         # __row_column__ is a special key to define the first column which
<         # actually has no name (<=> left most column <=> row names column)
<         self.size['__row_column__'] = '1*'
<         self.alignment = dict([(col_name,'right')
<                                for col_name in table.col_names])
<         self.alignment['__row_column__'] = 'right'
< 
<         # We shouldn't have to create an entry for
<         # the 1st col (the row_column one)
<         self.units = dict([(col_name,'') for col_name in table.col_names])
<         self.units['__row_column__'] = '' 
<        
<     # XXX FIXME : params order should be reversed for all set() methods
<     def set_size(self, value, col_id):
<         """sets the size of the specified col_id to value
<         """
<         self.size[col_id] = value
< 
<     def set_size_by_index(self, value, col_index):
<         """Allows to set the size according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         self.size[col_id] = value
< 
< 
<     def set_alignment(self, value, col_id):
<         """sets the alignment of the specified col_id to value
<         """
<         self.alignment[col_id] = value
< 
< 
<     def set_alignment_by_index(self, value, col_index):
<         """Allows to set the alignment according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         self.alignment[col_id] = value
< 
< 
<     def set_unit(self, value, col_id):
<         """sets the unit of the specified col_id to value
<         """
<         self.units[col_id] = value
< 
<     
<     def set_unit_by_index(self, value, col_index):
<         """Allows to set the unit according to the column index rather than
<         using the column's id.
<         BE CAREFUL :  the '0' column is the '__row_column__' one !
<         (Note that in the 'unit' case, you shouldn't have to set a unit
<         for the 1st column (the __row__column__ one))
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         self.units[col_id] = value
<     
< 
<     def get_size(self, col_id):
<         """Returns the size of the specified col_id
<         """
<         return self.size[col_id]
<     
< 
<     def get_size_by_index(self, col_index):
<         """Allows to get the size  according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         return self.size[col_id]
< 
< 
<     def get_alignment(self, col_id):
<         """Returns the alignment of the specified col_id
<         """
<         return self.alignment[col_id]
< 
< 
<     def get_alignment_by_index(self, col_index):
<         """Allors to get the alignment according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         return self.alignment[col_id]
< 
< 
<     def get_unit(self, col_id):
<         """Returns the unit of the specified col_id
<         """
<         return self.units[col_id]
< 
< 
<     def get_unit_by_index(self, col_index):
<         """Allors to get the unit according to the column index rather than
<         using the column's id.
<         BE CAREFUL : the '0' column is the '__row_column__' one !
<         """
<         if col_index == 0:
<             col_id = '__row_column__'
<         else:
<             col_id = self._table.col_names[col_index-1]
< 
<         return self.units[col_id]
< 
< 
< import re    
< CELL_PROG = re.compile("([0-9]+)_([0-9]+)")
< 
< class TableStyleSheet:
<     """A simple Table stylesheet
<     Rules are expressions where cells are defined by the row_index
<     and col_index separated by an underscore ('_').
<     For example, suppose you want to say that the (2,5) cell must be
<     the sum of its two preceding cells in the row, you would create
<     the following rule :
<         2_5 = 2_3 + 2_4
<     You can also use all the math.* operations you want. For example:
<         2_5 = sqrt(2_3**2 + 2_4**2)    
<     """
<     
<     def __init__(self, rules = None):
<         rules = rules or []
<         self.rules = []
<         self.instructions = []
<         for rule in rules:
<             self.add_rule(rule)
< 
< 
<     def add_rule(self, rule):
<         """Adds a rule to the stylesheet rules
<         """
<         try:
<             source_code = ['from math import *']
<             source_code.append(CELL_PROG.sub(r'self.data[\1][\2]', rule))
<             self.instructions.append(compile('\n'.join(source_code),
<                 'table.py', 'exec'))
<             self.rules.append(rule)
<         except SyntaxError:
<             print "Bad Stylesheet Rule : %s [skipped]"%rule
< 
<     
<     def add_rowsum_rule(self, dest_cell, row_index, start_col, end_col):
<         """Creates and adds a rule to sum over the row at row_index from
<         start_col to end_col.
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_col >= 0
<             end_col > start_col
<         """
<         cell_list = ['%d_%d'%(row_index, index) for index in range(start_col,
<                                                                    end_col + 1)]
<         rule = '%d_%d=' % dest_cell + '+'.join(cell_list)
<         self.add_rule(rule)
<             
< 
<     def add_rowavg_rule(self, dest_cell, row_index, start_col, end_col):
<         """Creates and adds a rule to make the row average (from start_col
<         to end_col)
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_col >= 0
<             end_col > start_col
<         """
<         cell_list = ['%d_%d'%(row_index, index) for index in range(start_col,
<                                                                    end_col + 1)]
<         num = (end_col - start_col + 1)
<         rule = '%d_%d=' % dest_cell + '('+'+'.join(cell_list)+')/%f'%num
<         self.add_rule(rule)
<         
< 
<     def add_colsum_rule(self, dest_cell, col_index, start_row, end_row):
<         """Creates and adds a rule to sum over the col at col_index from
<         start_row to end_row.
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_row >= 0
<             end_row > start_row
<         """        
<         cell_list = ['%d_%d'%(index, col_index) for index in range(start_row,
<                                                                    end_row + 1)]
<         rule = '%d_%d=' % dest_cell + '+'.join(cell_list)
<         self.add_rule(rule)
<         
<     
<     def add_colavg_rule(self, dest_cell, col_index, start_row, end_row):
<         """Creates and adds a rule to make the col average (from start_row
<         to end_row)
<         dest_cell is a tuple of two elements (x,y) of the destination cell
<         No check is done for indexes ranges.
<         pre:
<             start_row >= 0
<             end_row > start_row
<         """
<         cell_list = ['%d_%d'%(index, col_index) for index in range(start_row,
<                                                                    end_row + 1)]
<         num = (end_row - start_row + 1)
<         rule = '%d_%d=' % dest_cell + '('+'+'.join(cell_list)+')/%f'%num
<         self.add_rule(rule)
< 
< 
< 
< class TableCellRenderer:
<     """Defines a simple text renderer
<     """
< 
<     def __init__(self, **properties):
<         """keywords should be properties with an associated boolean as value.
<         For example :
<             renderer = TableCellRenderer(units = True, alignment = False)
<         An unspecified property will have a 'False' value by default.
<         Possible properties are :
<             alignment, unit
<         """
<         self.properties = properties
< 
< 
<     def render_cell(self, cell_coord, table, table_style):
<         """Renders the cell at 'cell_coord' in the table, using table_style
<         """
<         row_index, col_index = cell_coord
<         cell_value = table.data[row_index][col_index]
<         final_content = self._make_cell_content(cell_value,
<                                                 table_style, col_index  +1)
<         return self._render_cell_content(final_content,
<                                          table_style, col_index + 1)
<         
< 
<     def render_row_cell(self, row_name, table, table_style):
<         """Renders the cell for 'row_id' row
<         """
<         cell_value = row_name.encode('iso-8859-1')
<         return self._render_cell_content(cell_value, table_style, 0)
< 
< 
<     def render_col_cell(self, col_name, table, table_style):
<         """Renders the cell for 'col_id' row
<         """
<         cell_value = col_name.encode('iso-8859-1')
<         col_index = table.col_names.index(col_name)
<         return self._render_cell_content(cell_value, table_style, col_index +1)
< 
<     
< 
<     def _render_cell_content(self, content, table_style, col_index):
<         """Makes the appropriate rendering for this cell content.
<         Rendering properties will be searched using the
<         *table_style.get_xxx_by_index(col_index)' methods
< 
<         **This method should be overridden in the derived renderer classes.**
<         """
<         return content
< 
<     
<     def _make_cell_content(self, cell_content, table_style, col_index):
<         """Makes the cell content (adds decoration data, like units for
<         example)
<         """
<         final_content = cell_content
<         if 'skip_zero' in self.properties:
<             replacement_char = self.properties['skip_zero']
<         else:
<             replacement_char = 0
<         if replacement_char and final_content == 0:
<             return replacement_char
<         
<         try:
<             units_on = self.properties['units']
<             if units_on:
<                 final_content = self._add_unit(
<                     cell_content, table_style, col_index)
<         except KeyError:
<             pass
<         
<         return final_content
<         
<         
<     def _add_unit(self, cell_content, table_style, col_index):
<         """Adds unit to the cell_content if needed
<         """
<         unit = table_style.get_unit_by_index(col_index)
<         return str(cell_content) + " " + unit
<         
<         
< 
< class DocbookRenderer(TableCellRenderer):
<     """Defines how to render a cell for a docboook table
<     """
< 
<     def define_col_header(self, col_index, table_style):
<         """Computes the colspec element according to the style
<         """
<         size = table_style.get_size_by_index(col_index)
<         return '<colspec colname="c%d" colwidth="%s"/>\n' % \
<                (col_index, size)
<     
<         
<     def _render_cell_content(self, cell_content, table_style, col_index):
<         """Makes the appropriate rendering for this cell content.
<         Rendering properties will be searched using the
<         *table_style.get_xxx_by_index(col_index)' methods.
<         """
<         try:
<             align_on = self.properties['alignment']
<             alignment = table_style.get_alignment_by_index(col_index)
<             if align_on:
<                 return "<entry align='%s'>%s</entry>\n" % \
<                        (alignment, cell_content)
<         except KeyError:
<             # KeyError <=> Default alignment
<             return "<entry>%s</entry>\n" % cell_content
< 
< 
< class TableWriter:
<     """A class to write tables
<     """
<     
<     def __init__(self, stream, table, style, **properties):
<         self._stream = stream
<         self.style = style or TableStyle(table)
<         self._table = table
<         self.properties = properties
<         self.renderer = None
<         
< 
<     def set_style(self, style):
<         """sets the table's associated style
<         """
<         self.style = style
< 
< 
<     def set_renderer(self, renderer):
<         """sets the way to render cell
<         """
<         self.renderer = renderer
<     
<         
<     def update_properties(self, **properties):
<         """Updates writer's properties (for cell rendering)
<         """
<         self.properties.update(properties)
< 
< 
<     def write_table(self, title = ""):
<         """Writes the table
<         """
<         raise NotImplementedError("write_table must be implemented !")
<         
< 
< 
< class DocbookTableWriter(TableWriter):
<     """Defines an implementation of TableWriter to write a table in Docbook
<     """
< 
<     def _write_headers(self):
<         """Writes col headers
<         """
<         # Define col_headers (colstpec elements)
<         for col_index in range(len(self._table.col_names)+1):
<             self._stream.write(self.renderer.define_col_header(col_index,
<                                                               self.style))
<         
<         self._stream.write("<thead>\n<row>\n")
<         # XXX FIXME : write an empty entry <=> the first (__row_column) column
<         self._stream.write('<entry></entry>\n')
<         for col_name in self._table.col_names:
<             self._stream.write(self.renderer.render_col_cell(
<                 col_name, self._table,
<                 self.style))
<             
<         self._stream.write("</row>\n</thead>\n")
< 
< 
<     def _write_body(self):
<         """Writes the table body
<         """
<         self._stream.write('<tbody>\n')
<         
<         for row_index, row in enumerate(self._table.data):
<             self._stream.write('<row>\n')
<             row_name = self._table.row_names[row_index]
<             # Write the first entry (row_name)
<             self._stream.write(self.renderer.render_row_cell(row_name,
<                                                             self._table,
<                                                             self.style))
<             
<             for col_index, cell in enumerate(row):
<                 self._stream.write(self.renderer.render_cell(
<                     (row_index, col_index),
<                     self._table, self.style))
<                 
<             self._stream.write('</row>\n')
<             
<         self._stream.write('</tbody>\n')
< 
< 
<     def write_table(self, title = ""):
<         """Writes the table
<         """
<         self._stream.write('<table>\n<title>%s></title>\n'%(title))
<         self._stream.write(
<             '<tgroup cols="%d" align="left" colsep="1" rowsep="1">\n'%
<             (len(self._table.col_names)+1))
<         self._write_headers()
<         self._write_body()
<         
<         self._stream.write('</tgroup>\n</table>\n')
< 
<     
diff -r -N code-worker/tasks/clonedigger/logilab/common/testlib.py code-worker/code-worker/tasks/clonedigger/logilab/common/testlib.py
1,1446d0
< # modified copy of some functions from test/regrtest.py from PyXml
< """Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr  
< 
< Run tests.
< 
< This will find all modules whose name match a given prefix in the test
< directory, and run them.  Various command line options provide
< additional facilities.
< 
< Command line options:
< 
< -v: verbose -- run tests in verbose mode with output to stdout
< -q: quiet -- don't print anything except if a test fails
< -t: testdir -- directory where the tests will be found
< -x: exclude -- add a test to exclude
< -p: profile -- profiled execution
< -c: capture -- capture standard out/err during tests
< -d: dbc     -- enable design-by-contract
< 
< If no non-option arguments are present, prefixes used are 'test',
< 'regrtest', 'smoketest' and 'unittest'.
< 
< """
< import sys
< import os, os.path as osp
< import re
< import time
< import getopt
< import traceback
< import unittest
< import difflib
< import types
< from warnings import warn
< from compiler.consts import CO_GENERATOR
< try:
<     import readline
< except ImportError:
<     readline = None
< 
< # PRINT_ = file('stdout.txt', 'w').write
< 
< try:
<     from test import test_support
< except ImportError:
<     # not always available
<     class TestSupport:
<         def unload(self, test):
<             pass
<     test_support = TestSupport()
< 
< from clonedigger.logilab.common.deprecation import class_renamed, deprecated_function, \
<      obsolete
< from clonedigger.logilab.common.compat import set, enumerate, any
< from clonedigger.logilab.common.modutils import load_module_from_name
< from clonedigger.logilab.common.debugger import Debugger
< from clonedigger.logilab.common.decorators import cached
< 
< __all__ = ['main', 'unittest_main', 'find_tests', 'run_test', 'spawn']
< 
< DEFAULT_PREFIXES = ('test', 'regrtest', 'smoketest', 'unittest',
<                     'func', 'validation')
< 
< ENABLE_DBC = False
< 
< def main(testdir=None, exitafter=True):
<     """Execute a test suite.
< 
<     This also parses command-line options and modifies its behaviour
<     accordingly.
< 
<     tests -- a list of strings containing test names (optional)
<     testdir -- the directory in which to look for tests (optional)
< 
<     Users other than the Python test suite will certainly want to
<     specify testdir; if it's omitted, the directory containing the
<     Python test suite is searched for.
< 
<     If the tests argument is omitted, the tests listed on the
<     command-line will be used.  If that's empty, too, then all *.py
<     files beginning with test_ will be used.
< 
<     """
< 
<     try:
<         opts, args = getopt.getopt(sys.argv[1:], 'hvqx:t:pcd', ['help'])
<     except getopt.error, msg:
<         print msg
<         print __doc__
<         return 2
<     verbose = 0
<     quiet = False
<     profile = False
<     exclude = []
<     capture = 0
<     for o, a in opts:
<         if o == '-v':
<             verbose += 1
<         elif o == '-q':
<             quiet = True
<             verbose = 0
<         elif o == '-x':
<             exclude.append(a)
<         elif o == '-t':
<             testdir = a
<         elif o == '-p':
<             profile = True
<         elif o == '-c':
<             capture += 1
<         elif o == '-d':
<             global ENABLE_DBC
<             ENABLE_DBC = True
<         elif o in ('-h', '--help'):
<             print __doc__
<             sys.exit(0)
< 
<     args = [item.rstrip('.py') for item in args]
<     exclude = [item.rstrip('.py') for item in exclude]
< 
<     if testdir is not None:
<         os.chdir(testdir)
<     sys.path.insert(0, '')
<     tests = find_tests('.', args or DEFAULT_PREFIXES, excludes=exclude)
<     # Tell tests to be moderately quiet
<     test_support.verbose = verbose
<     if profile:
<         print >> sys.stderr, '** profiled run'
<         from hotshot import Profile
<         prof = Profile('stones.prof')
<         start_time, start_ctime = time.time(), time.clock()
<         good, bad, skipped, all_result = prof.runcall(run_tests, tests, quiet,
<                                                       verbose, None, capture)
<         end_time, end_ctime = time.time(), time.clock()
<         prof.close()
<     else:
<         start_time, start_ctime = time.time(), time.clock()
<         good, bad, skipped, all_result = run_tests(tests, quiet, verbose, None, capture)
<         end_time, end_ctime = time.time(), time.clock()
<     if not quiet:
<         print '*'*80
<         if all_result:
<             print 'Ran %s test cases in %0.2fs (%0.2fs CPU)' % (all_result.testsRun,
<                                                                 end_time - start_time,
<                                                                 end_ctime - start_ctime), 
<             if all_result.errors:
<                 print ', %s errors' % len(all_result.errors),
<             if all_result.failures:
<                 print ', %s failed' % len(all_result.failures),
<             if all_result.skipped:
<                 print ', %s skipped' % len(all_result.skipped),
<             print
<         if good:
<             if not bad and not skipped and len(good) > 1:
<                 print "All",
<             print _count(len(good), "test"), "OK."
<         if bad:
<             print _count(len(bad), "test"), "failed:",
<             print ', '.join(bad)
<         if skipped:
<             print _count(len(skipped), "test"), "skipped:",
<             print ', '.join(['%s (%s)' % (test, msg) for test, msg in skipped])
<     if profile:
<         from hotshot import stats
<         stats = stats.load('stones.prof')
<         stats.sort_stats('time', 'calls')
<         stats.print_stats(30)
<     if exitafter:
<         sys.exit(len(bad) + len(skipped))
<     else:
<         sys.path.pop(0)
<         return len(bad)
< main = obsolete("testlib.main() is obsolete, use the pytest tool instead")(main)
< 
< 
< def run_tests(tests, quiet, verbose, runner=None, capture=0):
<     """ execute a list of tests
<     return a 3-uple with :
<        _ the list of passed tests
<        _ the list of failed tests
<        _ the list of skipped tests
<     """
<     good = []
<     bad = []
<     skipped = []
<     all_result = None
<     for test in tests:
<         if not quiet:
<             print 
<             print '-'*80
<             print "Executing", test
<         result = run_test(test, verbose, runner, capture)
<         if type(result) is type(''):
<             # an unexpected error occured
<             skipped.append( (test, result))
<         else:
<             if all_result is None:
<                 all_result = result
<             else:
<                 all_result.testsRun += result.testsRun
<                 all_result.failures += result.failures
<                 all_result.errors += result.errors
<                 all_result.skipped += result.skipped
<             if result.errors or result.failures:
<                 bad.append(test)
<                 if verbose:
<                     print "test", test, \
<                           "failed -- %s errors, %s failures" % (
<                         len(result.errors), len(result.failures))
<             else:
<                 good.append(test)
<             
<     return good, bad, skipped, all_result
<     
< def find_tests(testdir,
<                prefixes=DEFAULT_PREFIXES, suffix=".py",
<                excludes=(),
<                remove_suffix=True):
<     """
<     Return a list of all applicable test modules.
<     """
<     tests = []
<     for name in os.listdir(testdir):
<         if not suffix or name.endswith(suffix):
<             for prefix in prefixes:
<                 if name.startswith(prefix):
<                     if remove_suffix and name.endswith(suffix):
<                         name = name[:-len(suffix)]
<                     if name not in excludes:
<                         tests.append(name)
<     tests.sort()
<     return tests
< 
< 
< def run_test(test, verbose, runner=None, capture=0):
<     """
<     Run a single test.
< 
<     test -- the name of the test
<     verbose -- if true, print more messages
<     """
<     test_support.unload(test)
<     try:
<         m = load_module_from_name(test, path=sys.path)
< #        m = __import__(test, globals(), locals(), sys.path)
<         try:
<             suite = m.suite
<             if callable(suite):
<                 suite = suite()
<         except AttributeError:
<             loader = unittest.TestLoader()
<             suite = loader.loadTestsFromModule(m)
<         if runner is None:
<             runner = SkipAwareTextTestRunner(capture=capture) # verbosity=0)
<         return runner.run(suite)
<     except KeyboardInterrupt, v:
<         raise KeyboardInterrupt, v, sys.exc_info()[2]
<     except:
<         # raise
<         type, value = sys.exc_info()[:2]
<         msg = "test %s crashed -- %s : %s" % (test, type, value)
<         if verbose:
<             traceback.print_exc()
<         return msg
< 
< def _count(n, word):
<     """format word according to n"""
<     if n == 1:
<         return "%d %s" % (n, word)
<     else:
<         return "%d %ss" % (n, word)
< 
< 
<     
< 
< ## PostMortem Debug facilities #####
< def start_interactive_mode(result):
<     """starts an interactive shell so that the user can inspect errors
<     """
<     debuggers = result.debuggers
<     descrs = result.error_descrs + result.fail_descrs
<     if len(debuggers) == 1:
<         # don't ask for test name if there's only one failure
<         debuggers[0].start()
<     else:
<         while True:
<             testindex = 0
<             print "Choose a test to debug:"
<             # order debuggers in the same way than errors were printed
<             print "\n".join(['\t%s : %s' % (i, descr) for i, (_, descr) in enumerate(descrs)])
<             print "Type 'exit' (or ^D) to quit"
<             print
<             try:
<                 todebug = raw_input('Enter a test name: ')
<                 if todebug.strip().lower() == 'exit':
<                     print
<                     break
<                 else:
<                     try:
<                         testindex = int(todebug)
<                         debugger = debuggers[descrs[testindex][0]]
<                     except (ValueError, IndexError):
<                         print "ERROR: invalid test number %r" % (todebug,)
<                     else:
<                         debugger.start()
<             except (EOFError, KeyboardInterrupt):
<                 print
<                 break
< 
< 
< # test utils ##################################################################
< from cStringIO import StringIO
< 
< class SkipAwareTestResult(unittest._TextTestResult):
< 
<     def __init__(self, stream, descriptions, verbosity,
<                  exitfirst=False, capture=0, printonly=None,
<                  pdbmode=False, cvg=None):
<         super(SkipAwareTestResult, self).__init__(stream,
<                                                   descriptions, verbosity)
<         self.skipped = []
<         self.debuggers = []
<         self.fail_descrs = []
<         self.error_descrs = []
<         self.exitfirst = exitfirst
<         self.capture = capture
<         self.printonly = printonly
<         self.pdbmode = pdbmode
<         self.cvg = cvg
<         self.pdbclass = Debugger
< 
<     def descrs_for(self, flavour):
<         return getattr(self, '%s_descrs' % flavour.lower())
<     
<     def _create_pdb(self, test_descr, flavour):
<         self.descrs_for(flavour).append( (len(self.debuggers), test_descr) )
<         if self.pdbmode:
<             self.debuggers.append(self.pdbclass(sys.exc_info()[2]))
<         
<     def addError(self, test, err):
<         exc_type, exc, tcbk = err
<         if exc_type == TestSkipped:
<             self.addSkipped(test, exc)
<         else:
<             if self.exitfirst:
<                 self.shouldStop = True
<             descr = self.getDescription(test)
<             super(SkipAwareTestResult, self).addError(test, err)
<             self._create_pdb(descr, 'error')
< 
<     def addFailure(self, test, err):
<         if self.exitfirst:
<             self.shouldStop = True
<         descr = self.getDescription(test)
<         super(SkipAwareTestResult, self).addFailure(test, err)
<         self._create_pdb(descr, 'fail')
< 
<     def addSkipped(self, test, reason):
<         self.skipped.append((test, self.getDescription(test), reason))
<         if self.showAll:
<             self.stream.writeln("SKIPPED")
<         elif self.dots:
<             self.stream.write('S')
< 
<     def printErrors(self):
<         super(SkipAwareTestResult, self).printErrors()
<         self.printSkippedList()
<         
<     def printSkippedList(self):
<         for test, descr, err in self.skipped:
<             self.stream.writeln(self.separator1)
<             self.stream.writeln("%s: %s" % ('SKIPPED', descr))
<             self.stream.writeln("\t%s" % err)
< 
<     def printErrorList(self, flavour, errors):
<         for (_, descr), (test, err) in zip(self.descrs_for(flavour), errors):
<             self.stream.writeln(self.separator1)
<             self.stream.writeln("%s: %s" % (flavour, descr))
<             self.stream.writeln(self.separator2)
<             self.stream.writeln("%s" % err)
<             try:
<                 output, errput = test.captured_output()
<             except AttributeError:
<                 pass # original unittest
<             else:
<                 if output:
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln("captured stdout".center(len(self.separator2)))
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln(output)
<                 else:
<                     self.stream.writeln('no stdout'.center(len(self.separator2)))
<                 if errput:
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln("captured stderr".center(len(self.separator2)))
<                     self.stream.writeln(self.separator2)
<                     self.stream.writeln(errput)
<                 else:
<                     self.stream.writeln('no stderr'.center(len(self.separator2)))
< 
< 
< 
< class TestSuite(unittest.TestSuite):
<     def run(self, result, runcondition=None, options=None):
<         for test in self._tests:
<             if result.shouldStop:
<                 break
<             test(result, runcondition, options)
<         return result
<     
<     # python2.3 compat
<     def __call__(self, *args, **kwds):
<         return self.run(*args, **kwds)
< 
< 
< class SkipAwareTextTestRunner(unittest.TextTestRunner):
< 
<     def __init__(self, stream=sys.stderr, verbosity=1,
<                  exitfirst=False, capture=False, printonly=None,
<                  pdbmode=False, cvg=None, test_pattern=None, skipped_patterns=(),
<                  options=None):
<         super(SkipAwareTextTestRunner, self).__init__(stream=stream,
<                                                       verbosity=verbosity)
<         self.exitfirst = exitfirst
<         self.capture = capture
<         self.printonly = printonly
<         self.pdbmode = pdbmode
<         self.cvg = cvg
<         self.test_pattern = test_pattern
<         self.skipped_patterns = skipped_patterns
<         self.options = options
< 
<     def _this_is_skipped(self, testedname):
<         return any([(pat in testedname) for pat in self.skipped_patterns])
< 
<     def _runcondition(self, test, skipgenerator=True):
<         if isinstance(test, InnerTest):
<             testname = test.name
<         else:
<             if isinstance(test, TestCase):
<                 meth = test._get_test_method()
<                 func = meth.im_func
<                 testname = '%s.%s' % (meth.im_class.__name__, func.__name__)
<             elif isinstance(test, types.FunctionType):
<                 func = test
<                 testname = func.__name__
<             elif isinstance(test, types.MethodType):
<                 func = test.im_func
<                 testname = '%s.%s' % (test.im_class.__name__, func.__name__)
<             else:
<                 return True # Not sure when this happens
<             if is_generator(func) and skipgenerator:
<                 return True # Let inner tests decide at run time
<         # print 'testname', testname, self.test_pattern
<         if self._this_is_skipped(testname):
<             return False # this was explicitly skipped
<         if self.test_pattern is None:
<             return True # no pattern
<         try:
<             classpattern, testpattern = self.test_pattern.split('.')
<             klass, name = testname.split('.')
<             return classpattern in klass and testpattern in name
<         except ValueError:
<             return self.test_pattern in testname
<     
<     def _makeResult(self):
<         return SkipAwareTestResult(self.stream, self.descriptions, self.verbosity,
<                                    self.exitfirst, self.capture, self.printonly,
<                                    self.pdbmode, self.cvg)
< 
<     def run(self, test):
<         "Run the given test case or test suite."
<         result = self._makeResult()
<         startTime = time.time()
<         test(result, self._runcondition, self.options)
<         stopTime = time.time()
<         timeTaken = stopTime - startTime
<         result.printErrors()
<         self.stream.writeln(result.separator2)
<         run = result.testsRun
<         self.stream.writeln("Ran %d test%s in %.3fs" %
<                             (run, run != 1 and "s" or "", timeTaken))
<         self.stream.writeln()
<         if not result.wasSuccessful():
<             self.stream.write("FAILED (")
<             failed, errored = map(len, (result.failures, result.errors))
<             if failed:
<                 self.stream.write("failures=%d" % failed)
<             if errored:
<                 if failed: self.stream.write(", ")
<                 self.stream.write("errors=%d" % errored)
<             self.stream.writeln(")")
<         else:
<             self.stream.writeln("OK")
<         return result
< 
< 
< class keywords(dict):
<     """keyword args (**kwargs) support for generative tests"""
< 
< class starargs(tuple):
<     """variable arguments (*args) for generative tests"""
<     def __new__(cls, *args):
<         return tuple.__new__(cls, args)
< 
< 
< 
< class NonStrictTestLoader(unittest.TestLoader):
<     """
<     overrides default testloader to be able to omit classname when
<     specifying tests to run on command line. For example, if the file
<     test_foo.py contains ::
<     
<         class FooTC(TestCase):
<             def test_foo1(self): # ...
<             def test_foo2(self): # ...
<             def test_bar1(self): # ...
< 
<         class BarTC(TestCase):
<             def test_bar2(self): # ...
< 
<     python test_foo.py will run the 3 tests in FooTC
<     python test_foo.py FooTC will run the 3 tests in FooTC
<     python test_foo.py test_foo will run test_foo1 and test_foo2
<     python test_foo.py test_foo1 will run test_foo1
<     python test_foo.py test_bar will run FooTC.test_bar1 and BarTC.test_bar2
<     """
<     suiteClass = TestSuite
< 
<     def __init__(self):
<         self.skipped_patterns = []
< 
<     def loadTestsFromNames(self, names, module=None):
<         suites = []
<         for name in names:
<             suites.extend(self.loadTestsFromName(name, module))
<         return self.suiteClass(suites)
< 
<     def _collect_tests(self, module):
<         tests = {}
<         for obj in vars(module).values():
<             if (issubclass(type(obj), (types.ClassType, type)) and
<                  issubclass(obj, unittest.TestCase)):
<                 classname = obj.__name__
<                 if self._this_is_skipped(classname):
<                     continue
<                 methodnames = []
<                 # obj is a TestCase class
<                 for attrname in dir(obj):
<                     if attrname.startswith(self.testMethodPrefix):
<                         attr = getattr(obj, attrname)
<                         if callable(attr):
<                             methodnames.append(attrname)
<                 # keep track of class (obj) for convenience
<                 tests[classname] = (obj, methodnames)
<         return tests
< 
<     def loadTestsFromSuite(self, module, suitename):
<         try:
<             suite = getattr(module, suitename)()
<         except AttributeError:
<             return []
<         assert hasattr(suite, '_tests'), \
<                "%s.%s is not a valid TestSuite" % (module.__name__, suitename)
<         # python2.3 does not implement __iter__ on suites, we need to return
<         # _tests explicitly
<         return suite._tests
<     
<     def loadTestsFromName(self, name, module=None):
<         parts = name.split('.')
<         if module is None or len(parts) > 2:
<             # let the base class do its job here
<             return [super(NonStrictTestLoader, self).loadTestsFromName(name)]
<         tests = self._collect_tests(module)
<         # import pprint
<         # pprint.pprint(tests)
<         collected = []
<         if len(parts) == 1:
<             pattern = parts[0]
<             if callable(getattr(module, pattern, None)) and pattern not in tests:
<                 # consider it as a suite
<                 return self.loadTestsFromSuite(module, pattern)
<             if pattern in tests:
<                 # case python unittest_foo.py MyTestTC
<                 klass, methodnames = tests[pattern]
<                 for methodname in methodnames:
<                     collected = [klass(methodname) for methodname in methodnames]
<             else:
<                 # case python unittest_foo.py something
<                 for klass, methodnames in tests.values():
<                     collected += [klass(methodname) for methodname in methodnames]
<         elif len(parts) == 2:
<             # case "MyClass.test_1"
<             classname, pattern = parts
<             klass, methodnames = tests.get(classname, (None, []))
<             for methodname in methodnames:
<                 collected = [klass(methodname) for methodname in methodnames]
<         return collected
< 
<     def _this_is_skipped(self, testedname):
<         return any([(pat in testedname) for pat in self.skipped_patterns])
< 
<     def getTestCaseNames(self, testCaseClass):
<         """Return a sorted sequence of method names found within testCaseClass
<         """
<         is_skipped = self._this_is_skipped
<         if is_skipped(testCaseClass.__name__):
<             return []
<         testnames = super(NonStrictTestLoader, self).getTestCaseNames(testCaseClass)
<         return [testname for testname in testnames if not is_skipped(testname)]
< 
<     
< class SkipAwareTestProgram(unittest.TestProgram):
<     # XXX: don't try to stay close to unittest.py, use optparse
<     USAGE = """\
< Usage: %(progName)s [options] [test] [...]
< 
< Options:
<   -h, --help       Show this message
<   -v, --verbose    Verbose output
<   -i, --pdb        Enable test failure inspection
<   -x, --exitfirst  Exit on first failure
<   -c, --capture    Captures and prints standard out/err only on errors
<   -p, --printonly  Only prints lines matching specified pattern (implies capture)
<   -s, --skip       skip test matching this pattern (no regexp for now)
<   -q, --quiet      Minimal output
< 
< Examples:
<   %(progName)s                               - run default set of tests
<   %(progName)s MyTestSuite                   - run suite 'MyTestSuite'
<   %(progName)s MyTestCase.testSomething      - run MyTestCase.testSomething
<   %(progName)s MyTestCase                    - run all 'test*' test methods
<                                                in MyTestCase
< """
<     def __init__(self, module='__main__', defaultTest=None, batchmode=False,
<                  cvg=None, options=None):
<         self.batchmode = batchmode
<         self.cvg = cvg
<         self.options = options
<         super(SkipAwareTestProgram, self).__init__(
<             module=module, defaultTest=defaultTest,
<             testLoader=NonStrictTestLoader())
<     
<     def parseArgs(self, argv):
<         self.pdbmode = False
<         self.exitfirst = False
<         self.capture = 0
<         self.printonly = None
<         self.skipped_patterns = []
<         self.test_pattern = None
<         import getopt
<         try:
<             options, args = getopt.getopt(argv[1:], 'hHvixqcp:s:',
<                                           ['help','verbose','quiet', 'pdb',
<                                            'exitfirst', 'capture', 'printonly=',
<                                            'skip='])
<             for opt, value in options:
<                 if opt in ('-h','-H','--help'):
<                     self.usageExit()
<                 if opt in ('-i', '--pdb'):
<                     self.pdbmode = True
<                 if opt in ('-x', '--exitfirst'):
<                     self.exitfirst = True
<                 if opt in ('-q','--quiet'):
<                     self.verbosity = 0
<                 if opt in ('-v','--verbose'):
<                     self.verbosity = 2
<                 if opt in ('-c', '--capture'):
<                     self.capture += 1
<                 if opt in ('-p', '--printonly'):
<                     self.printonly = re.compile(value)
<                 if opt in ('-s', '--skip'):
<                     self.skipped_patterns = [pat.strip() for pat in value.split(',')]
<             self.testLoader.skipped_patterns = self.skipped_patterns
<             if self.printonly is not None:
<                 self.capture += 1
<             if len(args) == 0 and self.defaultTest is None:
<                 suitefunc = getattr(self.module, 'suite', None)
<                 if isinstance(suitefunc, (types.FunctionType, types.MethodType)):
<                     self.test = self.module.suite()
<                 else:
<                     self.test = self.testLoader.loadTestsFromModule(self.module)
<                 return
<             if len(args) > 0:
<                 self.test_pattern = args[0]
<                 self.testNames = args
<             else:
<                 self.testNames = (self.defaultTest,)
<             self.createTests()
<         except getopt.error, msg:
<             self.usageExit(msg)
< 
< 
<     def runTests(self):
<         if hasattr(self.module, 'setup_module'):
<             try:
<                 self.module.setup_module(self.options)
<             except Exception, exc:
<                 print 'setup_module error:', exc
<                 sys.exit(1)
<         self.testRunner = SkipAwareTextTestRunner(verbosity=self.verbosity,
<                                                   exitfirst=self.exitfirst,
<                                                   capture=self.capture,
<                                                   printonly=self.printonly,
<                                                   pdbmode=self.pdbmode,
<                                                   cvg=self.cvg,
<                                                   test_pattern=self.test_pattern,
<                                                   skipped_patterns=self.skipped_patterns,
<                                                   options=self.options)
<         result = self.testRunner.run(self.test)
<         if hasattr(self.module, 'teardown_module'):
<             try:
<                 self.module.teardown_module(self.options)
<             except Exception, exc:
<                 print 'teardown_module error:', exc
<                 sys.exit(1)
<         if os.environ.get('PYDEBUG'):
<             warn("PYDEBUG usage is deprecated, use -i / --pdb instead", DeprecationWarning)
<             self.pdbmode = True
<         if result.debuggers and self.pdbmode:
<             start_interactive_mode(result)
<         if not self.batchmode:
<             sys.exit(not result.wasSuccessful())
<         self.result = result
< 
< 
< 
< 
< class FDCapture: 
<     """adapted from py lib (http://codespeak.net/py)
<     Capture IO to/from a given os-level filedescriptor.
<     """
<     def __init__(self, fd, attr='stdout', printonly=None):
<         self.targetfd = fd
<         self.tmpfile = os.tmpfile() # self.maketempfile()
<         self.printonly = printonly
<         # save original file descriptor
<         self._savefd = os.dup(fd)
<         # override original file descriptor
<         os.dup2(self.tmpfile.fileno(), fd)
<         # also modify sys module directly
<         self.oldval = getattr(sys, attr)
<         setattr(sys, attr, self) # self.tmpfile)
<         self.attr = attr
< 
<     def write(self, msg):
<         # msg might be composed of several lines
<         for line in msg.splitlines():
<             line += '\n' # keepdend=True is not enough
<             if self.printonly is None or self.printonly.search(line) is None:
<                 self.tmpfile.write(line)
<             else:
<                 os.write(self._savefd, line)
<         
< ##     def maketempfile(self):
< ##         tmpf = os.tmpfile()
< ##         fd = os.dup(tmpf.fileno())
< ##         newf = os.fdopen(fd, tmpf.mode, 0) # No buffering
< ##         tmpf.close()
< ##         return newf
<         
<     def restore(self):
<         """restore original fd and returns captured output"""
<         # hack hack hack
<         self.tmpfile.flush()
<         try:
<             ref_file = getattr(sys, '__%s__' % self.attr)
<             ref_file.flush()
<         except AttributeError:
<             pass
<         if hasattr(self.oldval, 'flush'):
<             self.oldval.flush()
<         # restore original file descriptor
<         os.dup2(self._savefd, self.targetfd)
<         # restore sys module
<         setattr(sys, self.attr, self.oldval)
<         # close backup descriptor
<         os.close(self._savefd)
<         # go to beginning of file and read it
<         self.tmpfile.seek(0)
<         return self.tmpfile.read()
< 
< 
< def _capture(which='stdout', printonly=None):
<     """private method, should not be called directly
<     (cf. capture_stdout() and capture_stderr())
<     """
<     assert which in ('stdout', 'stderr'), "Can only capture stdout or stderr, not %s" % which
<     if which == 'stdout':
<         fd = 1
<     else:
<         fd = 2
<     return FDCapture(fd, which, printonly)
<     
< def capture_stdout(printonly=None):
<     """captures the standard output
< 
<     returns a handle object which has a `restore()` method.
<     The restore() method returns the captured stdout and restores it
<     """
<     return _capture('stdout', printonly)
<         
< def capture_stderr(printonly=None):
<     """captures the standard error output
< 
<     returns a handle object which has a `restore()` method.
<     The restore() method returns the captured stderr and restores it
<     """
<     return _capture('stderr', printonly)
< 
< 
< def unittest_main(module='__main__', defaultTest=None,
<                   batchmode=False, cvg=None, options=None):
<     """use this functon if you want to have the same functionality
<     as unittest.main"""
<     return SkipAwareTestProgram(module, defaultTest, batchmode, cvg, options)
< 
< class TestSkipped(Exception):
<     """raised when a test is skipped"""
< 
< def is_generator(function):
<     flags = function.func_code.co_flags
<     return flags & CO_GENERATOR
< 
< 
< def parse_generative_args(params):
<     args = []
<     varargs = ()
<     kwargs = {}
<     flags = 0 # 2 <=> starargs, 4 <=> kwargs
<     for param in params:
<         if isinstance(param, starargs):
<             varargs = param
<             if flags:
<                 raise TypeError('found starargs after keywords !')
<             flags |= 2
<             args += list(varargs)
<         elif isinstance(param, keywords):
<             kwargs = param
<             if flags & 4:
<                 raise TypeError('got multiple keywords parameters')
<             flags |= 4
<         elif flags & 2 or flags & 4:
<             raise TypeError('found parameters after kwargs or args')
<         else:
<             args.append(param)
< 
<     return args, kwargs
< 
< class InnerTest(tuple):
<     def __new__(cls, name, *data):
<         instance = tuple.__new__(cls, data)
<         instance.name = name
<         return instance
< 
< class ClassGetProperty(object):
<     """this is a simple property-like class but for
<     class attributes.
<     """
<     
<     def __init__(self, getter):
<         self.getter = getter
< 
<     def __get__(self, obj, objtype):
<         return self.getter(objtype)
< 
< 
< class TestCase(unittest.TestCase):
<     """unittest.TestCase with some additional methods"""
< 
<     capture = False
<     pdbclass = Debugger
<     
<     def __init__(self, methodName='runTest'):
<         super(TestCase, self).__init__(methodName)
<         # internal API changed in python2.5
<         if sys.version_info >= (2, 5):
<             self.__exc_info = self._exc_info
<             self.__testMethodName = self._testMethodName
<         else:
<             # let's give easier access to _testMethodName to every subclasses
<             self._testMethodName = self.__testMethodName
<         self._captured_stdout = ""
<         self._captured_stderr = ""
<         self._out = []
<         self._err = []
<         self._current_test_descr = None
<         self._options_ = None
< 
<     def datadir(cls):
<         """helper attribute holding the standard test's data directory
<         
<         NOTE: this is a logilab's standard
<         """
<         mod = __import__(cls.__module__)
<         return osp.join(osp.dirname(osp.abspath(mod.__file__)), 'data')
<     # cache it (use a class method to cache on class since TestCase is
<     # instantiated for each test run)
<     datadir = ClassGetProperty(cached(datadir))
< 
<     def datapath(self, fname):
<         """joins the object's datadir and `fname`"""
<         return osp.join(self.datadir, fname)
< 
<     def set_description(self, descr):
<         """sets the current test's description.
<         This can be useful for generative tests because it allows to specify
<         a description per yield
<         """
<         self._current_test_descr = descr
< 
<     # override default's unittest.py feature
<     def shortDescription(self):
< 	"""override default unitest shortDescription to handle correctly
< 	generative tests
< 	"""
<         if self._current_test_descr is not None:
< 	    return self._current_test_descr
< 	return super(TestCase, self).shortDescription()
< 
<     
<     def captured_output(self):
<         return self._captured_stdout.strip(), self._captured_stderr.strip()
< 
<     def _start_capture(self):
<         if self.capture:
<             self.start_capture()
< 
<     def _stop_capture(self):
<         self._force_output_restore()
<     
<     def start_capture(self, printonly=None):
<         self._out.append(capture_stdout(printonly or self._printonly))
<         self._err.append(capture_stderr(printonly or self._printonly))
< 
<     def printonly(self, pattern, flags=0):
<         rgx = re.compile(pattern, flags)
<         if self._out:
<             self._out[-1].printonly = rgx
<             self._err[-1].printonly = rgx
<         else:
<             self.start_capture(printonly=rgx)
<         
<     def stop_capture(self):
<         if self._out:
<             _out = self._out.pop()
<             _err = self._err.pop()
<             return _out.restore(), _err.restore()
<         return '', ''
<     
<     def _force_output_restore(self):
<         while self._out:
<             self._captured_stdout += self._out.pop().restore()
<             self._captured_stderr += self._err.pop().restore()
<     
<     def quiet_run(self, result, func, *args, **kwargs):
<         self._start_capture()
<         try:
<             func(*args, **kwargs)
<         except (KeyboardInterrupt, SystemExit):
<             self._stop_capture()
<             raise
<         except:
<             self._stop_capture()
<             result.addError(self, self.__exc_info())
<             return False
<         self._stop_capture()
<         return True
< 
<     def _get_test_method(self):
<         return getattr(self, self.__testMethodName)
< 
< 
<     def optval(self, option, default=None):
<         return getattr(self._options_, option, default)
< 
<     def __call__(self, result=None, runcondition=None, options=None):
<         """rewrite TestCase.__call__ to support generative tests
<         This is mostly a copy/paste from unittest.py (i.e same
<         variable names, same logic, except for the generative tests part)
<         """
<         if result is None:
<             result = self.defaultTestResult()
<         result.pdbclass = self.pdbclass
<         # if self.capture is True here, it means it was explicitly specified
<         # in the user's TestCase class. If not, do what was asked on cmd line
<         self.capture = self.capture or getattr(result, 'capture', False)
<         self._options_ = options
<         self._printonly = getattr(result, 'printonly', None)
<         # if result.cvg:
<         #     result.cvg.start()
<         testMethod = self._get_test_method()
<         if runcondition and not runcondition(testMethod):
<             return # test is skipped
<         result.startTest(self)
<         try:
<             if not self.quiet_run(result, self.setUp):
<                 return
<             # generative tests
<             if is_generator(testMethod.im_func):
<                 success = self._proceed_generative(result, testMethod, runcondition)
<             else:
<                 status = self._proceed(result, testMethod)
<                 success = (status == 0)
<             if not self.quiet_run(result, self.tearDown):
<                 return
<             if success:
<                 result.addSuccess(self)
<         finally:
<             # if result.cvg:
<             #     result.cvg.stop()
<             result.stopTest(self)
< 
< 
<             
<     def _proceed_generative(self, result, testfunc, runcondition=None):
<         # cancel startTest()'s increment
<         result.testsRun -= 1
<         self._start_capture()
<         success = True
<         try:
<             for params in testfunc():
<                 if runcondition and not runcondition(testfunc, skipgenerator=False):
<                     if not (isinstance(params, InnerTest) and runcondition(params)):
<                         continue
<                 if not isinstance(params, (tuple, list)):
<                     params = (params,)
<                 func = params[0]
<                 args, kwargs = parse_generative_args(params[1:])
<                 # increment test counter manually
<                 result.testsRun += 1
<                 status = self._proceed(result, func, args, kwargs)
<                 if status == 0:
<                     result.addSuccess(self)
<                     success = True
<                 else:
<                     success = False
<                     if status == 2:
<                         result.shouldStop = True
<                 if result.shouldStop: # either on error or on exitfirst + error
<                     break
<         except:
<             # if an error occurs between two yield
<             result.addError(self, self.__exc_info())
<             success = False
<         self._stop_capture()
<         return success
< 
<     def _proceed(self, result, testfunc, args=(), kwargs=None):
<         """proceed the actual test
<         returns 0 on success, 1 on failure, 2 on error
< 
<         Note: addSuccess can't be called here because we have to wait
<         for tearDown to be successfully executed to declare the test as
<         successful
<         """
<         self._start_capture()
<         kwargs = kwargs or {}
<         try:
<             testfunc(*args, **kwargs)
<             self._stop_capture()
<         except self.failureException:
<             self._stop_capture()
<             result.addFailure(self, self.__exc_info())
<             return 1
<         except KeyboardInterrupt:
<             self._stop_capture()
<             raise
<         except:
<             self._stop_capture()
<             result.addError(self, self.__exc_info())
<             return 2
<         return 0
<             
<     def defaultTestResult(self):
<         return SkipAwareTestResult()
< 
<     def skip(self, msg=None):
<         msg = msg or 'test was skipped'
<         raise TestSkipped(msg)
<     skipped_test = deprecated_function(skip)
<     
<     def assertDictEquals(self, d1, d2):
<         """compares two dicts
< 
<         If the two dict differ, the first difference is shown in the error
<         message
<         """
<         d1 = d1.copy()
<         msgs = []
<         for key, value in d2.items():
<             try:
<                 if d1[key] != value:
<                     msgs.append('%r != %r for key %r' % (d1[key], value, key))
<                 del d1[key]
<             except KeyError:
<                 msgs.append('missing %r key' % key)
<         if d1:
<             msgs.append('d2 is lacking %r' % d1)
<         if msgs:
<             self.fail('\n'.join(msgs))
<     assertDictEqual = assertDictEquals
< 
<     def assertSetEquals(self, got, expected, msg=None):
<         """compares two iterables and shows difference between both"""
<         got, expected = list(got), list(expected)
<         if msg is None:
< 	        msg1 = '%s != %s' % (got, expected)
<         else:
<             msg1 = msg
<         self.assertEquals(len(got), len(expected), msg1)
<         got, expected = set(got), set(expected)
<         if got != expected:
<             missing = expected - got
<             unexpected = got - expected
<             if msg is None:
<                 msg = '\tunexepected: %s\n\tmissing: %s' % (unexpected,
<                                                                missing)
<             self.fail(msg)
<     assertSetEqual = assertSetEquals
< 
<     def assertListEquals(self, l1, l2, msg=None):
<         """compares two lists
< 
<         If the two list differ, the first difference is shown in the error
<         message
<         """
<         _l1 = l1[:]
<         for i, value in enumerate(l2):
<             try:
<                 if _l1[0] != value:
<                     from pprint import pprint
<                     pprint(l1)
<                     pprint(l2)
<                     self.fail('%r != %r for index %d' % (_l1[0], value, i))
<                 del _l1[0]
<             except IndexError:
<                 if msg is None:
<                     msg = 'l1 has only %d elements, not %s (at least %r missing)'% (i, len(l2), value)
<                 self.fail(msg)
<         if _l1:
<             if msg is None:
<                 msg = 'l2 is lacking %r' % _l1
<             self.fail(msg)
<     assertListEqual = assertListEquals
<     
<     def assertLinesEquals(self, l1, l2, msg=None):
<         """assert list of lines are equal"""
<         self.assertListEquals(l1.splitlines(), l2.splitlines(), msg)
<     assertLineEqual = assertLinesEquals
< 
<     def assertXMLWellFormed(self, stream, msg=None):
<         """asserts the XML stream is well-formed (no DTD conformance check)"""
<         from xml.sax import make_parser, SAXParseException
<         parser = make_parser()
<         try:
<             parser.parse(stream)
<         except SAXParseException:
<             if msg is None:
<                 msg = 'XML stream not well formed'
<             self.fail(msg)
<     assertXMLValid = deprecated_function(assertXMLWellFormed,
<                                          'assertXMLValid renamed to more precise assertXMLWellFormed')
< 
<     def assertXMLStringWellFormed(self, xml_string, msg=None):
<         """asserts the XML string is well-formed (no DTD conformance check)"""
<         stream = StringIO(xml_string)
<         self.assertXMLWellFormed(stream, msg)
<         
<     assertXMLStringValid = deprecated_function(
<         assertXMLStringWellFormed, 'assertXMLStringValid renamed to more precise assertXMLStringWellFormed')
< 
< 
<     def _difftext(self, lines1, lines2, junk=None):
<         junk = junk or (' ', '\t')
<         # result is a generator
<         result = difflib.ndiff(lines1, lines2, charjunk=lambda x: x in junk)
<         read = []
<         for line in result:
<             read.append(line)
<             # lines that don't start with a ' ' are diff ones
<             if not line.startswith(' '):
<                 self.fail(''.join(read + list(result)))
<         
<     def assertTextEquals(self, text1, text2, junk=None):
<         """compare two multiline strings (using difflib and splitlines())"""
<         self._difftext(text1.splitlines(True), text2.splitlines(True), junk)
<     assertTextEqual = assertTextEquals
<             
<     def assertStreamEqual(self, stream1, stream2, junk=None):
<         """compare two streams (using difflib and readlines())"""
<         # if stream2 is stream2, readlines() on stream1 will also read lines
<         # in stream2, so they'll appear different, although they're not
<         if stream1 is stream2:
<             return
<         # make sure we compare from the beginning of the stream
<         stream1.seek(0)
<         stream2.seek(0)
<         # ocmpare
<         self._difftext(stream1.readlines(), stream2.readlines(), junk)
<             
<     def assertFileEqual(self, fname1, fname2, junk=(' ', '\t')):
<         """compares two files using difflib"""
<         self.assertStreamEqual(file(fname1), file(fname2), junk)
<             
<     def assertIsInstance(self, obj, klass, msg=None, strict=False):
<         """compares two files using difflib"""
<         if msg is None:
<             if strict:
<                 msg = '%r is not of class %s but of %s'
<             else:
<                 msg = '%r is not an instance of %s but of %s'
<             msg = msg % (obj, klass, type(obj))
<         if strict:
<             self.assert_(obj.__class__ is klass, msg)
<         else:
<             self.assert_(isinstance(obj, klass), msg)
< 
< 
<     def failUnlessRaises(self, excClass, callableObj, *args, **kwargs):
<         """override default failUnlessRaise method to return the raised
<         exception instance.
<         
<         Fail unless an exception of class excClass is thrown
<         by callableObj when invoked with arguments args and keyword
<         arguments kwargs. If a different type of exception is
<         thrown, it will not be caught, and the test case will be
<         deemed to have suffered an error, exactly as for an
<         unexpected exception.
<         """
<         try:
<             callableObj(*args, **kwargs)
<         except excClass, exc:
<             return exc
<         else:
<             if hasattr(excClass, '__name__'):
<                 excName = excClass.__name__
<             else:
<                 excName = str(excClass)
<             raise self.failureException, "%s not raised" % excName
< 
<     assertRaises = failUnlessRaises
< 
< import doctest
< 
< class SkippedSuite(unittest.TestSuite):
<     def test(self):
<         """just there to trigger test execution"""
<         self.skipped_test('doctest module has no DocTestSuite class')
< 
< 
< # DocTestFinder was introduced in python2.4
< if sys.version_info >= (2, 4):
<     class DocTestFinder(doctest.DocTestFinder):
< 
<         def __init__(self, *args, **kwargs):
<             self.skipped = kwargs.pop('skipped', ())
<             doctest.DocTestFinder.__init__(self, *args, **kwargs)
< 
<         def _get_test(self, obj, name, module, globs, source_lines):
<             """override default _get_test method to be able to skip tests
<             according to skipped attribute's value
< 
<             Note: Python (<=2.4) use a _name_filter which could be used for that
<                   purpose but it's no longer available in 2.5
<                   Python 2.5 seems to have a [SKIP] flag
<             """
<             if getattr(obj, '__name__', '') in self.skipped:
<                 return None
<             return doctest.DocTestFinder._get_test(self, obj, name, module,
<                                                    globs, source_lines)
< else:
<     # this is a hack to make skipped work with python <= 2.3
<     class DocTestFinder(object):
<         def __init__(self, skipped):
<             self.skipped = skipped
<             self.original_find_tests = doctest._find_tests
<             doctest._find_tests = self._find_tests
<             
<         def _find_tests(self, module, prefix=None):
<             tests = []
<             for testinfo  in self.original_find_tests(module, prefix):
<                 testname, _, _, _ = testinfo
<                 # testname looks like A.B.C.function_name
<                 testname = testname.split('.')[-1]
<                 if testname not in self.skipped:
<                     tests.append(testinfo)
<             return tests
< 
< 
< class DocTest(TestCase):
<     """trigger module doctest
<     I don't know how to make unittest.main consider the DocTestSuite instance
<     without this hack
<     """
<     skipped = ()
<     def __call__(self, result=None, runcondition=None, options=None):
<         try:
<             finder = DocTestFinder(skipped=self.skipped)
<             if sys.version_info >= (2, 4):
<                 suite = doctest.DocTestSuite(self.module, test_finder=finder)
<             else:
<                 suite = doctest.DocTestSuite(self.module)
<         except AttributeError:
<             suite = SkippedSuite()
<         return suite.run(result)
<     run = __call__
<     
<     def test(self):
<         """just there to trigger test execution"""
< 
< MAILBOX = None
< 
< class MockSMTP:
<     """fake smtplib.SMTP"""
<     
<     def __init__(self, host, port):
<         self.host = host
<         self.port = port
<         global MAILBOX
<         self.reveived = MAILBOX = []
<         
<     def set_debuglevel(self, debuglevel):
<         """ignore debug level"""
< 
<     def sendmail(self, fromaddr, toaddres, body):
<         """push sent mail in the mailbox"""
<         self.reveived.append((fromaddr, toaddres, body))
< 
<     def quit(self):
<         """ignore quit"""
< 
< 
< class MockConfigParser:
<     """fake ConfigParser.ConfigParser"""
<     
<     def __init__(self, options):
<         self.options = options
<         
<     def get(self, section, option):
<         """return option in section"""
<         return self.options[section][option]
< 
<     def has_option(self, section, option):
<         """ask if option exists in section"""
<         try:
<             return self.get(section, option) or 1
<         except KeyError:
<             return 0
<     
< 
< class MockConnection:
<     """fake DB-API 2.0 connexion AND cursor (i.e. cursor() return self)"""
<     
<     def __init__(self, results):
<         self.received = []
<         self.states = []
<         self.results = results
<         
<     def cursor(self):
<         return self
<     def execute(self, query, args=None):
<         self.received.append( (query, args) )
<     def fetchone(self):
<         return self.results[0]
<     def fetchall(self):
<         return self.results
<     def commit(self):
<         self.states.append( ('commit', len(self.received)) )
<     def rollback(self):
<         self.states.append( ('rollback', len(self.received)) )
<     def close(self):
<         pass
< 
< MockConnexion = class_renamed('MockConnexion', MockConnection)
< 
< def mock_object(**params):
<     """creates an object using params to set attributes
<     >>> option = mock_object(verbose=False, index=range(5))
<     >>> option.verbose
<     False
<     >>> option.index
<     [0, 1, 2, 3, 4]
<     """
<     return type('Mock', (), params)()
< 
< 
< def create_files(paths, chroot):
<     """creates directories and files found in <path>
< 
<     :param path: list of relative paths to files or directories
<     :param chroot: the root directory in which paths will be created
< 
<     >>> from os.path import isdir, isfile
<     >>> isdir('/tmp/a')
<     False
<     >>> create_files(['a/b/foo.py', 'a/b/c/', 'a/b/c/d/e.py'], '/tmp')
<     >>> isdir('/tmp/a')
<     True
<     >>> isdir('/tmp/a/b/c')
<     True
<     >>> isfile('/tmp/a/b/c/d/e.py')
<     True 
<     >>> isfile('/tmp/a/b/foo.py')
<     True
<     """
<     dirs, files = set(), set()
<     for path in paths:
<         path = osp.join(chroot, path)
<         filename = osp.basename(path)
<         # path is a directory path
<         if filename == '':
<             dirs.add(path)
<         # path is a filename path
<         else:
<             dirs.add(osp.dirname(path))
<             files.add(path)
<     for dirpath in dirs:
<         if not osp.isdir(dirpath):
<             os.makedirs(dirpath)
<     for filepath in files:
<         file(filepath, 'w').close()
< 
< def enable_dbc(*args):
<     """
<     Without arguments, return True if contracts can be enabled and should be
<     enabled (see option -d), return False otherwise.
< 
<     With arguments, return False if contracts can't or shouldn't be enabled,
<     otherwise weave ContractAspect with items passed as arguments.
<     """
<     if not ENABLE_DBC:
<         return False
<     try:
<         from clonedigger.logilab.aspects.weaver import weaver
<         from clonedigger.logilab.aspects.lib.contracts import ContractAspect
<     except ImportError:
<         sys.stderr.write('Warning: logilab.aspects is not available. Contracts disabled.')
<         return False
<     for arg in args:
<         weaver.weave_module(arg, ContractAspect)
<     return True
< 
<     
< class AttrObject: # XXX cf mock_object
<     def __init__(self, **kwargs):
<         self.__dict__.update(kwargs)
diff -r -N code-worker/tasks/clonedigger/logilab/common/textutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/textutils.py
1,384d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Some text manipulation utility functions.
< 
< :author:    Logilab
< :copyright: 2003-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< 
< :group text formatting: normalize_text, normalize_paragraph, pretty_match,\
< unquote, colorize_ansi
< :group text manipulation: searchall, get_csv
< :sort: text formatting, text manipulation
< 
< 
< 
< :type ANSI_STYLES: dict(str)
< :var ANSI_STYLES: dictionary mapping style identifier to ANSI terminal code
< 
< :type ANSI_COLORS: dict(str)
< :var ANSI_COLORS: dictionary mapping color identifier to ANSI terminal code
< 
< :type ANSI_PREFIX: str
< :var ANSI_PREFIX:
<   ANSI terminal code notifing the start of an ANSI escape sequence
<   
< :type ANSI_END: str
< :var ANSI_END:
<   ANSI terminal code notifing the end of an ANSI escape sequence
<   
< :type ANSI_RESET: str
< :var ANSI_RESET:
<   ANSI terminal code reseting format defined by a previous ANSI escape sequence
< """
< 
< __docformat__ = "restructuredtext en"
< 
< import re
< from unicodedata import normalize as _uninormalize
< from os import linesep
< 
< 
< MANUAL_UNICODE_MAP = {
<     u'\xa1': u'!',    # INVERTED EXCLAMATION MARK
<     u'\u0142': u'l',  # LATIN SMALL LETTER L WITH STROKE
<     u'\u2044': u'/',  # FRACTION SLASH
<     u'\xc6': u'AE',   # LATIN CAPITAL LETTER AE
<     u'\xa9': u'(c)',  # COPYRIGHT SIGN
<     u'\xab': u'"',    # LEFT-POINTING DOUBLE ANGLE QUOTATION MARK
<     u'\xe6': u'ae',   # LATIN SMALL LETTER AE
<     u'\xae': u'(r)',  # REGISTERED SIGN
<     u'\u0153': u'oe', # LATIN SMALL LIGATURE OE
<     u'\u0152': u'OE', # LATIN CAPITAL LIGATURE OE
<     u'\xd8': u'O',    # LATIN CAPITAL LETTER O WITH STROKE
<     u'\xf8': u'o',    # LATIN SMALL LETTER O WITH STROKE
<     u'\xbb': u'"',    # RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK
<     u'\xdf': u'ss',   # LATIN SMALL LETTER SHARP S
<     }
< 
< def unormalize(ustring, ignorenonascii=False):
<     """replace diacritical characters with their corresponding ascii characters
<     """
<     res = []
<     for letter in ustring[:]:
<         try:
<             replacement = MANUAL_UNICODE_MAP[letter]
<         except KeyError:
<             if ord(letter) >= 2**8:
<                 if ignorenonascii:
<                     continue
<                 raise ValueError("can't deal with non-ascii based characters")
<             replacement = _uninormalize('NFD', letter)[0]
<         res.append(replacement)
<     return u''.join(res)
< 
< def unquote(string):
<     """remove optional quotes (simple or double) from the string
< 
<     :type string: str or unicode
<     :param string: an optionaly quoted string
< 
<     :rtype: str or unicode
<     :return: the unquoted string (or the input string if it wasn't quoted)
<     """
<     if not string:
<         return string
<     if string[0] in '"\'':
<         string = string[1:]
<     if string[-1] in '"\'':
<         string = string[:-1]
<     return string
< 
< 
< _BLANKLINES_RGX = re.compile('\r?\n\r?\n')
< _NORM_SPACES_RGX = re.compile('\s+')
< 
< def normalize_text(text, line_len=80, indent='', rest=False):
<     """normalize a text to display it with a maximum line size and
<     optionally arbitrary indentation. Line jumps are normalized but blank
<     lines are kept. The indentation string may be used to insert a
<     comment (#) or a quoting (>) mark  for instance.
< 
<     :type text: str or unicode
<     :param text: the input text to normalize
< 
<     :type line_len: int
<     :param line_len: expected maximum line's length, default to 80
< 
<     :type indent: str or unicode
<     :param indent: optional string to use as indentation
< 
<     :rtype: str or unicode
<     :return:
<       the input text normalized to fit on lines with a maximized size
<       inferior to `line_len`, and optionally prefixed by an
<       indentation string
<     """
<     if rest:
<         normp = normalize_rest_paragraph
<     else:
<         normp = normalize_paragraph
<     result = []
<     for text in _BLANKLINES_RGX.split(text):
<         result.append(normp(text, line_len, indent))
<     return ('%s%s%s' % (linesep, indent, linesep)).join(result)
< 
< 
< def normalize_paragraph(text, line_len=80, indent=''):
<     """normalize a text to display it with a maximum line size and
<     optionaly arbitrary indentation. Line jumps are normalized. The
<     indentation string may be used top insert a comment mark for
<     instance.
< 
<     :type text: str or unicode
<     :param text: the input text to normalize
< 
<     :type line_len: int
<     :param line_len: expected maximum line's length, default to 80
< 
<     :type indent: str or unicode
<     :param indent: optional string to use as indentation
< 
<     :rtype: str or unicode
<     :return:
<       the input text normalized to fit on lines with a maximized size
<       inferior to `line_len`, and optionally prefixed by an
<       indentation string
<     """
<     text = _NORM_SPACES_RGX.sub(' ', text)
<     line_len = line_len - len(indent)
<     lines = []
<     while text:
<         aline, text = splittext(text.strip(), line_len)
<         lines.append(indent + aline)
<     return linesep.join(lines)
<     
< def normalize_rest_paragraph(text, line_len=80, indent=''):
<     """normalize a ReST text to display it with a maximum line size and
<     optionaly arbitrary indentation. Line jumps are normalized. The
<     indentation string may be used top insert a comment mark for
<     instance.
< 
<     :type text: str or unicode
<     :param text: the input text to normalize
< 
<     :type line_len: int
<     :param line_len: expected maximum line's length, default to 80
< 
<     :type indent: str or unicode
<     :param indent: optional string to use as indentation
< 
<     :rtype: str or unicode
<     :return:
<       the input text normalized to fit on lines with a maximized size
<       inferior to `line_len`, and optionally prefixed by an
<       indentation string
<     """
<     toreport = ''
<     lines = []
<     line_len = line_len - len(indent)
<     for line in text.splitlines():
<         line = toreport + _NORM_SPACES_RGX.sub(' ', line.strip())
<         toreport = ''
<         while len(line) > line_len:
<             # too long line, need split
<             line, toreport = splittext(line, line_len)
<             lines.append(indent + line)
<             if toreport:
<                 line = toreport + ' '
<                 toreport = ''
<             else:
<                 line = ''
<         if line:
<             lines.append(indent + line.strip())
<     return linesep.join(lines)
< 
< def splittext(text, line_len):
<     """split the given text on space according to the given max line size
<     
<     return a 2-uple:
<     * a line <= line_len if possible
<     * the rest of the text which has to be reported on another line
<     """
<     if len(text) <= line_len:
<         return text, ''
<     pos = min(len(text)-1, line_len)
<     while pos > 0 and text[pos] != ' ':
<         pos -= 1
<     if pos == 0:
<         pos = min(len(text), line_len)
<         while len(text) > pos and text[pos] != ' ':
<             pos += 1
<     return text[:pos], text[pos+1:].strip()
< 
< 
< def get_csv(string, sep=','):
<     """return a list of string in from a csv formatted line
< 
<     >>> get_csv('a, b, c   ,  4')
<     ['a', 'b', 'c', '4']
<     >>> get_csv('a')
<     ['a']
<     >>>
< 
<     :type string: str or unicode
<     :param string: a csv line
< 
<     :type sep: str or unicode
<     :param sep: field separator, default to the comma (',')
< 
<     :rtype: str or unicode
<     :return: the unquoted string (or the input string if it wasn't quoted)    
<     """
<     return [word.strip() for word in string.split(sep) if word.strip()]
< 
< 
< _LINE_RGX = re.compile('\r\n|\r+|\n')
< 
< def pretty_match(match, string, underline_char='^'):
<     """return a string with the match location underlined:
< 
<     >>> import re
<     >>> print pretty_match(re.search('mange', 'il mange du bacon'), 'il mange du bacon')
<     il mange du bacon
<        ^^^^^
<     >>>
<     
<     :type match: _sre.SRE_match
<     :param match: object returned by re.match, re.search or re.finditer
< 
<     :type string: str or unicode
<     :param string:
<       the string on which the regular expression has been applied to
<       obtain the `match` object
< 
<     :type underline_char: str or unicode
<     :param underline_char:
<       character to use to underline the matched section, default to the
<       carret '^'
< 
<     :rtype: str or unicode
<     :return:
<       the original string with an inserted line to underline the match
<       location
<     """
<     start = match.start()
<     end = match.end()
<     string = _LINE_RGX.sub(linesep, string)
<     start_line_pos = string.rfind(linesep, 0, start)
<     if start_line_pos == -1:
<         start_line_pos = 0
<         result = []
<     else:
<         result = [string[:start_line_pos]]
<         start_line_pos += len(linesep)
<     offset = start - start_line_pos
<     underline = ' ' * offset + underline_char * (end - start)
<     end_line_pos = string.find(linesep, end)
<     if end_line_pos == -1:
<         string = string[start_line_pos:]
<         result.append(string)
<         result.append(underline)
<     else:
<         end = string[end_line_pos + len(linesep):]
<         string = string[start_line_pos:end_line_pos]
<         result.append(string)
<         result.append(underline)
<         result.append(end)
<     return linesep.join(result).rstrip()
< 
< 
< # Ansi colorization ###########################################################
< 
< ANSI_PREFIX = '\033['
< ANSI_END = 'm'
< ANSI_RESET = '\033[0m'
< ANSI_STYLES = {
<     'reset'     : "0",
<     'bold'      : "1",
<     'italic'    : "3",
<     'underline' : "4",
<     'blink'     : "5",
<     'inverse'   : "7",
<     'strike'    : "9",
< }
< ANSI_COLORS = {
<     'reset'   : "0",
<     'black'   : "30",
<     'red'     : "31",
<     'green'   : "32",
<     'yellow'  : "33",
<     'blue'    : "34",
<     'magenta' : "35",
<     'cyan'    : "36",
<     'white'   : "37",
< }
< 
< 
< def _get_ansi_code(color=None, style=None):
<     """return ansi escape code corresponding to color and style
<     
<     :type color: str or None
<     :param color:
<       the color identifier (see `ANSI_COLORS` for available values)
< 
<     :type style: str or None
<     :param style:
<       style string (see `ANSI_COLORS` for available values). To get
<       several style effects at the same time, use a coma as separator.
< 
<     :raise KeyError: if an unexistant color or style identifier is given
<     
<     :rtype: str
<     :return: the built escape code
<     """
<     ansi_code = []
<     if style:
<         style_attrs = get_csv(style)
<         for effect in style_attrs:
<             ansi_code.append(ANSI_STYLES[effect])
<     if color:
<         ansi_code.append(ANSI_COLORS[color])
<     if ansi_code:
<         return ANSI_PREFIX + ';'.join(ansi_code) + ANSI_END
<     return ''
< 
< def colorize_ansi(msg, color=None, style=None):
<     """colorize message by wrapping it with ansi escape codes
< 
<     :type msg: str or unicode
<     :param msg: the message string to colorize
< 
<     :type color: str or None
<     :param color:
<       the color identifier (see `ANSI_COLORS` for available values)
< 
<     :type style: str or None
<     :param style:
<       style string (see `ANSI_COLORS` for available values). To get
<       several style effects at the same time, use a coma as separator.
< 
<     :raise KeyError: if an unexistant color or style identifier is given
< 
<     :rtype: str or unicode
<     :return: the ansi escaped string
<     """
<     # If both color and style are not defined, then leave the text as is
<     if color is None and style is None:
<         return msg
<     escape_code = _get_ansi_code(color, style)
<     # If invalid (or unknown) color, don't wrap msg with ansi codes
<     if escape_code:
<         return '%s%s%s' % (escape_code, msg, ANSI_RESET)
<     return msg
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/tree.py code-worker/code-worker/tasks/clonedigger/logilab/common/tree.py
1,364d0
< # Copyright (c) 2003-2006 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
<  base class to represent tree structure
< """
< 
< import sys
< 
< from clonedigger.logilab.common import flatten
< from clonedigger.logilab.common.visitor import VisitedMixIn, FilteredIterator, no_filter
< 
< ## Exceptions #################################################################
< 
< class NodeNotFound(Exception):
<     """raised when a node has not been found"""
< 
< EX_SIBLING_NOT_FOUND = "No such sibling as '%s'"
< EX_CHILD_NOT_FOUND = "No such child as '%s'"
< EX_NODE_NOT_FOUND = "No such node as '%s'"
< 
< 
< # Base node ###################################################################
< 
< class Node(object):
<     """a basic tree node, caracterised by an id"""
< 
<     def __init__(self, nid=None) :
<         self.id = nid
<         # navigation
<         self.parent = None
<         self.children = []
< 
<     def __str__(self, indent=0):
<         s = ['%s%s %s' % (' '*indent, self.__class__.__name__, self.id)]
<         indent += 2
<         for child in self.children:
<             try:
<                 s.append(child.__str__(indent))
<             except TypeError:
<                 s.append(child.__str__())
<         return '\n'.join(s)
< 
< 
<     def is_leaf(self):
<         return not self.children
<     
<     def append(self, child):
<         """add a node to children"""
<         self.children.append(child)
<         child.parent = self
< 
<     def remove(self, child):
<         """remove a child node"""
<         self.children.remove(child)
<         child.parent = None
< 
<     def insert(self, index, child):
<         """insert a child node"""
<         self.children.insert(index, child)
<         child.parent = self
<         
<     def replace(self, old_child, new_child):
<         """replace a child node with another"""
<         i = self.children.index(old_child)
<         self.children.pop(i)
<         self.children.insert(i, new_child)
<         new_child.parent = self
< 
<     def get_sibling(self, nid):
<         """return the sibling node that has given id"""
<         try:
<             return self.parent.get_child_by_id(nid)
<         except NodeNotFound :
<             raise NodeNotFound(EX_SIBLING_NOT_FOUND % nid)
< 
<     def next_sibling(self):
<         """
<         return the next sibling for this node if any
<         """
<         parent = self.parent
<         if parent is None:
<             # root node has no sibling
<             return None
<         index = parent.children.index(self)
<         try:
<             return parent.children[index+1]
<         except IndexError:
<             return None
<         
<     def previous_sibling(self):
<         """
<         return the previous sibling for this node if any
<         """
<         parent = self.parent
<         if parent is None:
<             # root node has no sibling
<             return None
<         index = parent.children.index(self)
<         if index > 0:
<             return parent.children[index-1]
<         return None
< 
<     def get_node_by_id(self, nid):
<         """
<         return node in whole hierarchy that has given id
<         """
<         root = self.root()
<         try:
<             return root.get_child_by_id(nid, 1)
<         except NodeNotFound :
<             raise NodeNotFound(EX_NODE_NOT_FOUND % nid)
<         
<     def get_child_by_id(self, nid, recurse=None):
<         """
<         return child of given id
<         """
<         if self.id == nid:
<             return self
<         for c in self.children :
<             if recurse:
<                 try:
<                     return c.get_child_by_id(nid, 1)
<                 except NodeNotFound :
<                     continue
<             if c.id == nid :
<                 return c
<         raise NodeNotFound(EX_CHILD_NOT_FOUND % nid)
< 
<     def get_child_by_path(self, path):
<         """
<         return child of given path (path is a list of ids)
<         """
<         if len(path) > 0 and path[0] == self.id:
<             if len(path) == 1 :
<                 return self
<             else :
<                 for c in self.children :
<                     try:
<                         return c.get_child_by_path(path[1:])
<                     except NodeNotFound :
<                         pass
<         raise NodeNotFound(EX_CHILD_NOT_FOUND % path)
< 
<     def depth(self):
<         """
<         return depth of this node in the tree
<         """
<         if self.parent is not None:
<             return 1 + self.parent.depth()
<         else :
<             return 0
< 
<     def depth_down(self):
<         """
<         return depth of the tree from this node
<         """
<         if self.children:
<             return 1 + max([c.depth_down() for c in self.children])
<         return 1
< 
<     def width(self):
<         """
<         return the width of the tree from this node
<         """
<         return len(self.leaves())
<         
<     def root(self):
<         """
<         return the root node of the tree
<         """
<         if self.parent is not None:
<             return self.parent.root()
<         return self
< 
<     def leaves(self):
<         """
<         return a list with all the leaves nodes descendant from this node
<         """
<         leaves = []
<         if self.children:
<             for child in self.children:
<                 leaves += child.leaves()
<             return leaves
<         else:
<             return [self]
< 
<     def __iter__(self):
<         return iter(self.children)
<     
<     def flatten(self, _list=None):
<         """
<         return a list with all the nodes descendant from this node
<         """
<         if _list is None:
<             _list = []
<         _list.append(self)
<         for c in self.children:
<             c.flatten(_list)
<         return _list
< 
<     def lineage(self):
<         """
<         return list of parents up to root node
<         """
<         lst = [self]
<         if self.parent is not None:
<             lst.extend(self.parent.lineage())
<         return lst
<     
< class VNode(Node, VisitedMixIn):
<     """a visitable node
<     """
<     pass
< 
<             
< class BinaryNode(VNode):
<     """a binary node (ie only two children
<     """
<     def __init__(self, lhs=None, rhs=None) :
<         VNode.__init__(self)
<         if lhs is not None or rhs is not None:
<             assert lhs and rhs
<             self.append(lhs)
<             self.append(rhs)
<             
<     def remove(self, child):
<         """remove the child and replace this node with the other child
<         """
<         self.children.remove(child)
<         self.parent.replace(self, self.children[0])
<         
<     def get_parts(self):
<         """
<         return the left hand side and the right hand side of this node
<         """
<         return self.children[0], self.children[1]
<         
< 
< 
< if sys.version_info[0:2] >= (2, 2):
<     list_class = list
< else:
<     from UserList import UserList
<     list_class = UserList
<     
< class ListNode(VNode, list_class):
<     """Used to manipulate Nodes as Lists
<     """
<     def __init__(self):
<         list_class.__init__(self)
<         VNode.__init__(self)
<         self.children = self
<         
<     def __str__(self, indent=0):
<         return '%s%s %s' % (indent*' ', self.__class__.__name__,
<                             ', '.join([str(v) for v in self]))
< 
<     def append(self, child):
<         """add a node to children"""
<         list_class.append(self, child)
<         child.parent = self
<  
<     def insert(self, index, child):
<         """add a node to children"""
<         list_class.insert(self, index, child)
<         child.parent = self
<     
<     def remove(self, child):
<         """add a node to children"""
<         list_class.remove(self, child)
<         child.parent = None
<  
<     def pop(self, index):
<         """add a node to children"""
<         child = list_class.pop(self, index)
<         child.parent = None
< 
<     def __iter__(self):
<         return list_class.__iter__(self)
< 
< # construct list from tree ####################################################
< 
< def post_order_list(node, filter_func=no_filter):
<     """ 
<     create a list with tree nodes for which the <filter> function returned true
<     in a post order fashion
<     """
<     l, stack = [], []
<     poped, index = 0, 0
<     while node:
<         if filter_func(node):
<             if node.children and not poped:
<                 stack.append((node, index))
<                 index = 0
<                 node = node.children[0]
<             else:
<                 l.append(node)
<                 index += 1
<                 try:
<                     node = stack[-1][0].children[index]
<                 except IndexError:
<                     node = None
<         else:
<             node = None
<         poped = 0
<         if node is None and stack:
<             node, index = stack.pop()
<             poped = 1
<     return l
< 
< def pre_order_list(node, filter_func=no_filter):
<     """
<     create a list with tree nodes for which the <filter> function returned true
<     in a pre order fashion
<     """
<     l, stack = [], []
<     poped, index = 0, 0
<     while node:
<         if filter_func(node):
<             if not poped:
<                 l.append(node)
<             if node.children and not poped:
<                 stack.append((node, index))
<                 index = 0
<                 node = node.children[0]
<             else:
<                 index += 1
<                 try:
<                     node = stack[-1][0].children[index]
<                 except IndexError:
<                     node = None
<         else:
<             node = None
<         poped = 0
<         if node is None and len(stack) > 1:
<             node, index = stack.pop()
<             poped = 1
<     return l
< 
< class PostfixedDepthFirstIterator(FilteredIterator):
<     """a postfixed depth first iterator, designed to be used with visitors
<     """
<     def __init__(self, node, filter_func=None):
<         FilteredIterator.__init__(self, node, post_order_list, filter_func)
< 
< class PrefixedDepthFirstIterator(FilteredIterator):
<     """a pretfixed depth first iterator, designed to be used with visitors
<     """
<     def __init__(self, node, filter_func=None):
<         FilteredIterator.__init__(self, node, pre_order_list, filter_func)
<         
diff -r -N code-worker/tasks/clonedigger/logilab/common/twisted_distutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/twisted_distutils.py
1,215d0
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
< http://www.logilab.fr/ -- mailto:contact@logilab.fr
< 
< Distutils extensions for twisted framework.
< 
< This module enables the installation of plugins.tml files using standard
< distutils syntax. It adds the following commands to the standard
< setup.py commands:
< * build_twisted_plugins: build (i.e. copy) plugins
< * install_twisted_plugins: install plugins
< 
< Additionally, the following commands have been modified to deal with
< plugins files:
<  * sdist
<  * build
<  * install
< 
< To use these extenstion, you should import the setup fonction from this
< module, and use it normally. To list the plugins.tml files, use the
< twisted_plugins keyword argument to the setup function:
< 
< from twisted_distutils import setup # you can also import Extension if needed
< 
< if __name__ == '__main__':
<     setup(name='my_twisted_app',
<           version='1.0',
<           author='me',
<           packages=['my_package'],
<           twisted_plugins = ['my_package/plugins.tml'])
< 
< Note that you can use this to install files that are not twisted plugins in any
< package directory of your application.
< """
< #
< # (c) 2002 Alexandre Fayolle <alexandre.fayolle@free.fr>
< # This module is heavily based on code copied from the python distutils
< # framework, especially distutils.command.build_script,
< # distutils.command.install_script. Many thanks to the authors of these
< # modules.
< # This module is provided as is, I'm not responsible if anything bad
< # happens to you or your python library while using this module. You may
< # freely copy it, distribute it and use it in your library or to distribute
< # your applications. I'd appreciate if you could drop me an email if you plan
< # to do so <wink>.
< #
< # Happy twisting!
< #
< 
< 
< from warnings import warn
< warn('this module is deprecated and will disappear in a near release',
<      DeprecationWarning, stacklevel=1)
< 
< __revision__ = "$Id: twisted_distutils.py,v 1.4 2003-09-12 11:54:48 syt Exp $"
< 
< from distutils.core import Distribution, Command
< from distutils.command.install import install
< from distutils.command.build import build
< from distutils.command.sdist import sdist
< from distutils.dep_util import newer
< from distutils.util import convert_path
< import os
< 
< class twisted_sdist(sdist):
<     def add_defaults(self):
<         sdist.add_defaults(self)
<         if self.distribution.has_twisted_plugins():
<             plugins = self.get_finalized_command('build_twisted_plugins')
<             self.filelist.extend(plugins.get_source_files())
< 
< class twisted_install(install):
<     def initialize_options (self):
<         install.initialize_options(self)
<         self.twisted_plugins = None
<         
<     def has_twisted_plugins(self):
<         return self.distribution.has_twisted_plugins()
<     
<     sub_commands = []
<     sub_commands.extend(install.sub_commands)
<     sub_commands.append(('install_twisted_plugins', has_twisted_plugins))
<                    
< 
< class twisted_build(build):
<     def initialize_options (self):
<         build.initialize_options(self)
<         self.twisted_plugins = None
<         
<     def has_twisted_plugins(self):
<         return self.distribution.has_twisted_plugins()
<     
<     sub_commands = []
<     sub_commands.extend(build.sub_commands)
<     sub_commands.append(('build_twisted_plugins', has_twisted_plugins))
< 
< class build_twisted_plugins (Command):
< 
<     description = "\"build\" twisted plugins (copy)"
< 
<     user_options = [
<         ('build-dir=', 'd', "directory to \"build\" (copy) to"),
<         ('force', 'f', "forcibly build everything (ignore file timestamps"),
<         ]
< 
<     boolean_options = ['force']
< 
< 
<     def initialize_options (self):
<         self.build_dir = None
<         self.twisted_plugins = None
<         self.force = None
<         self.outfiles = None
< 
<     def get_source_files(self):
<         return self.twisted_plugins
< 
<     def finalize_options (self):
<         self.set_undefined_options('build',
<                                    ('build_lib', 'build_dir'),
<                                    ('force', 'force'))
<         self.twisted_plugins = self.distribution.twisted_plugins
< 
< 
<     def run (self):
<         if not self.twisted_plugins:
<             return
<         self.copy_twisted_plugins()
< 
< 
<     def copy_twisted_plugins (self):
<         """Copy each plugin listed in 'self.twisted_plugins'.
<         """
<         self.mkpath(self.build_dir)
<         for plugin in self.twisted_plugins:
<             adjust = 0
<             plugin = convert_path(plugin)
<             outfile = os.path.join(self.build_dir, plugin)
<             if not self.force and not newer(plugin, outfile):
<                 self.announce("not copying %s (up-to-date)" % plugin)
<                 continue
< 
<             # Always open the file, but ignore failures in dry-run mode --
<             # that way, we'll get accurate feedback if we can read the
<             # plugin.
<             try:
<                 f = open(plugin, "r")
<             except IOError:
<                 if not self.dry_run:
<                     raise
<                 f = None
<             else:
<                 f.close()
<                 self.copy_file(plugin, outfile)
< 
< 
< class install_twisted_plugins(Command):
< 
<     description = "install twisted plugins"
< 
<     user_options = [
<         ('install-dir=', 'd', "directory to install scripts to"),
<         ('build-dir=','b', "build directory (where to install from)"),
<         ('force', 'f', "force installation (overwrite existing files)"),
<         ('skip-build', None, "skip the build steps"),
<     ]
< 
<     boolean_options = ['force', 'skip-build']
< 
< 
<     def initialize_options (self):
<         self.install_dir = None
<         self.force = 0
<         self.build_dir = None
<         self.skip_build = None
< 
<     def finalize_options (self):
<         self.set_undefined_options('build', ('build_lib', 'build_dir'))
<         self.set_undefined_options('install',
<                                    ('install_lib', 'install_dir'),
<                                    ('force', 'force'),
<                                    ('skip_build', 'skip_build'),
<                                   )
< 
<     def run (self):
<         if not self.skip_build:
<             self.run_command('build_twisted_plugins')
<         self.outfiles = self.copy_tree(self.build_dir, self.install_dir)
< 
<     def get_inputs (self):
<         return self.distribution.twisted_plugins or []
< 
<     def get_outputs(self):
<         return self.outfiles or []
<         
<     
< 
< class TwistedDistribution(Distribution):
<     def __init__(self,attrs=None):
<         self.twisted_plugins = None
<         Distribution.__init__(self, attrs)
<         self.cmdclass = {'install':twisted_install,
<                          'install_twisted_plugins':install_twisted_plugins,
<                          'build':twisted_build,
<                          'build_twisted_plugins':build_twisted_plugins,
<                          'sdist':twisted_sdist,
<                          }
< 
<     def has_twisted_plugins(self):
<         return self.twisted_plugins and len(self.twisted_plugins) > 0
< 
< 
< def setup(**attrs):
<     from distutils import core
<     attrs['distclass'] = TwistedDistribution
<     core.setup(**attrs)
diff -r -N code-worker/tasks/clonedigger/logilab/common/umessage.py code-worker/code-worker/tasks/clonedigger/logilab/common/umessage.py
1,125d0
< """unicode email support"""
< 
< import email
< from email.Utils import parseaddr, parsedate
< from email.Header import decode_header
< 
< try:
<     from mx.DateTime import DateTime
< except ImportError:
<     def DateTime(*args): return None
< 
< def decode_QP(string):
<     parts = []
<     for decoded, charset in decode_header(string):
<         if charset is None:
<             charset = 'iso-8859-15'
<         parts.append(unicode(decoded, charset, 'replace'))
< 
<     return u' '.join(parts)
< 
< def message_from_file(fd):
<     try:
<         return UMessage(email.message_from_file(fd))
<     except email.Errors.MessageParseError:
<         return ''
<     
< def message_from_string(string):
<     try:
<         return UMessage(email.message_from_string(string))
<     except email.Errors.MessageParseError:
<         return ''
<     
< class UMessage:
<     """Encapsulates an email.Message instance and returns only unicode objects"""
< 
<     def __init__(self, message):
<         self.message = message
< 
<     # email.Message interface #################################################
<     
<     def get(self, header, default=None):
<         value = self.message.get(header, default)
<         if value:
<             return decode_QP(value)
<         return value
< 
<     def get_all(self, header, default=()):
<         return [decode_QP(val) for val in self.message.get_all(header, default)
<                 if val is not None]
<     
<     def get_payload(self, index=None, decode=False):
<         message = self.message
<         if index is None:
<             payload = message.get_payload(index, decode)
<             if isinstance(payload, list):
<                 return [UMessage(msg) for msg in payload]
<             if message.get_content_maintype() != 'text':
<                 return payload
< 
<             charset = message.get_content_charset() or 'iso-8859-1'
<             if charset == 'unknown-8bit':
<                 charset = 'iso-8859-1'
<             return unicode(payload or '', charset)
<         else:
<             payload = UMessage(message.get_payload(index, decode))
<         return payload
< 
<     def is_multipart(self):
<         return self.message.is_multipart()
< 
<     def get_boundary(self):
<         return self.message.get_boundary()
< 
<     def walk(self):
<         for part in self.message.walk():
<             yield UMessage(part)
<     
<     def get_content_maintype(self):
<         return unicode(self.message.get_content_maintype())
< 
<     def get_content_type(self):
<         return unicode(self.message.get_content_type())
< 
<     def get_filename(self, failobj=None):
<         value = self.message.get_filename(failobj)
<         if value is failobj:
<             return value
<         try:
<             return unicode(value)
<         except UnicodeDecodeError:
<             return u'error decoding filename'
< 
<     # other convenience methods ###############################################
< 
<     def headers(self):
<         """return an unicode string containing all the message's headers"""
<         values = []
<         for header in self.message.keys():
<             values.append(u'%s: %s' % (header, self.get(header)))
<         return '\n'.join(values)
< 
<     def multi_addrs(self, header):
<         """return a list of 2-uple (name, address) for the given address (which
<         is exepected to be an header containing address such as from, to, cc...)
<         """
<         persons = []
<         for person in self.get_all(header, ()):
<             name, mail = parseaddr(person)
<             persons.append((name, mail))
<         return persons
<     
<     def date(self):
<         """return a mx.DateTime object for the email's date or None if no date is
<         set or if it can't be parsed
<         """
<         value = self.get('date')
<         if value:
<             datetuple = parsedate(value)
<             if datetuple:
<                 return DateTime(*datetuple[:6])
<         return None
< 
<     
< 
<     
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/docbook_writer.py code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/docbook_writer.py
1,138d0
< # Copyright (c) 2002-2004 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """HTML formatting drivers for ureports
< """
< 
< __revision__ = "$Id: docbook_writer.py,v 1.4 2005-05-20 16:42:23 emb Exp $"
< 
< from clonedigger.logilab.common.ureports import HTMLWriter
< 
< class DocbookWriter(HTMLWriter):
<     """format layouts as HTML"""
<     
<     def begin_format(self, layout):
<         """begin to format a layout"""
<         super(HTMLWriter, self).begin_format(layout)
<         if self.snipet is None:
<             self.writeln('<?xml version="1.0" encoding="ISO-8859-1"?>')
<             self.writeln("""
< <book xmlns:xi='http://www.w3.org/2001/XInclude'
<       lang='fr'>
< """)
<     
<     def end_format(self, layout):
<         """finished to format a layout"""
<         if self.snipet is None:
<             self.writeln('</book>')
< 
<     def visit_section(self, layout):
<         """display a section (using <chapter> (level 0) or <section>)"""
<         if self.section == 0:
<             tag = "chapter"
<         else:
<             tag = "section"
<         self.section += 1
<         self.writeln(self._indent('<%s%s>' % (tag, self.handle_attrs(layout))))
<         self.format_children(layout)
<         self.writeln(self._indent('</%s>'% tag))
<         self.section -= 1
< 
<     def visit_title(self, layout):
<         """display a title using <title>"""
<         self.write(self._indent('  <title%s>' % self.handle_attrs(layout)))
<         self.format_children(layout)
<         self.writeln('</title>')
< 
<     def visit_table(self, layout):
<         """display a table as html"""
<         self.writeln(self._indent('  <table%s><title>%s</title>' \
<                      % (self.handle_attrs(layout), layout.title)))
<         self.writeln(self._indent('    <tgroup cols="%s">'% layout.cols))
<         for i in range(layout.cols): 
<             self.writeln(self._indent('      <colspec colname="c%s" colwidth="1*"/>' % i))
<            
<         table_content = self.get_table_content(layout)
<         # write headers
<         if layout.cheaders:
<             self.writeln(self._indent('      <thead>'))
<             self._write_row(table_content[0])
<             self.writeln(self._indent('      </thead>'))
<             table_content = table_content[1:]
<         elif layout.rcheaders:
<             self.writeln(self._indent('      <thead>'))
<             self._write_row(table_content[-1])
<             self.writeln(self._indent('      </thead>'))
<             table_content = table_content[:-1]
<         # write body
<         self.writeln(self._indent('      <tbody>'))
<         for i in range(len(table_content)):
<             row = table_content[i]
<             self.writeln(self._indent('        <row>'))
<             for j in range(len(row)):
<                 cell = row[j] or '&#160;'
<                 self.writeln(self._indent('          <entry>%s</entry>' % cell))
<             self.writeln(self._indent('        </row>'))
<         self.writeln(self._indent('      </tbody>'))
<         self.writeln(self._indent('    </tgroup>'))
<         self.writeln(self._indent('  </table>'))
< 
<     def _write_row(self, row):
<         """write content of row (using <row> <entry>)"""
<         self.writeln('        <row>')
<         for j in range(len(row)):
<             cell = row[j] or '&#160;'
<             self.writeln('          <entry>%s</entry>' % cell)
<         self.writeln(self._indent('        </row>'))
<         
<     def visit_list(self, layout):
<         """display a list (using <itemizedlist>)"""
<         self.writeln(self._indent('  <itemizedlist%s>' % self.handle_attrs(layout)))
<         for row in list(self.compute_content(layout)):
<             self.writeln('    <listitem><para>%s</para></listitem>' % row)
<         self.writeln(self._indent('  </itemizedlist>'))
<         
<     def visit_paragraph(self, layout):
<         """display links (using <para>)"""
<         self.write(self._indent('  <para>'))
<         self.format_children(layout)
<         self.writeln('</para>')
<                    
<     def visit_span(self, layout):
<         """display links (using <p>)"""
<         #TODO: translate in docbook
<         self.write('<literal %s>' % self.handle_attrs(layout))
<         self.format_children(layout)
<         self.write('</literal>')
<                    
<     def visit_link(self, layout):
<         """display links (using <ulink>)"""
<         self.write('<ulink url="%s"%s>%s</ulink>' % (layout.url,
<                                                self.handle_attrs(layout),
<                                                layout.label))
< 
<     def visit_verbatimtext(self, layout):
<         """display verbatim text (using <programlisting>)"""
<         self.writeln(self._indent('  <programlisting>'))
<         self.write(layout.data.replace('&', '&amp;').replace('<', '&lt;'))
<         self.writeln(self._indent('  </programlisting>'))
<         
<     def visit_text(self, layout):
<         """add some text"""
<         self.write(layout.data.replace('&', '&amp;').replace('<', '&lt;'))
<         
<     def _indent(self, string):
<         """correctly indent string according to section"""
<         return ' ' * 2*(self.section) + string 
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/html_writer.py code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/html_writer.py
1,131d0
< # Copyright (c) 2004-2005 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """HTML formatting drivers for ureports
< """
< 
< __revision__ = "$Id: html_writer.py,v 1.10 2006-03-08 09:47:29 katia Exp $"
< 
< from cgi import escape
< 
< from clonedigger.logilab.common.ureports import BaseWriter
< 
< 
< class HTMLWriter(BaseWriter):
<     """format layouts as HTML"""
<     
<     def __init__(self, snipet=None):
<         super(HTMLWriter, self).__init__(self)
<         self.snipet = snipet
<         
<     def handle_attrs(self, layout):
<         """get an attribute string from layout member attributes"""
<         attrs = ''
<         klass = getattr(layout, 'klass', None)
<         if klass:
<             attrs += ' class="%s"' % klass
<         nid = getattr(layout, 'id', None)
<         if nid:
<             attrs += ' id="%s"' % nid
<         return attrs
<     
<     def begin_format(self, layout):
<         """begin to format a layout"""
<         super(HTMLWriter, self).begin_format(layout)
<         if self.snipet is None:
<             self.writeln('<html>')
<             self.writeln('<body>')
<         
<     def end_format(self, layout):
<         """finished to format a layout"""
<         if self.snipet is None:
<             self.writeln('</body>')
<             self.writeln('</html>')
< 
< 
<     def visit_section(self, layout):
<         """display a section as html, using div + h[section level]"""
<         self.section += 1
<         self.writeln('<div%s>' % self.handle_attrs(layout))
<         self.format_children(layout)
<         self.writeln('</div>')
<         self.section -= 1
< 
<     def visit_title(self, layout):
<         """display a title using <hX>"""
<         self.write('<h%s%s>' % (self.section, self.handle_attrs(layout)))
<         self.format_children(layout)
<         self.writeln('</h%s>' % self.section)
< 
<     def visit_table(self, layout):
<         """display a table as html"""
<         self.writeln('<table%s>' % self.handle_attrs(layout))
<         table_content = self.get_table_content(layout)
<         for i in range(len(table_content)):
<             row = table_content[i]
<             if i == 0 and layout.rheaders:
<                 self.writeln('<tr class="header">')
<             elif i+1 == len(table_content) and layout.rrheaders:
<                 self.writeln('<tr class="header">')
<             else:
<                 self.writeln('<tr class="%s">' % (i%2 and 'even' or 'odd'))
<             for j in range(len(row)):
<                 cell = row[j] or '&nbsp;'
<                 if (layout.rheaders and i == 0) or \
<                    (layout.cheaders and j == 0) or \
<                    (layout.rrheaders and i+1 == len(table_content)) or \
<                    (layout.rcheaders and j+1 == len(row)):
<                     self.writeln('<th>%s</th>' % cell)
<                 else:
<                     self.writeln('<td>%s</td>' % cell)
<             self.writeln('</tr>')
<         self.writeln('</table>')
<         
<     def visit_list(self, layout):
<         """display a list as html"""
<         self.writeln('<ul%s>' % self.handle_attrs(layout))
<         for row in list(self.compute_content(layout)):
<             self.writeln('<li>%s</li>' % row)
<         self.writeln('</ul>')
<         
<     def visit_paragraph(self, layout):
<         """display links (using <p>)"""
<         self.write('<p>')
<         self.format_children(layout)
<         self.write('</p>')
<                    
<     def visit_span(self, layout):
<         """display links (using <p>)"""
<         self.write('<span%s>' % self.handle_attrs(layout))
<         self.format_children(layout)
<         self.write('</span>')
<                    
<     def visit_link(self, layout):
<         """display links (using <a>)"""
<         self.write(' <a href="%s"%s>%s</a>' % (layout.url,
<                                                self.handle_attrs(layout),
<                                                layout.label))
<     def visit_verbatimtext(self, layout):
<         """display verbatim text (using <pre>)"""
<         self.write('<pre>')
<         self.write(layout.data.replace('&', '&amp;').replace('<', '&lt;'))
<         self.write('</pre>')
<         
<     def visit_text(self, layout):
<         """add some text"""
<         data = layout.data
<         if layout.escaped:
<             data = data.replace('&', '&amp;').replace('<', '&lt;')
<         self.write(data)
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/__init__.py code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/__init__.py
1,171d0
< # Copyright (c) 2004-2005 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Universal report objects and some formatting drivers
< 
< a way to create simple reports using python objects, primarly designed to be
< formatted as text and html
< """
< 
< from __future__ import generators
< 
< import sys
< from os import linesep
< from cStringIO import StringIO
< from StringIO import StringIO as UStringIO
< 
< 
< def get_nodes(node, klass):
<     """return an iterator on all children node of the given klass"""
<     for child in node.children:
<         if isinstance(child, klass):
<             yield child
<         # recurse (FIXME: recursion controled by an option)
<         for grandchild in get_nodes(child, klass):
<             yield grandchild
<             
< def layout_title(layout):
<     """try to return the layout's title as string, return None if not found
<     """
<     for child in layout.children:
<         if isinstance(child, Title):
<             return ' '.join([node.data for node in get_nodes(child, Text)])
<             
< def build_summary(layout, level=1):
<     """make a summary for the report, including X level"""
<     assert level > 0
<     level -= 1
<     summary = List(klass='summary')
<     for child in layout.children:
<         if not isinstance(child, Section):
<             continue
<         label = layout_title(child)
<         if not label and not child.id:
<             continue
<         if not child.id:
<             child.id = label.replace(' ', '-')
<         node = Link('#'+child.id, label=label or child.id)
<         # FIXME: Three following lines produce not very compliant
<         # docbook: there are some useless <para><para>. They might be
<         # replaced by the three commented lines but this then produces
<         # a bug in html display...
<         if level and [n for n in child.children if isinstance(n, Section)]:
<             node = Paragraph([node, build_summary(child, level)])
<         summary.append(node)
< #         summary.append(node)
< #         if level and [n for n in child.children if isinstance(n, Section)]:
< #             summary.append(build_summary(child, level))
<     return summary
< 
< 
< class BaseWriter(object):
<     """base class for ureport writers"""
<     
<     def format(self, layout, stream=None, encoding=None):
<         """format and write the given layout into the stream object
< 
<         unicode policy: unicode strings may be found in the layout;
<         try to call stream.write with it, but give it back encoded using
<         the given encoding if it fails
<         """
<         if stream is None:
<             stream = sys.stdout
<         if not encoding:
<             encoding = getattr(stream, 'encoding', 'UTF-8')
<         self.encoding = encoding or 'UTF-8'
<         self.__compute_funcs = []
<         self.out = stream
<         self.begin_format(layout)
<         layout.accept(self)
<         self.end_format(layout)
<         
<     def format_children(self, layout):
<         """recurse on the layout children and call their accept method
<         (see the Visitor pattern)
<         """
<         for child in getattr(layout, 'children', ()):
<             child.accept(self)
< 
<     def writeln(self, string=''):
<         """write a line in the output buffer"""
<         self.write(string + linesep)
< 
<     def write(self, string):
<         """write a string in the output buffer"""
<         try:
<             self.out.write(string)
<         except UnicodeEncodeError:
<             self.out.write(string.encode(self.encoding))
< 
<     def begin_format(self, layout):
<         """begin to format a layout"""
<         self.section = 0
<         
<     def end_format(self, layout):
<         """finished to format a layout"""
< 
<     def get_table_content(self, table):
<         """trick to get table content without actually writing it
< 
<         return an aligned list of lists containing table cells values as string
<         """
<         result = [[]]
<         cols = table.cols
<         for cell in self.compute_content(table):
<             if cols == 0:
<                 result.append([])
<                 cols = table.cols
<             cols -= 1
<             result[-1].append(cell)
<         # fill missing cells
<         while len(result[-1]) < cols:
<             result[-1].append('')
<         return result
< 
<     def compute_content(self, layout):
<         """trick to compute the formatting of children layout before actually
<         writing it
< 
<         return an iterator on strings (one for each child element)
<         """
<         # use cells !
<         def write(data):
<             try:
<                 stream.write(data)
<             except UnicodeEncodeError:
<                 stream.write(data.encode(self.encoding))
<         def writeln(data=''):
<             try:
<                 stream.write(data+linesep)
<             except UnicodeEncodeError:
<                 stream.write(data.encode(self.encoding)+linesep)
<         self.write = write
<         self.writeln = writeln
<         self.__compute_funcs.append((write, writeln))
<         for child in layout.children:
<             stream = UStringIO()
<             child.accept(self)
<             yield stream.getvalue()
<         self.__compute_funcs.pop()
<         try:
<             self.write, self.writeln = self.__compute_funcs[-1]
<         except IndexError:
<             del self.write
<             del self.writeln
< 
< 
< from clonedigger.logilab.common.ureports.nodes import *
< from clonedigger.logilab.common.ureports.text_writer import TextWriter
< from clonedigger.logilab.common.ureports.html_writer import HTMLWriter
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/nodes.py code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/nodes.py
1,202d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Micro reports objects
< 
< A micro report is a tree of layout and content objects
< 
< 
< :author:    Logilab
< :copyright: 2004-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< __docformat__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.tree import VNode
< 
< class BaseComponent(VNode):
<     """base report component
< 
<     attributes
<     * id : the component's optional id
<     * klass : the component's optional klass
<     """
<     def __init__(self, id=None, klass=None):
<         VNode.__init__(self, id)
<         self.klass = klass
< 
< class BaseLayout(BaseComponent):
<     """base container node
< 
<     attributes
<     * BaseComponent attributes
<     * children : components in this table (i.e. the table's cells)
<     """
<     def __init__(self, children=(), **kwargs):
<         super(BaseLayout, self).__init__(**kwargs)
<         for child in children:
<             if isinstance(child, BaseComponent):
<                 self.append(child)
<             else:
<                 self.add_text(child)
< 
<     def append(self, child):
<         """overridden to detect problems easily"""
<         assert child not in self.parents()
<         VNode.append(self, child)
<         
<     def parents(self):
<         """return the ancestor nodes"""
<         assert self.parent is not self
<         if self.parent is None:
<             return []
<         return [self.parent] + self.parent.parents()
<     
<     def add_text(self, text):
<         """shortcut to add text data"""
<         self.children.append(Text(text))
< 
< 
< # non container nodes #########################################################
< 
< class Text(BaseComponent):
<     """a text portion
< 
<     attributes :
<     * BaseComponent attributes
<     * data : the text value as an encoded or unicode string
<     """
<     def __init__(self, data, escaped=True, **kwargs):
<         super(Text, self).__init__(**kwargs)
<         #if isinstance(data, unicode):
<         #    data = data.encode('ascii')
<         assert isinstance(data, (str, unicode)), data.__class__
<         self.escaped = escaped
<         self.data = data
< 
< class VerbatimText(Text):
<     """a verbatim text, display the raw data
< 
<     attributes :
<     * BaseComponent attributes
<     * data : the text value as an encoded or unicode string
<     """
<         
< class Link(BaseComponent):
<     """a labelled link
< 
<     attributes :
<     * BaseComponent attributes
<     * url : the link's target (REQUIRED)
<     * label : the link's label as a string (use the url by default)
<     """
<     def __init__(self, url, label=None, **kwargs):
<         super(Link, self).__init__(**kwargs)
<         assert url
<         self.url = url
<         self.label = label or url
< 
<         
< class Image(BaseComponent):
<     """an embeded or a single image
< 
<     attributes :
<     * BaseComponent attributes
<     * filename : the image's filename (REQUIRED)
<     * stream : the stream object containing the image data (REQUIRED)
<     * title : the image's optional title
<     """
<     def __init__(self, filename, stream, title=None, **kwargs):
<         super(Link, self).__init__(**kwargs)
<         assert filename
<         assert stream
<         self.filename = filename
<         self.stream = stream
<         self.title = title
< 
<         
< # container nodes #############################################################
<         
< class Section(BaseLayout):
<     """a section
< 
<     attributes :
<     * BaseLayout attributes
<     
<     a title may also be given to the constructor, it'll be added
<     as a first element
<     a description may also be given to the constructor, it'll be added
<     as a first paragraph
<     """
<     def __init__(self, title=None, description=None, **kwargs):
<         super(Section, self).__init__(**kwargs)
<         if description:
<             self.insert(0, Paragraph([Text(description)]))
<         if title:
<             self.insert(0, Title(children=(title,)))
<         
< class Title(BaseLayout):
<     """a title
<     
<     attributes :
<     * BaseLayout attributes
< 
<     A title must not contains a section nor a paragraph!
<     """
<     
< class Span(BaseLayout):
<     """a title
<     
<     attributes :
<     * BaseLayout attributes
< 
<     A span should only contains Text and Link nodes (in-line elements)
<     """
<     
< class Paragraph(BaseLayout):
<     """a simple text paragraph
<     
<     attributes :
<     * BaseLayout attributes
< 
<     A paragraph must not contains a section !
<     """
<     
< class Table(BaseLayout):
<     """some tabular data
< 
<     attributes :
<     * BaseLayout attributes
<     * cols : the number of columns of the table (REQUIRED)
<     * rheaders : the first row's elements are table's header
<     * cheaders : the first col's elements are table's header
<     * title : the table's optional title
<     """    
<     def __init__(self, cols, title=None,
<                  rheaders=0, cheaders=0, rrheaders=0, rcheaders=0,
<                  **kwargs):
<         super(Table, self).__init__(**kwargs)
<         assert isinstance(cols, int)
<         self.cols = cols
<         self.title = title
<         self.rheaders = rheaders
<         self.cheaders = cheaders
<         self.rrheaders = rrheaders
<         self.rcheaders = rcheaders
<         
< class List(BaseLayout):
<     """some list data
< 
<     attributes :
<     * BaseLayout attributes
<     """    
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/all-wcprops
1,35d0
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/ureports
< END
< nodes.py
< K 25
< svn:wc:ra_dav:version-url
< V 83
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/ureports/nodes.py
< END
< docbook_writer.py
< K 25
< svn:wc:ra_dav:version-url
< V 92
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/ureports/docbook_writer.py
< END
< __init__.py
< K 25
< svn:wc:ra_dav:version-url
< V 86
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/ureports/__init__.py
< END
< html_writer.py
< K 25
< svn:wc:ra_dav:version-url
< V 89
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/ureports/html_writer.py
< END
< text_writer.py
< K 25
< svn:wc:ra_dav:version-url
< V 89
< /svnroot/clonedigger/!svn/ver/60/trunk/clonedigger/logilab/common/ureports/text_writer.py
< END
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/entries code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/entries
1,198d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/logilab/common/ureports
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< nodes.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< c17e46267ad86498e5f2cd7ca82cd45c
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5918
< 
< docbook_writer.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< 14b3ff058a8d7c732ee52ec97aacb910
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5787
< 
< __init__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< 89bd9c75e062beb4afd18a62a7a70d03
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 6160
< 
< html_writer.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< 40a49f830ddde34c1b62d87150fce2e3
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 4993
< 
< text_writer.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:57.000000Z
< a9c5334592c184560a40c18f9fe0cb28
< 2008-07-01T07:47:44.415145Z
< 60
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5192
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/docbook_writer.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/docbook_writer.py.svn-base
1,138d0
< # Copyright (c) 2002-2004 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """HTML formatting drivers for ureports
< """
< 
< __revision__ = "$Id: docbook_writer.py,v 1.4 2005-05-20 16:42:23 emb Exp $"
< 
< from clonedigger.logilab.common.ureports import HTMLWriter
< 
< class DocbookWriter(HTMLWriter):
<     """format layouts as HTML"""
<     
<     def begin_format(self, layout):
<         """begin to format a layout"""
<         super(HTMLWriter, self).begin_format(layout)
<         if self.snipet is None:
<             self.writeln('<?xml version="1.0" encoding="ISO-8859-1"?>')
<             self.writeln("""
< <book xmlns:xi='http://www.w3.org/2001/XInclude'
<       lang='fr'>
< """)
<     
<     def end_format(self, layout):
<         """finished to format a layout"""
<         if self.snipet is None:
<             self.writeln('</book>')
< 
<     def visit_section(self, layout):
<         """display a section (using <chapter> (level 0) or <section>)"""
<         if self.section == 0:
<             tag = "chapter"
<         else:
<             tag = "section"
<         self.section += 1
<         self.writeln(self._indent('<%s%s>' % (tag, self.handle_attrs(layout))))
<         self.format_children(layout)
<         self.writeln(self._indent('</%s>'% tag))
<         self.section -= 1
< 
<     def visit_title(self, layout):
<         """display a title using <title>"""
<         self.write(self._indent('  <title%s>' % self.handle_attrs(layout)))
<         self.format_children(layout)
<         self.writeln('</title>')
< 
<     def visit_table(self, layout):
<         """display a table as html"""
<         self.writeln(self._indent('  <table%s><title>%s</title>' \
<                      % (self.handle_attrs(layout), layout.title)))
<         self.writeln(self._indent('    <tgroup cols="%s">'% layout.cols))
<         for i in range(layout.cols): 
<             self.writeln(self._indent('      <colspec colname="c%s" colwidth="1*"/>' % i))
<            
<         table_content = self.get_table_content(layout)
<         # write headers
<         if layout.cheaders:
<             self.writeln(self._indent('      <thead>'))
<             self._write_row(table_content[0])
<             self.writeln(self._indent('      </thead>'))
<             table_content = table_content[1:]
<         elif layout.rcheaders:
<             self.writeln(self._indent('      <thead>'))
<             self._write_row(table_content[-1])
<             self.writeln(self._indent('      </thead>'))
<             table_content = table_content[:-1]
<         # write body
<         self.writeln(self._indent('      <tbody>'))
<         for i in range(len(table_content)):
<             row = table_content[i]
<             self.writeln(self._indent('        <row>'))
<             for j in range(len(row)):
<                 cell = row[j] or '&#160;'
<                 self.writeln(self._indent('          <entry>%s</entry>' % cell))
<             self.writeln(self._indent('        </row>'))
<         self.writeln(self._indent('      </tbody>'))
<         self.writeln(self._indent('    </tgroup>'))
<         self.writeln(self._indent('  </table>'))
< 
<     def _write_row(self, row):
<         """write content of row (using <row> <entry>)"""
<         self.writeln('        <row>')
<         for j in range(len(row)):
<             cell = row[j] or '&#160;'
<             self.writeln('          <entry>%s</entry>' % cell)
<         self.writeln(self._indent('        </row>'))
<         
<     def visit_list(self, layout):
<         """display a list (using <itemizedlist>)"""
<         self.writeln(self._indent('  <itemizedlist%s>' % self.handle_attrs(layout)))
<         for row in list(self.compute_content(layout)):
<             self.writeln('    <listitem><para>%s</para></listitem>' % row)
<         self.writeln(self._indent('  </itemizedlist>'))
<         
<     def visit_paragraph(self, layout):
<         """display links (using <para>)"""
<         self.write(self._indent('  <para>'))
<         self.format_children(layout)
<         self.writeln('</para>')
<                    
<     def visit_span(self, layout):
<         """display links (using <p>)"""
<         #TODO: translate in docbook
<         self.write('<literal %s>' % self.handle_attrs(layout))
<         self.format_children(layout)
<         self.write('</literal>')
<                    
<     def visit_link(self, layout):
<         """display links (using <ulink>)"""
<         self.write('<ulink url="%s"%s>%s</ulink>' % (layout.url,
<                                                self.handle_attrs(layout),
<                                                layout.label))
< 
<     def visit_verbatimtext(self, layout):
<         """display verbatim text (using <programlisting>)"""
<         self.writeln(self._indent('  <programlisting>'))
<         self.write(layout.data.replace('&', '&amp;').replace('<', '&lt;'))
<         self.writeln(self._indent('  </programlisting>'))
<         
<     def visit_text(self, layout):
<         """add some text"""
<         self.write(layout.data.replace('&', '&amp;').replace('<', '&lt;'))
<         
<     def _indent(self, string):
<         """correctly indent string according to section"""
<         return ' ' * 2*(self.section) + string 
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/html_writer.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/html_writer.py.svn-base
1,131d0
< # Copyright (c) 2004-2005 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """HTML formatting drivers for ureports
< """
< 
< __revision__ = "$Id: html_writer.py,v 1.10 2006-03-08 09:47:29 katia Exp $"
< 
< from cgi import escape
< 
< from clonedigger.logilab.common.ureports import BaseWriter
< 
< 
< class HTMLWriter(BaseWriter):
<     """format layouts as HTML"""
<     
<     def __init__(self, snipet=None):
<         super(HTMLWriter, self).__init__(self)
<         self.snipet = snipet
<         
<     def handle_attrs(self, layout):
<         """get an attribute string from layout member attributes"""
<         attrs = ''
<         klass = getattr(layout, 'klass', None)
<         if klass:
<             attrs += ' class="%s"' % klass
<         nid = getattr(layout, 'id', None)
<         if nid:
<             attrs += ' id="%s"' % nid
<         return attrs
<     
<     def begin_format(self, layout):
<         """begin to format a layout"""
<         super(HTMLWriter, self).begin_format(layout)
<         if self.snipet is None:
<             self.writeln('<html>')
<             self.writeln('<body>')
<         
<     def end_format(self, layout):
<         """finished to format a layout"""
<         if self.snipet is None:
<             self.writeln('</body>')
<             self.writeln('</html>')
< 
< 
<     def visit_section(self, layout):
<         """display a section as html, using div + h[section level]"""
<         self.section += 1
<         self.writeln('<div%s>' % self.handle_attrs(layout))
<         self.format_children(layout)
<         self.writeln('</div>')
<         self.section -= 1
< 
<     def visit_title(self, layout):
<         """display a title using <hX>"""
<         self.write('<h%s%s>' % (self.section, self.handle_attrs(layout)))
<         self.format_children(layout)
<         self.writeln('</h%s>' % self.section)
< 
<     def visit_table(self, layout):
<         """display a table as html"""
<         self.writeln('<table%s>' % self.handle_attrs(layout))
<         table_content = self.get_table_content(layout)
<         for i in range(len(table_content)):
<             row = table_content[i]
<             if i == 0 and layout.rheaders:
<                 self.writeln('<tr class="header">')
<             elif i+1 == len(table_content) and layout.rrheaders:
<                 self.writeln('<tr class="header">')
<             else:
<                 self.writeln('<tr class="%s">' % (i%2 and 'even' or 'odd'))
<             for j in range(len(row)):
<                 cell = row[j] or '&nbsp;'
<                 if (layout.rheaders and i == 0) or \
<                    (layout.cheaders and j == 0) or \
<                    (layout.rrheaders and i+1 == len(table_content)) or \
<                    (layout.rcheaders and j+1 == len(row)):
<                     self.writeln('<th>%s</th>' % cell)
<                 else:
<                     self.writeln('<td>%s</td>' % cell)
<             self.writeln('</tr>')
<         self.writeln('</table>')
<         
<     def visit_list(self, layout):
<         """display a list as html"""
<         self.writeln('<ul%s>' % self.handle_attrs(layout))
<         for row in list(self.compute_content(layout)):
<             self.writeln('<li>%s</li>' % row)
<         self.writeln('</ul>')
<         
<     def visit_paragraph(self, layout):
<         """display links (using <p>)"""
<         self.write('<p>')
<         self.format_children(layout)
<         self.write('</p>')
<                    
<     def visit_span(self, layout):
<         """display links (using <p>)"""
<         self.write('<span%s>' % self.handle_attrs(layout))
<         self.format_children(layout)
<         self.write('</span>')
<                    
<     def visit_link(self, layout):
<         """display links (using <a>)"""
<         self.write(' <a href="%s"%s>%s</a>' % (layout.url,
<                                                self.handle_attrs(layout),
<                                                layout.label))
<     def visit_verbatimtext(self, layout):
<         """display verbatim text (using <pre>)"""
<         self.write('<pre>')
<         self.write(layout.data.replace('&', '&amp;').replace('<', '&lt;'))
<         self.write('</pre>')
<         
<     def visit_text(self, layout):
<         """add some text"""
<         data = layout.data
<         if layout.escaped:
<             data = data.replace('&', '&amp;').replace('<', '&lt;')
<         self.write(data)
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/__init__.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/__init__.py.svn-base
1,171d0
< # Copyright (c) 2004-2005 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Universal report objects and some formatting drivers
< 
< a way to create simple reports using python objects, primarly designed to be
< formatted as text and html
< """
< 
< from __future__ import generators
< 
< import sys
< from os import linesep
< from cStringIO import StringIO
< from StringIO import StringIO as UStringIO
< 
< 
< def get_nodes(node, klass):
<     """return an iterator on all children node of the given klass"""
<     for child in node.children:
<         if isinstance(child, klass):
<             yield child
<         # recurse (FIXME: recursion controled by an option)
<         for grandchild in get_nodes(child, klass):
<             yield grandchild
<             
< def layout_title(layout):
<     """try to return the layout's title as string, return None if not found
<     """
<     for child in layout.children:
<         if isinstance(child, Title):
<             return ' '.join([node.data for node in get_nodes(child, Text)])
<             
< def build_summary(layout, level=1):
<     """make a summary for the report, including X level"""
<     assert level > 0
<     level -= 1
<     summary = List(klass='summary')
<     for child in layout.children:
<         if not isinstance(child, Section):
<             continue
<         label = layout_title(child)
<         if not label and not child.id:
<             continue
<         if not child.id:
<             child.id = label.replace(' ', '-')
<         node = Link('#'+child.id, label=label or child.id)
<         # FIXME: Three following lines produce not very compliant
<         # docbook: there are some useless <para><para>. They might be
<         # replaced by the three commented lines but this then produces
<         # a bug in html display...
<         if level and [n for n in child.children if isinstance(n, Section)]:
<             node = Paragraph([node, build_summary(child, level)])
<         summary.append(node)
< #         summary.append(node)
< #         if level and [n for n in child.children if isinstance(n, Section)]:
< #             summary.append(build_summary(child, level))
<     return summary
< 
< 
< class BaseWriter(object):
<     """base class for ureport writers"""
<     
<     def format(self, layout, stream=None, encoding=None):
<         """format and write the given layout into the stream object
< 
<         unicode policy: unicode strings may be found in the layout;
<         try to call stream.write with it, but give it back encoded using
<         the given encoding if it fails
<         """
<         if stream is None:
<             stream = sys.stdout
<         if not encoding:
<             encoding = getattr(stream, 'encoding', 'UTF-8')
<         self.encoding = encoding or 'UTF-8'
<         self.__compute_funcs = []
<         self.out = stream
<         self.begin_format(layout)
<         layout.accept(self)
<         self.end_format(layout)
<         
<     def format_children(self, layout):
<         """recurse on the layout children and call their accept method
<         (see the Visitor pattern)
<         """
<         for child in getattr(layout, 'children', ()):
<             child.accept(self)
< 
<     def writeln(self, string=''):
<         """write a line in the output buffer"""
<         self.write(string + linesep)
< 
<     def write(self, string):
<         """write a string in the output buffer"""
<         try:
<             self.out.write(string)
<         except UnicodeEncodeError:
<             self.out.write(string.encode(self.encoding))
< 
<     def begin_format(self, layout):
<         """begin to format a layout"""
<         self.section = 0
<         
<     def end_format(self, layout):
<         """finished to format a layout"""
< 
<     def get_table_content(self, table):
<         """trick to get table content without actually writing it
< 
<         return an aligned list of lists containing table cells values as string
<         """
<         result = [[]]
<         cols = table.cols
<         for cell in self.compute_content(table):
<             if cols == 0:
<                 result.append([])
<                 cols = table.cols
<             cols -= 1
<             result[-1].append(cell)
<         # fill missing cells
<         while len(result[-1]) < cols:
<             result[-1].append('')
<         return result
< 
<     def compute_content(self, layout):
<         """trick to compute the formatting of children layout before actually
<         writing it
< 
<         return an iterator on strings (one for each child element)
<         """
<         # use cells !
<         def write(data):
<             try:
<                 stream.write(data)
<             except UnicodeEncodeError:
<                 stream.write(data.encode(self.encoding))
<         def writeln(data=''):
<             try:
<                 stream.write(data+linesep)
<             except UnicodeEncodeError:
<                 stream.write(data.encode(self.encoding)+linesep)
<         self.write = write
<         self.writeln = writeln
<         self.__compute_funcs.append((write, writeln))
<         for child in layout.children:
<             stream = UStringIO()
<             child.accept(self)
<             yield stream.getvalue()
<         self.__compute_funcs.pop()
<         try:
<             self.write, self.writeln = self.__compute_funcs[-1]
<         except IndexError:
<             del self.write
<             del self.writeln
< 
< 
< from clonedigger.logilab.common.ureports.nodes import *
< from clonedigger.logilab.common.ureports.text_writer import TextWriter
< from clonedigger.logilab.common.ureports.html_writer import HTMLWriter
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/nodes.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/nodes.py.svn-base
1,202d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Micro reports objects
< 
< A micro report is a tree of layout and content objects
< 
< 
< :author:    Logilab
< :copyright: 2004-2008 LOGILAB S.A. (Paris, FRANCE)
< :contact:   http://www.logilab.fr/ -- mailto:python-projects@logilab.org
< """
< 
< __docformat__ = "restructuredtext en"
< 
< from clonedigger.logilab.common.tree import VNode
< 
< class BaseComponent(VNode):
<     """base report component
< 
<     attributes
<     * id : the component's optional id
<     * klass : the component's optional klass
<     """
<     def __init__(self, id=None, klass=None):
<         VNode.__init__(self, id)
<         self.klass = klass
< 
< class BaseLayout(BaseComponent):
<     """base container node
< 
<     attributes
<     * BaseComponent attributes
<     * children : components in this table (i.e. the table's cells)
<     """
<     def __init__(self, children=(), **kwargs):
<         super(BaseLayout, self).__init__(**kwargs)
<         for child in children:
<             if isinstance(child, BaseComponent):
<                 self.append(child)
<             else:
<                 self.add_text(child)
< 
<     def append(self, child):
<         """overridden to detect problems easily"""
<         assert child not in self.parents()
<         VNode.append(self, child)
<         
<     def parents(self):
<         """return the ancestor nodes"""
<         assert self.parent is not self
<         if self.parent is None:
<             return []
<         return [self.parent] + self.parent.parents()
<     
<     def add_text(self, text):
<         """shortcut to add text data"""
<         self.children.append(Text(text))
< 
< 
< # non container nodes #########################################################
< 
< class Text(BaseComponent):
<     """a text portion
< 
<     attributes :
<     * BaseComponent attributes
<     * data : the text value as an encoded or unicode string
<     """
<     def __init__(self, data, escaped=True, **kwargs):
<         super(Text, self).__init__(**kwargs)
<         #if isinstance(data, unicode):
<         #    data = data.encode('ascii')
<         assert isinstance(data, (str, unicode)), data.__class__
<         self.escaped = escaped
<         self.data = data
< 
< class VerbatimText(Text):
<     """a verbatim text, display the raw data
< 
<     attributes :
<     * BaseComponent attributes
<     * data : the text value as an encoded or unicode string
<     """
<         
< class Link(BaseComponent):
<     """a labelled link
< 
<     attributes :
<     * BaseComponent attributes
<     * url : the link's target (REQUIRED)
<     * label : the link's label as a string (use the url by default)
<     """
<     def __init__(self, url, label=None, **kwargs):
<         super(Link, self).__init__(**kwargs)
<         assert url
<         self.url = url
<         self.label = label or url
< 
<         
< class Image(BaseComponent):
<     """an embeded or a single image
< 
<     attributes :
<     * BaseComponent attributes
<     * filename : the image's filename (REQUIRED)
<     * stream : the stream object containing the image data (REQUIRED)
<     * title : the image's optional title
<     """
<     def __init__(self, filename, stream, title=None, **kwargs):
<         super(Link, self).__init__(**kwargs)
<         assert filename
<         assert stream
<         self.filename = filename
<         self.stream = stream
<         self.title = title
< 
<         
< # container nodes #############################################################
<         
< class Section(BaseLayout):
<     """a section
< 
<     attributes :
<     * BaseLayout attributes
<     
<     a title may also be given to the constructor, it'll be added
<     as a first element
<     a description may also be given to the constructor, it'll be added
<     as a first paragraph
<     """
<     def __init__(self, title=None, description=None, **kwargs):
<         super(Section, self).__init__(**kwargs)
<         if description:
<             self.insert(0, Paragraph([Text(description)]))
<         if title:
<             self.insert(0, Title(children=(title,)))
<         
< class Title(BaseLayout):
<     """a title
<     
<     attributes :
<     * BaseLayout attributes
< 
<     A title must not contains a section nor a paragraph!
<     """
<     
< class Span(BaseLayout):
<     """a title
<     
<     attributes :
<     * BaseLayout attributes
< 
<     A span should only contains Text and Link nodes (in-line elements)
<     """
<     
< class Paragraph(BaseLayout):
<     """a simple text paragraph
<     
<     attributes :
<     * BaseLayout attributes
< 
<     A paragraph must not contains a section !
<     """
<     
< class Table(BaseLayout):
<     """some tabular data
< 
<     attributes :
<     * BaseLayout attributes
<     * cols : the number of columns of the table (REQUIRED)
<     * rheaders : the first row's elements are table's header
<     * cheaders : the first col's elements are table's header
<     * title : the table's optional title
<     """    
<     def __init__(self, cols, title=None,
<                  rheaders=0, cheaders=0, rrheaders=0, rcheaders=0,
<                  **kwargs):
<         super(Table, self).__init__(**kwargs)
<         assert isinstance(cols, int)
<         self.cols = cols
<         self.title = title
<         self.rheaders = rheaders
<         self.cheaders = cheaders
<         self.rrheaders = rrheaders
<         self.rcheaders = rcheaders
<         
< class List(BaseLayout):
<     """some list data
< 
<     attributes :
<     * BaseLayout attributes
<     """    
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/text_writer.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/.svn/text-base/text_writer.py.svn-base
1,141d0
< # Copyright (c) 2004-2005 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Text formatting drivers for ureports"""
< 
< __revision__ = "$Id: text_writer.py,v 1.9 2005-11-22 13:13:13 syt Exp $"
< 
< from os import linesep
< 
< from clonedigger.logilab.common.ureports import BaseWriter
< 
< TITLE_UNDERLINES = ['', '=', '-', '`', '.', '~', '^']
< BULLETS = ['*', '-']
<  
< class TextWriter(BaseWriter):
<     """format layouts as text
<     (ReStructured inspiration but not totally handled yet)
<     """
<     def begin_format(self, layout):
<         super(TextWriter, self).begin_format(layout)
<         self.list_level = 0
<         self.pending_urls = []
<         
<     def visit_section(self, layout):
<         """display a section as text
<         """
<         self.section += 1
<         self.writeln()
<         self.format_children(layout)
<         if self.pending_urls:
<             self.writeln()
<             for label, url in self.pending_urls:
<                 self.writeln('.. _`%s`: %s' % (label, url))
<             self.pending_urls = []
<         self.section -= 1
<         self.writeln()
<             
<     def visit_title(self, layout):
<         title = ''.join(list(self.compute_content(layout)))
<         self.writeln(title)
<         try:
<             self.writeln(TITLE_UNDERLINES[self.section] * len(title))
<         except IndexError:
<             print "FIXME TITLE TOO DEEP. TURNING TITLE INTO TEXT"
<         
<     def visit_paragraph(self, layout):
<         """enter a paragraph"""
<         self.format_children(layout)
<         self.writeln()
<          
<     def visit_span(self, layout):
<         """enter a span"""
<         self.format_children(layout)
<          
<     def visit_table(self, layout):
<         """display a table as text"""
<         table_content = self.get_table_content(layout)
<         # get columns width
<         cols_width = [0]*len(table_content[0])
<         for row in table_content:
<             for index in range(len(row)):
<                 col = row[index]
<                 cols_width[index] = max(cols_width[index], len(col))
<         if layout.klass == 'field':
<             self.field_table(layout, table_content, cols_width)
<         else:
<             self.default_table(layout, table_content, cols_width)
<         self.writeln()
<         
<     def default_table(self, layout, table_content, cols_width):
<         """format a table"""
<         cols_width = [size+1 for size in cols_width]
<         format_strings = ' '.join(['%%-%ss'] * len(cols_width))
<         format_strings = format_strings % tuple(cols_width)
<         format_strings = format_strings.split(' ')
<         table_linesep = '\n+' + '+'.join(['-'*w for w in cols_width]) + '+\n'
<         headsep = '\n+' + '+'.join(['='*w for w in cols_width]) + '+\n'
<         # FIXME: layout.cheaders
<         self.write(table_linesep)
<         for i in range(len(table_content)):
<             self.write('|')
<             line = table_content[i]
<             for j in range(len(line)):
<                 self.write(format_strings[j] % line[j])
<                 self.write('|')
<             if i == 0 and layout.rheaders:
<                 self.write(headsep)
<             else:
<                 self.write(table_linesep)
<  
<     def field_table(self, layout, table_content, cols_width):
<         """special case for field table"""
<         assert layout.cols == 2
<         format_string = '%s%%-%ss: %%s' % (linesep, cols_width[0])
<         for field, value in table_content:
<             self.write(format_string % (field, value))
<  
< 
<     def visit_list(self, layout):
<         """display a list layout as text"""
<         bullet = BULLETS[self.list_level % len(BULLETS)]
<         indent = '  ' * self.list_level
<         self.list_level += 1
<         for child in layout.children:
<             self.write('%s%s%s ' % (linesep, indent, bullet))
<             child.accept(self)
<         self.list_level -= 1
< 
<     def visit_link(self, layout):
<         """add a hyperlink"""
<         if layout.label != layout.url:
<             self.write('`%s`_' % layout.label)
<             self.pending_urls.append( (layout.label, layout.url) )
<         else:
<             self.write(layout.url)
<             
<     def visit_verbatimtext(self, layout):
<         """display a verbatim layout as text (so difficult ;)
<         """
<         self.writeln('::\n')
<         for line in layout.data.splitlines():
<             self.writeln('    ' + line)
<         self.writeln()
<         
<     def visit_text(self, layout):
<         """add some text"""
<         self.write(layout.data)
<             
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/ureports/text_writer.py code-worker/code-worker/tasks/clonedigger/logilab/common/ureports/text_writer.py
1,141d0
< # Copyright (c) 2004-2005 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """Text formatting drivers for ureports"""
< 
< __revision__ = "$Id: text_writer.py,v 1.9 2005-11-22 13:13:13 syt Exp $"
< 
< from os import linesep
< 
< from clonedigger.logilab.common.ureports import BaseWriter
< 
< TITLE_UNDERLINES = ['', '=', '-', '`', '.', '~', '^']
< BULLETS = ['*', '-']
<  
< class TextWriter(BaseWriter):
<     """format layouts as text
<     (ReStructured inspiration but not totally handled yet)
<     """
<     def begin_format(self, layout):
<         super(TextWriter, self).begin_format(layout)
<         self.list_level = 0
<         self.pending_urls = []
<         
<     def visit_section(self, layout):
<         """display a section as text
<         """
<         self.section += 1
<         self.writeln()
<         self.format_children(layout)
<         if self.pending_urls:
<             self.writeln()
<             for label, url in self.pending_urls:
<                 self.writeln('.. _`%s`: %s' % (label, url))
<             self.pending_urls = []
<         self.section -= 1
<         self.writeln()
<             
<     def visit_title(self, layout):
<         title = ''.join(list(self.compute_content(layout)))
<         self.writeln(title)
<         try:
<             self.writeln(TITLE_UNDERLINES[self.section] * len(title))
<         except IndexError:
<             print "FIXME TITLE TOO DEEP. TURNING TITLE INTO TEXT"
<         
<     def visit_paragraph(self, layout):
<         """enter a paragraph"""
<         self.format_children(layout)
<         self.writeln()
<          
<     def visit_span(self, layout):
<         """enter a span"""
<         self.format_children(layout)
<          
<     def visit_table(self, layout):
<         """display a table as text"""
<         table_content = self.get_table_content(layout)
<         # get columns width
<         cols_width = [0]*len(table_content[0])
<         for row in table_content:
<             for index in range(len(row)):
<                 col = row[index]
<                 cols_width[index] = max(cols_width[index], len(col))
<         if layout.klass == 'field':
<             self.field_table(layout, table_content, cols_width)
<         else:
<             self.default_table(layout, table_content, cols_width)
<         self.writeln()
<         
<     def default_table(self, layout, table_content, cols_width):
<         """format a table"""
<         cols_width = [size+1 for size in cols_width]
<         format_strings = ' '.join(['%%-%ss'] * len(cols_width))
<         format_strings = format_strings % tuple(cols_width)
<         format_strings = format_strings.split(' ')
<         table_linesep = '\n+' + '+'.join(['-'*w for w in cols_width]) + '+\n'
<         headsep = '\n+' + '+'.join(['='*w for w in cols_width]) + '+\n'
<         # FIXME: layout.cheaders
<         self.write(table_linesep)
<         for i in range(len(table_content)):
<             self.write('|')
<             line = table_content[i]
<             for j in range(len(line)):
<                 self.write(format_strings[j] % line[j])
<                 self.write('|')
<             if i == 0 and layout.rheaders:
<                 self.write(headsep)
<             else:
<                 self.write(table_linesep)
<  
<     def field_table(self, layout, table_content, cols_width):
<         """special case for field table"""
<         assert layout.cols == 2
<         format_string = '%s%%-%ss: %%s' % (linesep, cols_width[0])
<         for field, value in table_content:
<             self.write(format_string % (field, value))
<  
< 
<     def visit_list(self, layout):
<         """display a list layout as text"""
<         bullet = BULLETS[self.list_level % len(BULLETS)]
<         indent = '  ' * self.list_level
<         self.list_level += 1
<         for child in layout.children:
<             self.write('%s%s%s ' % (linesep, indent, bullet))
<             child.accept(self)
<         self.list_level -= 1
< 
<     def visit_link(self, layout):
<         """add a hyperlink"""
<         if layout.label != layout.url:
<             self.write('`%s`_' % layout.label)
<             self.pending_urls.append( (layout.label, layout.url) )
<         else:
<             self.write(layout.url)
<             
<     def visit_verbatimtext(self, layout):
<         """display a verbatim layout as text (so difficult ;)
<         """
<         self.writeln('::\n')
<         for line in layout.data.splitlines():
<             self.writeln('    ' + line)
<         self.writeln()
<         
<     def visit_text(self, layout):
<         """add some text"""
<         self.write(layout.data)
<             
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/vcgutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/vcgutils.py
1,212d0
< # Copyright (c) 2000-2002 LOGILAB S.A. (Paris, FRANCE).
< # http://www.logilab.fr/ -- mailto:contact@logilab.fr
< #
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """
< utilities functions to generate file readable with Georg Sander's vcg
< (Visualization of Compiler Graphs).
< 
< You can download vcg at http://rw4.cs.uni-sb.de/~sander/html/gshome.html
< Note that vcg exists as a debian package.
< 
< See the documentation of vcg for explanation about the different value that
< maybe used for the functions parameters
< """
< 
< __revision__ = "$Id: vcgutils.py,v 1.6 2003-12-10 08:15:09 syt Exp $"
< 
< import string
< 
< ATTRS_VAL = {
<     'algos':       ('dfs', 'tree', 'minbackward',
<                     'left_to_right','right_to_left',
<                     'top_to_bottom','bottom_to_top',
<                     'maxdepth', 'maxdepthslow', 'mindepth', 'mindepthslow',
<                     'mindegree', 'minindegree', 'minoutdegree',
<                     'maxdegree','maxindegree', 'maxoutdegree'),
<     'booleans':    ('yes', 'no'),
<     'colors':      ('black', 'white', 'blue', 'red', 'green', 'yellow',
<                     'magenta', 'lightgrey',
<                     'cyan', 'darkgrey', 'darkblue', 'darkred', 'darkgreen',
<                     'darkyellow', 'darkmagenta', 'darkcyan', 'gold',
<                     'lightblue', 'lightred', 'lightgreen', 'lightyellow',
<                     'lightmagenta', 'lightcyan', 'lilac', 'turquoise',
<                     'aquamarine', 'khaki', 'purple', 'yellowgreen', 'pink',
<                     'orange', 'orchid'),
<     'shapes':      ('box', 'ellipse', 'rhomb', 'triangle'),
<     'textmodes':   ('center', 'left_justify', 'right_justify'),
<     'arrowstyles': ('solid', 'line', 'none'),
<     'linestyles':  ('continuous', 'dashed', 'dotted', 'invisible'),
<     }
< 
< # meaning of possible values:
< #   O    -> string
< #   1    -> int 
< #   list -> value in list
< GRAPH_ATTRS = {
<     'title' :              0,
<     'label' :              0,
<     'color':               ATTRS_VAL['colors'],
<     'textcolor':           ATTRS_VAL['colors'],
<     'bordercolor':         ATTRS_VAL['colors'],
<     'width':               1,
<     'height':              1,
<     'borderwidth':         1,
<     'textmode':            ATTRS_VAL['textmodes'],
<     'shape':               ATTRS_VAL['shapes'],
<     'shrink':              1,
<     'stretch':             1,
<     'orientation':         ATTRS_VAL['algos'],
<     'vertical_order':      1,
<     'horizontal_order':    1,
<     'xspace':              1,
<     'yspace':              1,
<     'layoutalgorithm' :    ATTRS_VAL['algos'],
<     'late_edge_labels' :   ATTRS_VAL['booleans'],
<     'display_edge_labels': ATTRS_VAL['booleans'],
<     'dirty_edge_labels' :  ATTRS_VAL['booleans'],
<     'finetuning':          ATTRS_VAL['booleans'],
<     'manhattan_edges':     ATTRS_VAL['booleans'],
<     'smanhattan_edges':    ATTRS_VAL['booleans'],
<     'port_sharing':        ATTRS_VAL['booleans'],
<     'edges':               ATTRS_VAL['booleans'],
<     'nodes':               ATTRS_VAL['booleans'],
<     'splines':             ATTRS_VAL['booleans'],
<     }
< NODE_ATTRS = {
<     'title' :              0,
<     'label' :              0,
<     'color':               ATTRS_VAL['colors'],
<     'textcolor':           ATTRS_VAL['colors'],
<     'bordercolor':         ATTRS_VAL['colors'],
<     'width':               1,
<     'height':              1,
<     'borderwidth':         1,
<     'textmode':            ATTRS_VAL['textmodes'],
<     'shape':               ATTRS_VAL['shapes'],
<     'shrink':              1,
<     'stretch':             1,
<     'vertical_order':      1,
<     'horizontal_order':    1,
<     }
< EDGE_ATTRS = {
<     'sourcename' :         0,
<     'targetname' :         0,
<     'label' :              0,
<     'linestyle' :          ATTRS_VAL['linestyles'],
<     'class' :              1,
<     'thickness' :          0,
<     'color':               ATTRS_VAL['colors'],
<     'textcolor':           ATTRS_VAL['colors'],
<     'arrowcolor':          ATTRS_VAL['colors'],
<     'backarrowcolor':      ATTRS_VAL['colors'],
<     'arrowsize':           1,
<     'backarrowsize':       1,
<     'arrowstyle':          ATTRS_VAL['arrowstyles'],
<     'backarrowstyle':      ATTRS_VAL['arrowstyles'],
<     'textmode':            ATTRS_VAL['textmodes'],
<     'priority':            1,
<     'anchor':              1,
<     'horizontal_order':    1,
<     }
< 
< 
< # Misc utilities ###############################################################
< 
< def latin_to_vcg(st):
<     """convert latin characters using vcg escape sequence
<     """
<     for char in st:
<         if char not in string.ascii_letters:
<             try:
<                 num = ord(char)
<                 if num >= 192:
<                     st = st.replace(char, r'\fi%d'%ord(char))
<             except:
<                 pass
<     return st
< 
< 
< class VCGPrinter:
<     """a vcg graph writer
<     """
<     
<     def __init__(self, output_stream):
<         self._stream = output_stream
<         self._indent = ''
< 
<     def open_graph(self, **args):
<         """open a vcg graph
<         """
<         self._stream.write('%sgraph:{\n'%self._indent)
<         self._inc_indent()
<         self._write_attributes(GRAPH_ATTRS, **args)
< 
<     def close_graph(self):
<         """close a vcg graph
<         """
<         self._dec_indent()
<         self._stream.write('%s}\n'%self._indent)
< 
< 
<     def node(self, title, **args):
<         """draw a node
<         """
<         self._stream.write('%snode: {title:"%s"' % (self._indent, title))
<         self._write_attributes(NODE_ATTRS, **args)
<         self._stream.write('}\n')
< 
< 
<     def edge(self, from_node, to_node, edge_type='', **args):
<         """draw an edge from a node to another.
<         """
<         self._stream.write(
<             '%s%sedge: {sourcename:"%s" targetname:"%s"' % (
<             self._indent, edge_type, from_node, to_node))
<         self._write_attributes(EDGE_ATTRS, **args)
<         self._stream.write('}\n')
< 
< 
<     # private ##################################################################
<     
<     def _write_attributes(self, attributes_dict, **args):
<         """write graph, node or edge attributes
<         """
<         for key, value in args.items():
<             try:
<                 _type =  attributes_dict[key]
<             except KeyError:
<                 raise Exception('''no such attribute %s
< possible attributes are %s''' % (key, attributes_dict.keys()))
< 
<             if not _type:
<                 self._stream.write('%s%s:"%s"\n' % (self._indent, key, value))
<             elif _type == 1:
<                 self._stream.write('%s%s:%s\n' % (self._indent, key,
<                                                   int(value)))
<             elif value in _type:
<                 self._stream.write('%s%s:%s\n' % (self._indent, key, value))
<             else:
<                 raise Exception('''value %s isn\'t correct for attribute %s
< correct values are %s''' % (value, key, _type))
<     
<     def _inc_indent(self):
<         """increment indentation
<         """
<         self._indent = '  %s' % self._indent
<         
<     def _dec_indent(self):
<         """decrement indentation
<         """
<         self._indent = self._indent[:-2]
diff -r -N code-worker/tasks/clonedigger/logilab/common/visitor.py code-worker/code-worker/tasks/clonedigger/logilab/common/visitor.py
1,106d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """ Copyright (c) 2002-2003 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
<  
< a generic visitor abstract implementation
< """
< 
< def no_filter(_):
<     return 1
< 
< 
< # Iterators ###################################################################
< class FilteredIterator(object):
< 
<     def __init__(self, node, list_func, filter_func=None):
<         self._next = [(node, 0)]
<         if filter_func is None:
<             filter_func = no_filter
<         self._list = list_func(node, filter_func)
<         
<     def next(self):
<         try:
<             return self._list.pop(0)
<         except :
<             return None
< 
< 
< # Base Visitor ################################################################
< class Visitor(object):
< 
<     def __init__(self, iterator_class, filter_func=None):
<         self._iter_class = iterator_class
<         self.filter = filter_func
<         
<     def visit(self, node, *args, **kargs):
<         """
<         launch the visit on a given node
< 
<         call 'open_visit' before the begining of the visit, with extra args
<         given
<         when all nodes have been visited, call the 'close_visit' method
<         """
<         self.open_visit(node, *args, **kargs)
<         return self.close_visit(self._visit(node))
< 
<     def _visit(self, node):
<         iterator = self._get_iterator(node)
<         n = iterator.next()
<         while n:
<             result = n.accept(self)
<             n = iterator.next()
<         return result
< 
<     def _get_iterator(self, node):
<         return self._iter_class(node, self.filter)
<         
<     def open_visit(self, *args, **kargs):
<         """
<         method called at the beginning of the visit
<         """
<         pass
<     
<     def close_visit(self, result):
<         """
<         method called at the end of the visit
<         """
<         return result
< 
< 
< 
< # standard visited mixin ######################################################
< class VisitedMixIn(object):
<     """
<     Visited interface allow node visitors to use the node
<     """
<     def get_visit_name(self):
<         """
<         return the visit name for the mixed class. When calling 'accept', the
<         method <'visit_' + name returned by this method> will be called on the
<         visitor
<         """
<         try:
<             return self.TYPE.replace('-', '_')
<         except:
<             return self.__class__.__name__.lower()
<     
<     def accept(self, visitor, *args, **kwargs):
<         func = getattr(visitor, 'visit_%s' % self.get_visit_name())
<         return func(self, *args, **kwargs)
<     
<     def leave(self, visitor, *args, **kwargs):
<         func = getattr(visitor, 'leave_%s' % self.get_visit_name())
<         return func(self, *args, **kwargs)
< 
< 
diff -r -N code-worker/tasks/clonedigger/logilab/common/xmlrpcutils.py code-worker/code-worker/tasks/clonedigger/logilab/common/xmlrpcutils.py
1,131d0
< # This program is free software; you can redistribute it and/or modify it under
< # the terms of the GNU General Public License as published by the Free Software
< # Foundation; either version 2 of the License, or (at your option) any later
< # version.
< #
< # This program is distributed in the hope that it will be useful, but WITHOUT
< # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
< # FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details
< #
< # You should have received a copy of the GNU General Public License along with
< # this program; if not, write to the Free Software Foundation, Inc.,
< # 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
< """XML-RPC utilities
< 
<  Copyright (c) 2003-2004 LOGILAB S.A. (Paris, FRANCE).
<  http://www.logilab.fr/ -- mailto:contact@logilab.fr
< """
< 
< __revision__ = "$Id: xmlrpcutils.py,v 1.3 2005-11-22 13:13:03 syt Exp $"
< 
< import xmlrpclib
< from base64 import encodestring
< #from cStringIO import StringIO
< 
< ProtocolError = xmlrpclib.ProtocolError
< 
< ## class BasicAuthTransport(xmlrpclib.Transport):
< ##     def __init__(self, username=None, password=None):
< ##         self.username = username
< ##         self.password = password
< ##         self.verbose = None
< ##         self.has_ssl = httplib.__dict__.has_key("HTTPConnection")
<  
< ##     def request(self, host, handler, request_body, verbose=None):
< ##         # issue XML-RPC request
< ##         if self.has_ssl:
< ##             if host.startswith("https:"): h = httplib.HTTPSConnection(host)
< ##             else: h = httplib.HTTPConnection(host)
< ##         else: h = httplib.HTTP(host)
<  
< ##         h.putrequest("POST", handler)
<  
< ##         # required by HTTP/1.1
< ##         if not self.has_ssl: # HTTPConnection already does 1.1
< ##             h.putheader("Host", host)
< ##         h.putheader("Connection", "close")
<  
< ##         if request_body: h.send(request_body)
< ##         if self.has_ssl:
< ##             response = h.getresponse()
< ##             if response.status != 200:
< ##                 raise xmlrpclib.ProtocolError(host + handler,
< ##                                               response.status,
< ##                                               response.reason,
< ##                                               response.msg)
< ##             file = response.fp
< ##         else:
< ##             errcode, errmsg, headers = h.getreply()
< ##             if errcode != 200:
< ##                 raise xmlrpclib.ProtocolError(host + handler, errcode,
< ##                                               errmsg, headers)
<  
< ##             file = h.getfile()
<  
< ##         return self.parse_response(file)
<                                                                               
< 
< 
< class AuthMixin:
<     """basic http authentication mixin for xmlrpc transports"""
<     
<     def __init__(self, username, password, encoding):
<         self.verbose = 0
<         self.username = username
<         self.password = password
<         self.encoding = encoding
<         
<     def request(self, host, handler, request_body, verbose=0):
<         """issue XML-RPC request"""
<         h = self.make_connection(host)
<         h.putrequest("POST", handler)
<         # required by XML-RPC
<         h.putheader("User-Agent", self.user_agent)
<         h.putheader("Content-Type", "text/xml")
<         h.putheader("Content-Length", str(len(request_body)))
<         h.putheader("Host", host)
<         h.putheader("Connection", "close")
<         # basic auth
<         if self.username is not None and self.password is not None:
<             h.putheader("AUTHORIZATION", "Basic %s" % encodestring(
<                 "%s:%s" % (self.username, self.password)).replace("\012", ""))
<         h.endheaders()
<         # send body
<         if request_body:
<             h.send(request_body)
<         # get and check reply
<         errcode, errmsg, headers = h.getreply()
<         if errcode != 200:
<             raise ProtocolError(host + handler, errcode, errmsg, headers)
<         file = h.getfile()
< ##         # FIXME: encoding ??? iirc, this fix a bug in xmlrpclib but...
< ##         data = h.getfile().read()
< ##         if self.encoding != 'UTF-8':
< ##             data = data.replace("version='1.0'",
< ##                                 "version='1.0' encoding='%s'" % self.encoding)
< ##         result = StringIO()
< ##         result.write(data)
< ##         result.seek(0)
< ##         return self.parse_response(result)
<         return self.parse_response(file)
<     
< class BasicAuthTransport(AuthMixin, xmlrpclib.Transport):
<     """basic http authentication transport"""
<     
< class BasicAuthSafeTransport(AuthMixin, xmlrpclib.SafeTransport):
<     """basic https authentication transport"""
< 
< 
< def connect(url, user=None, passwd=None, encoding='ISO-8859-1'):
<     """return an xml rpc server on <url>, using user / password if specified
<     """
<     if user or passwd:
<         assert user and passwd is not None
<         if url.startswith('https://'):
<             transport = BasicAuthSafeTransport(user, passwd, encoding)
<         else:
<             transport = BasicAuthTransport(user, passwd, encoding)
<     else:
<         transport = None
<     server = xmlrpclib.ServerProxy(url, transport, encoding=encoding)
<     return server
diff -r -N code-worker/tasks/clonedigger/logilab/__init__.py code-worker/code-worker/tasks/clonedigger/logilab/__init__.py
1d0
< pass
diff -r -N code-worker/tasks/clonedigger/logilab/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/logilab/.svn/all-wcprops
1,11d0
< K 25
< svn:wc:ra_dav:version-url
< V 59
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/logilab
< END
< __init__.py
< K 25
< svn:wc:ra_dav:version-url
< V 70
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/logilab/__init__.py
< END
diff -r -N code-worker/tasks/clonedigger/logilab/.svn/entries code-worker/code-worker/tasks/clonedigger/logilab/.svn/entries
1,68d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/logilab
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< __init__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:58.000000Z
< 4528e6a7bb9341c36c425faf40ef32c3
< 2008-06-08T13:44:11.553084Z
< 41
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5
< 
< common
< dir
< 
< astng
< dir
< 
diff -r -N code-worker/tasks/clonedigger/logilab/.svn/text-base/__init__.py.svn-base code-worker/code-worker/tasks/clonedigger/logilab/.svn/text-base/__init__.py.svn-base
1d0
< pass
diff -r -N code-worker/tasks/clonedigger/lua_antlr/build_jar.sh code-worker/code-worker/tasks/clonedigger/lua_antlr/build_jar.sh
1,5d0
< export CLASSPATH=/home/peter/antlr/antlr-3.1.jar:/home/peter/antlr/antlr-3.0.1/lib/stringtemplate-3.1b1.jar:/home/peter/antlr/antlr-3.0.1/lib/antlr-2.7.7.jar:.
< java org.antlr.Tool -debug Lua.g
< javac *.java
< jar -cf TreeProducer.jar *.class
< rm *.class
diff -r -N code-worker/tasks/clonedigger/lua_antlr/Lua.g code-worker/code-worker/tasks/clonedigger/lua_antlr/Lua.g
1,160d0
< /*
<  * Lua 5.1 grammar
<  * 
<  * Nicolai Mainiero
<  * May 2007
<  * 
<  * This is a Lua (http://www.lua.org) grammar for the version 5.1 for ANTLR 3.
<  * I tested it with basic and extended examples and it worked fine. It is also used
<  * for LunarEclipse (http://lunareclipse.sf.net) a Lua editor based on Eclipse.
<  * 
<  * Thanks to Johannes Luber and Gavin Lambert who helped me with some mutually left recursion.
<  *  
<  */
< 
< grammar Lua;
< 
< options {
<   backtrack=true;
< }
< 
< chunk : (stat (';')?)* (laststat (';')?)?;
< 
< block : chunk;
< 
< stat :  varlist1 '=' explist1 | 
< 	functioncall | 
< 	'do' block 'end' | 
< 	'while' exp 'do' block 'end' | 
< 	'repeat' block 'until' exp | 
< 	'if' exp 'then' block ('elseif' exp 'then' block)* ('else' block)? 'end' | 
< 	'for' NAME '=' exp ',' exp (',' exp)? 'do' block 'end' | 
< 	'for' namelist 'in' explist1 'do' block 'end' | 
< 	'function' funcname funcbody | 
< 	'local' 'function' NAME funcbody | 
< 	'local' namelist ('=' explist1)? ;
< 
< laststat : 'return' (explist1)? | 'break';
< 
< funcname : NAME ('.' NAME)* (':' NAME)? ;
< 
< varlist1 : var (',' var)*;
< 
< 
< namelist : NAME (',' NAME)*;
< 
< explist1 : (exp ',')* exp;
< 
< exp :  ('nil' | 'false' | 'true' | number | string | '...' | function | prefixexp | tableconstructor | unop exp) (binop exp)* ;
< 
< var: (NAME | '(' exp ')' varSuffix) varSuffix*;
< 
< prefixexp: varOrExp nameAndArgs*;
< 
< functioncall: varOrExp nameAndArgs+;
< 
< /*
< var :  NAME | prefixexp '[' exp ']' | prefixexp '.' NAME; 
< 
< prefixexp : var | functioncall | '(' exp ')';
< 
< functioncall :  prefixexp args | prefixexp ':' NAME args ;
< */
< 
< varOrExp: var | '(' exp ')';
< 
< nameAndArgs: (':' NAME)? args;
< 
< varSuffix: nameAndArgs* ('[' exp ']' | '.' NAME);
< 
< args :  '(' (explist1)? ')' | tableconstructor | string ;
< 
< function : 'function' funcbody;
< 
< funcbody : '(' (parlist1)? ')' block 'end';
< 
< parlist1 : namelist (',' '...')? | '...';
< 
< tableconstructor : '{' (fieldlist)? '}';
< 
< fieldlist : field (fieldsep field)* (fieldsep)?;
< 
< field : '[' exp ']' '=' exp | NAME '=' exp | exp;
< 
< fieldsep : ',' | ';';
< 
< binop : '+' | '-' | '*' | '/' | '^' | '%' | '..' | 
< 		 '<' | '<=' | '>' | '>=' | '==' | '~=' | 
< 		 'and' | 'or';
< 
< unop : '-' | 'not' | '#';
< 
< number : INT | FLOAT | EXP | HEX;
< 
< string	: NORMALSTRING | CHARSTRING | LONGSTRING;
< 
< 
< // LEXER
< 
< NAME	:('a'..'z'|'A'..'Z'|'_')(options{greedy=true;}:	'a'..'z'|'A'..'Z'|'_'|'0'..'9')*
< 	;
< 
< INT	: ('0'..'9')+;
< 
< FLOAT 	:INT '.' INT ;
< 
< EXP	: (INT| FLOAT) ('E'|'e') ('-')? INT;
< 
< HEX	:'0x' ('0'..'9'| 'a'..'f')+ ;
< 
< 	
< 
< NORMALSTRING
<     :  '"' ( EscapeSequence | ~('\\'|'"') )* '"' 
<     ;
< 
< CHARSTRING
<    :	'\'' ( EscapeSequence | ~('\''|'\\') )* '\''
<    ;
< 
< LONGSTRING
< 	:	'['('=')*'[' ( EscapeSequence | ~('\\'|']') )* ']'('=')*']'
< 	;
< 
< fragment
< EscapeSequence
<     :   '\\' ('b'|'t'|'n'|'f'|'r'|'\"'|'\''|'\\')
<     |   UnicodeEscape
<     |   OctalEscape
<     ;
<     
< fragment
< OctalEscape
<     :   '\\' ('0'..'3') ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7')
<     ;
<     
< fragment
< UnicodeEscape
<     :   '\\' 'u' HexDigit HexDigit HexDigit HexDigit
<     ;
<     
< fragment
< HexDigit : ('0'..'9'|'a'..'f'|'A'..'F') ;
< 
< 
< COMMENT
<     :   '--[[' ( options {greedy=false;} : . )* ']]' {skip();}
<     ;
<     
< LINE_COMMENT
<     : '--' ~('\n'|'\r')* '\r'? '\n' {skip();}
<     ;
<     
<     
< WS  :  (' '|'\t'|'\u000C') {skip();}
<     ;
<     
< NEWLINE	: ('\r')? '\n' {skip();}
< 	;
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/all-wcprops
1,29d0
< K 25
< svn:wc:ra_dav:version-url
< V 61
< /svnroot/clonedigger/!svn/ver/182/trunk/clonedigger/lua_antlr
< END
< TreeProducer.java
< K 25
< svn:wc:ra_dav:version-url
< V 79
< /svnroot/clonedigger/!svn/ver/182/trunk/clonedigger/lua_antlr/TreeProducer.java
< END
< build_jar.sh
< K 25
< svn:wc:ra_dav:version-url
< V 74
< /svnroot/clonedigger/!svn/ver/182/trunk/clonedigger/lua_antlr/build_jar.sh
< END
< Lua.g
< K 25
< svn:wc:ra_dav:version-url
< V 67
< /svnroot/clonedigger/!svn/ver/182/trunk/clonedigger/lua_antlr/Lua.g
< END
< TreeProducer.jar
< K 25
< svn:wc:ra_dav:version-url
< V 78
< /svnroot/clonedigger/!svn/ver/182/trunk/clonedigger/lua_antlr/TreeProducer.jar
< END
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/entries code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/entries
1,164d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger/lua_antlr
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2008-08-29T11:39:47.746139Z
< 182
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< TreeProducer.java
< file
< 
< 
< 
< 
< 2011-07-05T05:47:48.000000Z
< 9fc83eaf5f84913fb49ec1160680334b
< 2008-08-29T11:39:47.746139Z
< 182
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3548
< 
< build_jar.sh
< file
< 
< 
< 
< 
< 2011-07-05T05:47:48.000000Z
< e03485503fc4d37b4bc8b108c7a40c7f
< 2008-08-29T11:39:47.746139Z
< 182
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 250
< 
< Lua.g
< file
< 
< 
< 
< 
< 2011-07-05T05:47:48.000000Z
< 343a155a01cbc7057dc0692ee336594d
< 2008-08-29T11:39:47.746139Z
< 182
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3474
< 
< TreeProducer.jar
< file
< 
< 
< 
< 
< 2011-07-05T05:47:48.000000Z
< 2bdddb223afa4b0e14fccbeb2294bd33
< 2008-08-29T11:39:47.746139Z
< 182
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 50796
< 
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/prop-base/build_jar.sh.svn-base code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/prop-base/build_jar.sh.svn-base
1,5d0
< K 14
< svn:executable
< V 1
< *
< END
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/prop-base/TreeProducer.jar.svn-base code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/prop-base/TreeProducer.jar.svn-base
1,5d0
< K 13
< svn:mime-type
< V 24
< application/octet-stream
< END
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/build_jar.sh.svn-base code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/build_jar.sh.svn-base
1,5d0
< export CLASSPATH=/home/peter/antlr/antlr-3.1.jar:/home/peter/antlr/antlr-3.0.1/lib/stringtemplate-3.1b1.jar:/home/peter/antlr/antlr-3.0.1/lib/antlr-2.7.7.jar:.
< java org.antlr.Tool -debug Lua.g
< javac *.java
< jar -cf TreeProducer.jar *.class
< rm *.class
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/Lua.g.svn-base code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/Lua.g.svn-base
1,160d0
< /*
<  * Lua 5.1 grammar
<  * 
<  * Nicolai Mainiero
<  * May 2007
<  * 
<  * This is a Lua (http://www.lua.org) grammar for the version 5.1 for ANTLR 3.
<  * I tested it with basic and extended examples and it worked fine. It is also used
<  * for LunarEclipse (http://lunareclipse.sf.net) a Lua editor based on Eclipse.
<  * 
<  * Thanks to Johannes Luber and Gavin Lambert who helped me with some mutually left recursion.
<  *  
<  */
< 
< grammar Lua;
< 
< options {
<   backtrack=true;
< }
< 
< chunk : (stat (';')?)* (laststat (';')?)?;
< 
< block : chunk;
< 
< stat :  varlist1 '=' explist1 | 
< 	functioncall | 
< 	'do' block 'end' | 
< 	'while' exp 'do' block 'end' | 
< 	'repeat' block 'until' exp | 
< 	'if' exp 'then' block ('elseif' exp 'then' block)* ('else' block)? 'end' | 
< 	'for' NAME '=' exp ',' exp (',' exp)? 'do' block 'end' | 
< 	'for' namelist 'in' explist1 'do' block 'end' | 
< 	'function' funcname funcbody | 
< 	'local' 'function' NAME funcbody | 
< 	'local' namelist ('=' explist1)? ;
< 
< laststat : 'return' (explist1)? | 'break';
< 
< funcname : NAME ('.' NAME)* (':' NAME)? ;
< 
< varlist1 : var (',' var)*;
< 
< 
< namelist : NAME (',' NAME)*;
< 
< explist1 : (exp ',')* exp;
< 
< exp :  ('nil' | 'false' | 'true' | number | string | '...' | function | prefixexp | tableconstructor | unop exp) (binop exp)* ;
< 
< var: (NAME | '(' exp ')' varSuffix) varSuffix*;
< 
< prefixexp: varOrExp nameAndArgs*;
< 
< functioncall: varOrExp nameAndArgs+;
< 
< /*
< var :  NAME | prefixexp '[' exp ']' | prefixexp '.' NAME; 
< 
< prefixexp : var | functioncall | '(' exp ')';
< 
< functioncall :  prefixexp args | prefixexp ':' NAME args ;
< */
< 
< varOrExp: var | '(' exp ')';
< 
< nameAndArgs: (':' NAME)? args;
< 
< varSuffix: nameAndArgs* ('[' exp ']' | '.' NAME);
< 
< args :  '(' (explist1)? ')' | tableconstructor | string ;
< 
< function : 'function' funcbody;
< 
< funcbody : '(' (parlist1)? ')' block 'end';
< 
< parlist1 : namelist (',' '...')? | '...';
< 
< tableconstructor : '{' (fieldlist)? '}';
< 
< fieldlist : field (fieldsep field)* (fieldsep)?;
< 
< field : '[' exp ']' '=' exp | NAME '=' exp | exp;
< 
< fieldsep : ',' | ';';
< 
< binop : '+' | '-' | '*' | '/' | '^' | '%' | '..' | 
< 		 '<' | '<=' | '>' | '>=' | '==' | '~=' | 
< 		 'and' | 'or';
< 
< unop : '-' | 'not' | '#';
< 
< number : INT | FLOAT | EXP | HEX;
< 
< string	: NORMALSTRING | CHARSTRING | LONGSTRING;
< 
< 
< // LEXER
< 
< NAME	:('a'..'z'|'A'..'Z'|'_')(options{greedy=true;}:	'a'..'z'|'A'..'Z'|'_'|'0'..'9')*
< 	;
< 
< INT	: ('0'..'9')+;
< 
< FLOAT 	:INT '.' INT ;
< 
< EXP	: (INT| FLOAT) ('E'|'e') ('-')? INT;
< 
< HEX	:'0x' ('0'..'9'| 'a'..'f')+ ;
< 
< 	
< 
< NORMALSTRING
<     :  '"' ( EscapeSequence | ~('\\'|'"') )* '"' 
<     ;
< 
< CHARSTRING
<    :	'\'' ( EscapeSequence | ~('\''|'\\') )* '\''
<    ;
< 
< LONGSTRING
< 	:	'['('=')*'[' ( EscapeSequence | ~('\\'|']') )* ']'('=')*']'
< 	;
< 
< fragment
< EscapeSequence
<     :   '\\' ('b'|'t'|'n'|'f'|'r'|'\"'|'\''|'\\')
<     |   UnicodeEscape
<     |   OctalEscape
<     ;
<     
< fragment
< OctalEscape
<     :   '\\' ('0'..'3') ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7') ('0'..'7')
<     |   '\\' ('0'..'7')
<     ;
<     
< fragment
< UnicodeEscape
<     :   '\\' 'u' HexDigit HexDigit HexDigit HexDigit
<     ;
<     
< fragment
< HexDigit : ('0'..'9'|'a'..'f'|'A'..'F') ;
< 
< 
< COMMENT
<     :   '--[[' ( options {greedy=false;} : . )* ']]' {skip();}
<     ;
<     
< LINE_COMMENT
<     : '--' ~('\n'|'\r')* '\r'? '\n' {skip();}
<     ;
<     
<     
< WS  :  (' '|'\t'|'\u000C') {skip();}
<     ;
<     
< NEWLINE	: ('\r')? '\n' {skip();}
< 	;
Binary files code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/TreeProducer.jar.svn-base and code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/TreeProducer.jar.svn-base differ
diff -r -N code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/TreeProducer.java.svn-base code-worker/code-worker/tasks/clonedigger/lua_antlr/.svn/text-base/TreeProducer.java.svn-base
1,128d0
< /*  Copyright 2008 Peter Bulychev
<  *
<  *  This file is part of Clone Digger.
<  *
<  *  Clone Digger is free software: you can redistribute it and/or modify
<  *  it under the terms of the GNU General Public License as published by
<  *  the Free Software Foundation, either version 3 of the License, or
<  *  (at your option) any later version.
<  *
<  *  Clone Digger is distributed in the hope that it will be useful,
<  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
<  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<  *  GNU General Public License for more details.
<  *
<  *  You should have received a copy of the GNU General Public License
<  *  along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
<  */
< import org.antlr.runtime.*;
< import org.antlr.stringtemplate.*;
< import org.antlr.runtime.tree.*;
< 
< import org.antlr.runtime.tree.ParseTree;
< 
< import org.antlr.runtime.*;
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.debug.*;
< 
< import java.lang.reflect.*;
< import java.io.*;
< import java.util.*;
< import java.text.*;
< import java.lang.*;
< 
< 
< 
< public class TreeProducer
< {
<     public TreeProducer ()
<     {
< 	super ();
<     }
< 
<     /*
<      * forXml function was taken from http://www.javapractices.com/topic/TopicAction.do?Id=96
<      * the license is: http://creativecommons.org/licenses/by/3.0/
<      */
<     public static String forXML (String aText)
<     {
< 	final StringBuilder result = new StringBuilder ();
< 	final StringCharacterIterator iterator =
< 	    new StringCharacterIterator (aText);
< 	char character = iterator.current ();
< 	while (character != CharacterIterator.DONE)
< 	{
< 	    if (character == '<')
< 	    {
< 		result.append ("&lt;");
< 	    }
< 	    else if (character == '>')
< 	    {
< 		result.append ("&gt;");
< 	    }
< 	    else if (character == '\"')
< 	    {
< 		result.append ("&quot;");
< 	    }
< 	    else if (character == '\'')
< 	    {
< 		result.append ("&#039;");
< 	    }
< 	    else if (character == '&')
< 	    {
< 		result.append ("&amp;");
< 	    }
< 	    else
< 	    {
< 		//the char is not a special one
< 		//        //add it to the result as is
< 		result.append (character);
< 	    }
< 	    character = iterator.next ();
< 	}
< 	return result.toString ();
<     }
<     //                                      }
< 
<     public static void printTree (ParseTree tree, PrintWriter outputStream,	String indent)
< {
< //    String xml_node_name = (tree.is_statement?"statement_node":"node");
<     String xml_node_name = "node";
<     int lineno;
<     if ( tree.payload instanceof Token ) {
< 	Token t = (Token)tree.payload;
< 	lineno = t.getLine();
<     } else {
< 	lineno = 0;
<     }
< 
<     outputStream.println (indent + "<" + xml_node_name + " name=\"" + forXML ("" + tree) + "\"" + 
< 	    " line_number=\"" + lineno + "\" " +
< 	    ">");
<     for (int i = 0; i < tree.getChildCount (); i += 1)
<     {
< 	printTree ((ParseTree )tree.getChild (i), outputStream, indent + "  ");
<     }
<     outputStream.println (indent + "</"+xml_node_name+">");
< }
< 
< public static void main (String[]args) throws Exception
< {
<     ANTLRFileStream input = new ANTLRFileStream (args[0]);
<     LuaLexer lexer = new LuaLexer (input);
<     CommonTokenStream tokens = new CommonTokenStream (lexer);
< 
<     ParseTreeBuilder builder = new ParseTreeBuilder("chunk");
<     
<     LuaParser parser = new LuaParser (tokens, builder);
< 
<     parser.chunk();
<     ParseTree tree = builder.getTree();
<     
<     PrintWriter outputStream =
< 	new PrintWriter (new FileWriter (args[1], false));
<     outputStream.println ("<?xml version=\"1.0\" ?>");
<     printTree (tree, outputStream, "");
<     outputStream.close ();
< }
< }
Binary files code-worker/tasks/clonedigger/lua_antlr/TreeProducer.jar and code-worker/code-worker/tasks/clonedigger/lua_antlr/TreeProducer.jar differ
diff -r -N code-worker/tasks/clonedigger/lua_antlr/TreeProducer.java code-worker/code-worker/tasks/clonedigger/lua_antlr/TreeProducer.java
1,128d0
< /*  Copyright 2008 Peter Bulychev
<  *
<  *  This file is part of Clone Digger.
<  *
<  *  Clone Digger is free software: you can redistribute it and/or modify
<  *  it under the terms of the GNU General Public License as published by
<  *  the Free Software Foundation, either version 3 of the License, or
<  *  (at your option) any later version.
<  *
<  *  Clone Digger is distributed in the hope that it will be useful,
<  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
<  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<  *  GNU General Public License for more details.
<  *
<  *  You should have received a copy of the GNU General Public License
<  *  along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
<  */
< import org.antlr.runtime.*;
< import org.antlr.stringtemplate.*;
< import org.antlr.runtime.tree.*;
< 
< import org.antlr.runtime.tree.ParseTree;
< 
< import org.antlr.runtime.*;
< import org.antlr.runtime.tree.*;
< import org.antlr.runtime.debug.*;
< 
< import java.lang.reflect.*;
< import java.io.*;
< import java.util.*;
< import java.text.*;
< import java.lang.*;
< 
< 
< 
< public class TreeProducer
< {
<     public TreeProducer ()
<     {
< 	super ();
<     }
< 
<     /*
<      * forXml function was taken from http://www.javapractices.com/topic/TopicAction.do?Id=96
<      * the license is: http://creativecommons.org/licenses/by/3.0/
<      */
<     public static String forXML (String aText)
<     {
< 	final StringBuilder result = new StringBuilder ();
< 	final StringCharacterIterator iterator =
< 	    new StringCharacterIterator (aText);
< 	char character = iterator.current ();
< 	while (character != CharacterIterator.DONE)
< 	{
< 	    if (character == '<')
< 	    {
< 		result.append ("&lt;");
< 	    }
< 	    else if (character == '>')
< 	    {
< 		result.append ("&gt;");
< 	    }
< 	    else if (character == '\"')
< 	    {
< 		result.append ("&quot;");
< 	    }
< 	    else if (character == '\'')
< 	    {
< 		result.append ("&#039;");
< 	    }
< 	    else if (character == '&')
< 	    {
< 		result.append ("&amp;");
< 	    }
< 	    else
< 	    {
< 		//the char is not a special one
< 		//        //add it to the result as is
< 		result.append (character);
< 	    }
< 	    character = iterator.next ();
< 	}
< 	return result.toString ();
<     }
<     //                                      }
< 
<     public static void printTree (ParseTree tree, PrintWriter outputStream,	String indent)
< {
< //    String xml_node_name = (tree.is_statement?"statement_node":"node");
<     String xml_node_name = "node";
<     int lineno;
<     if ( tree.payload instanceof Token ) {
< 	Token t = (Token)tree.payload;
< 	lineno = t.getLine();
<     } else {
< 	lineno = 0;
<     }
< 
<     outputStream.println (indent + "<" + xml_node_name + " name=\"" + forXML ("" + tree) + "\"" + 
< 	    " line_number=\"" + lineno + "\" " +
< 	    ">");
<     for (int i = 0; i < tree.getChildCount (); i += 1)
<     {
< 	printTree ((ParseTree )tree.getChild (i), outputStream, indent + "  ");
<     }
<     outputStream.println (indent + "</"+xml_node_name+">");
< }
< 
< public static void main (String[]args) throws Exception
< {
<     ANTLRFileStream input = new ANTLRFileStream (args[0]);
<     LuaLexer lexer = new LuaLexer (input);
<     CommonTokenStream tokens = new CommonTokenStream (lexer);
< 
<     ParseTreeBuilder builder = new ParseTreeBuilder("chunk");
<     
<     LuaParser parser = new LuaParser (tokens, builder);
< 
<     parser.chunk();
<     ParseTree tree = builder.getTree();
<     
<     PrintWriter outputStream =
< 	new PrintWriter (new FileWriter (args[1], false));
<     outputStream.println ("<?xml version=\"1.0\" ?>");
<     printTree (tree, outputStream, "");
<     outputStream.close ();
< }
< }
diff -r -N code-worker/tasks/clonedigger/lua_antlr.py code-worker/code-worker/tasks/clonedigger/lua_antlr.py
1,80d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>. 
< 
< import os
< import xml.parsers.expat
< 
< from abstract_syntax_tree import *
< 
< class LuaANTLRSourceFile (SourceFile):
<     extension = 'lua'
<     size_threshold = 5 
<     distance_threshold = 5
<     def __init__(self, file_name):
<         SourceFile.__init__(self, file_name)
<         class ExpatHandler:
<             def __init__(self, start_node, parent):
<                 self.parent = parent
<                 self.stack = [start_node]
<             def start_element(expat_self, xml_node_name, attrs):
<                 line_number = int(attrs["line_number"])-1
<                 line_numbers = [line_number]
<                 if line_numbers == [-1]:
<                     line_numbers = []
<                 name = attrs["name"]
<                 r = AbstractSyntaxTree(name, line_numbers, self)
<                 if name in ["stat", "chunk"]:
<                     r.markAsStatement()
<                 else:
<                     assert(xml_node_name == "node")
<                 expat_self.stack[-1].addChild(r)                
<                 expat_self.stack.append(r)
<             def end_element(self, name):
<                 self.stack.pop()
< 
<         tree_file_name  = 'temporary_ast.xml'
<         producer_class_path = os.path.join('.','lua_antlr', 'TreeProducer.jar')
<         antlr_class_path = os.path.join('.','antlr_runtime','antlr-runtime-3.1.jar')
<         if os.name in ['mac', 'posix']:
<             class_path_delimeter = ':'
<         elif os.name in ['nt', 'dos', 'ce']:
<             class_path_delimeter = ';'
<         else:
<             print 'unsupported OS'
<             assert(0)
< 
<         if os.system('java -classpath ' + producer_class_path + class_path_delimeter + antlr_class_path + ' TreeProducer %s %s 2>err.log'%(file_name, tree_file_name)):
<             f = open('err.log')
<             s = f.read()
<             f.close()
<             raise s
<         f = open('err.log')
<         s = f.read()
<         f.close()
<         if s:
<             print s
<         
<         self._tree = AbstractSyntaxTree('program')
<         handler = ExpatHandler(self._tree, self)
<         p = xml.parsers.expat.ParserCreate()
<         p.StartElementHandler = handler.start_element
<         p.EndElementHandler = handler.end_element
<         f = open(tree_file_name)
<         p.ParseFile(f)
<         f.close()
< #       os.remove(tree_file_name)
diff -r -N code-worker/tasks/clonedigger/python_compiler.py code-worker/code-worker/tasks/clonedigger/python_compiler.py
1,182d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import compiler
< import types
< import logilab.astng.nodes
< 
< from abstract_syntax_tree import *
< 
< class PythonNodeLeaf:
<     def __init__(self, val):
<         self._val = val
<     def getVal(self):
<         return self._val
<     def as_string(self):
<         return str(self.getVal())
<     def __str__(self):
<         return self.as_string()
< 
< class PythonCompilerSourceFile (SourceFile):
<     extension = 'py'
<     distance_threshold = 5
<     size_threshold = 5
<     ignored_statements = ['Import', 'From']
<     def __init__(self, file_name, func_prefixes = ()):
<         SourceFile.__init__(self, file_name)
<         self._func_prefixes = func_prefixes
<         def rec_build_tree(compiler_ast_node, is_statement=False):
<             def flatten(list):
<                 l = []
<                 for elt in list:
<                     t = type(elt)
<                     if t is tuple or t is list:
<                         for elt2 in flatten(elt):
<                             l.append(elt2)
<                     else:
<                         l.append(elt)
<                 return l
<             def add_childs(childs):             
<                 assert(type(childs) == type([]))
<                 for child in childs:                
<                     assert(isinstance(child, compiler.ast.Node))
<                     t = rec_build_tree(child, is_statement)     
<                     if t.getName() in self.ignored_statements:
<                         # TODO move it up
<                         continue
<                     t.setParent(r)
<                     r.addChild(t)                   
<             def add_leaf_child(child, name):
<                 assert(not (type(child) == type([])))
<                 assert(not isinstance(child, compiler.ast.Node))                                
<                 t = AbstractSyntaxTree(repr(child))
<                 t.setParent(r)
<                 l = PythonNodeLeaf(child)
<                 t.ast_node = l 
<                 r.addChild(t)               
<                 setattr(r.ast_node, name, l)
<                 return t
<             def add_leaf_childs(childs, name):
<                 assert(type(childs) == type([]) or type(childs) == type((0,)))
<                 a = getattr(r.ast_node, name)
<                 for i in range(len(childs)):
<                     child = childs[i]
<                     assert(not isinstance(child, compiler.ast.Node))
<                     t = AbstractSyntaxTree(repr(child))
<                     t.setParent(r)
<                     l = PythonNodeLeaf(child)
<                     t.ast_node = l 
<                     r.addChild(t)                   
<                     a[i] = l
<             def add_leaf_string_childs(childs):
<                 assert(type(childs) == type([]))
<                 for child in childs:
<                     assert(not isinstance(child, compiler.ast.Node))
<                     t = AbstractSyntaxTree(repr(child))
<                     t.setParent(t)
<                     r.addChild(t)                   
< 
<             if isinstance(compiler_ast_node, compiler.ast.Node):                
<                 name = compiler_ast_node.__class__.__name__
<                 if name == 'Function':
<                    for prefix in self._func_prefixes:
<                        if compiler_ast_node.name.startswith(prefix):
<                            # skip function that matches pattern
<                            return AbstractSyntaxTree('none')
<                 if name in ['Function', 'Class']:
<                     # ignoring class and function docs
<                     compiler_ast_node.doc = None
<                 if compiler_ast_node.lineno:
<                     lines = [compiler_ast_node.lineno-1]
<                 else:
<                     lines = []      
<                 r = AbstractSyntaxTree(name, lines, self)
<                 r.ast_node = compiler_ast_node
<                 if is_statement and compiler_ast_node.lineno: 
<                     r.markAsStatement()
<                 is_statement = (name == 'Stmt')
<                 if name == "AssAttr":
<                     add_childs([compiler_ast_node.expr])
<                     add_leaf_child(compiler_ast_node.attrname, 'attrname')
<                     add_leaf_string_childs([compiler_ast_node.flags])
<                 elif name == "AssName":
<                     add_leaf_child(compiler_ast_node.name, 'name')
< #                   add_leaf_child(compiler_ast_node.flags, 'flags')
<                 elif name == "AugAssign":
<                     add_childs([compiler_ast_node.node])
<                     add_leaf_child(compiler_ast_node.op, 'op')
<                     add_childs([compiler_ast_node.expr])
<                 elif name == "Class":
<                     add_leaf_child(compiler_ast_node.name, 'name')
< #                   print '>>>>>>>>>>>>>>>>>>>>', flatten(compiler_ast_node.bases)
<                     add_childs(flatten(compiler_ast_node.bases)) 
< #                   add_leaf_child(compiler_ast_node.doc, 'doc') we don't want class docs in our tree, do we?
<                     add_childs([compiler_ast_node.code])
<                 elif name == "Compare":
<                     add_childs([compiler_ast_node.expr])
<                     for i in range(len(compiler_ast_node.ops)):
<                         (op, expr) = compiler_ast_node.ops[i]
<                         t = add_leaf_child(op, 'op')
<                         add_childs([expr])
<                         compiler_ast_node.ops[i] = (t.ast_node, expr)
<                 elif name == "Const":
<                     add_leaf_child(repr(compiler_ast_node.value), "value")
< #               elif name == "From":
< #                   add_leaf_child(compiler_ast_node.modname, "modname")
< #                   add_childs(compiler_ast_node.names)
<                 elif name == "Function":
< #                   add_childs(compiler_ast_node.decorators)  FIXME do we need that?
<                     add_leaf_child(compiler_ast_node.name, "name")
<                     add_leaf_childs(compiler_ast_node.argnames, "argnames")
<                     if compiler_ast_node.defaults == ():
<                         compiler_ast_node.defaults = []
<                     add_childs(compiler_ast_node.defaults) #TODO incomment and fix
<                     add_leaf_string_childs([compiler_ast_node.flags])
< #                   add_leaf_child(compiler_ast_node.doc, "doc") same as class docs... we don't need them
<                     add_childs([compiler_ast_node.code])
<                 elif name == "Getattr":
<                     add_childs([compiler_ast_node.expr])
<                     add_leaf_child(compiler_ast_node.attrname, "attrname")
<                 elif name == "Global":
<                     add_leaf_childs(compiler_ast_node.names, "names")
< #               elif name == "Import":
< #                   add_leaf_childs(compiler_ast_node.names, "names")
<                 elif name == "Keyword":
<                     add_leaf_child(compiler_ast_node.name, "name")
<                     add_childs([compiler_ast_node.expr])
<                 elif name == "Lambda": 
< #                   TODO: uncomment and fix
<                     add_leaf_childs(compiler_ast_node.argnames, "argnames")                    
<                     if compiler_ast_node.defaults == ():
<                         compiler_ast_node.defaults = []
<                     add_childs(compiler_ast_node.defaults)              
<                     add_childs([compiler_ast_node.code])
<                 elif name == "Name":
<                     # the most important one :)
<                     add_leaf_child(compiler_ast_node.name, "name")
<                 else:
<                     for c in compiler_ast_node.getChildren():               
<                         t = rec_build_tree(c, is_statement)
<                         if t.getName() in self.ignored_statements:
<                             continue                    
<                         t.setParent(r)
<                         r.addChild(t)
<                 return r
<             else:
<                 return AbstractSyntaxTree(repr(compiler_ast_node))
<         self._setTree(rec_build_tree(compiler.parseFile(file_name)))
diff -r -N code-worker/tasks/clonedigger/README.txt code-worker/code-worker/tasks/clonedigger/README.txt
1,26d0
< ===================
< Clone Digger README
< ===================
< 
< available at http://clonedigger.sourceforge.net
< 
< Clone Digger is the tool for finding software clones. 
< Currently only Python language is supported, Java support will be added soon.
< See the site for details.
< 
< Usage
< =====
< 
< The simplest way of running Clone Digger is::
< 
<     clonedigger source_file_1 source_file_2 ...
< 
< Or::
< 
<     clonedigger --recursive path_to_source_tree
< 
< Don't forget to remove automatically generated sources, tests and third party libraries from the source tree.
< 
< See http://clonedigger.sourceforge.net/documentation.html for more complex arguments.
< 
< The available arguments can be obtained using '--help' also.
diff -r -N code-worker/tasks/clonedigger/suffix_tree.py code-worker/code-worker/tasks/clonedigger/suffix_tree.py
1,119d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< 
< class SuffixTree:    
<     class StringPosition:
<         def __init__(self, string, position,prevelem):
<             self.string = string
<             self.position = position
<             self.prevelem = prevelem
<     class SuffixTreeNode:
<         def __init__(self):
<             self.childs = {} #
<             self.string_positions = []
<             self.ending_strings = []
< 
<     def __init__(self, f_code):
<         self._node = self.SuffixTreeNode()
<         self._f_code = f_code
<     def _add(self, string, prevelem):
<         pos = 0
<         node = self._node
<         for pos in range(len(string)):
<             e = string[pos]
<             code = self._f_code(e)
<             node.string_positions.append(self.StringPosition(string, pos, prevelem))
<             if not node.childs.has_key(code):
<                 node.childs[code] = self.SuffixTreeNode()
<             node = node.childs[code]
<         node.ending_strings.append(self.StringPosition(string, pos+1, prevelem))
<     def add(self, string):
<         for i in range(len(string)):
<             if i == 0:
<                 prevelem = None
<             else:
<                 prevelem = self._f_code(string[i-1])
<             self._add(string[i:],prevelem)
<     def getBestMaxSubstrings(self, threshold, f, f_elem, node = None, initial_threshold=None):  
<         if initial_threshold==None:
<             initial_threshold = threshold
<         def check_left_diverse_and_add(s1, s2, p):
<             if ((s1.prevelem == None) or (s2.prevelem == None) or (s1.prevelem != s2.prevelem)) and s1.position>p:
<                 candidate = (s1.string[:s1.position-p], s2.string[:s2.position-p])
<                 if f_elem(candidate[0]) >= initial_threshold or \
<                     f_elem(candidate[1]) >= initial_threshold:
<                     r.append(candidate)
<                 return True
<             else:
<                 return False
<         if node == None:
<             node = self._node
<         r = []  
<         if threshold <= 0:          
<             for s1 in node.ending_strings:
<                 for s2 in node.string_positions:
<                     if s1.string == s2.string:
<                         continue
<                     check_left_diverse_and_add(s1, s2, 0)
<             for i in range(len(node.ending_strings)):
<                 for j in range(i):
<                     s1 = node.ending_strings[i]
<                     s2 = node.ending_strings[j]
<                     check_left_diverse_and_add(s1, s2, 0)
<             for i in range(len(node.childs.keys())):
<                 for j in range(i):
<                     c1 = node.childs.keys()[i]
<                     c2 = node.childs.keys()[j]
<                     for s1 in node.childs[c1].string_positions + node.childs[c1].ending_strings:
<                         for s2 in node.childs[c2].string_positions + node.childs[c2].ending_strings:
<                             check_left_diverse_and_add(s1, s2, 1)
<         for (code, child) in node.childs.items():
<             r += self.getBestMaxSubstrings(threshold - f(code), f, f_elem, child, initial_threshold)
<         return r
< 
< if __name__ == '__main__':
<     class Elem:
<         def __init__(self, code):
<             self._code = code
<         def getCode(self):
<             return self._code
<         def __str__(self):
<             return str(self._code)
<     def test1():
<         t = SuffixTree()
<         for w in ['abcPeter', 'Pet1erbca', 'Peter', 'aPet0--']:
<             t.add([Elem(c) for c in w])
<         maxs =  t.getBestMaxSubstrings(3)
<         l =  []
<         for (s1, s2) in maxs:
<             l.append([''.join([str(e) for e in s1]), ''.join([str(e) for e in s2])])
<         assert(l == [['Pe1t', 'P2et'], ['P3et', 'Pe4t'], ['Pet', 'Pet'], ['Pet', 'Pet'], ['Pet', 'Pet'], ['Peter', 'Peter']])
<     def test2():
<         t = SuffixTree()
<         for w in ['a', 'aa']:
<             t.add([Elem(c) for c in w])
<         maxs =  t.getBestMaxSubstrings(0)
<         l =  []
<         for (s1, s2) in maxs:       
<             l.append([''.join([str(e) for e in s1]), ''.join([str(e) for e in s2])])
<         assert(l == [['a', 'a'], ['a', 'a'], ['a', 'a']]) 
<     for s in dir():
<         if s.find('test') == 0:
<             eval(s + '()')
< 
diff -r -N code-worker/tasks/clonedigger/.svn/all-wcprops code-worker/code-worker/tasks/clonedigger/.svn/all-wcprops
1,95d0
< K 25
< svn:wc:ra_dav:version-url
< V 51
< /svnroot/clonedigger/!svn/ver/211/trunk/clonedigger
< END
< abstract_syntax_tree.py
< K 25
< svn:wc:ra_dav:version-url
< V 75
< /svnroot/clonedigger/!svn/ver/211/trunk/clonedigger/abstract_syntax_tree.py
< END
< ast_suppliers.py
< K 25
< svn:wc:ra_dav:version-url
< V 68
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/ast_suppliers.py
< END
< html_report.py
< K 25
< svn:wc:ra_dav:version-url
< V 66
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/html_report.py
< END
< __init__.py
< K 25
< svn:wc:ra_dav:version-url
< V 62
< /svnroot/clonedigger/!svn/ver/62/trunk/clonedigger/__init__.py
< END
< clone_detection_algorithm.py
< K 25
< svn:wc:ra_dav:version-url
< V 80
< /svnroot/clonedigger/!svn/ver/197/trunk/clonedigger/clone_detection_algorithm.py
< END
< arguments.py
< K 25
< svn:wc:ra_dav:version-url
< V 64
< /svnroot/clonedigger/!svn/ver/173/trunk/clonedigger/arguments.py
< END
< LICENSE.txt
< K 25
< svn:wc:ra_dav:version-url
< V 62
< /svnroot/clonedigger/!svn/ver/53/trunk/clonedigger/LICENSE.txt
< END
< python_compiler.py
< K 25
< svn:wc:ra_dav:version-url
< V 70
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/python_compiler.py
< END
< js_antlr.py
< K 25
< svn:wc:ra_dav:version-url
< V 63
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/js_antlr.py
< END
< java_antlr.py
< K 25
< svn:wc:ra_dav:version-url
< V 65
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/java_antlr.py
< END
< lua_antlr.py
< K 25
< svn:wc:ra_dav:version-url
< V 64
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/lua_antlr.py
< END
< clonedigger.py
< K 25
< svn:wc:ra_dav:version-url
< V 66
< /svnroot/clonedigger/!svn/ver/209/trunk/clonedigger/clonedigger.py
< END
< suffix_tree.py
< K 25
< svn:wc:ra_dav:version-url
< V 66
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/suffix_tree.py
< END
< anti_unification.py
< K 25
< svn:wc:ra_dav:version-url
< V 71
< /svnroot/clonedigger/!svn/ver/210/trunk/clonedigger/anti_unification.py
< END
< README.txt
< K 25
< svn:wc:ra_dav:version-url
< V 61
< /svnroot/clonedigger/!svn/ver/69/trunk/clonedigger/README.txt
< END
diff -r -N code-worker/tasks/clonedigger/.svn/entries code-worker/code-worker/tasks/clonedigger/.svn/entries
1,553d0
< 10
< 
< dir
< 211
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger/trunk/clonedigger
< https://clonedigger.svn.sourceforge.net/svnroot/clonedigger
< 
< 
< 
< 2011-07-03T21:32:14.070856Z
< 211
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 7cf15c16-0848-0410-9509-a110975daa34
< 
< abstract_syntax_tree.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< b15dc5a276352fe5860e5505d9062939
< 2011-07-03T21:32:14.070856Z
< 211
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 10817
< 
< java_antlr
< dir
< 
< lua_antlr
< dir
< 
< antlr_runtime
< dir
< 
< ast_suppliers.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 6841e87d9c3a89a3fa1e35728ea2295c
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 1298
< 
< html_report.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 865886d7ac254b1fb9117d8b911ac310
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 16252
< 
< __init__.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< d41d8cd98f00b204e9800998ecf8427e
< 2008-07-01T07:49:26.140688Z
< 62
< tarek-ziade
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 0
< 
< clone_detection_algorithm.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 1776b327c134598ffab81617f15d0502
< 2009-02-15T16:20:42.829460Z
< 197
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 15663
< 
< arguments.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< cb562b90c7e67db99ac2acad3ed5c7e2
< 2008-08-22T11:11:02.402623Z
< 173
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 180
< 
< LICENSE.txt
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< d32239bcb673463ab874e80d47fae504
< 2008-06-20T20:28:54.564896Z
< 52
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 35147
< 
< python_compiler.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 7192ff315ddbe8fd1eb9559213feec44
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 8825
< 
< js_antlr.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 0ba1b33ee1036e8d92136d3748f5de07
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3119
< 
< lua_antlr.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 251e1d5109c1a05c204c0a66c3094fb0
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 3078
< 
< java_antlr.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 1c6c5c3f8ce4ba53282f94118d37718c
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 2992
< 
< logilab
< dir
< 
< clonedigger.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 8d3811af6c8139a9cfdf83af56d21d73
< 2009-12-02T08:39:33.418673Z
< 209
< peter_bulychev
< has-props
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 9109
< 
< anti_unification.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 379ebbc6b3454173cdfe498c60e9b086
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 5819
< 
< suffix_tree.py
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< 67ae00de0824ea926e6088c808372c33
< 2010-02-08T06:35:14.397690Z
< 210
< peter_bulychev
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 4949
< 
< README.txt
< file
< 
< 
< 
< 
< 2011-07-05T05:47:59.000000Z
< e659d174e51143251fd5d001aa40134b
< 2008-07-08T09:02:27.229368Z
< 69
< zzaabb
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 693
< 
< js_antlr
< dir
< 
diff -r -N code-worker/tasks/clonedigger/.svn/prop-base/clonedigger.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/prop-base/clonedigger.py.svn-base
1,5d0
< K 14
< svn:executable
< V 0
< 
< END
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/abstract_syntax_tree.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/abstract_syntax_tree.py.svn-base
1,307d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import types
< 
< import arguments
< 
< free_variable_cost = 0.5
< 
< class ParseError:    
<     def __init__(self, descr):
<         self._descr = descr
<     def __str__(self):
<         return self._descr
< 
< class SourceFile:        
<     size_threshold = 5
<     distance_threshold = 5
<     def __init__(self, file_name):      
<         f = open(file_name, 'r')
<         def filter_func(s):
<             for i in range(len(s)-1, -2, -1):
<                 if i<0 or not s[i].isspace():
<                     break
<             if i>=0:
<                 return s[:i+1]
<             else:
<                 return s
<         self._source_lines = [filter_func(s) for s in f.readlines()]
<         f.close()
<         self._file_name = file_name
<     def getSourceLine(self, n):
< #       if n >= len(self._source_lines):
< #           return ''
< #TODO
< #error here
<         return self._source_lines[n] 
<     def _setTree(self, tree):
<         self._tree = tree
<     def getTree(self):
<         return self._tree
<     def getFileName(self):
<         return self._file_name
< 
< class AbstractSyntaxTree:
<     def __init__(self, name=None, line_numbers=[], source_file=None):
<         self._childs = []
<         self._line_numbers= line_numbers
<         self._covered_line_numbers = None
<         self._parent = None
<         self._hash = None
<         self._source_file = source_file
<         self._is_statement = False
<         if name != None:
<             self.setName(name)
<     def getSourceFile(self):
<         return self._source_file
<     def setMark(self, mark):
<         self._mark = mark 
<     def getMark(self):
<         return self._mark
<     def markAsStatement(self, val=True):
<         self._is_statement = val
<     def isStatement(self):
<         return self._is_statement
<     def setName(self, name):
<         self._name = name
<     def getLineNumbers(self):
<         return self._line_numbers   
<     def getCoveredLineNumbers(self):
<         return self._covered_line_numbers
<     def getParent(self):
<         return self._parent
<     def setParent(self, parent):
<         self._parent = parent
<     def getAncestors(self):
<         r = []
<         t = self.getParent()    
<         while t:
<             if t.isStatement():
<                 r.append(t)
<             t = t.getParent()
<         return r
<     def getSourceLines(self):
<         source_line_numbers = set([])
<         r = []  
<         source_line_numbers = self.getCoveredLineNumbers()
<         source_line_numbers_list = list(range(min(source_line_numbers), max(source_line_numbers)+1))
<         source_line_numbers_list.sort()
<         for source_line_number in source_line_numbers_list:
<             r.append(self.getSourceFile().getSourceLine(source_line_number) ) 
<         return r
<     def getName(self):
<         return self._name
<     def getChilds(self):
<         return self._childs
<     def getChildCount(self):
<         return len(self._childs)
<     def propagateCoveredLineNumbers(self):
<         self._covered_line_numbers = set(self._line_numbers)
<         for child in self.getChilds():
<             self._covered_line_numbers.update(child.propagateCoveredLineNumbers())
<         return self._covered_line_numbers
<     def propagateHeight(self):
<         if self.getChildCount()==0:
<             self._height = 0
<         else:
<             self._height = max([c.propagateHeight() for c in self.getChilds()])+1
<         return self._height
<     def getHeight(self):
<         return self._height
<     def addChild(self, child, save_parent = False):
<         if not save_parent:
<             child.setParent(self)
<         self._childs.append(child)
<     def setChildCount(self, count):
<         assert(not self._childs)
<         self._childs = count * [None]
<     def setNextUndefinedChild(self, c):
<         for i in range(len(self.getChilds())):
<             if self.getChilds()[i] == None:
<                 self._childs[i] = c
<         assert()
<     def __str__(self):
<         return ' ( ' + self.getName() + ' '.join([str(child) for child in self.getChilds()]) + ' ) '
<     def getFullHash(self):
<         return self.getDCupHash(-1) 
<     def getDCupHash(self, level):
<         if len(self._childs) == 0:
<             ret = 0 # in case of names and constants
<         else:
<             ret = (level+1) * hash(self._name) * len(self._childs)
<         # if level == -1, it will not stop until it reaches the leaves 
<         if level != 0:
<             for i in range(len(self._childs)):
<                 child = self._childs[i]
<                 ret += (i+1)*child.getDCupHash(level-1)
<         return hash(ret)
<     def __hash__(self):
<         #TODO check correctness
<         if not self._hash:
<             self._hash =  hash(self.getDCupHash(3) + hash(self.getName()))
<         return self._hash
< #       return  hash(self.getDCupHash(3) + hash(self.getName()))
<  
<     def __eq__(self, tree2):
<         tree1 = self
<         if type(tree2) == types.NoneType:
<             return False
<         if tree1.getName() != tree2.getName():
<             return False
<         if tree1.getChildCount() != tree2.getChildCount():
<             return False
<         for i in range(tree1.getChildCount()):
<             if tree1.getChilds()[i] != tree2.getChilds()[i]:
<                 return False
<         return True
<     def getAllStatementSequences(self):
<         r = []
<         current = StatementSequence()
<         for child in self.getChilds():
<             if child.isStatement():
<                 current.addStatement(child)
<             else:
<                 if (not current.isEmpty()) and len(current.getCoveredLineNumbers())>=arguments.size_threshold:
<                     r.append(current)
<                     current = StatementSequence() 
<             r.extend(child.getAllStatementSequences())
<         if (not current.isEmpty()) and len(current.getCoveredLineNumbers())>=arguments.size_threshold:
<             r.append(current)
<         return r
<     def storeSize(self):
<         observed = set()
<         self._none_count = 0
<         def rec_calc_size(t):
<             r = 0
<             if not t in observed:
<                 if t.getChildCount():
<                     for c in t.getChilds():
<                         r += rec_calc_size(c)
<                 else:
<                     observed.add(t)
<                     if t.getName()=='None':
<                         self._none_count += 1
<                     if t.__class__.__name__ == 'FreeVariable':
<                         r+= free_variable_cost
<                     else:
<                         r+= 1
<             return r
<         if not hasattr(self, '_size'):
<             self._size = rec_calc_size(self)
<     def getSize(self, ignore_none = True):
<         ret = self._size
<         if ignore_none:
<             ret -= self._none_count
<         return ret    
<     def getTokenCount(self):
<         def rec_calc_size(t):
< 	    if t.getChildCount():
< 		if t.getName() in ['Add', 'Assign', 'Sub', 'Div', 'Mul', 'Mod', 'Function', 'If', 'Class', 'Raise']:
< 	            r = 1
< 		else:
< 	            r = 0
< 		for c in t.getChilds():
< 	            r += rec_calc_size(c)
< 	    else:
< 	        if t.getName()[0] != "'" and t.getName() != 'Pass':
< 		   return 0
< 		else:
< 		   return 1
<             return r
<         return rec_calc_size(self)
< 
< class StatementSequence:
<     def __init__(self, sequence = []):
<         self._sequence = []
<         self._source_file = None
<         for s in sequence:
<             self.addStatement(s)
<     def getCoveredLineNumbers(self):
<         r = set()
<         for s in self:
<             r.update(s.getCoveredLineNumbers())
<         return r
<     def getAncestors(self):
<         return self[0].getAncestors()
<     def isEmpty(self):
<         return (self._sequence == [])
<     def addStatement(self, statement):
<         self._sequence.append(statement)
<         if self._source_file == None:
<             self._source_file = statement.getSourceFile()
<         else:
<             assert(self._source_file == statement.getSourceFile())
<     def __getitem__(self, *args):
<         return self._sequence.__getitem__(*args)
<     def __len__(self):
<         return self._sequence.__len__()
<     def __str__(self):
<         return ','.join([str(s) for s in self])
<     def getWeight(self):
<         return sum([s.getCluster().getUnifierSize() for s in self._sequence])
<     def getSourceFile(self):
<         return self._source_file
<     def getSourceLines(self):
<         source_line_numbers = set([])
<         r = []
<         for statement in self:
<             r.extend(statement.getSourceLines())
<         return r
<     def getLineNumbers(self):
<         r = []
<         for statement in self:
<             r.extend(statement.getLineNumbers())
<         return r
<     def getLineNumberHashables(self):   
<         source_file_name = self.getSourceFile().getFileName()
<         line_numbers = self.getCoveredLineNumbers()
<         return set([(source_file_name, line_number) for line_number in line_numbers])
<     def constructTree(self):
<         tree = AbstractSyntaxTree('__SEQUENCE__')
<         for statement in self:
<             tree.addChild(statement, True)
<         return tree    
<     def getLength(self):
<         return len(self)
<     def getCoveredLineNumbersCount(self):
<         covered = set()
<         for t in self:
<             covered.update(t.getCoveredLineNumbers())
<         return len(covered)
< 
< class PairSequences:
<     def __init__(self, sequences):
<         self._sequences = sequences
<     def __getitem__(self, *args):
<         return self._sequences.__getitem__(*args)
<     def __str__(self):
<         return ';\t'.join([str(s) for s in self])
<     def getWeight(self):
<         assert(self[0].getWeight() == self[1].getWeight())
<         return self[0].getWeight()
<     def calcDistance(self):
<         import anti_unification
<         trees = [s.constructTree() for s in self]
<         unifier = anti_unification.Unifier(trees[0], trees[1])
<         return unifier.getSize()
<     def subSequence(self, first, length):
<         return PairSequences([StatementSequence(self[0][first:first+length]), StatementSequence(self[1][first:first+length])])
<     def getLength(self):
<         return self[0].getLength()
<     def getMaxCoveredLineNumbersCount(self):
<         return min([s.getCoveredLineNumbersCount() for s in self])
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/anti_unification.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/anti_unification.py.svn-base
1,150d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import copy
< import sys
< 
< from abstract_syntax_tree import *
< import suffix_tree
< import arguments
< 
< # NOTE that everywhere is written Unifier instead of AntiUnifier, for simplicity
< 
< # Constants here
< verbose = True 
< 
< class FreeVariable(AbstractSyntaxTree):
<     free_variables_count = 1
<     def __init__(self):
<         global free_variables_count
<         FreeVariable.free_variables_count += 1
<         name =  'VAR(%d)'%(FreeVariable.free_variables_count, )
< #       self._childs = []
<         AbstractSyntaxTree.__init__(self, name)
< 
< class Substitution:
<     def __init__(self, initial_value = None):
<         if initial_value == None:
<             initial_value = {}
<         self._map = initial_value
<     def substitute(self, tree, without_copying=False):  
<         if tree in self._map.keys():
<             return self._map[tree]
<         else:
<             if isinstance(tree, FreeVariable):
<                 return tree 
<             if without_copying:
<                 return tree
<             else:
<                 r = AbstractSyntaxTree(tree.getName())
<                 for child in tree.getChilds():
<                     r.addChild(self.substitute(child, without_copying))
<                 return r
< 
<     def getMap(self):
<         return self._map
<     def getSize(self):
<         ret = 0
<         for (u, tree) in self.getMap().items():
<             ret += tree.getSize(False) - free_variable_cost
<         return ret
< 
< class Unifier:
<     def __init__(self, t1, t2, ignore_parametrization=False):
<         def combineSubs(node, s, t):
<             # s and t are 2-tuples
<             assert(s[0].getMap().keys() == s[1].getMap().keys())
<             assert(t[0].getMap().keys() == t[1].getMap().keys())
<             newt = (copy.copy(t[0]), copy.copy(t[1]))
<             relabel = {}
<             for si in s[0].getMap().keys():
<                 if not ignore_parametrization:
<                     foundone = False
<                     for ti in t[0].getMap().keys():
<                         if (s[0].getMap()[si] == t[0].getMap()[ti]) and (s[1].getMap()[si] == t[1].getMap()[ti]): 
<                             relabel[si] = ti
<                             foundone = True
<                             break
<                 if ignore_parametrization or not foundone:
<                     newt[0].getMap()[si] = s[0].getMap()[si]
<                     newt[1].getMap()[si] = s[1].getMap()[si]
<             return (Substitution(relabel).substitute(node), newt)
<         def unify(node1, node2):
<             if node1 == node2:
<                 return (node1, (Substitution(), Substitution()))
<             elif (node1.getName() != node2.getName()) or (node1.getChildCount() != node2.getChildCount()):
<                 var = FreeVariable()
<                 return (var, (Substitution({var:node1}), Substitution({var:node2})))
<             else:
<                 s = (Substitution(), Substitution())
<                 name = node1.getName()
<                 retNode = AbstractSyntaxTree(name) 
<                 count = node1.getChildCount()
<                 for i in range(count):              
<                     (ai, si) = unify(node1.getChilds()[i], node2.getChilds()[i])
<                     (ai, s) = combineSubs(ai, si, s)
<                     retNode.addChild(ai)
<                 return (retNode, s)
<         (self._unifier, self._substitutions) = unify(t1, t2)
<         self._unifier.storeSize()
<         for i in (0,1):
<             for key in self._substitutions[i].getMap():
<                 self._substitutions[i].getMap()[key].storeSize()
<     def getSubstitutions(self):
<         return self._substitutions
<     def getUnifier(self):
<         return self._unifier
<     def getSize(self):
<         return sum([s.getSize() for s in self.getSubstitutions()])
< 
< class Cluster:
<     count = 0
<     def __init__(self, tree=None):
<         if tree:
<             self._n = 1
<             self._unifier_tree = tree
<             self._trees = [tree]
<             self._max_covered_lines = len(tree.getCoveredLineNumbers())
<         else:
<             self._n = 0
<             self._trees = []
<             self._max_covered_lines = 0
<         Cluster.count += 1
<         self._cluster_number = Cluster.count    
<     def getUnifierTree(self):
<         return self._unifier_tree
<     def getCount(self):
<         return self._n
<     def getAddCost(self, tree):
<         unifier = Unifier(self.getUnifierTree(), tree)
<         return (self.getCount()* unifier.getSubstitutions()[0].getSize() + unifier.getSubstitutions()[1].getSize())
<     def unify(self, tree):
<         self._n += 1
<         self._unifier_tree = Unifier(self.getUnifierTree(), tree).getUnifier()
<         self._trees.append(tree)
<     def eraseAllTrees(self):
<         self._n = 0
<         self._trees = []
<     def addWithoutUnification(self, tree):
<         self._n += 1
<         self._trees.append(tree)
<         if len(tree.getCoveredLineNumbers())>self._max_covered_lines:
<             self._max_covered_lines = len(tree.getCoveredLineNumbers())
<     def getMaxCoveredLines(self):
<         return self._max_covered_lines
<     def getUnifierSize(self):
<         return self.getUnifierTree().getSize()
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/arguments.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/arguments.py.svn-base
1,8d0
< clustering_threshold = 10
< hashing_depth = 1
< clusterize_using_dcup = False
< report_unifiers = False
< print_time = True
< force = False  
< use_diff = False 
< clusterize_using_hash = False
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/ast_suppliers.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/ast_suppliers.py.svn-base
1,33d0
< #    Copyright 2008 Peter Bulychev
< #        http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< # Abstract Syntax Tree suppliers
< abstract_syntax_tree_suppliers = {}
< 
< import python_compiler
< abstract_syntax_tree_suppliers['python'] = python_compiler.PythonCompilerSourceFile
< 
< import java_antlr
< abstract_syntax_tree_suppliers['java'] = java_antlr.JavaANTLRSourceFile
< 
< import lua_antlr
< abstract_syntax_tree_suppliers['lua'] = lua_antlr.LuaANTLRSourceFile
< 
< import js_antlr
< abstract_syntax_tree_suppliers['javascript'] = js_antlr.JsANTLRSourceFile
< abstract_syntax_tree_suppliers['js'] = js_antlr.JsANTLRSourceFile
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/clone_detection_algorithm.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/clone_detection_algorithm.py.svn-base
1,361d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import sys
< 
< from anti_unification import *
< from abstract_syntax_tree import *
< 
< def findDuplicateCode(source_files, report):
<     statement_sequences = []
<     statement_count = 0
<     sequences_lengths = []
<     for source_file in source_files:
<         sequences = source_file.getTree().getAllStatementSequences()
<         statement_sequences.extend(sequences)
<         sequences_lengths.extend([len(s) for s in sequences])
<         statement_count += sum([len(s) for s in sequences])
< 
<     if not sequences_lengths:
<         print 'Input is empty or the size of the input is below the size threshold'
<         sys.exit(0)
< 
<     if verbose:
<         n_sequences = len(sequences_lengths)    
<         avg_seq_length = sum(sequences_lengths)/float(n_sequences)
<         max_seq_length = max(sequences_lengths)
< 
<         print '%d sequences' %(n_sequences,)
<         print 'average sequence length: %f' % (avg_seq_length,)
<         print 'maximum sequence length: %d' % (max_seq_length,)
<         sequences_without_restriction = statement_sequences
<         sequences = []
<         if not arguments.force:
<             for sequence in sequences_without_restriction:
<                 if len(sequence) > 1000:
<                     first_statement = sequence[0]
<                     print
<                     print '-----------------------------------------'
<                     print 'Warning: sequences of statements, consists of %d elements is too long.' %(len(sequence),)
<                     print 'It starts at %s:%d.'%(first_statement.getSourceFile().getFileName(), min(first_statement.getCoveredLineNumbers()))
<                     print 'It will be ignored. Use --force to override this restriction.'
<                     print 'Please refer to http://clonedigger.sourceforge.net/documentation.html'
<                     print '-----------------------------------------'
<                 else:
<                     sequences.append(sequence)
<   
<     def calc_statement_sizes():
<         for sequence in statement_sequences:
<             for statement in sequence:
<                 statement.storeSize()
< 
<     def build_hash_to_statement(dcup_hash = True):
<         hash_to_statement = {}
<         for statement_sequence in statement_sequences:
<             for statement in statement_sequence:
<                 if dcup_hash:
<                     # 3 - CONSTANT HERE!
<                     h = statement.getDCupHash(arguments.hashing_depth)
<                 else:
<                     h = statement.getFullHash()
<                 if not hash_to_statement.has_key(h):
<                     hash_to_statement[h] = [statement]
<                 else:
<                     hash_to_statement[h].append(statement)                  
<         return hash_to_statement
<     def build_unifiers(hash_to_statement):
<         processed_statements_count = 0
<         clusters = []
<         ret = {}
<         for h in hash_to_statement.keys():
<             local_clusters = []
<             statements = hash_to_statement[h]
<             for statement in statements:
<                 processed_statements_count += 1
<                 if verbose and ((processed_statements_count % 1000) == 0):
<                     print '%d,' %(processed_statements_count,),
<                     sys.stdout.flush()
<                 bestcluster = None
<                 mincost = sys.maxint
<                 for cluster in local_clusters:
<                     cost = cluster.getAddCost(statement)
<                     if cost < mincost:
<                         mincost = cost
<                         bestcluster = cluster
<                 assert(local_clusters==[] or bestcluster)
<                 if mincost < 0:
<                     pdb.set_trace()
<                 assert(mincost >= 0)
<                 if bestcluster == None or mincost > arguments.clustering_threshold:
<                     newcluster = Cluster(statement)
<                     local_clusters.append(newcluster)
<                 else:
<                     bestcluster.unify(statement)                
<             ret[h] = local_clusters 
<             clusters.extend(local_clusters)
<         return ret
< 
<     def clusterize(hash_to_statement, clusters_map):
<         processed_statements_count = 0
<         # clusters_map contain hash values for statements, not unifiers
<         # therefore it will work correct even if unifiers are smaller than hashing depth value
<         for h in hash_to_statement.keys():
<             clusters = clusters_map[h]
<             for statement in hash_to_statement[h]:
<                 processed_statements_count += 1
<                 if verbose and ((processed_statements_count % 1000) == 0):
<                     print '%d,' %(processed_statements_count,),
<                     sys.stdout.flush()
<                 mincost = sys.maxint
<                 for cluster in clusters:
<                     new_u = Unifier(cluster.getUnifierTree(), statement)
< #                   assert(new_u.getSubstitutions()[0].getSize() == 0)
<                     cost = new_u.getSize()
<                     if cost < mincost:
<                         mincost = cost
<                         statement.setMark(cluster)
<                         cluster.addWithoutUnification(statement)
<     def filterOutLongEquallyLabeledSequences(statement_sequences):
<         #TODO - refactor, combine with the previous warning
<         sequences_without_restriction = statement_sequences
<         statement_sequences = []
<         for sequence in sequences_without_restriction:
<             new_sequence = copy.copy(sequence._sequence) 
<             current_mark = None
<             length = 0
<             first_statement_index = None
<             flag = False 
<             for i in range(len(sequence)):
<                 statement = sequence[i]
<                 if statement.getMark() != current_mark:
<                     if flag == True:
<                         flag = False 
<                     current_mark=statement.getMark()
<                     length=0
<                     first_statement_index = i
<                 else:
<                     length += 1
<                     if length>10:
<                         new_sequence[i] = None
<                         if not flag:
<                             for i in range(first_statement_index, i):
<                                 new_sequence[i] = None
<                             first_statement = sequence[first_statement_index]                        
<                             print
<                             print '-----------------------------------------'
<                             print 'Warning: sequence of statements starting at %s:%d'%(first_statement.getSourceFile().getFileName(), min(first_statement.getCoveredLineNumbers()))
<                             print 'consists of many similar statements.'
<                             print 'It will be ignored. Use --force to override this restriction.'
<                             print 'Please refer to http://clonedigger.sourceforge.net/documentation.html'
<                             print '-----------------------------------------'
<                             flag = True 
<             new_sequence = new_sequence + [None]
<             cur_sequence = StatementSequence() 
<             for statement in new_sequence:
<                 if statement == None:
<                     if cur_sequence:
<                         statement_sequences.append(cur_sequence)
<                         cur_sequence = StatementSequence() 
<                 else:
<                     cur_sequence.addStatement(statement)
<         return statement_sequences
< 
<     def mark_using_hash(hash_to_statement):     
<         for h in hash_to_statement:
<             cluster = Cluster()
<             for statement in hash_to_statement[h]:
<                 cluster.addWithoutUnification(statement)
<                 statement.setMark(cluster)              
<     def findHugeSequences():
<         def f_size(x):    
<             return x.getMaxCoveredLines()
<         def f_elem(x):
<             return StatementSequence(x).getCoveredLineNumbersCount()
<         def fcode(x):
<             return x.getMark()
<         f = f_size
<         suffix_tree_instance = suffix_tree.SuffixTree(fcode)
<         for sequence in statement_sequences:
<             suffix_tree_instance.add(sequence)
<         return [PairSequences([StatementSequence(s1), StatementSequence(s2)]) for (s1,s2) in suffix_tree_instance.getBestMaxSubstrings(arguments.size_threshold, f, f_elem)]
<     def refineDuplicates(pairs_sequences):
<         r = []
<         flag = False
<         while pairs_sequences:      
<             pair_sequences = pairs_sequences.pop()
<             def all_pairsubsequences_size_n_threshold(n):
<                 lr = []
<                 for first in range(0, pair_sequences.getLength()-n+1):
<                     new_pair_sequences = pair_sequences.subSequence(first, n)
<                     size = new_pair_sequences.getMaxCoveredLineNumbersCount()
<                     if size >= arguments.size_threshold:
<                         lr.append((new_pair_sequences, first))
<                 return lr
<             n = pair_sequences.getLength() + 1
<             while 1:
<                 n-=1
<                 if n == 0:
<                     break
<                 new_pairs_sequences = all_pairsubsequences_size_n_threshold(n)
<                 for (candidate_sequence, first) in new_pairs_sequences:             
<                     distance = candidate_sequence.calcDistance()
<                     if (distance < arguments.distance_threshold):
<                         r.append(candidate_sequence)
<                         if first > 0:
<                             pairs_sequences.append(pair_sequences.subSequence(0, first-1))
<                         if first+n < pair_sequences.getLength():
<                             pairs_sequences.append(pair_sequences.subSequence(first+n, pair_sequences.getLength() - first - n))
<                         n+=1
<                         flag = True
<                         break
<                 if flag:
<                     flag = False
<                     break
<         return r
<     def remove_dominated_clones(clones):
<         ret_clones = []
< #       def f_cmp(a, b):
< #           return a.getLevel().__cmp__(b.getLevel())
< #       clones.sort(f_cmp)
<         statement_to_clone = {}
<         for clone in clones:
<             for sequence in clone:
<                 for statement in sequence:
<                     if not statement_to_clone.has_key(statement):
<                         statement_to_clone[statement] = []
<                     statement_to_clone[statement].append(clone)
<         for clone in clones:
<             ancestors_2 = clone[1].getAncestors()
<             flag = True
<             for s1 in clone[0].getAncestors():
<                 if statement_to_clone.has_key(s1):
<                     for clone2 in statement_to_clone[s1]:
<                         if s1 in clone2[0]:
<                             seq = clone2[1]
<                         else:
<                             assert(s1 in clone2[1])
<                             seq = clone2[0]
<                         for s2 in seq:
<                             if s2 in ancestors_2:
<                                 flag = False
<                                 break
<                         if not flag:
<                             break
<                 if not flag:
<                     break
<             if flag:
<                 ret_clones.append(clone)
<         return ret_clones
< 
<     if verbose:
<         print 'Number of statements: ', statement_count
<         print 'Calculating size for each statement...',
<         sys.stdout.flush()
<     calc_statement_sizes() 
<     if verbose:
<         print 'done'
< 
<     if verbose:
<         print 'Building statement hash...',
<         sys.stdout.flush()
<     report.startTimer('Building statement hash')
<     if arguments.clusterize_using_hash:
<         hash_to_statement = build_hash_to_statement(dcup_hash = False)
<     else:
<         hash_to_statement = build_hash_to_statement(dcup_hash = True)
<     report.stopTimer()
<     if verbose:
<         print 'done'
<         print 'Number of different hash values: ', len(hash_to_statement)
<     
<     if arguments.clusterize_using_dcup or arguments.clusterize_using_hash:
<         print 'Marking each statement with its hash value'
<         mark_using_hash(hash_to_statement)
<     else:
<         if verbose:
<             print 'Building patterns...',
<             sys.stdout.flush()
<         report.startTimer('Building patterns')
<         clusters_map = build_unifiers(hash_to_statement)    
<         report.stopTimer()
<         if verbose:
<             print Cluster.count, 'patterns were discovered'
<             print 'Choosing pattern for each statement...',
<             sys.stdout.flush()
<         report.startTimer('Marking similar statements')
<         clusterize(hash_to_statement, clusters_map)
<         report.stopTimer()
<         if verbose:
<             print 'done'
< 
<     if arguments.report_unifiers:
<         if verbose:
<             print 'Building reverse hash for reporting ...',
<             sys.stdout.flush()
<         reverse_hash = {}
<         for sequence in statement_sequences:
<             for statement in sequence:
<                 mark = statement.getMark()
<                 if not reverse_hash.has_key(mark):
<                     reverse_hash[mark] = []
<                 reverse_hash[mark].append(statement)
<         report.setMarkToStatementHash(reverse_hash)
<         if verbose:
<             print 'done'
< 
<     if verbose:
<         print 'Finding similar sequences of statements...',
<         sys.stdout.flush()
<     
<     if not arguments.force:
<         statement_sequences = filterOutLongEquallyLabeledSequences(statement_sequences)
< 
<     report.startTimer('Finding similar sequences of statements')
<     duplicate_candidates = findHugeSequences()
<     report.stopTimer()
<     if verbose:
<         print len(duplicate_candidates), ' sequences were found'
<         print 'Refining candidates...',
<         sys.stdout.flush()    
<     if arguments.distance_threshold!=-1:
<         report.startTimer('Refining candidates')
<         clones = refineDuplicates(duplicate_candidates)
<         report.stopTimer()
<     else:
<         clones = duplicate_candidates
<     if verbose:
<         print len(clones), 'clones were found'
<     if arguments.distance_threshold!=-1:
<         if verbose:
<             print 'Removing dominated clones...',
<             sys.stdout.flush()
<         old_clone_count = len(clones)
<         clones = remove_dominated_clones(clones)
<         if verbose:
<             print len(clones) - old_clone_count, 'clones were removed' 
< 
<     covered_source_lines = set()
<     for clone in clones:
<         for sequence in clone:
<             covered_source_lines = covered_source_lines.union(sequence.getLineNumberHashables())
<     source_lines = set()
<     for sequence in statement_sequences:
<         source_lines = source_lines.union(sequence.getLineNumberHashables())
<     report.all_source_lines_count = len(source_lines)
<     report.covered_source_lines_count = len(covered_source_lines)
< 
<     return clones
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/clonedigger.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/clonedigger.py.svn-base
1,202d0
< #!/usr/bin/python
< 
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< import sys
< 
< if __name__ == '__main__':
<     sys.modules['clonedigger.logilab'] = __import__('logilab')
< 
< import re
< import os
< import traceback
< from optparse import OptionParser
< from fnmatch import fnmatch
< 
< import ast_suppliers
< import clone_detection_algorithm
< import arguments 
< import html_report
< 
< def main():
<     cmdline = OptionParser(usage="""To run Clone Digger type:
< python clonedigger.py [OPTION]... [SOURCE FILE OR DIRECTORY]...
< 
< The typical usage is:
< python clonedigger.py source_file_1 source_file_2 ...
<   or
< python clonedigger.py path_to_source_tree
< Don't forget to remove automatically generated sources, tests and third party libraries from the source tree.
< 
< Notice:
< The semantics of threshold options is discussed in the paper "Duplicate code detection using anti-unification", which can be downloaded from the site http://clonedigger.sourceforge.net . All arguments are optional. Supported options are: 
< """)
<     cmdline.add_option('-l', '--language', dest='language',
<                        type='choice', choices=['python', 'java', 'lua', 'javascript', 'js'],
<                        help='the programming language')
<     cmdline.add_option('--no-recursion', dest='no_recursion',
<                        action='store_true', 
<                        help='do not traverse directions recursively')    
<     cmdline.add_option('-o', '--output', dest='output',
<                        help='the name of the output file ("output.html" by default)')
<     cmdline.add_option('--clustering-threshold', 
<                        type='int', dest='clustering_threshold',
<                        help='read the paper for semantics')
<     cmdline.add_option('--distance-threshold', 
<                        type='int', dest='distance_threshold',
<                        help='the maximum amount of differences between pair of sequences in clone pair (5 by default). Larger value leads to larger amount of false positives')
<     cmdline.add_option('--hashing-depth', 
<                        type='int', dest='hashing_depth',
<                        help='default value if 1, read the paper for semantics. Computation can be speeded up by increasing this value (but some clones can be missed)')
<     cmdline.add_option('--size-threshold', 
<                        type='int', dest='size_threshold',
<                        help='the minimum clone size. The clone size for its turn is equal to the count of lines of code in its the largest fragment')
<     cmdline.add_option('--clusterize-using-dcup', 
<                        action='store_true', dest='clusterize_using_dcup',
<                        help='mark each statement with its D-cup value instead of the most similar pattern. This option together with --hashing-depth=0 make it possible to catch all considered clones (but it is slow and applicable only to small programs)')
<     cmdline.add_option('--dont-print-time', 
<                        action='store_false', dest='print_time',
<                        help='do not print time')
<     cmdline.add_option('-f', '--force', 
<                        action='store_true', dest='force',
<                        help='')
<     cmdline.add_option('--force-diff', 
<                        action='store_true', dest='use_diff',
<                        help='force highlighting of differences based on the diff algorithm')
<     cmdline.add_option('--fast', 
<                        action='store_true', dest='clusterize_using_hash',
<                        help='find only clones, which differ in variable and function names and constants')
<     cmdline.add_option('--ignore-dir', 
<                        action='append', dest='ignore_dirs',
<                        help='exclude directories from parsing')
<     cmdline.add_option('--eclipse-output', 
<                        dest='eclipse_output',
<                        help='for internal usage only')
<     cmdline.add_option('--cpd-output', 
<                        action='store_true', dest='cpd_output',
<                        help='output as PMD''s CPD''s XML format. If output file not defined, output.xml is generated')
<     cmdline.add_option('--report-unifiers', 
<                        action='store_true', dest='report_unifiers',
<                        help='')
<     cmdline.add_option('--func-prefixes',
<                       action='store',
<                        dest='f_prefixes',
<                       help='skip functions/methods with these prefixes (provide a CSV string as argument)')
<     cmdline.add_option('--file-list', dest='file_list',
<                       help='a file that contains a list of file names that must be processed by Clone Digger')
< 
<     cmdline.set_defaults(language='python', 
<                          ingore_dirs=[],
<                          f_prefixes = None,
<                          **arguments.__dict__)
< 
<     (options, source_file_names) = cmdline.parse_args()
<     if options.f_prefixes != None:
<        func_prefixes = tuple([x.strip() for x in options.f_prefixes.split(',')])
<     else:
<        func_prefixes = ()
<     source_files = [] 
< 
<     supplier = ast_suppliers.abstract_syntax_tree_suppliers[options.language]
<     if options.language != 'python':
<         options.use_diff = True
< 
<     if options.cpd_output:
<         if options.output is None:
< 	    options.output = 'output.xml'
< 	report = html_report.CPDXMLReport()
<     else:
<     	report = html_report.HTMLReport()    
< 
<     if options.output is None:
<     	options.output = 'output.html'
< 
<     output_file_name = options.output
< 
<     for option in cmdline.option_list:
<         if option.dest == 'file_list' and options.file_list != None:           
<             source_file_names.extend(open(options.file_list).read().split())
<             continue
<         elif option.dest is None:
<             continue
<         setattr(arguments, option.dest, getattr(options, option.dest))
< 
<     if options.distance_threshold is None:
<         arguments.distance_threshold = supplier.distance_threshold
<     if options.size_threshold is None:
<         arguments.size_threshold = supplier.size_threshold
<     
<     report.startTimer('Construction of AST')
< 
<     def parse_file(file_name, func_prefixes):
<         try:
<             print 'Parsing ', file_name, '...',
<             sys.stdout.flush()
<             if options.language=='python':
<                 source_file = supplier(file_name, func_prefixes)
<             else:
<                 # TODO implement func_prefixes for java also
<                 source_file = supplier(file_name)
<             source_file.getTree().propagateCoveredLineNumbers()
<             source_file.getTree().propagateHeight()
<             source_files.append(source_file)
<             report.addFileName(file_name)                
<             print 'done'
<         except:
<             s = 'Error: can\'t parse "%s" \n: '%(file_name,) + traceback.format_exc()
<             report.addErrorInformation(s)
<             print s
< 
<     def walk(dirname):
<         for dirpath, dirs, files in os.walk(file_name):
<             dirs[:] = (not options.ignore_dirs and dirs)  or [d for d in dirs if d not in options.ignore_dirs]
<             # Skip all non-parseable files
<             files[:] = [f for f in files 
<                         if os.path.splitext(f)[1][1:] == supplier.extension]
<             yield (dirpath, dirs, files)
< 
<     for file_name in source_file_names:
<         if os.path.isdir(file_name):
<             if arguments.no_recursion:
<                 dirpath = file_name
<                 files = [os.path.join(file_name, f) for f in os.listdir(file_name) 
<                         if os.path.splitext(f)[1][1:] == supplier.extension]
<                 for f in files:
<                     parse_file(f, func_prefixes)
<             else:
<                 for dirpath, dirnames, filenames in walk(file_name):
<                     for f in filenames:
<                         parse_file(os.path.join(dirpath, f), func_prefixes)
<         else:
<             parse_file(file_name, func_prefixes)
<         
<     report.stopTimer()
<     duplicates = clone_detection_algorithm.findDuplicateCode(source_files, report)
<     for duplicate in duplicates:
<         report.addClone(duplicate)
<     report.sortByCloneSize()
<     try:
<         report.writeReport(output_file_name)
<     except:
<         print "catched error, removing output file"
<         if os.path.exists(output_file_name):
<             os.remove(output_file_name)
<         raise 
< 
< if __name__ == '__main__':
<     main()
< 
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/html_report.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/html_report.py.svn-base
1,351d0
< #    Copyright 2008 Peter Bulychev
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import sys
< import time
< import difflib
< import re
< import copy
< import traceback
< import os.path
< from cgi import escape
< 
< import arguments
< import anti_unification
< import python_compiler
< from abstract_syntax_tree import AbstractSyntaxTree
< 
< class Report:
<     def __init__(self):
<         self._error_info = []
<         self._clones = []
<         self._timers = []
<         self._file_names = []
<     def addFileName(self, file_name):
<         self._file_names.append(file_name)
<     def addErrorInformation(self, error_info):
<         self._error_info.append(error_info)
<     def addClone(self, clone):
<         self._clones.append(clone)
<     def sortByCloneSize(self):
<         def f(a,b):
<             return cmp(b.getMaxCoveredLineNumbersCount(), a.getMaxCoveredLineNumbersCount())
<         self._clones.sort(f)
<     def startTimer(self, descr):
<         self._timers.append([descr, time.time(), time.ctime()])
<         sys.stdout.flush()
<     def stopTimer(self, descr=''):      
<         self._timers[-1][1] = time.time() - self._timers[-1][1]
<     def getTimerValues(self):
<         return self._timers
<     def getTotalTime(self):
<         return sum([i[1] for i in self.getTimerValues()])
< 
< class CPDXMLReport(Report):
<     def __init__(self):
<         Report.__init__(self)
<         self._mark_to_statement_hash = None
<     def setMarkToStatementHash(self, mark_to_statement_hash):   
<         self._mark_to_statement_hash = mark_to_statement_hash
<     def writeReport(self, file_name):
< 	f = open(file_name, 'w')
< 	f.write('<?xml version="1.0" encoding="UTF-8"?>\n')
< 	f.write('<pmd-cpd>\n')
< 	for clone in self._clones:	    
< 	    token_numbers = [sum([s.getTokenCount() for s in clone[i]]) for i in (0,1)]
< 	    f.write('<duplication lines="' + str(max([len(set(clone[i].getCoveredLineNumbers())) for i in [0,1]] )) + '" tokens="' + str(max(token_numbers)) +'">\n')
< 	    for i in [0,1]:
< 		f.write('<file line="' + str(1 + min(clone[i].getCoveredLineNumbers())) +  '" path="' + os.path.abspath(clone[i].getSourceFile().getFileName()) + '"/>\n')
< 	    f.write('<codefragment>\n')
< 	    f.write('<![CDATA[\n')
< 	    for line in clone[0].getSourceLines():
< 		f.write(line.replace(']]>','-CLONEDIGGER REMOVED CDATAEND-'))
<                 f.write('\n')
< 	    f.write(']]>\n')
< 	    f.write('</codefragment>\n')
< 	    f.write('</duplication>\n')
< 	f.write('</pmd-cpd>\n')
< 	f.close()
< 
< 
< class HTMLReport(Report):
<     def __init__(self):
<         Report.__init__(self)
<         self._mark_to_statement_hash = None
<     def setMarkToStatementHash(self, mark_to_statement_hash):   
<         self._mark_to_statement_hash = mark_to_statement_hash
<     def writeReport(self, file_name):
< # TODO REWRITE! This function code was created in a hurry
<         eclipse_start = '\n<!--ECLIPSE START-->'
<         eclipse_end   = '\n<!--ECLIPSE END-->'
<         def format_line_code(s):
<             s = s.replace('\t', ' ')
<             s = s.replace(' ', '&nbsp; ')
<             return '<span style="font-family: monospace;">%s</span>'%(s,)
<         errors_info = "\n".join(['<P> <FONT COLOR=RED> %s </FONT> </P>' % (error_info.replace('\n', '<BR>'),) for error_info in self._error_info])
< 
<         very_strange_const = 'VERY_STRANGE_CONST'
< 
<         clone_descriptions = []
<         for clone_i in range(len(self._clones)):
<             try:
<                 clone = self._clones[clone_i]
<                 s = '<P>'
<                 s += '<B>Clone # %d</B><BR>'%(clone_i +1,)
< #           s = '<P> Clone detected in source files "%s" and "%s" <BR>\n' % (sequences[0].getSourceFile().getFileName(), sequences[1].getSourceFile().getFileName())
<                 s+= 'Distance between two fragments = %d <BR>' %(clone.calcDistance())
<                 s+= 'Clone size = ' + str(max([len(set(clone[i].getCoveredLineNumbers())) for i in [0,1]] ))
<                 s+= '<TABLE NOWRAP WIDTH=100% BORDER=1>'
<                 s+= eclipse_start
<                 s+= '<TR>'
<                 for j in [0,1]:
<                     s+= '<TD> <a href="clone://%s?%d&%d"> Go to this fragment in Eclipse </a> </TD>'%(clone[j].getSourceFile().getFileName(), min(clone[j][0].getCoveredLineNumbers()), max(clone[j][-1].getCoveredLineNumbers()))
<                     if j==0:
<                         s += '<TD></TD>'
<                 s+= '</TR>'
<                 s+= eclipse_end
<                 for j in [0,1]:
<                     s+= '<TD>'
<                     s+= 'Source file "%s"<BR>' %(clone[j].getSourceFile().getFileName(),)
<                     if clone[j][0].getCoveredLineNumbers() == []:
<                         # TODO remove after...
<                         pdb.set_trace()
<                     s+= 'The first line is %d' %(min(clone[j][0].getCoveredLineNumbers())+1,)
<                     s+= '</TD>'
<                     if j == 0:
<                         s+= '<TD></TD>'
<                 s+= '</TR>'
<                 for i in range(clone[0].getLength()):
<                     s += '<TR>\n'
<                     t = []
<                     statements = [clone[j][i] for j in [0,1]]
< 
<                     def diff_highlight(seqs):
<                         s = difflib.SequenceMatcher(lambda x:x == '<BR>\n')
<                         s.set_seqs(seqs[0], seqs[1])
<                         blocks = s.get_matching_blocks()
<                         if not ((blocks[0][0]==0) and (blocks[0][1]==0)):
<                             blocks = [(0,0,0)] + blocks
<                         r = ['', '']
<                         for i in range(len(blocks)):
<                             block = blocks[i]
<                             for j in [0,1]:
<                                 r[j] += escape(seqs[j][block[j]:block[j]+block[2]])
<                             if (i < (len(blocks)-1)):                           
<                                 nextblock = blocks[i+1]
<                                 for j in [0,1]:
<                                     r[j] += '<span'+very_strange_const+'style="color:rgb(255,0,0);">%s</span>'%\
<                                                 (escape(seqs[j][block[j]+block[2]:nextblock[j]]),)
<                         return r
<                     # preparation of indentation
<                     indentations = (set(), set())
<                     for j in (0,1):
<                         for source_line in statements[j].getSourceLines():
<                             indentations[j].add(re.findall('^\s*', source_line)[0].replace('\t', 4*' '))
<                     indentations = (list(indentations[0]), list(indentations[1]))
<                     indentations[0].sort()
<                     indentations[1].sort()
<                     source_lines = ([], [])
<                     def use_diff():
<                         for j in (0,1):
<                             for source_line in statements[j].getSourceLines():
<                                 indent1 = re.findall('^\s*', source_line)[0]
<                                 indent2 = indent1.replace('\t', 4*' ')
<                                 source_line = re.sub('^' + indent1,  indentations[j].index(indent2)*' ', source_line)
<                                 source_lines[j].append(source_line)
<                         d = diff_highlight([('\n'.join(source_lines[j])) for j in [0,1]])
<                         d = [format_line_code(d[i].replace('\n', '<BR>\n')) for i in [0,1]]                
<                         d = [d[i].replace(very_strange_const, ' ') for i in (0,1)]
<                         u = anti_unification.Unifier(statements[0], statements[1])
<                         return d,u
<                     if arguments.use_diff:
<                         (d,u) = use_diff()
<                     else:
<                         try:
<                             def rec_correct_as_string(t1, t2, s1, s2):
<                                 def highlight(s):
<                                     return '<span style="color: rgb(255, 0, 0);">' + s + '</span>'
<                                 class NewAsString:
<                                     def __init__(self, s):
<                                         self.s = highlight(s)
<                                     def __call__(self):
<                                         return self.s
<                                 def set_as_string_node_parent(t):
<                                     if not isinstance(t, AbstractSyntaxTree):
<                                         t = t.getParent()
<                                     n = NewAsString(t.ast_node.as_string())
<                                     t.ast_node.as_string = n
< 
<                                 if (t1 in s1) or (t2 in s2):
<                                     for t in (t1, t2):
<                                         set_as_string_node_parent(t)
<                                     return
<                                 assert(len(t1.getChilds()) == len(t2.getChilds()))
<                                 for i in range(len(t1.getChilds())):
<                                     c1 = t1.getChilds()[i]
<                                     c2 = t2.getChilds()[i]
<                                     rec_correct_as_string(c1, c2, s1, s2)
< 
<                             (s1, s2) = (statements[0], statements[1])
<                             u = anti_unification.Unifier(s1, s2)
<                             rec_correct_as_string(s1, s2, u.getSubstitutions()[0].getMap().values(), u.getSubstitutions()[1].getMap().values() )
<                             d = [None, None]
<                             for j in (0,1):
<                                 d[j] = statements[j].ast_node.as_string()
< 
<                                 lines = d[j].split('\n')
<                                 for ii in range(len(lines)):
<                                     temp_line = ''
<                                     jj = 0
<                                     try:
<                                         while lines[ii][jj] == ' ':
<                                             temp_line += '&nbsp;'
<                                             jj += 1
<                                     except IndexError:
<                                         # suppress errors if line has no leading spaces
<                                         pass
<                                     temp_line += lines[ii][jj:]
<                                     lines[ii] = temp_line
<                                 d[j] = '\n'.join(lines)
< 
<                                 d[j] = d[j].replace('\n', '<BR>\n')
< 
< 
<                         except:
<                             print 'The following error occured during highlighting of differences on the AST level:'
<                             traceback.print_exc()                       
<                             print 'using diff highlight'
<                             (d,u) = use_diff()
<                     for j in [0,1]:                 
<                         t.append('<TD>\n' + d[j] + '</TD>\n')
<                     if u.getSize() > 0:
<                         color = 'RED'
<                     else:
<                         color = 'AQUA'
<                     s+= t[0] + '<TD style="width: 10px;" BGCOLOR=%s> </TD>'%(color,) + t[1]
<                     s += '</TR>\n'
<                 s+= '</TABLE> </P> <HR>'
<                 clone_descriptions.append(s)
<             except:
<                 print "Clone info can't be written to the report. "
<                 traceback.print_exc()                   
<         
<         descr = """<P>Source files: %d</P>
<         <a href = "javascript:unhide('files');">Click here to show/hide file names</a><div id="files" class="hidden"><P><B>Source files:</B><BR>%s</P></div>
<         <P>Clones detected: %d</P>
<         <P>%d of %d lines are duplicates (%.2f%%) </P>
< <P>
< <B>Parameters<BR> </B>
< clustering_threshold = %d<BR>
< distance_threshold = %d<BR>
< size_threshold = %d<BR>
< hashing_depth = %d<BR>
< clusterize_using_hash = %s<BR>
< clusterize_using_dcup = %s<BR>
< </P> 
<         """ % (len(self._file_names), ', <BR>'.join(self._file_names), len(self._clones), self.covered_source_lines_count, self.all_source_lines_count, (not self.all_source_lines_count and 100) or 100*self.covered_source_lines_count/float(self.all_source_lines_count), arguments.clustering_threshold, arguments.distance_threshold, arguments.size_threshold, arguments.hashing_depth, str(arguments.clusterize_using_hash), str(arguments.clusterize_using_dcup))
<         if arguments.print_time:
<             timings = ''
<             timings += '<B>Time elapsed</B><BR>'
<             timings += '<BR>\n'.join(['%s : %.2f seconds'%(i[0], i[1]) for i in self._timers])
<             timings += '<BR>\n Total time: %.2f' % (self.getTotalTime())
<             timings += '<BR>\n Started at: ' + self._timers[0][2]
<             timings += '<BR>\n Finished at: ' + self._timers[-1][2]
<         else:
<             timings = ''
<         
<         marks_report = ''
<         if self._mark_to_statement_hash:
<             marks_report += '<P>Top 20 statement marks:'
<             marks = self._mark_to_statement_hash.keys()
<             marks.sort(lambda y,x:cmp(len(self._mark_to_statement_hash[x]), len(self._mark_to_statement_hash[y])))
<             counter = 0
<             for mark in marks[:20]:
<                 counter += 1
<                 marks_report += '<BR>' + str(len(self._mark_to_statement_hash[mark])) + ':' +  str(mark.getUnifierTree()) + "<a href=\"javascript:unhide('stmt%d');\">show/hide representatives</a> "%(counter,)
<                 marks_report += '<div id="stmt%d" class="hidden"> <BR>'%(counter,)
<                 for statement in self._mark_to_statement_hash[mark]:
<                     marks_report += str(statement) + '<BR>'
<                 marks_report += '</div>'
<                 marks_report += '</P>'
< 
<         warnings = ''
<         if arguments.use_diff:
<             warnings += '<P>(*) Warning: the highlighting of differences is based on diff and doesn\'t reflect the tree-based clone detection algorithm.</P>'
<         save_to = eclipse_start + '<b><a href="file://%s">Save this report</a></b>'%(file_name,) +eclipse_end   
<         HTML_code = """
< <HTML>
<     <HEAD>
<         <TITLE> CloneDigger Report </TITLE>
<         <script type="text/javascript">
<         function unhide(divID) {
<             var item = document.getElementById(divID);
<             if (item) {
<                 item.className=(item.className=='hidden')?'unhidden':'hidden';
<             }
<         }
< </script>
< 
< <style type="text/css">
< .hidden { display: none; }
< .unhidden { display: block; }
< .preformatted {
<         border: 1px dashed #3c78b5;
<     font-size: 11px;
<         font-family: Courier;
<     margin: 10px;
<         line-height: 13px;
< }
< .preformattedHeader {
<     background-color: #f0f0f0;
<         border-bottom: 1px dashed #3c78b5;
<     padding: 3px;
<         text-align: center;
< }
< .preformattedContent {
<     background-color: #f0f0f0;
<     padding: 3px;
< }
< <!--
< <div class="preformatted"><div class="preformattedContent">
< <pre>Clone Digger
< </pre>
< </div></div>
< -->
< 
< </style>
< 
<     </HEAD>
<     <BODY>
<     %s
<     %s
<     %s
<     %s
<     %s
<     %s
<     %s
<     <HR>
<     Clone Digger is aimed to find software clones in Python and Java programs. It is provided under the GPL license and can be downloaded from the site <a href="http://clonedigger.sourceforge.net">http://clonedigger.sourceforge.net</a>
<     </BODY>
< </HTML>""" % (errors_info, save_to, descr, timings, '<BR>\n'.join(clone_descriptions), marks_report, warnings)
<         f = open(file_name, 'w')
<         f.write(re.sub(eclipse_start+'.*?'+eclipse_end, '' ,HTML_code))
<         f.close()
<         if arguments.eclipse_output:
<             f = open(arguments.eclipse_output, 'w')
<             f.write(HTML_code)
<             f.close()
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/java_antlr.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/java_antlr.py.svn-base
1,74d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>. 
< 
< import os
< import xml.parsers.expat
< 
< from abstract_syntax_tree import *
< 
< class JavaANTLRSourceFile (SourceFile):
<     extension = 'java'
<     size_threshold = 10
<     distance_threshold = 7
<     def __init__(self, file_name):
<         SourceFile.__init__(self, file_name)
<         class ExpatHandler:
<             def __init__(self, start_node, parent):
<                 self.parent = parent
<                 self.stack = [start_node]
<             def start_element(expat_self, xml_node_name, attrs):
<                 line_number = int(attrs["line_number"])-1
<                 line_numbers = [line_number]
<                 if line_numbers == [-1]:
<                     line_numbers = []
<                 name = attrs["name"]
<                 r = AbstractSyntaxTree(name, line_numbers, self)
<                 if xml_node_name == "statement_node":
<                     r.markAsStatement()
<                 else:
<                     assert(xml_node_name == "node")
<                 expat_self.stack[-1].addChild(r)                
<                 expat_self.stack.append(r)
<             def end_element(self, name):
<                 self.stack.pop()
< 
<         tree_file_name  = 'temporary_ast.xml'
<         producer_class_path = os.path.join('.','java_antlr', 'TreeProducer.jar')
<         antlr_class_path = os.path.join('.','antlr_runtime','runtime-2008-01-10.16.jar')
<         if os.name in ['mac', 'posix']:
<             class_path_delimeter = ':'
<         elif os.name in ['nt', 'dos', 'ce']:
<             class_path_delimeter = ';'
<         else:
<             print 'unsupported OS'
<             assert(0)
<         if os.system('java -classpath ' + producer_class_path + class_path_delimeter + antlr_class_path + ' TreeProducer %s %s 2>err.log' %(file_name, tree_file_name)):
<             f = open('err.log')
<             s = f.read()
<             f.close()
<             raise s
<         
<         self._tree = AbstractSyntaxTree('program')
<         handler = ExpatHandler(self._tree, self)
<         p = xml.parsers.expat.ParserCreate()
<         p.StartElementHandler = handler.start_element
<         p.EndElementHandler = handler.end_element
<         f = open(tree_file_name)
<         p.ParseFile(f)
<         f.close()
<         os.remove(tree_file_name)
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/js_antlr.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/js_antlr.py.svn-base
1,81d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>. 
< 
< import os
< import xml.parsers.expat
< 
< from abstract_syntax_tree import *
< 
< class JsANTLRSourceFile (SourceFile):
<     extension = 'js'
<     size_threshold = 5
<     distance_threshold = 5
<     def __init__(self, file_name):
<         SourceFile.__init__(self, file_name)
<         class ExpatHandler:
<             def __init__(self, start_node, parent):
<                 self.parent = parent
<                 self.stack = [start_node]
<             def start_element(expat_self, xml_node_name, attrs):
<                 line_number = int(attrs["line_number"])-1
<                 line_numbers = [line_number]
<                 if line_numbers == [-1]:
<                     line_numbers = []
<                 name = attrs["name"]
<                 r = AbstractSyntaxTree(name, line_numbers, self)
<                 if xml_node_name == "statement_node":
<                 #if name in ["CALL", "BLOCK"]:
<                     r.markAsStatement()
<                 else:
<                     assert(xml_node_name == "node")
<                 expat_self.stack[-1].addChild(r)
<                 expat_self.stack.append(r)
<             def end_element(self, name):
<                 self.stack.pop()
< 
<         tree_file_name  = 'temporary_ast.xml'
<         producer_class_path = os.path.join('.','js_antlr', 'TreeProducer.jar')
<         antlr_class_path = os.path.join('.','antlr_runtime', 'antlr-3.1.1.jar')
<         if os.name in ['mac', 'posix']:
<             class_path_delimeter = ':'
<         elif os.name in ['nt', 'dos', 'ce']:
<             class_path_delimeter = ';'
<         else:
<             print 'unsupported OS'
<             assert(0)
< 
<         if os.system('java -classpath ' + producer_class_path + class_path_delimeter + antlr_class_path + ' TreeProducer %s %s 2>err.log'%(file_name, tree_file_name)):
<             f = open('err.log')
<             s = f.read()
<             f.close()
<             raise Exception(s)
<         f = open('err.log')
<         s = f.read()
<         f.close()
<         if s:
<             print s
<         
<         self._tree = AbstractSyntaxTree('program')
<         handler = ExpatHandler(self._tree, self)
<         p = xml.parsers.expat.ParserCreate()
<         p.StartElementHandler = handler.start_element
<         p.EndElementHandler = handler.end_element
<         f = open(tree_file_name)
<         p.ParseFile(f)
<         f.close()
< #       os.remove(tree_file_name)
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/LICENSE.txt.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/LICENSE.txt.svn-base
1,674d0
<                     GNU GENERAL PUBLIC LICENSE
<                        Version 3, 29 June 2007
< 
<  Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
<  Everyone is permitted to copy and distribute verbatim copies
<  of this license document, but changing it is not allowed.
< 
<                             Preamble
< 
<   The GNU General Public License is a free, copyleft license for
< software and other kinds of works.
< 
<   The licenses for most software and other practical works are designed
< to take away your freedom to share and change the works.  By contrast,
< the GNU General Public License is intended to guarantee your freedom to
< share and change all versions of a program--to make sure it remains free
< software for all its users.  We, the Free Software Foundation, use the
< GNU General Public License for most of our software; it applies also to
< any other work released this way by its authors.  You can apply it to
< your programs, too.
< 
<   When we speak of free software, we are referring to freedom, not
< price.  Our General Public Licenses are designed to make sure that you
< have the freedom to distribute copies of free software (and charge for
< them if you wish), that you receive source code or can get it if you
< want it, that you can change the software or use pieces of it in new
< free programs, and that you know you can do these things.
< 
<   To protect your rights, we need to prevent others from denying you
< these rights or asking you to surrender the rights.  Therefore, you have
< certain responsibilities if you distribute copies of the software, or if
< you modify it: responsibilities to respect the freedom of others.
< 
<   For example, if you distribute copies of such a program, whether
< gratis or for a fee, you must pass on to the recipients the same
< freedoms that you received.  You must make sure that they, too, receive
< or can get the source code.  And you must show them these terms so they
< know their rights.
< 
<   Developers that use the GNU GPL protect your rights with two steps:
< (1) assert copyright on the software, and (2) offer you this License
< giving you legal permission to copy, distribute and/or modify it.
< 
<   For the developers' and authors' protection, the GPL clearly explains
< that there is no warranty for this free software.  For both users' and
< authors' sake, the GPL requires that modified versions be marked as
< changed, so that their problems will not be attributed erroneously to
< authors of previous versions.
< 
<   Some devices are designed to deny users access to install or run
< modified versions of the software inside them, although the manufacturer
< can do so.  This is fundamentally incompatible with the aim of
< protecting users' freedom to change the software.  The systematic
< pattern of such abuse occurs in the area of products for individuals to
< use, which is precisely where it is most unacceptable.  Therefore, we
< have designed this version of the GPL to prohibit the practice for those
< products.  If such problems arise substantially in other domains, we
< stand ready to extend this provision to those domains in future versions
< of the GPL, as needed to protect the freedom of users.
< 
<   Finally, every program is threatened constantly by software patents.
< States should not allow patents to restrict development and use of
< software on general-purpose computers, but in those that do, we wish to
< avoid the special danger that patents applied to a free program could
< make it effectively proprietary.  To prevent this, the GPL assures that
< patents cannot be used to render the program non-free.
< 
<   The precise terms and conditions for copying, distribution and
< modification follow.
< 
<                        TERMS AND CONDITIONS
< 
<   0. Definitions.
< 
<   "This License" refers to version 3 of the GNU General Public License.
< 
<   "Copyright" also means copyright-like laws that apply to other kinds of
< works, such as semiconductor masks.
< 
<   "The Program" refers to any copyrightable work licensed under this
< License.  Each licensee is addressed as "you".  "Licensees" and
< "recipients" may be individuals or organizations.
< 
<   To "modify" a work means to copy from or adapt all or part of the work
< in a fashion requiring copyright permission, other than the making of an
< exact copy.  The resulting work is called a "modified version" of the
< earlier work or a work "based on" the earlier work.
< 
<   A "covered work" means either the unmodified Program or a work based
< on the Program.
< 
<   To "propagate" a work means to do anything with it that, without
< permission, would make you directly or secondarily liable for
< infringement under applicable copyright law, except executing it on a
< computer or modifying a private copy.  Propagation includes copying,
< distribution (with or without modification), making available to the
< public, and in some countries other activities as well.
< 
<   To "convey" a work means any kind of propagation that enables other
< parties to make or receive copies.  Mere interaction with a user through
< a computer network, with no transfer of a copy, is not conveying.
< 
<   An interactive user interface displays "Appropriate Legal Notices"
< to the extent that it includes a convenient and prominently visible
< feature that (1) displays an appropriate copyright notice, and (2)
< tells the user that there is no warranty for the work (except to the
< extent that warranties are provided), that licensees may convey the
< work under this License, and how to view a copy of this License.  If
< the interface presents a list of user commands or options, such as a
< menu, a prominent item in the list meets this criterion.
< 
<   1. Source Code.
< 
<   The "source code" for a work means the preferred form of the work
< for making modifications to it.  "Object code" means any non-source
< form of a work.
< 
<   A "Standard Interface" means an interface that either is an official
< standard defined by a recognized standards body, or, in the case of
< interfaces specified for a particular programming language, one that
< is widely used among developers working in that language.
< 
<   The "System Libraries" of an executable work include anything, other
< than the work as a whole, that (a) is included in the normal form of
< packaging a Major Component, but which is not part of that Major
< Component, and (b) serves only to enable use of the work with that
< Major Component, or to implement a Standard Interface for which an
< implementation is available to the public in source code form.  A
< "Major Component", in this context, means a major essential component
< (kernel, window system, and so on) of the specific operating system
< (if any) on which the executable work runs, or a compiler used to
< produce the work, or an object code interpreter used to run it.
< 
<   The "Corresponding Source" for a work in object code form means all
< the source code needed to generate, install, and (for an executable
< work) run the object code and to modify the work, including scripts to
< control those activities.  However, it does not include the work's
< System Libraries, or general-purpose tools or generally available free
< programs which are used unmodified in performing those activities but
< which are not part of the work.  For example, Corresponding Source
< includes interface definition files associated with source files for
< the work, and the source code for shared libraries and dynamically
< linked subprograms that the work is specifically designed to require,
< such as by intimate data communication or control flow between those
< subprograms and other parts of the work.
< 
<   The Corresponding Source need not include anything that users
< can regenerate automatically from other parts of the Corresponding
< Source.
< 
<   The Corresponding Source for a work in source code form is that
< same work.
< 
<   2. Basic Permissions.
< 
<   All rights granted under this License are granted for the term of
< copyright on the Program, and are irrevocable provided the stated
< conditions are met.  This License explicitly affirms your unlimited
< permission to run the unmodified Program.  The output from running a
< covered work is covered by this License only if the output, given its
< content, constitutes a covered work.  This License acknowledges your
< rights of fair use or other equivalent, as provided by copyright law.
< 
<   You may make, run and propagate covered works that you do not
< convey, without conditions so long as your license otherwise remains
< in force.  You may convey covered works to others for the sole purpose
< of having them make modifications exclusively for you, or provide you
< with facilities for running those works, provided that you comply with
< the terms of this License in conveying all material for which you do
< not control copyright.  Those thus making or running the covered works
< for you must do so exclusively on your behalf, under your direction
< and control, on terms that prohibit them from making any copies of
< your copyrighted material outside their relationship with you.
< 
<   Conveying under any other circumstances is permitted solely under
< the conditions stated below.  Sublicensing is not allowed; section 10
< makes it unnecessary.
< 
<   3. Protecting Users' Legal Rights From Anti-Circumvention Law.
< 
<   No covered work shall be deemed part of an effective technological
< measure under any applicable law fulfilling obligations under article
< 11 of the WIPO copyright treaty adopted on 20 December 1996, or
< similar laws prohibiting or restricting circumvention of such
< measures.
< 
<   When you convey a covered work, you waive any legal power to forbid
< circumvention of technological measures to the extent such circumvention
< is effected by exercising rights under this License with respect to
< the covered work, and you disclaim any intention to limit operation or
< modification of the work as a means of enforcing, against the work's
< users, your or third parties' legal rights to forbid circumvention of
< technological measures.
< 
<   4. Conveying Verbatim Copies.
< 
<   You may convey verbatim copies of the Program's source code as you
< receive it, in any medium, provided that you conspicuously and
< appropriately publish on each copy an appropriate copyright notice;
< keep intact all notices stating that this License and any
< non-permissive terms added in accord with section 7 apply to the code;
< keep intact all notices of the absence of any warranty; and give all
< recipients a copy of this License along with the Program.
< 
<   You may charge any price or no price for each copy that you convey,
< and you may offer support or warranty protection for a fee.
< 
<   5. Conveying Modified Source Versions.
< 
<   You may convey a work based on the Program, or the modifications to
< produce it from the Program, in the form of source code under the
< terms of section 4, provided that you also meet all of these conditions:
< 
<     a) The work must carry prominent notices stating that you modified
<     it, and giving a relevant date.
< 
<     b) The work must carry prominent notices stating that it is
<     released under this License and any conditions added under section
<     7.  This requirement modifies the requirement in section 4 to
<     "keep intact all notices".
< 
<     c) You must license the entire work, as a whole, under this
<     License to anyone who comes into possession of a copy.  This
<     License will therefore apply, along with any applicable section 7
<     additional terms, to the whole of the work, and all its parts,
<     regardless of how they are packaged.  This License gives no
<     permission to license the work in any other way, but it does not
<     invalidate such permission if you have separately received it.
< 
<     d) If the work has interactive user interfaces, each must display
<     Appropriate Legal Notices; however, if the Program has interactive
<     interfaces that do not display Appropriate Legal Notices, your
<     work need not make them do so.
< 
<   A compilation of a covered work with other separate and independent
< works, which are not by their nature extensions of the covered work,
< and which are not combined with it such as to form a larger program,
< in or on a volume of a storage or distribution medium, is called an
< "aggregate" if the compilation and its resulting copyright are not
< used to limit the access or legal rights of the compilation's users
< beyond what the individual works permit.  Inclusion of a covered work
< in an aggregate does not cause this License to apply to the other
< parts of the aggregate.
< 
<   6. Conveying Non-Source Forms.
< 
<   You may convey a covered work in object code form under the terms
< of sections 4 and 5, provided that you also convey the
< machine-readable Corresponding Source under the terms of this License,
< in one of these ways:
< 
<     a) Convey the object code in, or embodied in, a physical product
<     (including a physical distribution medium), accompanied by the
<     Corresponding Source fixed on a durable physical medium
<     customarily used for software interchange.
< 
<     b) Convey the object code in, or embodied in, a physical product
<     (including a physical distribution medium), accompanied by a
<     written offer, valid for at least three years and valid for as
<     long as you offer spare parts or customer support for that product
<     model, to give anyone who possesses the object code either (1) a
<     copy of the Corresponding Source for all the software in the
<     product that is covered by this License, on a durable physical
<     medium customarily used for software interchange, for a price no
<     more than your reasonable cost of physically performing this
<     conveying of source, or (2) access to copy the
<     Corresponding Source from a network server at no charge.
< 
<     c) Convey individual copies of the object code with a copy of the
<     written offer to provide the Corresponding Source.  This
<     alternative is allowed only occasionally and noncommercially, and
<     only if you received the object code with such an offer, in accord
<     with subsection 6b.
< 
<     d) Convey the object code by offering access from a designated
<     place (gratis or for a charge), and offer equivalent access to the
<     Corresponding Source in the same way through the same place at no
<     further charge.  You need not require recipients to copy the
<     Corresponding Source along with the object code.  If the place to
<     copy the object code is a network server, the Corresponding Source
<     may be on a different server (operated by you or a third party)
<     that supports equivalent copying facilities, provided you maintain
<     clear directions next to the object code saying where to find the
<     Corresponding Source.  Regardless of what server hosts the
<     Corresponding Source, you remain obligated to ensure that it is
<     available for as long as needed to satisfy these requirements.
< 
<     e) Convey the object code using peer-to-peer transmission, provided
<     you inform other peers where the object code and Corresponding
<     Source of the work are being offered to the general public at no
<     charge under subsection 6d.
< 
<   A separable portion of the object code, whose source code is excluded
< from the Corresponding Source as a System Library, need not be
< included in conveying the object code work.
< 
<   A "User Product" is either (1) a "consumer product", which means any
< tangible personal property which is normally used for personal, family,
< or household purposes, or (2) anything designed or sold for incorporation
< into a dwelling.  In determining whether a product is a consumer product,
< doubtful cases shall be resolved in favor of coverage.  For a particular
< product received by a particular user, "normally used" refers to a
< typical or common use of that class of product, regardless of the status
< of the particular user or of the way in which the particular user
< actually uses, or expects or is expected to use, the product.  A product
< is a consumer product regardless of whether the product has substantial
< commercial, industrial or non-consumer uses, unless such uses represent
< the only significant mode of use of the product.
< 
<   "Installation Information" for a User Product means any methods,
< procedures, authorization keys, or other information required to install
< and execute modified versions of a covered work in that User Product from
< a modified version of its Corresponding Source.  The information must
< suffice to ensure that the continued functioning of the modified object
< code is in no case prevented or interfered with solely because
< modification has been made.
< 
<   If you convey an object code work under this section in, or with, or
< specifically for use in, a User Product, and the conveying occurs as
< part of a transaction in which the right of possession and use of the
< User Product is transferred to the recipient in perpetuity or for a
< fixed term (regardless of how the transaction is characterized), the
< Corresponding Source conveyed under this section must be accompanied
< by the Installation Information.  But this requirement does not apply
< if neither you nor any third party retains the ability to install
< modified object code on the User Product (for example, the work has
< been installed in ROM).
< 
<   The requirement to provide Installation Information does not include a
< requirement to continue to provide support service, warranty, or updates
< for a work that has been modified or installed by the recipient, or for
< the User Product in which it has been modified or installed.  Access to a
< network may be denied when the modification itself materially and
< adversely affects the operation of the network or violates the rules and
< protocols for communication across the network.
< 
<   Corresponding Source conveyed, and Installation Information provided,
< in accord with this section must be in a format that is publicly
< documented (and with an implementation available to the public in
< source code form), and must require no special password or key for
< unpacking, reading or copying.
< 
<   7. Additional Terms.
< 
<   "Additional permissions" are terms that supplement the terms of this
< License by making exceptions from one or more of its conditions.
< Additional permissions that are applicable to the entire Program shall
< be treated as though they were included in this License, to the extent
< that they are valid under applicable law.  If additional permissions
< apply only to part of the Program, that part may be used separately
< under those permissions, but the entire Program remains governed by
< this License without regard to the additional permissions.
< 
<   When you convey a copy of a covered work, you may at your option
< remove any additional permissions from that copy, or from any part of
< it.  (Additional permissions may be written to require their own
< removal in certain cases when you modify the work.)  You may place
< additional permissions on material, added by you to a covered work,
< for which you have or can give appropriate copyright permission.
< 
<   Notwithstanding any other provision of this License, for material you
< add to a covered work, you may (if authorized by the copyright holders of
< that material) supplement the terms of this License with terms:
< 
<     a) Disclaiming warranty or limiting liability differently from the
<     terms of sections 15 and 16 of this License; or
< 
<     b) Requiring preservation of specified reasonable legal notices or
<     author attributions in that material or in the Appropriate Legal
<     Notices displayed by works containing it; or
< 
<     c) Prohibiting misrepresentation of the origin of that material, or
<     requiring that modified versions of such material be marked in
<     reasonable ways as different from the original version; or
< 
<     d) Limiting the use for publicity purposes of names of licensors or
<     authors of the material; or
< 
<     e) Declining to grant rights under trademark law for use of some
<     trade names, trademarks, or service marks; or
< 
<     f) Requiring indemnification of licensors and authors of that
<     material by anyone who conveys the material (or modified versions of
<     it) with contractual assumptions of liability to the recipient, for
<     any liability that these contractual assumptions directly impose on
<     those licensors and authors.
< 
<   All other non-permissive additional terms are considered "further
< restrictions" within the meaning of section 10.  If the Program as you
< received it, or any part of it, contains a notice stating that it is
< governed by this License along with a term that is a further
< restriction, you may remove that term.  If a license document contains
< a further restriction but permits relicensing or conveying under this
< License, you may add to a covered work material governed by the terms
< of that license document, provided that the further restriction does
< not survive such relicensing or conveying.
< 
<   If you add terms to a covered work in accord with this section, you
< must place, in the relevant source files, a statement of the
< additional terms that apply to those files, or a notice indicating
< where to find the applicable terms.
< 
<   Additional terms, permissive or non-permissive, may be stated in the
< form of a separately written license, or stated as exceptions;
< the above requirements apply either way.
< 
<   8. Termination.
< 
<   You may not propagate or modify a covered work except as expressly
< provided under this License.  Any attempt otherwise to propagate or
< modify it is void, and will automatically terminate your rights under
< this License (including any patent licenses granted under the third
< paragraph of section 11).
< 
<   However, if you cease all violation of this License, then your
< license from a particular copyright holder is reinstated (a)
< provisionally, unless and until the copyright holder explicitly and
< finally terminates your license, and (b) permanently, if the copyright
< holder fails to notify you of the violation by some reasonable means
< prior to 60 days after the cessation.
< 
<   Moreover, your license from a particular copyright holder is
< reinstated permanently if the copyright holder notifies you of the
< violation by some reasonable means, this is the first time you have
< received notice of violation of this License (for any work) from that
< copyright holder, and you cure the violation prior to 30 days after
< your receipt of the notice.
< 
<   Termination of your rights under this section does not terminate the
< licenses of parties who have received copies or rights from you under
< this License.  If your rights have been terminated and not permanently
< reinstated, you do not qualify to receive new licenses for the same
< material under section 10.
< 
<   9. Acceptance Not Required for Having Copies.
< 
<   You are not required to accept this License in order to receive or
< run a copy of the Program.  Ancillary propagation of a covered work
< occurring solely as a consequence of using peer-to-peer transmission
< to receive a copy likewise does not require acceptance.  However,
< nothing other than this License grants you permission to propagate or
< modify any covered work.  These actions infringe copyright if you do
< not accept this License.  Therefore, by modifying or propagating a
< covered work, you indicate your acceptance of this License to do so.
< 
<   10. Automatic Licensing of Downstream Recipients.
< 
<   Each time you convey a covered work, the recipient automatically
< receives a license from the original licensors, to run, modify and
< propagate that work, subject to this License.  You are not responsible
< for enforcing compliance by third parties with this License.
< 
<   An "entity transaction" is a transaction transferring control of an
< organization, or substantially all assets of one, or subdividing an
< organization, or merging organizations.  If propagation of a covered
< work results from an entity transaction, each party to that
< transaction who receives a copy of the work also receives whatever
< licenses to the work the party's predecessor in interest had or could
< give under the previous paragraph, plus a right to possession of the
< Corresponding Source of the work from the predecessor in interest, if
< the predecessor has it or can get it with reasonable efforts.
< 
<   You may not impose any further restrictions on the exercise of the
< rights granted or affirmed under this License.  For example, you may
< not impose a license fee, royalty, or other charge for exercise of
< rights granted under this License, and you may not initiate litigation
< (including a cross-claim or counterclaim in a lawsuit) alleging that
< any patent claim is infringed by making, using, selling, offering for
< sale, or importing the Program or any portion of it.
< 
<   11. Patents.
< 
<   A "contributor" is a copyright holder who authorizes use under this
< License of the Program or a work on which the Program is based.  The
< work thus licensed is called the contributor's "contributor version".
< 
<   A contributor's "essential patent claims" are all patent claims
< owned or controlled by the contributor, whether already acquired or
< hereafter acquired, that would be infringed by some manner, permitted
< by this License, of making, using, or selling its contributor version,
< but do not include claims that would be infringed only as a
< consequence of further modification of the contributor version.  For
< purposes of this definition, "control" includes the right to grant
< patent sublicenses in a manner consistent with the requirements of
< this License.
< 
<   Each contributor grants you a non-exclusive, worldwide, royalty-free
< patent license under the contributor's essential patent claims, to
< make, use, sell, offer for sale, import and otherwise run, modify and
< propagate the contents of its contributor version.
< 
<   In the following three paragraphs, a "patent license" is any express
< agreement or commitment, however denominated, not to enforce a patent
< (such as an express permission to practice a patent or covenant not to
< sue for patent infringement).  To "grant" such a patent license to a
< party means to make such an agreement or commitment not to enforce a
< patent against the party.
< 
<   If you convey a covered work, knowingly relying on a patent license,
< and the Corresponding Source of the work is not available for anyone
< to copy, free of charge and under the terms of this License, through a
< publicly available network server or other readily accessible means,
< then you must either (1) cause the Corresponding Source to be so
< available, or (2) arrange to deprive yourself of the benefit of the
< patent license for this particular work, or (3) arrange, in a manner
< consistent with the requirements of this License, to extend the patent
< license to downstream recipients.  "Knowingly relying" means you have
< actual knowledge that, but for the patent license, your conveying the
< covered work in a country, or your recipient's use of the covered work
< in a country, would infringe one or more identifiable patents in that
< country that you have reason to believe are valid.
< 
<   If, pursuant to or in connection with a single transaction or
< arrangement, you convey, or propagate by procuring conveyance of, a
< covered work, and grant a patent license to some of the parties
< receiving the covered work authorizing them to use, propagate, modify
< or convey a specific copy of the covered work, then the patent license
< you grant is automatically extended to all recipients of the covered
< work and works based on it.
< 
<   A patent license is "discriminatory" if it does not include within
< the scope of its coverage, prohibits the exercise of, or is
< conditioned on the non-exercise of one or more of the rights that are
< specifically granted under this License.  You may not convey a covered
< work if you are a party to an arrangement with a third party that is
< in the business of distributing software, under which you make payment
< to the third party based on the extent of your activity of conveying
< the work, and under which the third party grants, to any of the
< parties who would receive the covered work from you, a discriminatory
< patent license (a) in connection with copies of the covered work
< conveyed by you (or copies made from those copies), or (b) primarily
< for and in connection with specific products or compilations that
< contain the covered work, unless you entered into that arrangement,
< or that patent license was granted, prior to 28 March 2007.
< 
<   Nothing in this License shall be construed as excluding or limiting
< any implied license or other defenses to infringement that may
< otherwise be available to you under applicable patent law.
< 
<   12. No Surrender of Others' Freedom.
< 
<   If conditions are imposed on you (whether by court order, agreement or
< otherwise) that contradict the conditions of this License, they do not
< excuse you from the conditions of this License.  If you cannot convey a
< covered work so as to satisfy simultaneously your obligations under this
< License and any other pertinent obligations, then as a consequence you may
< not convey it at all.  For example, if you agree to terms that obligate you
< to collect a royalty for further conveying from those to whom you convey
< the Program, the only way you could satisfy both those terms and this
< License would be to refrain entirely from conveying the Program.
< 
<   13. Use with the GNU Affero General Public License.
< 
<   Notwithstanding any other provision of this License, you have
< permission to link or combine any covered work with a work licensed
< under version 3 of the GNU Affero General Public License into a single
< combined work, and to convey the resulting work.  The terms of this
< License will continue to apply to the part which is the covered work,
< but the special requirements of the GNU Affero General Public License,
< section 13, concerning interaction through a network will apply to the
< combination as such.
< 
<   14. Revised Versions of this License.
< 
<   The Free Software Foundation may publish revised and/or new versions of
< the GNU General Public License from time to time.  Such new versions will
< be similar in spirit to the present version, but may differ in detail to
< address new problems or concerns.
< 
<   Each version is given a distinguishing version number.  If the
< Program specifies that a certain numbered version of the GNU General
< Public License "or any later version" applies to it, you have the
< option of following the terms and conditions either of that numbered
< version or of any later version published by the Free Software
< Foundation.  If the Program does not specify a version number of the
< GNU General Public License, you may choose any version ever published
< by the Free Software Foundation.
< 
<   If the Program specifies that a proxy can decide which future
< versions of the GNU General Public License can be used, that proxy's
< public statement of acceptance of a version permanently authorizes you
< to choose that version for the Program.
< 
<   Later license versions may give you additional or different
< permissions.  However, no additional obligations are imposed on any
< author or copyright holder as a result of your choosing to follow a
< later version.
< 
<   15. Disclaimer of Warranty.
< 
<   THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
< APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
< HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
< OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
< THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
< PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
< IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
< ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
< 
<   16. Limitation of Liability.
< 
<   IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
< WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
< THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
< GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
< USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
< DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
< PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
< EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
< SUCH DAMAGES.
< 
<   17. Interpretation of Sections 15 and 16.
< 
<   If the disclaimer of warranty and limitation of liability provided
< above cannot be given local legal effect according to their terms,
< reviewing courts shall apply local law that most closely approximates
< an absolute waiver of all civil liability in connection with the
< Program, unless a warranty or assumption of liability accompanies a
< copy of the Program in return for a fee.
< 
<                      END OF TERMS AND CONDITIONS
< 
<             How to Apply These Terms to Your New Programs
< 
<   If you develop a new program, and you want it to be of the greatest
< possible use to the public, the best way to achieve this is to make it
< free software which everyone can redistribute and change under these terms.
< 
<   To do so, attach the following notices to the program.  It is safest
< to attach them to the start of each source file to most effectively
< state the exclusion of warranty; and each file should have at least
< the "copyright" line and a pointer to where the full notice is found.
< 
<     <one line to give the program's name and a brief idea of what it does.>
<     Copyright (C) <year>  <name of author>
< 
<     This program is free software: you can redistribute it and/or modify
<     it under the terms of the GNU General Public License as published by
<     the Free Software Foundation, either version 3 of the License, or
<     (at your option) any later version.
< 
<     This program is distributed in the hope that it will be useful,
<     but WITHOUT ANY WARRANTY; without even the implied warranty of
<     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<     GNU General Public License for more details.
< 
<     You should have received a copy of the GNU General Public License
<     along with this program.  If not, see <http://www.gnu.org/licenses/>.
< 
< Also add information on how to contact you by electronic and paper mail.
< 
<   If the program does terminal interaction, make it output a short
< notice like this when it starts in an interactive mode:
< 
<     <program>  Copyright (C) <year>  <name of author>
<     This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
<     This is free software, and you are welcome to redistribute it
<     under certain conditions; type `show c' for details.
< 
< The hypothetical commands `show w' and `show c' should show the appropriate
< parts of the General Public License.  Of course, your program's commands
< might be different; for a GUI interface, you would use an "about box".
< 
<   You should also get your employer (if you work as a programmer) or school,
< if any, to sign a "copyright disclaimer" for the program, if necessary.
< For more information on this, and how to apply and follow the GNU GPL, see
< <http://www.gnu.org/licenses/>.
< 
<   The GNU General Public License does not permit incorporating your program
< into proprietary programs.  If your program is a subroutine library, you
< may consider it more useful to permit linking proprietary applications with
< the library.  If this is what you want to do, use the GNU Lesser General
< Public License instead of this License.  But first, please read
< <http://www.gnu.org/philosophy/why-not-lgpl.html>.
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/lua_antlr.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/lua_antlr.py.svn-base
1,80d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>. 
< 
< import os
< import xml.parsers.expat
< 
< from abstract_syntax_tree import *
< 
< class LuaANTLRSourceFile (SourceFile):
<     extension = 'lua'
<     size_threshold = 5 
<     distance_threshold = 5
<     def __init__(self, file_name):
<         SourceFile.__init__(self, file_name)
<         class ExpatHandler:
<             def __init__(self, start_node, parent):
<                 self.parent = parent
<                 self.stack = [start_node]
<             def start_element(expat_self, xml_node_name, attrs):
<                 line_number = int(attrs["line_number"])-1
<                 line_numbers = [line_number]
<                 if line_numbers == [-1]:
<                     line_numbers = []
<                 name = attrs["name"]
<                 r = AbstractSyntaxTree(name, line_numbers, self)
<                 if name in ["stat", "chunk"]:
<                     r.markAsStatement()
<                 else:
<                     assert(xml_node_name == "node")
<                 expat_self.stack[-1].addChild(r)                
<                 expat_self.stack.append(r)
<             def end_element(self, name):
<                 self.stack.pop()
< 
<         tree_file_name  = 'temporary_ast.xml'
<         producer_class_path = os.path.join('.','lua_antlr', 'TreeProducer.jar')
<         antlr_class_path = os.path.join('.','antlr_runtime','antlr-runtime-3.1.jar')
<         if os.name in ['mac', 'posix']:
<             class_path_delimeter = ':'
<         elif os.name in ['nt', 'dos', 'ce']:
<             class_path_delimeter = ';'
<         else:
<             print 'unsupported OS'
<             assert(0)
< 
<         if os.system('java -classpath ' + producer_class_path + class_path_delimeter + antlr_class_path + ' TreeProducer %s %s 2>err.log'%(file_name, tree_file_name)):
<             f = open('err.log')
<             s = f.read()
<             f.close()
<             raise s
<         f = open('err.log')
<         s = f.read()
<         f.close()
<         if s:
<             print s
<         
<         self._tree = AbstractSyntaxTree('program')
<         handler = ExpatHandler(self._tree, self)
<         p = xml.parsers.expat.ParserCreate()
<         p.StartElementHandler = handler.start_element
<         p.EndElementHandler = handler.end_element
<         f = open(tree_file_name)
<         p.ParseFile(f)
<         f.close()
< #       os.remove(tree_file_name)
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/python_compiler.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/python_compiler.py.svn-base
1,182d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< import compiler
< import types
< import logilab.astng.nodes
< 
< from abstract_syntax_tree import *
< 
< class PythonNodeLeaf:
<     def __init__(self, val):
<         self._val = val
<     def getVal(self):
<         return self._val
<     def as_string(self):
<         return str(self.getVal())
<     def __str__(self):
<         return self.as_string()
< 
< class PythonCompilerSourceFile (SourceFile):
<     extension = 'py'
<     distance_threshold = 5
<     size_threshold = 5
<     ignored_statements = ['Import', 'From']
<     def __init__(self, file_name, func_prefixes = ()):
<         SourceFile.__init__(self, file_name)
<         self._func_prefixes = func_prefixes
<         def rec_build_tree(compiler_ast_node, is_statement=False):
<             def flatten(list):
<                 l = []
<                 for elt in list:
<                     t = type(elt)
<                     if t is tuple or t is list:
<                         for elt2 in flatten(elt):
<                             l.append(elt2)
<                     else:
<                         l.append(elt)
<                 return l
<             def add_childs(childs):             
<                 assert(type(childs) == type([]))
<                 for child in childs:                
<                     assert(isinstance(child, compiler.ast.Node))
<                     t = rec_build_tree(child, is_statement)     
<                     if t.getName() in self.ignored_statements:
<                         # TODO move it up
<                         continue
<                     t.setParent(r)
<                     r.addChild(t)                   
<             def add_leaf_child(child, name):
<                 assert(not (type(child) == type([])))
<                 assert(not isinstance(child, compiler.ast.Node))                                
<                 t = AbstractSyntaxTree(repr(child))
<                 t.setParent(r)
<                 l = PythonNodeLeaf(child)
<                 t.ast_node = l 
<                 r.addChild(t)               
<                 setattr(r.ast_node, name, l)
<                 return t
<             def add_leaf_childs(childs, name):
<                 assert(type(childs) == type([]) or type(childs) == type((0,)))
<                 a = getattr(r.ast_node, name)
<                 for i in range(len(childs)):
<                     child = childs[i]
<                     assert(not isinstance(child, compiler.ast.Node))
<                     t = AbstractSyntaxTree(repr(child))
<                     t.setParent(r)
<                     l = PythonNodeLeaf(child)
<                     t.ast_node = l 
<                     r.addChild(t)                   
<                     a[i] = l
<             def add_leaf_string_childs(childs):
<                 assert(type(childs) == type([]))
<                 for child in childs:
<                     assert(not isinstance(child, compiler.ast.Node))
<                     t = AbstractSyntaxTree(repr(child))
<                     t.setParent(t)
<                     r.addChild(t)                   
< 
<             if isinstance(compiler_ast_node, compiler.ast.Node):                
<                 name = compiler_ast_node.__class__.__name__
<                 if name == 'Function':
<                    for prefix in self._func_prefixes:
<                        if compiler_ast_node.name.startswith(prefix):
<                            # skip function that matches pattern
<                            return AbstractSyntaxTree('none')
<                 if name in ['Function', 'Class']:
<                     # ignoring class and function docs
<                     compiler_ast_node.doc = None
<                 if compiler_ast_node.lineno:
<                     lines = [compiler_ast_node.lineno-1]
<                 else:
<                     lines = []      
<                 r = AbstractSyntaxTree(name, lines, self)
<                 r.ast_node = compiler_ast_node
<                 if is_statement and compiler_ast_node.lineno: 
<                     r.markAsStatement()
<                 is_statement = (name == 'Stmt')
<                 if name == "AssAttr":
<                     add_childs([compiler_ast_node.expr])
<                     add_leaf_child(compiler_ast_node.attrname, 'attrname')
<                     add_leaf_string_childs([compiler_ast_node.flags])
<                 elif name == "AssName":
<                     add_leaf_child(compiler_ast_node.name, 'name')
< #                   add_leaf_child(compiler_ast_node.flags, 'flags')
<                 elif name == "AugAssign":
<                     add_childs([compiler_ast_node.node])
<                     add_leaf_child(compiler_ast_node.op, 'op')
<                     add_childs([compiler_ast_node.expr])
<                 elif name == "Class":
<                     add_leaf_child(compiler_ast_node.name, 'name')
< #                   print '>>>>>>>>>>>>>>>>>>>>', flatten(compiler_ast_node.bases)
<                     add_childs(flatten(compiler_ast_node.bases)) 
< #                   add_leaf_child(compiler_ast_node.doc, 'doc') we don't want class docs in our tree, do we?
<                     add_childs([compiler_ast_node.code])
<                 elif name == "Compare":
<                     add_childs([compiler_ast_node.expr])
<                     for i in range(len(compiler_ast_node.ops)):
<                         (op, expr) = compiler_ast_node.ops[i]
<                         t = add_leaf_child(op, 'op')
<                         add_childs([expr])
<                         compiler_ast_node.ops[i] = (t.ast_node, expr)
<                 elif name == "Const":
<                     add_leaf_child(repr(compiler_ast_node.value), "value")
< #               elif name == "From":
< #                   add_leaf_child(compiler_ast_node.modname, "modname")
< #                   add_childs(compiler_ast_node.names)
<                 elif name == "Function":
< #                   add_childs(compiler_ast_node.decorators)  FIXME do we need that?
<                     add_leaf_child(compiler_ast_node.name, "name")
<                     add_leaf_childs(compiler_ast_node.argnames, "argnames")
<                     if compiler_ast_node.defaults == ():
<                         compiler_ast_node.defaults = []
<                     add_childs(compiler_ast_node.defaults) #TODO incomment and fix
<                     add_leaf_string_childs([compiler_ast_node.flags])
< #                   add_leaf_child(compiler_ast_node.doc, "doc") same as class docs... we don't need them
<                     add_childs([compiler_ast_node.code])
<                 elif name == "Getattr":
<                     add_childs([compiler_ast_node.expr])
<                     add_leaf_child(compiler_ast_node.attrname, "attrname")
<                 elif name == "Global":
<                     add_leaf_childs(compiler_ast_node.names, "names")
< #               elif name == "Import":
< #                   add_leaf_childs(compiler_ast_node.names, "names")
<                 elif name == "Keyword":
<                     add_leaf_child(compiler_ast_node.name, "name")
<                     add_childs([compiler_ast_node.expr])
<                 elif name == "Lambda": 
< #                   TODO: uncomment and fix
<                     add_leaf_childs(compiler_ast_node.argnames, "argnames")                    
<                     if compiler_ast_node.defaults == ():
<                         compiler_ast_node.defaults = []
<                     add_childs(compiler_ast_node.defaults)              
<                     add_childs([compiler_ast_node.code])
<                 elif name == "Name":
<                     # the most important one :)
<                     add_leaf_child(compiler_ast_node.name, "name")
<                 else:
<                     for c in compiler_ast_node.getChildren():               
<                         t = rec_build_tree(c, is_statement)
<                         if t.getName() in self.ignored_statements:
<                             continue                    
<                         t.setParent(r)
<                         r.addChild(t)
<                 return r
<             else:
<                 return AbstractSyntaxTree(repr(compiler_ast_node))
<         self._setTree(rec_build_tree(compiler.parseFile(file_name)))
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/README.txt.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/README.txt.svn-base
1,26d0
< ===================
< Clone Digger README
< ===================
< 
< available at http://clonedigger.sourceforge.net
< 
< Clone Digger is the tool for finding software clones. 
< Currently only Python language is supported, Java support will be added soon.
< See the site for details.
< 
< Usage
< =====
< 
< The simplest way of running Clone Digger is::
< 
<     clonedigger source_file_1 source_file_2 ...
< 
< Or::
< 
<     clonedigger --recursive path_to_source_tree
< 
< Don't forget to remove automatically generated sources, tests and third party libraries from the source tree.
< 
< See http://clonedigger.sourceforge.net/documentation.html for more complex arguments.
< 
< The available arguments can be obtained using '--help' also.
diff -r -N code-worker/tasks/clonedigger/.svn/text-base/suffix_tree.py.svn-base code-worker/code-worker/tasks/clonedigger/.svn/text-base/suffix_tree.py.svn-base
1,119d0
< #    Copyright 2008 Peter Bulychev
< #    http://clonedigger.sourceforge.net
< #
< #    This file is part of Clone Digger.
< #
< #    Clone Digger is free software: you can redistribute it and/or modify
< #    it under the terms of the GNU General Public License as published by
< #    the Free Software Foundation, either version 3 of the License, or
< #    (at your option) any later version.
< #
< #    Clone Digger is distributed in the hope that it will be useful,
< #    but WITHOUT ANY WARRANTY; without even the implied warranty of
< #    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
< #    GNU General Public License for more details.
< #
< #   You should have received a copy of the GNU General Public License
< #   along with Clone Digger.  If not, see <http://www.gnu.org/licenses/>.
< 
< 
< class SuffixTree:    
<     class StringPosition:
<         def __init__(self, string, position,prevelem):
<             self.string = string
<             self.position = position
<             self.prevelem = prevelem
<     class SuffixTreeNode:
<         def __init__(self):
<             self.childs = {} #
<             self.string_positions = []
<             self.ending_strings = []
< 
<     def __init__(self, f_code):
<         self._node = self.SuffixTreeNode()
<         self._f_code = f_code
<     def _add(self, string, prevelem):
<         pos = 0
<         node = self._node
<         for pos in range(len(string)):
<             e = string[pos]
<             code = self._f_code(e)
<             node.string_positions.append(self.StringPosition(string, pos, prevelem))
<             if not node.childs.has_key(code):
<                 node.childs[code] = self.SuffixTreeNode()
<             node = node.childs[code]
<         node.ending_strings.append(self.StringPosition(string, pos+1, prevelem))
<     def add(self, string):
<         for i in range(len(string)):
<             if i == 0:
<                 prevelem = None
<             else:
<                 prevelem = self._f_code(string[i-1])
<             self._add(string[i:],prevelem)
<     def getBestMaxSubstrings(self, threshold, f, f_elem, node = None, initial_threshold=None):  
<         if initial_threshold==None:
<             initial_threshold = threshold
<         def check_left_diverse_and_add(s1, s2, p):
<             if ((s1.prevelem == None) or (s2.prevelem == None) or (s1.prevelem != s2.prevelem)) and s1.position>p:
<                 candidate = (s1.string[:s1.position-p], s2.string[:s2.position-p])
<                 if f_elem(candidate[0]) >= initial_threshold or \
<                     f_elem(candidate[1]) >= initial_threshold:
<                     r.append(candidate)
<                 return True
<             else:
<                 return False
<         if node == None:
<             node = self._node
<         r = []  
<         if threshold <= 0:          
<             for s1 in node.ending_strings:
<                 for s2 in node.string_positions:
<                     if s1.string == s2.string:
<                         continue
<                     check_left_diverse_and_add(s1, s2, 0)
<             for i in range(len(node.ending_strings)):
<                 for j in range(i):
<                     s1 = node.ending_strings[i]
<                     s2 = node.ending_strings[j]
<                     check_left_diverse_and_add(s1, s2, 0)
<             for i in range(len(node.childs.keys())):
<                 for j in range(i):
<                     c1 = node.childs.keys()[i]
<                     c2 = node.childs.keys()[j]
<                     for s1 in node.childs[c1].string_positions + node.childs[c1].ending_strings:
<                         for s2 in node.childs[c2].string_positions + node.childs[c2].ending_strings:
<                             check_left_diverse_and_add(s1, s2, 1)
<         for (code, child) in node.childs.items():
<             r += self.getBestMaxSubstrings(threshold - f(code), f, f_elem, child, initial_threshold)
<         return r
< 
< if __name__ == '__main__':
<     class Elem:
<         def __init__(self, code):
<             self._code = code
<         def getCode(self):
<             return self._code
<         def __str__(self):
<             return str(self._code)
<     def test1():
<         t = SuffixTree()
<         for w in ['abcPeter', 'Pet1erbca', 'Peter', 'aPet0--']:
<             t.add([Elem(c) for c in w])
<         maxs =  t.getBestMaxSubstrings(3)
<         l =  []
<         for (s1, s2) in maxs:
<             l.append([''.join([str(e) for e in s1]), ''.join([str(e) for e in s2])])
<         assert(l == [['Pe1t', 'P2et'], ['P3et', 'Pe4t'], ['Pet', 'Pet'], ['Pet', 'Pet'], ['Pet', 'Pet'], ['Peter', 'Peter']])
<     def test2():
<         t = SuffixTree()
<         for w in ['a', 'aa']:
<             t.add([Elem(c) for c in w])
<         maxs =  t.getBestMaxSubstrings(0)
<         l =  []
<         for (s1, s2) in maxs:       
<             l.append([''.join([str(e) for e in s1]), ''.join([str(e) for e in s2])])
<         assert(l == [['a', 'a'], ['a', 'a'], ['a', 'a']]) 
<     for s in dir():
<         if s.find('test') == 0:
<             eval(s + '()')
< 
diff -r -N code-worker/tasks/pep8/CHANGES.txt code-worker/code-worker/tasks/pep8/CHANGES.txt
1,131d0
< Changelog
< =========
< 
< 
< 0.6.0 (2010-09-19)
< ------------------
< 
< * Test suite reorganized and enhanced in order to check more failures
<   with fewer test files.  Read the ``run_tests`` docstring for details
<   about the syntax.
< 
< * Fix E225: accept ``print >>sys.stderr, "..."`` syntax.
< 
< * Fix E501 for lines containing multibyte encoded characters. (Issue #7)
< 
< * Fix E221, E222, E223, E224 not detected in some cases. (Issue #16)
< 
< * Fix E211 to reject ``v = dic['a'] ['b']``. (Issue #17)
< 
< * Exit code is always 1 if any error or warning is found. (Issue #10)
< 
< * ``--ignore`` checks are now really ignored, especially in
<   conjunction with ``--count``. (Issue #8)
< 
< * Blank lines with spaces yield W293 instead of W291: some developers
<   want to ignore this warning and indent the blank lines to paste their
<   code easily in the Python interpreter.
< 
< * Fix E301: do not require a blank line before an indented block. (Issue #14)
< 
< * Fix E203 to accept NumPy slice notation ``a[0, :]``. (Issue #13)
< 
< * Performance improvements.
< 
< * Fix decoding and checking non-UTF8 files in Python 3.
< 
< * Fix E225: reject ``True+False`` when running on Python 3.
< 
< * Fix an exception when the line starts with an operator.
< 
< * Allow a new line before closing ``)``, ``}`` or ``]``. (Issue #5)
< 
< 
< 0.5.0 (2010-02-17)
< ------------------
< 
< * Changed the ``--count`` switch to print to sys.stderr and set
<   exit code to 1 if any error or warning is found.
< 
< * E241 and E242 are removed from the standard checks. If you want to
<   include these checks, use switch ``--select=E,W``. (Issue #4)
< 
< * Blank line is not mandatory before the first class method or nested
<   function definition, even if there's a docstring. (Issue #1)
< 
< * Add the switch ``--version``.
< 
< * Fix decoding errors with Python 3. (Issue #13 [1]_)
< 
< * Add ``--select`` option which is mirror of ``--ignore``.
< 
< * Add checks E261 and E262 for spaces before inline comments.
< 
< * New check W604 warns about deprecated usage of backticks.
< 
< * New check W603 warns about the deprecated operator ``<>``.
< 
< * Performance improvement, due to rewriting of E225.
< 
< * E225 now accepts:
< 
<   - no whitespace after unary operator or similar. (Issue #9 [1]_)
< 
<   - lambda function with argument unpacking or keyword defaults.
< 
< * Reserve "2 blank lines" for module-level logical blocks. (E303)
< 
< * Allow multi-line comments. (E302, issue #10 [1]_)
< 
< 
< 0.4.2 (2009-10-22)
< ------------------
< 
< * Decorators on classes and class methods are OK now.
< 
< 
< 0.4 (2009-10-20)
< ----------------
< 
< * Support for all versions of Python from 2.3 to 3.1.
< 
< * New and greatly expanded self tests.
< 
< * Added ``--count`` option to print the total number of errors and warnings.
< 
< * Further improvements to the handling of comments and blank lines.
<   (Issue #1 [1]_ and others changes.)
< 
< * Check all py files in directory when passed a directory (Issue
<   #2 [1]_). This also prevents an exception when traversing directories
<   with non ``*.py`` files.
< 
< * E231 should allow commas to be followed by ``)``. (Issue #3 [1]_)
< 
< * Spaces are no longer required around the equals sign for keyword
<   arguments or default parameter values.
< 
< 
< .. [1] These issues refer to the `previous issue tracker`__.
< .. __:  http://github.com/cburroughs/pep8.py/issues
< 
< 
< 0.3.1 (2009-09-14)
< ------------------
< 
< * Fixes for comments: do not count them when checking for blank lines between
<   items.
< 
< * Added setup.py for pypi upload and easy_installability.
< 
< 
< 0.2 (2007-10-16)
< ----------------
< 
< * Loads of fixes and improvements.
< 
< 
< 0.1 (2006-10-01)
< ----------------
< 
< * First release.
diff -r -N code-worker/tasks/pep8/.gitignore code-worker/code-worker/tasks/pep8/.gitignore
1d0
< pep8.egg-info
diff -r -N code-worker/tasks/pep8/Makefile code-worker/code-worker/tasks/pep8/Makefile
1,33d0
< test :
< 	python pep8.py --testsuite testsuite
< 
< selftest :
< 	python pep8.py --repeat --statistics pep8.py
< 
< doctest :
< 	python pep8.py --doctest
< 
< alltest : test selftest doctest
< 
< multitest :
< 	python2.3 pep8.py --testsuite testsuite
< 	python2.4 pep8.py --testsuite testsuite
< 	python2.5 pep8.py --testsuite testsuite
< 	python2.6 pep8.py --testsuite testsuite
< 	python2.7 pep8.py --testsuite testsuite
< 	python3.0 pep8.py --testsuite testsuite
< 	python3.1 pep8.py --testsuite testsuite
< 	python2.3 pep8.py --doctest
< 	python2.4 pep8.py --doctest
< 	python2.5 pep8.py --doctest
< 	python2.6 pep8.py --doctest
< 	python2.7 pep8.py --doctest
< 	python3.0 pep8.py --doctest
< 	python3.1 pep8.py --doctest
< 	python2.3 pep8.py --repeat --statistics pep8.py
< 	python2.4 pep8.py --repeat --statistics pep8.py
< 	python2.5 pep8.py --repeat --statistics pep8.py
< 	python2.6 pep8.py --repeat --statistics pep8.py
< 	python2.7 pep8.py --repeat --statistics pep8.py
< 	python3.0 pep8.py --repeat --statistics pep8.py
< 	python3.1 pep8.py --repeat --statistics pep8.py
diff -r -N code-worker/tasks/pep8/MANIFEST.in code-worker/code-worker/tasks/pep8/MANIFEST.in
1,3d0
< include pep8.py
< include *.txt
< include *.rst
diff -r -N code-worker/tasks/pep8/pep8.py code-worker/code-worker/tasks/pep8/pep8.py
1,1360d0
< #!/usr/bin/python
< # pep8.py - Check Python source code formatting, according to PEP 8
< # Copyright (C) 2006 Johann C. Rocholl <johann@rocholl.net>
< #
< # Permission is hereby granted, free of charge, to any person
< # obtaining a copy of this software and associated documentation files
< # (the "Software"), to deal in the Software without restriction,
< # including without limitation the rights to use, copy, modify, merge,
< # publish, distribute, sublicense, and/or sell copies of the Software,
< # and to permit persons to whom the Software is furnished to do so,
< # subject to the following conditions:
< #
< # The above copyright notice and this permission notice shall be
< # included in all copies or substantial portions of the Software.
< #
< # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
< # EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
< # MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
< # NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
< # BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
< # ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
< # CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
< # SOFTWARE.
< 
< """
< Check Python source code formatting, according to PEP 8:
< http://www.python.org/dev/peps/pep-0008/
< 
< For usage and a list of options, try this:
< $ python pep8.py -h
< 
< This program and its regression test suite live here:
< http://github.com/jcrocholl/pep8
< 
< Groups of errors and warnings:
< E errors
< W warnings
< 100 indentation
< 200 whitespace
< 300 blank lines
< 400 imports
< 500 line length
< 600 deprecation
< 700 statements
< 
< You can add checks to this program by writing plugins. Each plugin is
< a simple function that is called for each line of source code, either
< physical or logical.
< 
< Physical line:
< - Raw line of text from the input file.
< 
< Logical line:
< - Multi-line statements converted to a single line.
< - Stripped left and right.
< - Contents of strings replaced with 'xxx' of same length.
< - Comments removed.
< 
< The check function requests physical or logical lines by the name of
< the first argument:
< 
< def maximum_line_length(physical_line)
< def extraneous_whitespace(logical_line)
< def blank_lines(logical_line, blank_lines, indent_level, line_number)
< 
< The last example above demonstrates how check plugins can request
< additional information with extra arguments. All attributes of the
< Checker object are available. Some examples:
< 
< lines: a list of the raw lines from the input file
< tokens: the tokens that contribute to this logical line
< line_number: line number in the input file
< blank_lines: blank lines before this one
< indent_char: first indentation character in this file (' ' or '\t')
< indent_level: indentation (with tabs expanded to multiples of 8)
< previous_indent_level: indentation on previous line
< previous_logical: previous logical line
< 
< The docstring of each check function shall be the relevant part of
< text from PEP 8. It is printed if the user enables --show-pep8.
< Several docstrings contain examples directly from the PEP 8 document.
< 
< Okay: spam(ham[1], {eggs: 2})
< E201: spam( ham[1], {eggs: 2})
< 
< These examples are verified automatically when pep8.py is run with the
< --doctest option. You can add examples for your own check functions.
< The format is simple: "Okay" or error/warning code followed by colon
< and space, the rest of the line is example source code. If you put 'r'
< before the docstring, you can use \n for newline, \t for tab and \s
< for space.
< 
< """
< 
< __version__ = '0.5.1dev'
< 
< import os
< import sys
< import re
< import time
< import inspect
< import keyword
< import tokenize
< from optparse import OptionParser
< from fnmatch import fnmatch
< try:
<     frozenset
< except NameError:
<     from sets import ImmutableSet as frozenset
< 
< 
< DEFAULT_EXCLUDE = '.svn,CVS,.bzr,.hg,.git'
< DEFAULT_IGNORE = 'E24'
< MAX_LINE_LENGTH = 79
< 
< INDENT_REGEX = re.compile(r'([ \t]*)')
< RAISE_COMMA_REGEX = re.compile(r'raise\s+\w+\s*(,)')
< SELFTEST_REGEX = re.compile(r'(Okay|[EW]\d{3}):\s(.*)')
< ERRORCODE_REGEX = re.compile(r'[EW]\d{3}')
< DOCSTRING_REGEX = re.compile(r'u?r?["\']')
< WHITESPACE_AROUND_OPERATOR_REGEX = \
<     re.compile('([^\w\s]*)\s*(\t|  )\s*([^\w\s]*)')
< EXTRANEOUS_WHITESPACE_REGEX = re.compile(r'[[({] | []}),;:]')
< WHITESPACE_AROUND_NAMED_PARAMETER_REGEX = \
<     re.compile(r'[()]|\s=[^=]|[^=!<>]=\s')
< 
< 
< WHITESPACE = ' \t'
< 
< BINARY_OPERATORS = frozenset(['**=', '*=', '+=', '-=', '!=', '<>',
<     '%=', '^=', '&=', '|=', '==', '/=', '//=', '<=', '>=', '<<=', '>>=',
<     '%',  '^',  '&',  '|',  '=',  '/',  '//',  '<',  '>',  '<<'])
< UNARY_OPERATORS = frozenset(['>>', '**', '*', '+', '-'])
< OPERATORS = BINARY_OPERATORS | UNARY_OPERATORS
< SKIP_TOKENS = frozenset([tokenize.COMMENT, tokenize.NL, tokenize.INDENT,
<                          tokenize.DEDENT, tokenize.NEWLINE])
< E225NOT_KEYWORDS = (frozenset(keyword.kwlist + ['print']) -
<                     frozenset(['False', 'None', 'True']))
< BENCHMARK_KEYS = ('directories', 'files', 'logical lines', 'physical lines')
< 
< options = None
< args = None
< 
< 
< ##############################################################################
< # Plugins (check functions) for physical lines
< ##############################################################################
< 
< 
< def tabs_or_spaces(physical_line, indent_char):
<     r"""
<     Never mix tabs and spaces.
< 
<     The most popular way of indenting Python is with spaces only.  The
<     second-most popular way is with tabs only.  Code indented with a mixture
<     of tabs and spaces should be converted to using spaces exclusively.  When
<     invoking the Python command line interpreter with the -t option, it issues
<     warnings about code that illegally mixes tabs and spaces.  When using -tt
<     these warnings become errors.  These options are highly recommended!
< 
<     Okay: if a == 0:\n        a = 1\n        b = 1
<     E101: if a == 0:\n        a = 1\n\tb = 1
<     """
<     indent = INDENT_REGEX.match(physical_line).group(1)
<     for offset, char in enumerate(indent):
<         if char != indent_char:
<             return offset, "E101 indentation contains mixed spaces and tabs"
< 
< 
< def tabs_obsolete(physical_line):
<     r"""
<     For new projects, spaces-only are strongly recommended over tabs.  Most
<     editors have features that make this easy to do.
< 
<     Okay: if True:\n    return
<     W191: if True:\n\treturn
<     """
<     indent = INDENT_REGEX.match(physical_line).group(1)
<     if indent.count('\t'):
<         return indent.index('\t'), "W191 indentation contains tabs"
< 
< 
< def trailing_whitespace(physical_line):
<     r"""
<     JCR: Trailing whitespace is superfluous.
<     FBM: Except when it occurs as part of a blank line (i.e. the line is
<          nothing but whitespace). According to Python docs[1] a line with only
<          whitespace is considered a blank line, and is to be ignored. However,
<          matching a blank line to its indentation level avoids mistakenly
<          terminating a multi-line statement (e.g. class declaration) when
<          pasting code into the standard Python interpreter.
< 
<          [1] http://docs.python.org/reference/lexical_analysis.html#blank-lines
< 
<     The warning returned varies on whether the line itself is blank, for easier
<     filtering for those who want to indent their blank lines.
< 
<     Okay: spam(1)
<     W291: spam(1)\s
<     W293: class Foo(object):\n    \n    bang = 12
<     """
<     physical_line = physical_line.rstrip('\n')    # chr(10), newline
<     physical_line = physical_line.rstrip('\r')    # chr(13), carriage return
<     physical_line = physical_line.rstrip('\x0c')  # chr(12), form feed, ^L
<     stripped = physical_line.rstrip()
<     if physical_line != stripped:
<         if stripped:
<             return len(stripped), "W291 trailing whitespace"
<         else:
<             return 0, "W293 blank line contains whitespace"
< 
< 
< def trailing_blank_lines(physical_line, lines, line_number):
<     r"""
<     JCR: Trailing blank lines are superfluous.
< 
<     Okay: spam(1)
<     W391: spam(1)\n
<     """
<     if physical_line.strip() == '' and line_number == len(lines):
<         return 0, "W391 blank line at end of file"
< 
< 
< def missing_newline(physical_line):
<     """
<     JCR: The last line should have a newline.
<     """
<     if physical_line.rstrip() == physical_line:
<         return len(physical_line), "W292 no newline at end of file"
< 
< 
< def maximum_line_length(physical_line):
<     """
<     Limit all lines to a maximum of 79 characters.
< 
<     There are still many devices around that are limited to 80 character
<     lines; plus, limiting windows to 80 characters makes it possible to have
<     several windows side-by-side.  The default wrapping on such devices looks
<     ugly.  Therefore, please limit all lines to a maximum of 79 characters.
<     For flowing long blocks of text (docstrings or comments), limiting the
<     length to 72 characters is recommended.
<     """
<     line = physical_line.rstrip()
<     length = len(line)
<     if length > MAX_LINE_LENGTH:
<         try:
<             # The line could contain multi-byte characters
<             if not hasattr(line, 'decode'):   # Python 3
<                 line = line.encode('latin-1')
<             length = len(line.decode('utf-8'))
<         except UnicodeDecodeError:
<             pass
<     if length > MAX_LINE_LENGTH:
<         return MAX_LINE_LENGTH, "E501 line too long (%d characters)" % length
< 
< 
< ##############################################################################
< # Plugins (check functions) for logical lines
< ##############################################################################
< 
< 
< def blank_lines(logical_line, blank_lines, indent_level, line_number,
<                 previous_logical, previous_indent_level,
<                 blank_lines_before_comment):
<     r"""
<     Separate top-level function and class definitions with two blank lines.
< 
<     Method definitions inside a class are separated by a single blank line.
< 
<     Extra blank lines may be used (sparingly) to separate groups of related
<     functions.  Blank lines may be omitted between a bunch of related
<     one-liners (e.g. a set of dummy implementations).
< 
<     Use blank lines in functions, sparingly, to indicate logical sections.
< 
<     Okay: def a():\n    pass\n\n\ndef b():\n    pass
<     Okay: def a():\n    pass\n\n\n# Foo\n# Bar\n\ndef b():\n    pass
< 
<     E301: class Foo:\n    b = 0\n    def bar():\n        pass
<     E302: def a():\n    pass\n\ndef b(n):\n    pass
<     E303: def a():\n    pass\n\n\n\ndef b(n):\n    pass
<     E303: def a():\n\n\n\n    pass
<     E304: @decorator\n\ndef a():\n    pass
<     """
<     if line_number == 1:
<         return  # Don't expect blank lines before the first line
<     max_blank_lines = max(blank_lines, blank_lines_before_comment)
<     if previous_logical.startswith('@'):
<         if max_blank_lines:
<             return 0, "E304 blank lines found after function decorator"
<     elif max_blank_lines > 2 or (indent_level and max_blank_lines == 2):
<         return 0, "E303 too many blank lines (%d)" % max_blank_lines
<     elif (logical_line.startswith('def ') or
<           logical_line.startswith('class ') or
<           logical_line.startswith('@')):
<         if indent_level:
<             if not (max_blank_lines or previous_indent_level < indent_level or
<                     DOCSTRING_REGEX.match(previous_logical)):
<                 return 0, "E301 expected 1 blank line, found 0"
<         elif max_blank_lines != 2:
<             return 0, "E302 expected 2 blank lines, found %d" % max_blank_lines
< 
< 
< def extraneous_whitespace(logical_line):
<     """
<     Avoid extraneous whitespace in the following situations:
< 
<     - Immediately inside parentheses, brackets or braces.
< 
<     - Immediately before a comma, semicolon, or colon.
< 
<     Okay: spam(ham[1], {eggs: 2})
<     E201: spam( ham[1], {eggs: 2})
<     E201: spam(ham[ 1], {eggs: 2})
<     E201: spam(ham[1], { eggs: 2})
<     E202: spam(ham[1], {eggs: 2} )
<     E202: spam(ham[1 ], {eggs: 2})
<     E202: spam(ham[1], {eggs: 2 })
< 
<     E203: if x == 4: print x, y; x, y = y , x
<     E203: if x == 4: print x, y ; x, y = y, x
<     E203: if x == 4 : print x, y; x, y = y, x
<     """
<     line = logical_line
<     for match in EXTRANEOUS_WHITESPACE_REGEX.finditer(line):
<         text = match.group()
<         char = text.strip()
<         found = match.start()
<         if text == char + ' ' and char in '([{':
<             return found + 1, "E201 whitespace after '%s'" % char
<         if text == ' ' + char and line[found - 1] != ',':
<             if char in '}])':
<                 return found, "E202 whitespace before '%s'" % char
<             if char in ',;:':
<                 return found, "E203 whitespace before '%s'" % char
< 
< 
< def missing_whitespace(logical_line):
<     """
<     JCR: Each comma, semicolon or colon should be followed by whitespace.
< 
<     Okay: [a, b]
<     Okay: (3,)
<     Okay: a[1:4]
<     Okay: a[:4]
<     Okay: a[1:]
<     Okay: a[1:4:2]
<     E231: ['a','b']
<     E231: foo(bar,baz)
<     """
<     line = logical_line
<     for index in range(len(line) - 1):
<         char = line[index]
<         if char in ',;:' and line[index + 1] not in WHITESPACE:
<             before = line[:index]
<             if char == ':' and before.count('[') > before.count(']'):
<                 continue  # Slice syntax, no space required
<             if char == ',' and line[index + 1] == ')':
<                 continue  # Allow tuple with only one element: (3,)
<             return index, "E231 missing whitespace after '%s'" % char
< 
< 
< def indentation(logical_line, previous_logical, indent_char,
<                 indent_level, previous_indent_level):
<     r"""
<     Use 4 spaces per indentation level.
< 
<     For really old code that you don't want to mess up, you can continue to
<     use 8-space tabs.
< 
<     Okay: a = 1
<     Okay: if a == 0:\n    a = 1
<     E111:   a = 1
< 
<     Okay: for item in items:\n    pass
<     E112: for item in items:\npass
< 
<     Okay: a = 1\nb = 2
<     E113: a = 1\n    b = 2
<     """
<     if indent_char == ' ' and indent_level % 4:
<         return 0, "E111 indentation is not a multiple of four"
<     indent_expect = previous_logical.endswith(':')
<     if indent_expect and indent_level <= previous_indent_level:
<         return 0, "E112 expected an indented block"
<     if indent_level > previous_indent_level and not indent_expect:
<         return 0, "E113 unexpected indentation"
< 
< 
< def whitespace_before_parameters(logical_line, tokens):
<     """
<     Avoid extraneous whitespace in the following situations:
< 
<     - Immediately before the open parenthesis that starts the argument
<       list of a function call.
< 
<     - Immediately before the open parenthesis that starts an indexing or
<       slicing.
< 
<     Okay: spam(1)
<     E211: spam (1)
< 
<     Okay: dict['key'] = list[index]
<     E211: dict ['key'] = list[index]
<     E211: dict['key'] = list [index]
<     """
<     prev_type = tokens[0][0]
<     prev_text = tokens[0][1]
<     prev_end = tokens[0][3]
<     for index in range(1, len(tokens)):
<         token_type, text, start, end, line = tokens[index]
<         if (token_type == tokenize.OP and
<             text in '([' and
<             start != prev_end and
<             (prev_type == tokenize.NAME or prev_text in '}])') and
<             # Syntax "class A (B):" is allowed, but avoid it
<             (index < 2 or tokens[index - 2][1] != 'class') and
<             # Allow "return (a.foo for a in range(5))"
<             (not keyword.iskeyword(prev_text))):
<             return prev_end, "E211 whitespace before '%s'" % text
<         prev_type = token_type
<         prev_text = text
<         prev_end = end
< 
< 
< def whitespace_around_operator(logical_line):
<     """
<     Avoid extraneous whitespace in the following situations:
< 
<     - More than one space around an assignment (or other) operator to
<       align it with another.
< 
<     Okay: a = 12 + 3
<     E221: a = 4  + 5
<     E222: a = 4 +  5
<     E223: a = 4\t+ 5
<     E224: a = 4 +\t5
<     """
<     for match in WHITESPACE_AROUND_OPERATOR_REGEX.finditer(logical_line):
<         before, whitespace, after = match.groups()
<         tab = whitespace == '\t'
<         offset = match.start(2)
<         if before in OPERATORS:
<             return offset, (tab and "E224 tab after operator" or
<                             "E222 multiple spaces after operator")
<         elif after in OPERATORS:
<             return offset, (tab and "E223 tab before operator" or
<                             "E221 multiple spaces before operator")
< 
< 
< def missing_whitespace_around_operator(logical_line, tokens):
<     r"""
<     - Always surround these binary operators with a single space on
<       either side: assignment (=), augmented assignment (+=, -= etc.),
<       comparisons (==, <, >, !=, <>, <=, >=, in, not in, is, is not),
<       Booleans (and, or, not).
< 
<     - Use spaces around arithmetic operators.
< 
<     Okay: i = i + 1
<     Okay: submitted += 1
<     Okay: x = x * 2 - 1
<     Okay: hypot2 = x * x + y * y
<     Okay: c = (a + b) * (a - b)
<     Okay: foo(bar, key='word', *args, **kwargs)
<     Okay: baz(**kwargs)
<     Okay: negative = -1
<     Okay: spam(-1)
<     Okay: alpha[:-i]
<     Okay: if not -5 < x < +5:\n    pass
<     Okay: lambda *args, **kw: (args, kw)
< 
<     E225: i=i+1
<     E225: submitted +=1
<     E225: x = x*2 - 1
<     E225: hypot2 = x*x + y*y
<     E225: c = (a+b) * (a-b)
<     E225: c = alpha -4
<     E225: z = x **y
<     """
<     parens = 0
<     need_space = False
<     prev_type = tokenize.OP
<     prev_text = prev_end = None
<     for token_type, text, start, end, line in tokens:
<         if token_type in (tokenize.NL, tokenize.NEWLINE, tokenize.ERRORTOKEN):
<             # ERRORTOKEN is triggered by backticks in Python 3000
<             continue
<         if text in ('(', 'lambda'):
<             parens += 1
<         elif text == ')':
<             parens -= 1
<         if need_space:
<             if start != prev_end:
<                 need_space = False
<             elif text == '>' and prev_text == '<':
<                 # Tolerate the "<>" operator, even if running Python 3
<                 pass
<             else:
<                 return prev_end, "E225 missing whitespace around operator"
<         elif token_type == tokenize.OP and prev_end is not None:
<             if text == '=' and parens:
<                 # Allow keyword args or defaults: foo(bar=None).
<                 pass
<             elif text in BINARY_OPERATORS:
<                 need_space = True
<             elif text in UNARY_OPERATORS:
<                 # Allow unary operators: -123, -x, +1.
<                 # Allow argument unpacking: foo(*args, **kwargs).
<                 if prev_type == tokenize.OP:
<                     if prev_text in '}])':
<                         need_space = True
<                 elif prev_type == tokenize.NAME:
<                     if prev_text not in E225NOT_KEYWORDS:
<                         need_space = True
<                 else:
<                     need_space = True
<             if need_space and start == prev_end:
<                 return prev_end, "E225 missing whitespace around operator"
<         prev_type = token_type
<         prev_text = text
<         prev_end = end
< 
< 
< def whitespace_around_comma(logical_line):
<     """
<     Avoid extraneous whitespace in the following situations:
< 
<     - More than one space around an assignment (or other) operator to
<       align it with another.
< 
<     JCR: This should also be applied around comma etc.
<     Note: these checks are disabled by default
< 
<     Okay: a = (1, 2)
<     E241: a = (1,  2)
<     E242: a = (1,\t2)
<     """
<     line = logical_line
<     for separator in ',;:':
<         found = line.find(separator + '  ')
<         if found > -1:
<             return found + 1, "E241 multiple spaces after '%s'" % separator
<         found = line.find(separator + '\t')
<         if found > -1:
<             return found + 1, "E242 tab after '%s'" % separator
< 
< 
< def whitespace_around_named_parameter_equals(logical_line):
<     """
<     Don't use spaces around the '=' sign when used to indicate a
<     keyword argument or a default parameter value.
< 
<     Okay: def complex(real, imag=0.0):
<     Okay: return magic(r=real, i=imag)
<     Okay: boolean(a == b)
<     Okay: boolean(a != b)
<     Okay: boolean(a <= b)
<     Okay: boolean(a >= b)
< 
<     E251: def complex(real, imag = 0.0):
<     E251: return magic(r = real, i = imag)
<     """
<     parens = 0
<     for match in WHITESPACE_AROUND_NAMED_PARAMETER_REGEX.finditer(
<             logical_line):
<         text = match.group()
<         if parens and len(text) == 3:
<             issue = "E251 no spaces around keyword / parameter equals"
<             return match.start(), issue
<         if text == '(':
<             parens += 1
<         elif text == ')':
<             parens -= 1
< 
< 
< def whitespace_before_inline_comment(logical_line, tokens):
<     """
<     Separate inline comments by at least two spaces.
< 
<     An inline comment is a comment on the same line as a statement.  Inline
<     comments should be separated by at least two spaces from the statement.
<     They should start with a # and a single space.
< 
<     Okay: x = x + 1  # Increment x
<     Okay: x = x + 1    # Increment x
<     E261: x = x + 1 # Increment x
<     E262: x = x + 1  #Increment x
<     E262: x = x + 1  #  Increment x
<     """
<     prev_end = (0, 0)
<     for token_type, text, start, end, line in tokens:
<         if token_type == tokenize.NL:
<             continue
<         if token_type == tokenize.COMMENT:
<             if not line[:start[1]].strip():
<                 continue
<             if prev_end[0] == start[0] and start[1] < prev_end[1] + 2:
<                 return (prev_end,
<                         "E261 at least two spaces before inline comment")
<             if (len(text) > 1 and text.startswith('#  ')
<                            or not text.startswith('# ')):
<                 return start, "E262 inline comment should start with '# '"
<         else:
<             prev_end = end
< 
< 
< def imports_on_separate_lines(logical_line):
<     r"""
<     Imports should usually be on separate lines.
< 
<     Okay: import os\nimport sys
<     E401: import sys, os
< 
<     Okay: from subprocess import Popen, PIPE
<     Okay: from myclas import MyClass
<     Okay: from foo.bar.yourclass import YourClass
<     Okay: import myclass
<     Okay: import foo.bar.yourclass
<     """
<     line = logical_line
<     if line.startswith('import '):
<         found = line.find(',')
<         if found > -1:
<             return found, "E401 multiple imports on one line"
< 
< 
< def compound_statements(logical_line):
<     r"""
<     Compound statements (multiple statements on the same line) are
<     generally discouraged.
< 
<     While sometimes it's okay to put an if/for/while with a small body
<     on the same line, never do this for multi-clause statements. Also
<     avoid folding such long lines!
< 
<     Okay: if foo == 'blah':\n    do_blah_thing()
<     Okay: do_one()
<     Okay: do_two()
<     Okay: do_three()
< 
<     E701: if foo == 'blah': do_blah_thing()
<     E701: for x in lst: total += x
<     E701: while t < 10: t = delay()
<     E701: if foo == 'blah': do_blah_thing()
<     E701: else: do_non_blah_thing()
<     E701: try: something()
<     E701: finally: cleanup()
<     E701: if foo == 'blah': one(); two(); three()
< 
<     E702: do_one(); do_two(); do_three()
<     """
<     line = logical_line
<     found = line.find(':')
<     if -1 < found < len(line) - 1:
<         before = line[:found]
<         if (before.count('{') <= before.count('}') and  # {'a': 1} (dict)
<             before.count('[') <= before.count(']') and  # [1:2] (slice)
<             not re.search(r'\blambda\b', before)):      # lambda x: x
<             return found, "E701 multiple statements on one line (colon)"
<     found = line.find(';')
<     if -1 < found:
<         return found, "E702 multiple statements on one line (semicolon)"
< 
< 
< def python_3000_has_key(logical_line):
<     """
<     The {}.has_key() method will be removed in the future version of
<     Python. Use the 'in' operation instead, like:
<     d = {"a": 1, "b": 2}
<     if "b" in d:
<         print d["b"]
<     """
<     pos = logical_line.find('.has_key(')
<     if pos > -1:
<         return pos, "W601 .has_key() is deprecated, use 'in'"
< 
< 
< def python_3000_raise_comma(logical_line):
<     """
<     When raising an exception, use "raise ValueError('message')"
<     instead of the older form "raise ValueError, 'message'".
< 
<     The paren-using form is preferred because when the exception arguments
<     are long or include string formatting, you don't need to use line
<     continuation characters thanks to the containing parentheses.  The older
<     form will be removed in Python 3000.
<     """
<     match = RAISE_COMMA_REGEX.match(logical_line)
<     if match:
<         return match.start(1), "W602 deprecated form of raising exception"
< 
< 
< def python_3000_not_equal(logical_line):
<     """
<     != can also be written <>, but this is an obsolete usage kept for
<     backwards compatibility only. New code should always use !=.
<     The older syntax is removed in Python 3000.
<     """
<     pos = logical_line.find('<>')
<     if pos > -1:
<         return pos, "W603 '<>' is deprecated, use '!='"
< 
< 
< def python_3000_backticks(logical_line):
<     """
<     Backticks are removed in Python 3000.
<     Use repr() instead.
<     """
<     pos = logical_line.find('`')
<     if pos > -1:
<         return pos, "W604 backticks are deprecated, use 'repr()'"
< 
< 
< ##############################################################################
< # Helper functions
< ##############################################################################
< 
< 
< if '' == ''.encode():
<     # Python 2: implicit encoding.
<     def readlines(filename):
<         return open(filename).readlines()
< else:
<     # Python 3: decode to latin-1.
<     # This function is lazy, it does not read the encoding declaration.
<     # XXX: use tokenize.detect_encoding()
<     def readlines(filename):
<         return open(filename, encoding='latin-1').readlines()
< 
< 
< def expand_indent(line):
<     """
<     Return the amount of indentation.
<     Tabs are expanded to the next multiple of 8.
< 
<     >>> expand_indent('    ')
<     4
<     >>> expand_indent('\\t')
<     8
<     >>> expand_indent('    \\t')
<     8
<     >>> expand_indent('       \\t')
<     8
<     >>> expand_indent('        \\t')
<     16
<     """
<     result = 0
<     for char in line:
<         if char == '\t':
<             result = result // 8 * 8 + 8
<         elif char == ' ':
<             result += 1
<         else:
<             break
<     return result
< 
< 
< def mute_string(text):
<     """
<     Replace contents with 'xxx' to prevent syntax matching.
< 
<     >>> mute_string('"abc"')
<     '"xxx"'
<     >>> mute_string("'''abc'''")
<     "'''xxx'''"
<     >>> mute_string("r'abc'")
<     "r'xxx'"
<     """
<     start = 1
<     end = len(text) - 1
<     # String modifiers (e.g. u or r)
<     if text.endswith('"'):
<         start += text.index('"')
<     elif text.endswith("'"):
<         start += text.index("'")
<     # Triple quotes
<     if text.endswith('"""') or text.endswith("'''"):
<         start += 2
<         end -= 2
<     return text[:start] + 'x' * (end - start) + text[end:]
< 
< 
< def message(text):
<     """Print a message."""
<     # print >> sys.stderr, options.prog + ': ' + text
<     # print >> sys.stderr, text
<     print(text)
< 
< 
< ##############################################################################
< # Framework to run all checks
< ##############################################################################
< 
< 
< def find_checks(argument_name):
<     """
<     Find all globally visible functions where the first argument name
<     starts with argument_name.
<     """
<     checks = []
<     for name, function in globals().items():
<         if not inspect.isfunction(function):
<             continue
<         args = inspect.getargspec(function)[0]
<         if args and args[0].startswith(argument_name):
<             codes = ERRORCODE_REGEX.findall(inspect.getdoc(function) or '')
<             for code in codes or ['']:
<                 if not code or not ignore_code(code):
<                     checks.append((name, function, args))
<                     break
<     checks.sort()
<     return checks
< 
< 
< class Checker(object):
<     """
<     Load a Python source file, tokenize it, check coding style.
<     """
< 
<     def __init__(self, filename, lines=None):
<         self.filename = filename
<         if filename is None:
<             self.filename = 'stdin'
<             self.lines = lines or []
<         elif lines is None:
<             self.lines = readlines(filename)
<         else:
<             self.lines = lines
<         options.counters['physical lines'] += len(self.lines)
< 
<     def readline(self):
<         """
<         Get the next line from the input buffer.
<         """
<         self.line_number += 1
<         if self.line_number > len(self.lines):
<             return ''
<         return self.lines[self.line_number - 1]
< 
<     def readline_check_physical(self):
<         """
<         Check and return the next physical line. This method can be
<         used to feed tokenize.generate_tokens.
<         """
<         line = self.readline()
<         if line:
<             self.check_physical(line)
<         return line
< 
<     def run_check(self, check, argument_names):
<         """
<         Run a check plugin.
<         """
<         arguments = []
<         for name in argument_names:
<             arguments.append(getattr(self, name))
<         return check(*arguments)
< 
<     def check_physical(self, line):
<         """
<         Run all physical checks on a raw input line.
<         """
<         self.physical_line = line
<         if self.indent_char is None and len(line) and line[0] in ' \t':
<             self.indent_char = line[0]
<         for name, check, argument_names in options.physical_checks:
<             result = self.run_check(check, argument_names)
<             if result is not None:
<                 offset, text = result
<                 self.report_error(self.line_number, offset, text, check)
< 
<     def build_tokens_line(self):
<         """
<         Build a logical line from tokens.
<         """
<         self.mapping = []
<         logical = []
<         length = 0
<         previous = None
<         for token in self.tokens:
<             token_type, text = token[0:2]
<             if token_type in SKIP_TOKENS:
<                 continue
<             if token_type == tokenize.STRING:
<                 text = mute_string(text)
<             if previous:
<                 end_line, end = previous[3]
<                 start_line, start = token[2]
<                 if end_line != start_line:  # different row
<                     prev_text = self.lines[end_line - 1][end - 1]
<                     if prev_text == ',' or (prev_text not in '{[('
<                                             and text not in '}])'):
<                         logical.append(' ')
<                         length += 1
<                 elif end != start:  # different column
<                     fill = self.lines[end_line - 1][end:start]
<                     logical.append(fill)
<                     length += len(fill)
<             self.mapping.append((length, token))
<             logical.append(text)
<             length += len(text)
<             previous = token
<         self.logical_line = ''.join(logical)
<         assert self.logical_line.lstrip() == self.logical_line
<         assert self.logical_line.rstrip() == self.logical_line
< 
<     def check_logical(self):
<         """
<         Build a line from tokens and run all logical checks on it.
<         """
<         options.counters['logical lines'] += 1
<         self.build_tokens_line()
<         first_line = self.lines[self.mapping[0][1][2][0] - 1]
<         indent = first_line[:self.mapping[0][1][2][1]]
<         self.previous_indent_level = self.indent_level
<         self.indent_level = expand_indent(indent)
<         if options.verbose >= 2:
<             print(self.logical_line[:80].rstrip())
<         for name, check, argument_names in options.logical_checks:
<             if options.verbose >= 4:
<                 print('   ' + name)
<             result = self.run_check(check, argument_names)
<             if result is not None:
<                 offset, text = result
<                 if isinstance(offset, tuple):
<                     original_number, original_offset = offset
<                 else:
<                     for token_offset, token in self.mapping:
<                         if offset >= token_offset:
<                             original_number = token[2][0]
<                             original_offset = (token[2][1]
<                                                + offset - token_offset)
<                 self.report_error(original_number, original_offset,
<                                   text, check)
<         self.previous_logical = self.logical_line
< 
<     def check_all(self, expected=None, line_offset=0):
<         """
<         Run all checks on the input file.
<         """
<         self.expected = expected or ()
<         self.line_offset = line_offset
<         self.line_number = 0
<         self.file_errors = 0
<         self.indent_char = None
<         self.indent_level = 0
<         self.previous_logical = ''
<         self.blank_lines = 0
<         self.blank_lines_before_comment = 0
<         self.tokens = []
<         parens = 0
<         for token in tokenize.generate_tokens(self.readline_check_physical):
<             if options.verbose >= 3:
<                 if token[2][0] == token[3][0]:
<                     pos = '[%s:%s]' % (token[2][1] or '', token[3][1])
<                 else:
<                     pos = 'l.%s' % token[3][0]
<                 print('l.%s\t%s\t%s\t%r' %
<                     (token[2][0], pos, tokenize.tok_name[token[0]], token[1]))
<             self.tokens.append(token)
<             token_type, text = token[0:2]
<             if token_type == tokenize.OP and text in '([{':
<                 parens += 1
<             if token_type == tokenize.OP and text in '}])':
<                 parens -= 1
<             if token_type == tokenize.NEWLINE and not parens:
<                 self.check_logical()
<                 self.blank_lines = 0
<                 self.blank_lines_before_comment = 0
<                 self.tokens = []
<             if token_type == tokenize.NL and not parens:
<                 if len(self.tokens) <= 1:
<                     # The physical line contains only this token.
<                     self.blank_lines += 1
<                 self.tokens = []
<             if token_type == tokenize.COMMENT:
<                 source_line = token[4]
<                 token_start = token[2][1]
<                 if source_line[:token_start].strip() == '':
<                     self.blank_lines_before_comment = max(self.blank_lines,
<                         self.blank_lines_before_comment)
<                     self.blank_lines = 0
<                 if text.endswith('\n') and not parens:
<                     # The comment also ends a physical line.  This works around
<                     # Python < 2.6 behaviour, which does not generate NL after
<                     # a comment which is on a line by itself.
<                     self.tokens = []
<         return self.file_errors
< 
<     def report_error(self, line_number, offset, text, check):
<         """
<         Report an error, according to options.
<         """
<         code = text[:4]
<         if ignore_code(code):
<             return
<         if options.quiet == 1 and not self.file_errors:
<             message(self.filename)
<         if code in options.counters:
<             options.counters[code] += 1
<         else:
<             options.counters[code] = 1
<             options.messages[code] = text[5:]
<         if options.quiet or code in self.expected:
<             # Don't care about expected errors or warnings
<             return
<         self.file_errors += 1
<         if options.counters[code] == 1 or options.repeat:
<             message("%s:%s:%d: %s" %
<                     (self.filename, self.line_offset + line_number,
<                      offset + 1, text))
<             if options.show_source:
<                 line = self.lines[line_number - 1]
<                 message(line.rstrip())
<                 message(' ' * offset + '^')
<             if options.show_pep8:
<                 message(check.__doc__.lstrip('\n').rstrip())
< 
< 
< def input_file(filename):
<     """
<     Run all checks on a Python source file.
<     """
<     if options.verbose:
<         message('checking ' + filename)
<     errors = Checker(filename).check_all()
< 
< 
< def input_dir(dirname, runner=None):
<     """
<     Check all Python source files in this directory and all subdirectories.
<     """
<     dirname = dirname.rstrip('/')
<     if excluded(dirname):
<         return
<     if runner is None:
<         runner = input_file
<     for root, dirs, files in os.walk(dirname):
<         if options.verbose:
<             message('directory ' + root)
<         options.counters['directories'] += 1
<         dirs.sort()
<         for subdir in dirs:
<             if excluded(subdir):
<                 dirs.remove(subdir)
<         files.sort()
<         for filename in files:
<             if filename_match(filename) and not excluded(filename):
<                 options.counters['files'] += 1
<                 runner(os.path.join(root, filename))
< 
< 
< def excluded(filename):
<     """
<     Check if options.exclude contains a pattern that matches filename.
<     """
<     basename = os.path.basename(filename)
<     for pattern in options.exclude:
<         if fnmatch(basename, pattern):
<             # print basename, 'excluded because it matches', pattern
<             return True
< 
< 
< def filename_match(filename):
<     """
<     Check if options.filename contains a pattern that matches filename.
<     If options.filename is unspecified, this always returns True.
<     """
<     if not options.filename:
<         return True
<     for pattern in options.filename:
<         if fnmatch(filename, pattern):
<             return True
< 
< 
< def ignore_code(code):
<     """
<     Check if options.ignore contains a prefix of the error code.
<     If options.select contains a prefix of the error code, do not ignore it.
<     """
<     for select in options.select:
<         if code.startswith(select):
<             return False
<     for ignore in options.ignore:
<         if code.startswith(ignore):
<             return True
< 
< 
< def reset_counters():
<     for key in list(options.counters.keys()):
<         if key not in BENCHMARK_KEYS:
<             del options.counters[key]
<     options.messages = {}
< 
< 
< def get_error_statistics():
<     """Get error statistics."""
<     return get_statistics("E")
< 
< 
< def get_warning_statistics():
<     """Get warning statistics."""
<     return get_statistics("W")
< 
< 
< def get_statistics(prefix=''):
<     """
<     Get statistics for message codes that start with the prefix.
< 
<     prefix='' matches all errors and warnings
<     prefix='E' matches all errors
<     prefix='W' matches all warnings
<     prefix='E4' matches all errors that have to do with imports
<     """
<     stats = []
<     keys = list(options.messages.keys())
<     keys.sort()
<     for key in keys:
<         if key.startswith(prefix):
<             stats.append('%-7s %s %s' %
<                          (options.counters[key], key, options.messages[key]))
<     return stats
< 
< 
< def get_count(prefix=''):
<     """Return the total count of errors and warnings."""
<     keys = list(options.messages.keys())
<     count = 0
<     for key in keys:
<         if key.startswith(prefix):
<             count += options.counters[key]
<     return count
< 
< 
< def print_statistics(prefix=''):
<     """Print overall statistics (number of errors and warnings)."""
<     for line in get_statistics(prefix):
<         print(line)
< 
< 
< def print_benchmark(elapsed):
<     """
<     Print benchmark numbers.
<     """
<     print('%-7.2f %s' % (elapsed, 'seconds elapsed'))
<     for key in BENCHMARK_KEYS:
<         print('%-7d %s per second (%d total)' % (
<             options.counters[key] / elapsed, key,
<             options.counters[key]))
< 
< 
< def run_tests(filename):
<     """
<     Run all the tests from a file.
< 
<     A test file can provide many tests.  Each test starts with a declaration.
<     This declaration is a single line starting with '#:'.
<     It declares codes of expected failures, separated by spaces or 'Okay'
<     if no failure is expected.
<     If the file does not contain such declaration, it should pass all tests.
<     If the declaration is empty, following lines are not checked, until next
<     declaration.
< 
<     Examples:
< 
<      * Only E224 and W701 are expected:         #: E224 W701
<      * Following example is conform:            #: Okay
<      * Don't check these lines:                 #:
<     """
<     lines = readlines(filename) + ['#:\n']
<     line_offset = 0
<     codes = ['Okay']
<     testcase = []
<     for index, line in enumerate(lines):
<         if not line.startswith('#:'):
<             if codes:
<                 # Collect the lines of the test case
<                 testcase.append(line)
<             continue
<         if codes and index > 0:
<             label = '%s:%s:1' % (filename, line_offset + 1)
<             codes = [c for c in codes if c != 'Okay']
<             # Run the checker
<             errors = Checker(filename, testcase).check_all(codes, line_offset)
<             # Check if the expected errors were found
<             for code in codes:
<                 if not options.counters.get(code):
<                     errors += 1
<                     message('%s: error %s not found' % (label, code))
<             if options.verbose and not errors:
<                 message('%s: passed (%s)' % (label, ' '.join(codes)))
<             # Keep showing errors for multiple tests
<             reset_counters()
<         # output the real line numbers
<         line_offset = index
<         # configure the expected errors
<         codes = line.split()[1:]
<         # empty the test case buffer
<         del testcase[:]
< 
< 
< def selftest():
<     """
<     Test all check functions with test cases in docstrings.
<     """
<     count_passed = 0
<     count_failed = 0
<     checks = options.physical_checks + options.logical_checks
<     for name, check, argument_names in checks:
<         for line in check.__doc__.splitlines():
<             line = line.lstrip()
<             match = SELFTEST_REGEX.match(line)
<             if match is None:
<                 continue
<             code, source = match.groups()
<             checker = Checker(None)
<             for part in source.split(r'\n'):
<                 part = part.replace(r'\t', '\t')
<                 part = part.replace(r'\s', ' ')
<                 checker.lines.append(part + '\n')
<             options.quiet = 2
<             checker.check_all()
<             error = None
<             if code == 'Okay':
<                 if len(options.counters) > len(BENCHMARK_KEYS):
<                     codes = [key for key in options.counters.keys()
<                              if key not in BENCHMARK_KEYS]
<                     error = "incorrectly found %s" % ', '.join(codes)
<             elif not options.counters.get(code):
<                 error = "failed to find %s" % code
<             # Reset the counters
<             reset_counters()
<             if not error:
<                 count_passed += 1
<             else:
<                 count_failed += 1
<                 if len(checker.lines) == 1:
<                     print("pep8.py: %s: %s" %
<                           (error, checker.lines[0].rstrip()))
<                 else:
<                     print("pep8.py: %s:" % error)
<                     for line in checker.lines:
<                         print(line.rstrip())
<     if options.verbose:
<         print("%d passed and %d failed." % (count_passed, count_failed))
<         if count_failed:
<             print("Test failed.")
<         else:
<             print("Test passed.")
< 
< 
< def process_options(arglist=None):
<     """
<     Process options passed either via arglist or via command line args.
<     """
<     global options, args
<     parser = OptionParser(version=__version__,
<                           usage="%prog [options] input ...")
<     parser.add_option('-v', '--verbose', default=0, action='count',
<                       help="print status messages, or debug with -vv")
<     parser.add_option('-q', '--quiet', default=0, action='count',
<                       help="report only file names, or nothing with -qq")
<     parser.add_option('-r', '--repeat', action='store_true',
<                       help="show all occurrences of the same error")
<     parser.add_option('--exclude', metavar='patterns', default=DEFAULT_EXCLUDE,
<                       help="exclude files or directories which match these "
<                         "comma separated patterns (default: %s)" %
<                         DEFAULT_EXCLUDE)
<     parser.add_option('--filename', metavar='patterns', default='*.py',
<                       help="when parsing directories, only check filenames "
<                         "matching these comma separated patterns (default: "
<                         "*.py)")
<     parser.add_option('--select', metavar='errors', default='',
<                       help="select errors and warnings (e.g. E,W6)")
<     parser.add_option('--ignore', metavar='errors', default='',
<                       help="skip errors and warnings (e.g. E4,W)")
<     parser.add_option('--show-source', action='store_true',
<                       help="show source code for each error")
<     parser.add_option('--show-pep8', action='store_true',
<                       help="show text of PEP 8 for each error")
<     parser.add_option('--statistics', action='store_true',
<                       help="count errors and warnings")
<     parser.add_option('--count', action='store_true',
<                       help="print total number of errors and warnings "
<                         "to standard error and set exit code to 1 if "
<                         "total is not null")
<     parser.add_option('--benchmark', action='store_true',
<                       help="measure processing speed")
<     parser.add_option('--testsuite', metavar='dir',
<                       help="run regression tests from dir")
<     parser.add_option('--doctest', action='store_true',
<                       help="run doctest on myself")
<     options, args = parser.parse_args(arglist)
<     if options.testsuite:
<         args.append(options.testsuite)
<     if not args and not options.doctest:
<         parser.error('input not specified')
<     options.prog = os.path.basename(sys.argv[0])
<     options.exclude = options.exclude.split(',')
<     for index in range(len(options.exclude)):
<         options.exclude[index] = options.exclude[index].rstrip('/')
<     if options.filename:
<         options.filename = options.filename.split(',')
<     if options.select:
<         options.select = options.select.split(',')
<     else:
<         options.select = []
<     if options.ignore:
<         options.ignore = options.ignore.split(',')
<     elif options.select:
<         # Ignore all checks which are not explicitly selected
<         options.ignore = ['']
<     elif options.testsuite or options.doctest:
<         # For doctest and testsuite, all checks are required
<         options.ignore = []
<     else:
<         # The default choice: ignore controversial checks
<         options.ignore = DEFAULT_IGNORE.split(',')
<     options.physical_checks = find_checks('physical_line')
<     options.logical_checks = find_checks('logical_line')
<     options.counters = dict.fromkeys(BENCHMARK_KEYS, 0)
<     options.messages = {}
<     return options, args
< 
< 
< def _main():
<     """
<     Parse options and run checks on Python source.
<     """
<     options, args = process_options()
<     if options.doctest:
<         import doctest
<         doctest.testmod(verbose=options.verbose)
<         selftest()
<     if options.testsuite:
<         runner = run_tests
<     else:
<         runner = input_file
<     start_time = time.time()
<     for path in args:
<         if os.path.isdir(path):
<             input_dir(path, runner=runner)
<         elif not excluded(path):
<             options.counters['files'] += 1
<             runner(path)
<     elapsed = time.time() - start_time
<     if options.statistics:
<         print_statistics()
<     if options.benchmark:
<         print_benchmark(elapsed)
<     count = get_count()
<     if count:
<         if options.count:
<             sys.stderr.write(str(count) + '\n')
<         sys.exit(1)
< 
< 
< if __name__ == '__main__':
<     _main()
diff -r -N code-worker/tasks/pep8/README.rst code-worker/code-worker/tasks/pep8/README.rst
1,127d0
< pep8 - Python style guide checker
< =================================
< 
< pep8 is a tool to check your Python code against some of the style
< conventions in `PEP 8`_.
< 
< .. _PEP 8: http://www.python.org/dev/peps/pep-0008/
< 
< 
< Mailing List
< ------------
< http://groups.google.com/group/pep8
< 
< 
< Features
< --------
< 
< * Plugin architecture: Adding new checks is easy.
< 
< * Parseable output: Jump to error location in your editor.
< 
< * Small: Just one Python file, requires only stdlib. You can use just
<   the pep8.py file for this purpose.
< 
< * Comes with a comprehensive test suite.
< 
< Installation
< ------------
< 
< You can install, upgrade, uninstall pep8.py with these commands::
< 
<   $ sudo pip install pep8
<   $ sudo pip install --upgrade pep8
<   $ sudo pip uninstall pep8
< 
< Or if you don't have `pip`::
< 
<   $ sudo easy_install pep8
< 
< There's also a package for Debian/Ubuntu, but it's not always the
< latest version::
< 
<   $ sudo apt-get install pep8
< 
< Example usage and output
< ------------------------
< 
< ::
< 
<   $ pep8 optparse.py
<   optparse.py:69:11: E401 multiple imports on one line
<   optparse.py:77:1: E302 expected 2 blank lines, found 1
<   optparse.py:88:5: E301 expected 1 blank line, found 0
<   optparse.py:222:34: W602 deprecated form of raising exception
<   optparse.py:347:31: E211 whitespace before '('
<   optparse.py:357:17: E201 whitespace after '{'
<   optparse.py:472:29: E221 multiple spaces before operator
<   optparse.py:544:21: W601 .has_key() is deprecated, use 'in'
< 
< You can also make pep8.py show the source code for each error, and
< even the relevant text from PEP 8::
< 
<   $ pep8 --show-source --show-pep8 testsuite/E111.py
<   testsuite/E111.py:2:3: E111 indentation is not a multiple of four
<     print x
<     ^
<       Use 4 spaces per indentation level.
< 
<       For really old code that you don't want to mess up, you can
<       continue to use 8-space tabs.
< 
< Or you can display how often each error was found::
< 
<   $ pep8 --statistics -qq --filename=*.py Python-2.5/Lib
<   232     E201 whitespace after '['
<   599     E202 whitespace before ')'
<   631     E203 whitespace before ','
<   842     E211 whitespace before '('
<   2531    E221 multiple spaces before operator
<   4473    E301 expected 1 blank line, found 0
<   4006    E302 expected 2 blank lines, found 1
<   165     E303 too many blank lines (4)
<   325     E401 multiple imports on one line
<   3615    E501 line too long (82 characters)
<   612     W601 .has_key() is deprecated, use 'in'
<   1188    W602 deprecated form of raising exception
< 
< Quick help is available on the command line::
< 
<   $ pep8 -h
<   Usage: pep8.py [options] input ...
< 
<   Options:
<     --version            show program's version number and exit
<     -h, --help           show this help message and exit
<     -v, --verbose        print status messages, or debug with -vv
<     -q, --quiet          report only file names, or nothing with -qq
<     -r, --repeat         show all occurrences of the same error
<     --exclude=patterns   exclude files or directories which match these comma
<                          separated patterns (default: .svn,CVS,.bzr,.hg,.git)
<     --filename=patterns  when parsing directories, only check filenames matching
<                          these comma separated patterns (default: *.py)
<     --select=errors      select errors and warnings (e.g. E,W6)
<     --ignore=errors      skip errors and warnings (e.g. E4,W)
<     --show-source        show source code for each error
<     --show-pep8          show text of PEP 8 for each error
<     --statistics         count errors and warnings
<     --count              print total number of errors and warnings to standard
<                          error and set exit code to 1 if total is not null
<     --benchmark          measure processing speed
<     --testsuite=dir      run regression tests from dir
<     --doctest            run doctest on myself
< 
< Feedback
< --------
< 
< Your feedback is more than welcome. Write email to
< johann@rocholl.net or post bugs and feature requests on github:
< 
< http://github.com/jcrocholl/pep8/issues
< 
< Source download
< ---------------
< 
< The source code is currently available on github. Fork away!
< 
< http://github.com/jcrocholl/pep8/
diff -r -N code-worker/tasks/pep8/setup.py code-worker/code-worker/tasks/pep8/setup.py
1,31d0
< from setuptools import setup, find_packages
< 
< version = '0.6.0'
< long_description = '\n\n'.join([open('README.rst').read(),
<                                 open('CHANGES.txt').read(),
<                                 open('TODO.txt').read()])
< 
< setup(name='pep8',
<       version=version,
<       description="Python style guide checker",
<       long_description=long_description,
<       classifiers=[],
<       keywords='pep8',
<       author='Johann C. Rocholl',
<       author_email='johann@rocholl.net',
<       url='http://github.com/jcrocholl/pep8',
<       license='Expat license',
<       py_modules=['pep8'],
<       namespace_packages=[],
<       include_package_data=True,
<       zip_safe=False,
<       install_requires=[
<           'setuptools',
<           # -*- Extra requirements: -*-
<       ],
<       entry_points={
<           'console_scripts': [
<               'pep8 = pep8:_main',
<               ],
<           },
<       )
diff -r -N code-worker/tasks/pep8/testsuite/E10.py code-worker/code-worker/tasks/pep8/testsuite/E10.py
1,5d0
< #: E101 W191
< for a in 'abc':
<     for b in 'xyz':
<         print a  # indented with 8 spaces
< 	print b  # indented with 1 tab
diff -r -N code-worker/tasks/pep8/testsuite/E11.py code-worker/code-worker/tasks/pep8/testsuite/E11.py
1,12d0
< #: E111
< if x > 2:
<   print x
< #: E111
< if True:
<      print
< #: E112
< if False:
< print
< #: E113
< print
<     print
diff -r -N code-worker/tasks/pep8/testsuite/E20.py code-worker/code-worker/tasks/pep8/testsuite/E20.py
1,55d0
< #: E201
< spam( ham[1], {eggs: 2})
< #: E201
< spam(ham[ 1], {eggs: 2})
< #: E201
< spam(ham[1], { eggs: 2})
< #: Okay
< spam(ham[1], {eggs: 2})
< #:
< 
< 
< #: E202
< spam(ham[1], {eggs: 2} )
< #: E202
< spam(ham[1], {eggs: 2 })
< #: E202
< spam(ham[1 ], {eggs: 2})
< #: Okay
< spam(ham[1], {eggs: 2})
< 
< result = func(
<     arg1='some value',
<     arg2='another value',
< )
< 
< result = func(
<     arg1='some value',
<     arg2='another value'
< )
< 
< result = [
<     item for item in items
<     if item > 5
< ]
< #:
< 
< 
< #: E203
< if x == 4 :
<     print x, y
<     x, y = y, x
< #: E203 E702
< if x == 4:
<     print x, y ; x, y = y, x
< #: E203
< if x == 4:
<     print x, y
<     x, y = y , x
< #: Okay
< if x == 4:
<     print x, y
<     x, y = y, x
< a[b1, :] == a[b1, ...]
< b = a[:, b1]
< #:
diff -r -N code-worker/tasks/pep8/testsuite/E21.py code-worker/code-worker/tasks/pep8/testsuite/E21.py
1,17d0
< #: E211
< spam (1)
< #: E211
< dict ['key'] = list [index]
< #: E211
< dict['key'] ['subkey'] = list[index]
< #: E225
< def squares(n):
<     return (i**2 for i in range(n))
< #: Okay
< spam(1)
< dict['key'] = list[index]
< 
< 
< # This is not prohibited by PEP8, but avoid it.
< class Foo (Bar, Baz):
<     pass
diff -r -N code-worker/tasks/pep8/testsuite/E22.py code-worker/code-worker/tasks/pep8/testsuite/E22.py
1,87d0
< #: E221
< a = 12 + 3
< b = 4  + 5
< #: E221
< x             = 1
< y             = 2
< long_variable = 3
< #: E221
< x[0]          = 1
< x[1]          = 2
< long_variable = 3
< #: E221
< x = f(x)          + 1
< y = long_variable + 2
< z = x[0]          + 3
< #: Okay
< x = 1
< y = 2
< long_variable = 3
< #:
< 
< 
< #: E222
< a = a +  1
< b = b + 10
< #: E222
< x =            -1
< y =            -2
< long_variable = 3
< #: E222
< x[0] =          1
< x[1] =          2
< long_variable = 3
< #:
< 
< 
< #: E223
< foobart = 4
< a	= 3  # aligned with tab
< #:
< 
< 
< #: E224
< a +=	1
< b += 1000
< #:
< 
< 
< #: E225
< i=i+1
< #: E225
< submitted +=1
< #: E225
< x = x*2 - 1
< #: E225
< hypot2 = x*x + y*y
< #: E225
< c = (a+b) * (a-b)
< #: E225
< c =-1
< #: E225
< c = alpha -4
< #: E225
< z = (x + 1) **y
< #: E225
< norman = True+False
< #: E225
< _1MB = 2 ** 20
< _1kB = _1MB >>10
< #:
< #: Okay
< i = i + 1
< submitted += 1
< x = x * 2 - 1
< hypot2 = x * x + y * y
< c = (a + b) * (a - b)
< foo(bar, key='word', *args, **kwargs)
< baz(**kwargs)
< negative = -1
< spam(-1)
< -negative
< lambda *args, **kw: (args, kw)
< lambda a, b=h[:], c=0: (a, b, c)
< if not -5 < x < +5:
<     print >>sys.stderr, "x is out of range."
< print >> sys.stdout, "x is an integer."
< #:
diff -r -N code-worker/tasks/pep8/testsuite/E23.py code-worker/code-worker/tasks/pep8/testsuite/E23.py
1,12d0
< #: E231
< a = (1,2)
< #: E231
< a[b1,:]
< #: Okay
< a = (4,)
< b = (5, )
< 
< result = {
<    'key1': 'value',
<    'key2': 'value',
< }
diff -r -N code-worker/tasks/pep8/testsuite/E24.py code-worker/code-worker/tasks/pep8/testsuite/E24.py
1,6d0
< #: E241
< a = (1,  2)
< b = (1, 20)
< #: E242
< a = (1,	2)  # tab before 2
< b = (1, 20)  # space before 20
diff -r -N code-worker/tasks/pep8/testsuite/E25.py code-worker/code-worker/tasks/pep8/testsuite/E25.py
1,15d0
< #: E251
< def foo(bar = False):
<     '''Test function with an error in declaration'''
<     pass
< #: E251
< foo(bar= True)
< #: E251
< foo(bar =True)
< #: E251
< foo(bar = True)
< #: Okay
< foo(bar=(1 == 1))
< foo(bar=(1 != 1))
< foo(bar=(1 >= 1))
< foo(bar=(1 <= 1))
diff -r -N code-worker/tasks/pep8/testsuite/E26.py code-worker/code-worker/tasks/pep8/testsuite/E26.py
1,6d0
< #: E261
< pass # an inline comment
< #: E262
< x = x + 1  #Increment x
< #: E262
< x = x + 1  #  Increment x
diff -r -N code-worker/tasks/pep8/testsuite/E30not.py code-worker/code-worker/tasks/pep8/testsuite/E30not.py
1,118d0
< class X:
< 
<     def a():
<         pass
< 
<     # comment
<     def b():
<         pass
< 
<     # This is a
<     # ... multi-line comment
< 
<     def c():
<         pass
< 
< 
< # This is a
< # ... multi-line comment
< 
< @some_decorator
< class Y:
< 
<     def a():
<         pass
< 
<     # comment
< 
<     def b():
<         pass
< 
<     @property
<     def c():
<         pass
< 
< 
< try:
<     from nonexistent import Bar
< except ImportError:
<     class Bar(object):
<         """This is a Bar replacement"""
< 
< 
< def with_feature(f):
<     """Some decorator"""
<     wrapper = f
<     if has_this_feature(f):
<         def wrapper(*args):
<             call_feature(args[0])
<             return f(*args)
<     return wrapper
< 
< 
< try:
<     next
< except NameError:
<     def next(iterator, default):
<         for item in iterator:
<             return item
<         return default
< 
< 
< def a():
<     pass
< 
< 
< class Foo():
<     """Class Foo"""
< 
<     def b():
< 
<         pass
< 
< 
< # comment
< def c():
<     pass
< 
< 
< # comment
< 
< 
< def d():
<     pass
< 
< # This is a
< # ... multi-line comment
< 
< # And this one is
< # ... a second paragraph
< # ... which spans on 3 lines
< 
< 
< # Function `e` is below
< # NOTE: Hey this is a testcase
< 
< def e():
<     pass
< 
< 
< def a():
<     print
< 
<     # comment
< 
<     print
< 
<     print
< 
< # Comment 1
< 
< # Comment 2
< 
< 
< # Comment 3
< 
< def b():
< 
<     pass
diff -r -N code-worker/tasks/pep8/testsuite/E30.py code-worker/code-worker/tasks/pep8/testsuite/E30.py
1,66d0
< #: E301
< class X:
< 
<     def a():
<         pass
<     def b():
<         pass
< #: E301
< class X:
< 
<     def a():
<         pass
<     # comment
<     def b():
<         pass
< #:
< 
< 
< #: E302
< def a():
<     pass
< 
< def b():
<     pass
< #: E302
< def a():
<     pass
< 
< # comment
< 
< def b():
<     pass
< #:
< 
< 
< #: E303
< print
< 
< 
< 
< print
< #: E303
< print
< 
< 
< 
< # comment
< 
< print
< #: E303
< def a():
<     print
< 
< 
<     # comment
< 
<     print
< #:
< 
< 
< #: E304
< @decorator
< 
< def function():
<     pass
< #:
diff -r -N code-worker/tasks/pep8/testsuite/E40.py code-worker/code-worker/tasks/pep8/testsuite/E40.py
1,13d0
< #: E401
< import os, sys
< #: Okay
< import os
< import sys
< 
< from subprocess import Popen, PIPE
< 
< from myclass import MyClass
< from foo.bar.yourclass import YourClass
< 
< import myclass
< import foo.bar.yourclass
diff -r -N code-worker/tasks/pep8/testsuite/E50.py code-worker/code-worker/tasks/pep8/testsuite/E50.py
1,2d0
< #: E501
< a = '12345678901234567890123456789012345678901234567890123456789012345678901234567890'
diff -r -N code-worker/tasks/pep8/testsuite/E70.py code-worker/code-worker/tasks/pep8/testsuite/E70.py
1,4d0
< #: E701
< if a: a = False
< #: E702
< a = False; b = True
diff -r -N code-worker/tasks/pep8/testsuite/latin-1.py code-worker/code-worker/tasks/pep8/testsuite/latin-1.py
1,6d0
< # -*- coding: latin-1 -*-
< # Test non-UTF8 encoding
< latin1 = (''
<           '')
< 
< c = ("w")
diff -r -N code-worker/tasks/pep8/testsuite/utf-8.py code-worker/code-worker/tasks/pep8/testsuite/utf-8.py
1,26d0
< # -*- coding: utf-8 -*-
< 
< 
< class Rectangle(Blob):
< 
<         def __init__(self, width, height,
<                      color='black', emphasis=None, highlight=0):
<             if width == 0 and height == 0 and \
<                color == 'red' and emphasis == 'strong' or \
<                highlight > 100:
<                 raise ValueError("sorry, you lose")
<             if width == 0 and height == 0 and (color == 'red' or
<                                                emphasis is None):
<                 raise ValueError("I don't think so -- values are %s, %s" %
<                                  (width, height))
<             Blob.__init__(self, width, height,
<                           color, emphasis, highlight)
< 
< 
< # Some random text with multi-byte characters (utf-8 encoded)
< #
< #    ,     .    
< # ,    .     , 
< #    .     .  
< #  ,     .   
< # .
diff -r -N code-worker/tasks/pep8/testsuite/W19.py code-worker/code-worker/tasks/pep8/testsuite/W19.py
1,3d0
< #: W191
< if False:
< 	print  # indented with 1 tab
diff -r -N code-worker/tasks/pep8/testsuite/W29.py code-worker/code-worker/tasks/pep8/testsuite/W29.py
1,8d0
< #: W291
< print 
< #: W293
< class Foo(object):
<     
<     bang = 12
< #: W292
< # This line doesn't have a linefeed
\ No newline at end of file
diff -r -N code-worker/tasks/pep8/testsuite/W39.py code-worker/code-worker/tasks/pep8/testsuite/W39.py
1,3d0
< #: W391
< # The next line is blank
< 
diff -r -N code-worker/tasks/pep8/testsuite/W60.py code-worker/code-worker/tasks/pep8/testsuite/W60.py
1,10d0
< #: W601
< if a.has_key("b"):
<     print a
< #: W602
< raise DummyError, "Message"
< #: W603
< if x <> 0:
<     x = 0
< #: W604
< val = `1 + 2`
diff -r -N code-worker/tasks/pep8/TODO.txt code-worker/code-worker/tasks/pep8/TODO.txt
1,8d0
< TODO
< ====
< 
< - Should command line option --repeat be enabled by default?
< 
< - Does command line option --ignore properly prevent status code 1?
< 
< - Release version 1.0 after a brief stabilization period.
diff -r -N code-worker/test.py code-worker/code-worker/test.py
1,14d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< 
< import urllib2, json
< f = urllib2.urlopen('http://dl.dropbox.com/u/4972572/get_next_job')
< #f = urllib2.urlopen('http://www.reddit.com/.json')
< 
< jsonStr = json.load(f)
< 
< print jsonStr
< print jsonStr['repo']
< print jsonStr['command']
< print jsonStr['job_type']
< f.close()
diff -r -N code-worker/timerTest.py code-worker/code-worker/timerTest.py
1,13d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< 
< import time
< 
< def print_time(): print "time.time: ", time.time()
< 
< def test():
< 	for i in range(1,4):
< 		print_time()
< 		time.sleep(i*2)
< 
< test()
diff -r -N code-worker/worker.py code-worker/code-worker/worker.py
0a1,119
> #!/usr/bin/env python
> # -*- coding: utf-8 -*-
> # Author: Karthik Muthuswamy
> # Reads jobs and models from the given URL
> # Clones a repo retrieved from data retrieved from the URL
> # Executes a file and logs the result from the downloaded repo
> 
> import urllib2, json, os
> from commands import getoutput as cmd
> 
> baseURL = 'http://code-comparison.appspot.com/rest/'
> 
> # The main worker thread that fetches a job
> def mainWorker():
> 	URL = baseURL + 'metadata'
> 	f = urllib2.urlopen(URL)
> 
> 	jsonStr = json.load(f)
> 	for i in range(0, len(jsonStr['type'])):
> 		fetchJobFromURL(jsonStr['type'][i])
> 	f.close()
> 
> # Fetches a job from a given URL
> # Params: job - the type of the job as string, to be retrieved
> def fetchJobFromURL(job):
> 	print 'Processing job: ' + job
> 	# Concatenate with the base URL
> 	URL = baseURL + job + '?feq_jobType=TEST&fne_status=PROCESSED'
> 	# For testing: remove itr otherwise
> 	# Will be replaced with while True or any other break condition
> 	itr = 10
> 	for i in range(0,10):
> 		f = urllib2.urlopen(URL)
> 		req = f.read()
> 
> 		jobStr = json.loads(req)
> 		numJobs = len(jobStr)
> 		print 'There are ' + str(numJobs) + ' TEST jobs pending'
> 		# There are no jobs pending, hence sleep and check again
> 		if numJobs == 0:
> 			# Checks to see if there are jobs available every 2^iteration
> 			# Once time reaches 64, it checks constantly every minute
> 			sleepTime = math.pow(i,2)
> 			if sleepTime < 64:
> 				time.sleep(sleepTime)
> 				continue
> 			else:
> 				time.sleep(60)
> 				continue
> 
> 		for i in range(0, numJobs):
> 			fetchURL = baseURL + job + '/' + jobStr[i]['key']
> 			fetchModelFromURL(fetchURL)
> 
> # Fetches a job from a given URL using the key
> # Params: URL - the URL as string, of the job to be retrieved
> def fetchModelFromURL(URL):
> 	data = json.dumps({'status':'PROCESSED'})
> 	print 'Processing model from : ' + URL
> 	u = urllib2.urlopen(URL)
> 	req = u.read()
> 
> 	modelStr = json.loads(req)
> 	# Obtain the repository and command strings
> 
> 	tarRepos = modelStr['target'].strip()
> 	masRepos = modelStr['master'].strip()
> 	fExecute = modelStr['command'].replace('python ','').strip()
> 
> 	# Obtain the folder from the git URL
> 	sp = tarRepos.partition('/')
> 	tarRepoFolder = sp[2].replace('.git','')
> 	sp = masRepos.partition('/')
> 	masRepoFolder = sp[2].replace('.git','')
> 
> 	gitCloneUpdateRepo(masRepos, masRepoFolder, fExecute)
> 	gitCloneUpdateRepo(tarRepos, tarRepoFolder, fExecute)
> 
> 
> def gitCloneUpdateRepo(repoFolder, folderName, fExecute):
> 	# If the directory exists, update the folder with
> 	# the latest code from git
> 	# Else clone the repository
> 	if os.path.exists(folderName):
> 		os.chdir(folderName)
> 		print('Updating git repository to latest version: %s' % (folderName))
> 		os.system('git pull')
> 	else:
> 		print('Cloning git repository: %s' % (folderName))
> 		os.system('git clone ' + repoFolder + ' ' + folderName)
> 		os.chdir(folderName);
> 		# Execute the command retrieved from the JSON string
> 	print('Executing \"' + fExecute + '\" with output...')
> 
> 	try:
> 		if os.path.isfile(fExecute):
> 			os.system('python ' + fExecute + ' > log.txt')
> 			if os.path.isfile('ccresult.json'):
> 				f = open('ccresult.json','r')
> 				fContents = f.read()
> 				if checkForJSONValidity(fContents):
> 					print 'JSON Validity Approved'
> 				else:
> 					print 'JSON Validity Not Approved'
> 	except OSError:
> 		pass
> 
> 	os.chdir('..')
> 
> # Tests the JSON validity 
> # Params: jsonContent - the data as string, which is tested for validity
> def checkForJSONValidity(jsonContent):
> 	try:
> 		json.loads(jsonContent)
> 		return True
> 	except ValueError:
> 		return False
> 
> mainWorker()
diff -r -N code-worker/worker-readiness-test.py code-worker/code-worker/worker-readiness-test.py
1,50d0
< #!/usr/bin/env python
< # -*- coding: utf-8 -*-
< 
< import urllib2, json
< 
< baseurl = 'http://code-comparison.appspot.com/rest/'                        
< 
< def get_unprocessed_test_jobs():
<   url = baseurl+'Job?feq_jobType=TEST&fne_status=PROCESSED'                   
<   data = None                                                                 
<   result = json.loads(urllib2.urlopen(urllib2.Request(url, data, {'Content-Type': 'application/json'})).read())
<   print 'There are currently', len(result), 'unprocessed TEST jobs.'
<   return result
< 
< #You can filter results on the REST interface using feq_ and fne_. 
< #This means that we can make sure that there are no jobs of jobType=TEST& status!=PROCESSED. If there are, we can mark all the TEST jobs as PROCESSED.  
< 
< result = get_unprocessed_test_jobs()
< 
< for k in result:
<   data = json.dumps({'status':'PROCESSED'})
<   url = baseurl + 'Job/'+k['key']
<   result = json.loads(urllib2.urlopen(urllib2.Request(url, data, {'Content-Type': 'application/json'})).read())
<   print 'Marking existing TEST job as PROCESSED'
<   
< #Now that we now that there are no TEST jobs that have not been marked as PROCESSED, we can create some new TEST jobs for the worker to process. 
< result = get_unprocessed_test_jobs()
< 
< test_jobs = [{'command':'python -V', 'jobType':'TEST'}, 
< 			 {'command':'java -version', 'jobType':'TEST'}, 
< 			 {'command':'git --version', 'jobType':'TEST'}, 
< 			 {'command':'python code-worker/tasks/pep8/pep8.py -h', 'jobType':'TEST'},
< 			 {'command':'python code-worker/tasks/clonedigger/clonedigger.py -h', 'jobType':'TEST'}, 
< 			 #{'command':'code-worker/tasks/pep8/pep8.py -h', 'jobType':'TEST'}, #let pep8.py be executible without typing python or path
< 			 #{'command':'code-worker/tasks/clonedigger/clonedigger.py -h', 'jobType':'TEST'}, 
< 			 {'command':'python code-worker/tasks/pep8/pep8.py target --count -qq', #target repo should be downloaded to target directory. master repo should be downloaded to master directory
< 			  'target':'git@github.com:SMU-SIS/code-worker.git',
< 			  'jobType':'TEST'},
< 			 ]
< 
< for job in test_jobs:
<   url = baseurl+'Job'
<   data = json.dumps(job)
<   print 'Creating job to run command', url, data                  
<   result = json.loads(urllib2.urlopen(urllib2.Request(url, data, {'Content-Type': 'application/json'})).read())
< 
< result = get_unprocessed_test_jobs()
< 
< # Now check back every 10 seconds to see if the TEST jobs have been processed by the worker. If they don't all get processed in a minute or two, the integration test would fail.   
< # The next time this script is run, all these TEST jobs well be marked as PROCESSED
